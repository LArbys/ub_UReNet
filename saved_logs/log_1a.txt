I0825 17:21:28.046972 27361 caffe.cpp:217] Using GPUs 0
I0825 17:21:28.059602 27361 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I0825 17:21:28.321748 27361 solver.cpp:48] Initializing solver from parameters: 
train_net: "ub_uresnet_train.prototxt"
test_net: "ub_uresnet_test.prototxt"
test_iter: 40
test_interval: 100
base_lr: 1e-05
display: 10
max_iter: 100000
lr_policy: "inv"
gamma: 0.0002
power: 0.75
momentum: 0
weight_decay: 0
snapshot: 1000
snapshot_prefix: "snapshot_rmsprop_uburn"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
iter_size: 10
rms_decay: 0.9
type: "RMSProp"
I0825 17:21:28.321887 27361 solver.cpp:81] Creating training net from train_net file: ub_uresnet_train.prototxt
I0825 17:21:28.324471 27361 net.cpp:58] Initializing net from parameters: 
name: "uB-U-ResNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ROOTData"
  top: "data"
  top: "label"
  root_data_param {
    batch_size: 1
    filler_config: "filler.cfg"
    filler_name: "train"
  }
}
layer {
  name: "resnet1a_bypass"
  type: "Convolution"
  bottom: "data"
  top: "resnet1a_bypass"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_btlnk"
  type: "Convolution"
  bottom: "data"
  top: "resnet1a_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet1a_btlnk"
  top: "resnet1a_btlnk"
}
layer {
  name: "resnet1a_conv"
  type: "Convolution"
  bottom: "resnet1a_btlnk"
  top: "resnet1a_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_conv_relu"
  type: "ReLU"
  bottom: "resnet1a_conv"
  top: "resnet1a_conv"
}
layer {
  name: "resnet1a_expnd"
  type: "Convolution"
  bottom: "resnet1a_conv"
  top: "resnet1a_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_eltwise"
  type: "Eltwise"
  bottom: "resnet1a_bypass"
  bottom: "resnet1a_expnd"
  top: "resnet1a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet1a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet1a_eltwise"
  top: "resnet1a_eltwise"
}
layer {
  name: "resnet1b_btlnk"
  type: "Convolution"
  bottom: "resnet1a_eltwise"
  top: "resnet1b_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet1b_btlnk"
  top: "resnet1b_btlnk"
}
layer {
  name: "resnet1b_conv"
  type: "Convolution"
  bottom: "resnet1b_btlnk"
  top: "resnet1b_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1b_conv_relu"
  type: "ReLU"
  bottom: "resnet1b_conv"
  top: "resnet1b_conv"
}
layer {
  name: "resnet1b_expnd"
  type: "Convolution"
  bottom: "resnet1b_conv"
  top: "resnet1b_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1b_eltwise"
  type: "Eltwise"
  bottom: "resnet1a_eltwise"
  bottom: "resnet1b_expnd"
  top: "resnet1b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet1b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet1b_eltwise"
  top: "resnet1b_eltwise"
}
layer {
  name: "maxpool1"
  type: "Pooling"
  bottom: "resnet1b_eltwise"
  top: "maxpool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet2a_bypass"
  type: "Convolution"
  bottom: "maxpool1"
  top: "resnet2a_bypass"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_btlnk"
  type: "Convolution"
  bottom: "maxpool1"
  top: "resnet2a_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet2a_btlnk"
  top: "resnet2a_btlnk"
}
layer {
  name: "resnet2a_conv"
  type: "Convolution"
  bottom: "resnet2a_btlnk"
  top: "resnet2a_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_conv_relu"
  type: "ReLU"
  bottom: "resnet2a_conv"
  top: "resnet2a_conv"
}
layer {
  name: "resnet2a_expnd"
  type: "Convolution"
  bottom: "resnet2a_conv"
  top: "resnet2a_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_eltwise"
  type: "Eltwise"
  bottom: "resnet2a_bypass"
  bottom: "resnet2a_expnd"
  top: "resnet2a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet2a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet2a_eltwise"
  top: "resnet2a_eltwise"
}
layer {
  name: "resnet2b_btlnk"
  type: "Convolution"
  bottom: "resnet2a_eltwise"
  top: "resnet2b_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet2b_btlnk"
  top: "resnet2b_btlnk"
}
layer {
  name: "resnet2b_conv"
  type: "Convolution"
  bottom: "resnet2b_btlnk"
  top: "resnet2b_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2b_conv_relu"
  type: "ReLU"
  bottom: "resnet2b_conv"
  top: "resnet2b_conv"
}
layer {
  name: "resnet2b_expnd"
  type: "Convolution"
  bottom: "resnet2b_conv"
  top: "resnet2b_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2b_eltwise"
  type: "Eltwise"
  bottom: "resnet2a_eltwise"
  bottom: "resnet2b_expnd"
  top: "resnet2b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet2b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet2b_eltwise"
  top: "resnet2b_eltwise"
}
layer {
  name: "maxpool2"
  type: "Pooling"
  bottom: "resnet2b_eltwise"
  top: "maxpool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet3a_bypass"
  type: "Convolution"
  bottom: "maxpool2"
  top: "resnet3a_bypass"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_btlnk"
  type: "Convolution"
  bottom: "maxpool2"
  top: "resnet3a_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet3a_btlnk"
  top: "resnet3a_btlnk"
}
layer {
  name: "resnet3a_conv"
  type: "Convolution"
  bottom: "resnet3a_btlnk"
  top: "resnet3a_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_conv_relu"
  type: "ReLU"
  bottom: "resnet3a_conv"
  top: "resnet3a_conv"
}
layer {
  name: "resnet3a_expnd"
  type: "Convolution"
  bottom: "resnet3a_conv"
  top: "resnet3a_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_eltwise"
  type: "Eltwise"
  bottom: "resnet3a_bypass"
  bottom: "resnet3a_expnd"
  top: "resnet3a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet3a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet3a_eltwise"
  top: "resnet3a_eltwise"
}
layer {
  name: "resnet3b_btlnk"
  type: "Convolution"
  bottom: "resnet3a_eltwise"
  top: "resnet3b_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet3b_btlnk"
  top: "resnet3b_btlnk"
}
layer {
  name: "resnet3b_conv"
  type: "Convolution"
  bottom: "resnet3b_btlnk"
  top: "resnet3b_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3b_conv_relu"
  type: "ReLU"
  bottom: "resnet3b_conv"
  top: "resnet3b_conv"
}
layer {
  name: "resnet3b_expnd"
  type: "Convolution"
  bottom: "resnet3b_conv"
  top: "resnet3b_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3b_eltwise"
  type: "Eltwise"
  bottom: "resnet3a_eltwise"
  bottom: "resnet3b_expnd"
  top: "resnet3b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet3b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet3b_eltwise"
  top: "resnet3b_eltwise"
}
layer {
  name: "maxpool3"
  type: "Pooling"
  bottom: "resnet3b_eltwise"
  top: "maxpool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet4a_bypass"
  type: "Convolution"
  bottom: "maxpool3"
  top: "resnet4a_bypass"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_btlnk"
  type: "Convolution"
  bottom: "maxpool3"
  top: "resnet4a_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet4a_btlnk"
  top: "resnet4a_btlnk"
}
layer {
  name: "resnet4a_conv"
  type: "Convolution"
  bottom: "resnet4a_btlnk"
  top: "resnet4a_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_conv_relu"
  type: "ReLU"
  bottom: "resnet4a_conv"
  top: "resnet4a_conv"
}
layer {
  name: "resnet4a_expnd"
  type: "Convolution"
  bottom: "resnet4a_conv"
  top: "resnet4a_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_eltwise"
  type: "Eltwise"
  bottom: "resnet4a_bypass"
  bottom: "resnet4a_expnd"
  top: "resnet4a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet4a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet4a_eltwise"
  top: "resnet4a_eltwise"
}
layer {
  name: "resnet4b_btlnk"
  type: "Convolution"
  bottom: "resnet4a_eltwise"
  top: "resnet4b_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet4b_btlnk"
  top: "resnet4b_btlnk"
}
layer {
  name: "resnet4b_conv"
  type: "Convolution"
  bottom: "resnet4b_btlnk"
  top: "resnet4b_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4b_conv_relu"
  type: "ReLU"
  bottom: "resnet4b_conv"
  top: "resnet4b_conv"
}
layer {
  name: "resnet4b_expnd"
  type: "Convolution"
  bottom: "resnet4b_conv"
  top: "resnet4b_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4b_eltwise"
  type: "Eltwise"
  bottom: "resnet4a_eltwise"
  bottom: "resnet4b_expnd"
  top: "resnet4b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet4b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet4b_eltwise"
  top: "resnet4b_eltwise"
}
layer {
  name: "maxpool4"
  type: "Pooling"
  bottom: "resnet4b_eltwise"
  top: "maxpool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet5a_bypass"
  type: "Convolution"
  bottom: "maxpool4"
  top: "resnet5a_bypass"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_btlnk"
  type: "Convolution"
  bottom: "maxpool4"
  top: "resnet5a_btlnk"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet5a_btlnk"
  top: "resnet5a_btlnk"
}
layer {
  name: "resnet5a_conv"
  type: "Convolution"
  bottom: "resnet5a_btlnk"
  top: "resnet5a_conv"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_conv_relu"
  type: "ReLU"
  bottom: "resnet5a_conv"
  top: "resnet5a_conv"
}
layer {
  name: "resnet5a_expnd"
  type: "Convolution"
  bottom: "resnet5a_conv"
  top: "resnet5a_expnd"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_eltwise"
  type: "Eltwise"
  bottom: "resnet5a_bypass"
  bottom: "resnet5a_expnd"
  top: "resnet5a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet5a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet5a_eltwise"
  top: "resnet5a_eltwise"
}
layer {
  name: "resnet5b_btlnk"
  type: "Convolution"
  bottom: "resnet5a_eltwise"
  top: "resnet5b_btlnk"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet5b_btlnk"
  top: "resnet5b_btlnk"
}
layer {
  name: "resnet5b_conv"
  type: "Convolution"
  bottom: "resnet5b_btlnk"
  top: "resnet5b_conv"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5b_conv_relu"
  type: "ReLU"
  bottom: "resnet5b_conv"
  top: "resnet5b_conv"
}
layer {
  name: "resnet5b_expnd"
  type: "Convolution"
  bottom: "resnet5b_conv"
  top: "resnet5b_expnd"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5b_eltwise"
  type: "Eltwise"
  bottom: "resnet5a_eltwise"
  bottom: "resnet5b_expnd"
  top: "resnet5b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet5b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet5b_eltwise"
  top: "resnet5b_eltwise"
}
layer {
  name: "unpool4"
  type: "Deconvolution"
  bottom: "resnet5b_eltwise"
  top: "unpool4"
  param {
    name: "par_unpool4_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool4_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat56_concat"
  type: "Concat"
  bottom: "resnet4b_eltwise"
  bottom: "unpool4"
  top: "concat56_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet6a_bypass"
  type: "Convolution"
  bottom: "concat56_concat"
  top: "resnet6a_bypass"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_btlnk"
  type: "Convolution"
  bottom: "concat56_concat"
  top: "resnet6a_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet6a_btlnk"
  top: "resnet6a_btlnk"
}
layer {
  name: "resnet6a_conv"
  type: "Convolution"
  bottom: "resnet6a_btlnk"
  top: "resnet6a_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_conv_relu"
  type: "ReLU"
  bottom: "resnet6a_conv"
  top: "resnet6a_conv"
}
layer {
  name: "resnet6a_expnd"
  type: "Convolution"
  bottom: "resnet6a_conv"
  top: "resnet6a_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_eltwise"
  type: "Eltwise"
  bottom: "resnet6a_bypass"
  bottom: "resnet6a_expnd"
  top: "resnet6a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet6a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet6a_eltwise"
  top: "resnet6a_eltwise"
}
layer {
  name: "resnet6b_btlnk"
  type: "Convolution"
  bottom: "resnet6a_eltwise"
  top: "resnet6b_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet6b_btlnk"
  top: "resnet6b_btlnk"
}
layer {
  name: "resnet6b_conv"
  type: "Convolution"
  bottom: "resnet6b_btlnk"
  top: "resnet6b_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6b_conv_relu"
  type: "ReLU"
  bottom: "resnet6b_conv"
  top: "resnet6b_conv"
}
layer {
  name: "resnet6b_expnd"
  type: "Convolution"
  bottom: "resnet6b_conv"
  top: "resnet6b_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6b_eltwise"
  type: "Eltwise"
  bottom: "resnet6a_eltwise"
  bottom: "resnet6b_expnd"
  top: "resnet6b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet6b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet6b_eltwise"
  top: "resnet6b_eltwise"
}
layer {
  name: "unpool3"
  type: "Deconvolution"
  bottom: "resnet6b_eltwise"
  top: "unpool3"
  param {
    name: "par_unpool3_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool3_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat37_concat"
  type: "Concat"
  bottom: "resnet3b_eltwise"
  bottom: "unpool3"
  top: "concat37_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet7a_bypass"
  type: "Convolution"
  bottom: "concat37_concat"
  top: "resnet7a_bypass"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_btlnk"
  type: "Convolution"
  bottom: "concat37_concat"
  top: "resnet7a_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet7a_btlnk"
  top: "resnet7a_btlnk"
}
layer {
  name: "resnet7a_conv"
  type: "Convolution"
  bottom: "resnet7a_btlnk"
  top: "resnet7a_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_conv_relu"
  type: "ReLU"
  bottom: "resnet7a_conv"
  top: "resnet7a_conv"
}
layer {
  name: "resnet7a_expnd"
  type: "Convolution"
  bottom: "resnet7a_conv"
  top: "resnet7a_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_eltwise"
  type: "Eltwise"
  bottom: "resnet7a_bypass"
  bottom: "resnet7a_expnd"
  top: "resnet7a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet7a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet7a_eltwise"
  top: "resnet7a_eltwise"
}
layer {
  name: "resnet7b_btlnk"
  type: "Convolution"
  bottom: "resnet7a_eltwise"
  top: "resnet7b_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet7b_btlnk"
  top: "resnet7b_btlnk"
}
layer {
  name: "resnet7b_conv"
  type: "Convolution"
  bottom: "resnet7b_btlnk"
  top: "resnet7b_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7b_conv_relu"
  type: "ReLU"
  bottom: "resnet7b_conv"
  top: "resnet7b_conv"
}
layer {
  name: "resnet7b_expnd"
  type: "Convolution"
  bottom: "resnet7b_conv"
  top: "resnet7b_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7b_eltwise"
  type: "Eltwise"
  bottom: "resnet7a_eltwise"
  bottom: "resnet7b_expnd"
  top: "resnet7b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet7b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet7b_eltwise"
  top: "resnet7b_eltwise"
}
layer {
  name: "unpool2"
  type: "Deconvolution"
  bottom: "resnet7b_eltwise"
  top: "unpool2"
  param {
    name: "par_unpool2_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool2_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat28_concat"
  type: "Concat"
  bottom: "resnet2b_eltwise"
  bottom: "unpool2"
  top: "concat28_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet8a_bypass"
  type: "Convolution"
  bottom: "concat28_concat"
  top: "resnet8a_bypass"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_btlnk"
  type: "Convolution"
  bottom: "concat28_concat"
  top: "resnet8a_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet8a_btlnk"
  top: "resnet8a_btlnk"
}
layer {
  name: "resnet8a_conv"
  type: "Convolution"
  bottom: "resnet8a_btlnk"
  top: "resnet8a_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_conv_relu"
  type: "ReLU"
  bottom: "resnet8a_conv"
  top: "resnet8a_conv"
}
layer {
  name: "resnet8a_expnd"
  type: "Convolution"
  bottom: "resnet8a_conv"
  top: "resnet8a_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_eltwise"
  type: "Eltwise"
  bottom: "resnet8a_bypass"
  bottom: "resnet8a_expnd"
  top: "resnet8a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet8a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet8a_eltwise"
  top: "resnet8a_eltwise"
}
layer {
  name: "resnet8b_btlnk"
  type: "Convolution"
  bottom: "resnet8a_eltwise"
  top: "resnet8b_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet8b_btlnk"
  top: "resnet8b_btlnk"
}
layer {
  name: "resnet8b_conv"
  type: "Convolution"
  bottom: "resnet8b_btlnk"
  top: "resnet8b_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8b_conv_relu"
  type: "ReLU"
  bottom: "resnet8b_conv"
  top: "resnet8b_conv"
}
layer {
  name: "resnet8b_expnd"
  type: "Convolution"
  bottom: "resnet8b_conv"
  top: "resnet8b_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8b_eltwise"
  type: "Eltwise"
  bottom: "resnet8a_eltwise"
  bottom: "resnet8b_expnd"
  top: "resnet8b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet8b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet8b_eltwise"
  top: "resnet8b_eltwise"
}
layer {
  name: "unpool1"
  type: "Deconvolution"
  bottom: "resnet8b_eltwise"
  top: "unpool1"
  param {
    name: "par_unpool1_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool1_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat19_concat"
  type: "Concat"
  bottom: "resnet1b_eltwise"
  bottom: "unpool1"
  top: "concat19_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet9a_bypass"
  type: "Convolution"
  bottom: "concat19_concat"
  top: "resnet9a_bypass"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_btlnk"
  type: "Convolution"
  bottom: "concat19_concat"
  top: "resnet9a_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet9a_btlnk"
  top: "resnet9a_btlnk"
}
layer {
  name: "resnet9a_conv"
  type: "Convolution"
  bottom: "resnet9a_btlnk"
  top: "resnet9a_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_conv_relu"
  type: "ReLU"
  bottom: "resnet9a_conv"
  top: "resnet9a_conv"
}
layer {
  name: "resnet9a_expnd"
  type: "Convolution"
  bottom: "resnet9a_conv"
  top: "resnet9a_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_eltwise"
  type: "Eltwise"
  bottom: "resnet9a_bypass"
  bottom: "resnet9a_expnd"
  top: "resnet9a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet9a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet9a_eltwise"
  top: "resnet9a_eltwise"
}
layer {
  name: "resnet9b_bypass"
  type: "Convolution"
  bottom: "resnet9a_eltwise"
  top: "resnet9b_bypass"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_btlnk"
  type: "Convolution"
  bottom: "resnet9a_eltwise"
  top: "resnet9b_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet9b_btlnk"
  top: "resnet9b_btlnk"
}
layer {
  name: "resnet9b_conv"
  type: "Convolution"
  bottom: "resnet9b_btlnk"
  top: "resnet9b_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_conv_relu"
  type: "ReLU"
  bottom: "resnet9b_conv"
  top: "resnet9b_conv"
}
layer {
  name: "resnet9b_expnd"
  type: "Convolution"
  bottom: "resnet9b_conv"
  top: "resnet9b_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_eltwise"
  type: "Eltwise"
  bottom: "resnet9b_bypass"
  bottom: "resnet9b_expnd"
  top: "resnet9b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet9b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet9b_eltwise"
  top: "resnet9b_eltwise"
}
layer {
  name: "score_conv"
  type: "Convolution"
  bottom: "resnet9b_eltwise"
  top: "score_conv"
  param {
    name: "par_score_conv_w"
    lr_mult: 1
  }
  param {
    name: "par_score_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "score_relu"
  type: "ReLU"
  bottom: "score_conv"
  top: "score_conv"
}
layer {
  name: "crop_score"
  type: "Crop"
  bottom: "score_conv"
  bottom: "label"
  top: "crop_score"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "softmaxloss"
  type: "SoftmaxWithLoss"
  bottom: "crop_score"
  bottom: "label"
  top: "softmaxloss"
  loss_param {
    normalize: true
    class_loss_weights: 1
    class_loss_weight
I0825 17:21:28.325078 27361 layer_factory.hpp:77] Creating layer data
I0825 17:21:28.325090 27361 net.cpp:100] Creating Layer data
I0825 17:21:28.325095 27361 net.cpp:408] data -> data
I0825 17:21:28.325117 27361 net.cpp:408] data -> label
    [95m[NORMAL][00m [0m [94m<train::configure>[00m IOManager configuration will be ignored...
    [95m[NORMAL][00m [0m [94m<trainProcessDriver::configure>[00m Instantiating Process ID=0 Type: ADCThreshold w/ Name: ADCThres
    [95m[NORMAL][00m [0m [94m<trainProcessDriver::configure>[00m Instantiating Process ID=1 Type: EmbedImage w/ Name: EmbedTPC
    [95m[NORMAL][00m [0m [94m<trainProcessDriver::configure>[00m Instantiating Process ID=2 Type: EmbedImage w/ Name: EmbedLabels
    [95m[NORMAL][00m [0m [94m<trainProcessDriver::configure>[00m Instantiating Process ID=3 Type: SegFiller w/ Name: SegFiller
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Opening a file in READ mode: /mnt/raid0/taritree/v0/hires_test/bnb_mc_hirescrop_train.root
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Skipping: producer=tpc_int00 type= image2d
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Skipping: producer=tpc type= image2d
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Skipping: producer=tpc type= partroi
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Skipping: producer=pmt type= image2d
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Skipping: producer=segment type= image2d
    [95m[NORMAL][00m [0m [94m<trainIOManager::prepare_input>[00m Skipping: producer=tpc_hires_crop type= partroi
    [95m[NORMAL][00m [0m [94m<trainIOManager::initialize>[00m Prepared input with 9471 entries...
I0825 17:21:28.842406 27361 net.cpp:150] Setting up data
I0825 17:21:28.842470 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842483 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842490 27361 net.cpp:165] Memory required for data: 2097152
I0825 17:21:28.842514 27361 layer_factory.hpp:77] Creating layer data_data_0_split
I0825 17:21:28.842540 27361 net.cpp:100] Creating Layer data_data_0_split
I0825 17:21:28.842548 27361 net.cpp:434] data_data_0_split <- data
I0825 17:21:28.842568 27361 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0825 17:21:28.842600 27361 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0825 17:21:28.842664 27361 net.cpp:150] Setting up data_data_0_split
I0825 17:21:28.842676 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842684 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842692 27361 net.cpp:165] Memory required for data: 4194304
I0825 17:21:28.842700 27361 layer_factory.hpp:77] Creating layer label_data_1_split
I0825 17:21:28.842710 27361 net.cpp:100] Creating Layer label_data_1_split
I0825 17:21:28.842718 27361 net.cpp:434] label_data_1_split <- label
I0825 17:21:28.842730 27361 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0825 17:21:28.842741 27361 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0825 17:21:28.842752 27361 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0825 17:21:28.842818 27361 net.cpp:150] Setting up label_data_1_split
I0825 17:21:28.842828 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842836 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842844 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:28.842851 27361 net.cpp:165] Memory required for data: 7340032
I0825 17:21:28.842859 27361 layer_factory.hpp:77] Creating layer resnet1a_bypass
I0825 17:21:28.842897 27361 net.cpp:100] Creating Layer resnet1a_bypass
I0825 17:21:28.842905 27361 net.cpp:434] resnet1a_bypass <- data_data_0_split_0
I0825 17:21:28.842916 27361 net.cpp:408] resnet1a_bypass -> resnet1a_bypass
I0825 17:21:28.843778 27361 net.cpp:150] Setting up resnet1a_bypass
I0825 17:21:28.843798 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.843806 27361 net.cpp:165] Memory required for data: 74448896
I0825 17:21:28.843822 27361 layer_factory.hpp:77] Creating layer resnet1a_btlnk
I0825 17:21:28.843837 27361 net.cpp:100] Creating Layer resnet1a_btlnk
I0825 17:21:28.843844 27361 net.cpp:434] resnet1a_btlnk <- data_data_0_split_1
I0825 17:21:28.843858 27361 net.cpp:408] resnet1a_btlnk -> resnet1a_btlnk
I0825 17:21:28.844118 27361 net.cpp:150] Setting up resnet1a_btlnk
I0825 17:21:28.844132 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.844139 27361 net.cpp:165] Memory required for data: 82837504
I0825 17:21:28.844152 27361 layer_factory.hpp:77] Creating layer resnet1a_btlnk_relu
I0825 17:21:28.844166 27361 net.cpp:100] Creating Layer resnet1a_btlnk_relu
I0825 17:21:28.844173 27361 net.cpp:434] resnet1a_btlnk_relu <- resnet1a_btlnk
I0825 17:21:28.844182 27361 net.cpp:395] resnet1a_btlnk_relu -> resnet1a_btlnk (in-place)
I0825 17:21:28.844194 27361 net.cpp:150] Setting up resnet1a_btlnk_relu
I0825 17:21:28.844203 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.844210 27361 net.cpp:165] Memory required for data: 91226112
I0825 17:21:28.844218 27361 layer_factory.hpp:77] Creating layer resnet1a_conv
I0825 17:21:28.844231 27361 net.cpp:100] Creating Layer resnet1a_conv
I0825 17:21:28.844238 27361 net.cpp:434] resnet1a_conv <- resnet1a_btlnk
I0825 17:21:28.844250 27361 net.cpp:408] resnet1a_conv -> resnet1a_conv
I0825 17:21:28.845233 27361 net.cpp:150] Setting up resnet1a_conv
I0825 17:21:28.845257 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.845265 27361 net.cpp:165] Memory required for data: 99614720
I0825 17:21:28.845279 27361 layer_factory.hpp:77] Creating layer resnet1a_conv_relu
I0825 17:21:28.845291 27361 net.cpp:100] Creating Layer resnet1a_conv_relu
I0825 17:21:28.845299 27361 net.cpp:434] resnet1a_conv_relu <- resnet1a_conv
I0825 17:21:28.845309 27361 net.cpp:395] resnet1a_conv_relu -> resnet1a_conv (in-place)
I0825 17:21:28.845321 27361 net.cpp:150] Setting up resnet1a_conv_relu
I0825 17:21:28.845331 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.845345 27361 net.cpp:165] Memory required for data: 108003328
I0825 17:21:28.845355 27361 layer_factory.hpp:77] Creating layer resnet1a_expnd
I0825 17:21:28.845373 27361 net.cpp:100] Creating Layer resnet1a_expnd
I0825 17:21:28.845381 27361 net.cpp:434] resnet1a_expnd <- resnet1a_conv
I0825 17:21:28.845391 27361 net.cpp:408] resnet1a_expnd -> resnet1a_expnd
I0825 17:21:28.845692 27361 net.cpp:150] Setting up resnet1a_expnd
I0825 17:21:28.845706 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.845713 27361 net.cpp:165] Memory required for data: 175112192
I0825 17:21:28.845723 27361 layer_factory.hpp:77] Creating layer resnet1a_eltwise
I0825 17:21:28.845736 27361 net.cpp:100] Creating Layer resnet1a_eltwise
I0825 17:21:28.845743 27361 net.cpp:434] resnet1a_eltwise <- resnet1a_bypass
I0825 17:21:28.845752 27361 net.cpp:434] resnet1a_eltwise <- resnet1a_expnd
I0825 17:21:28.845762 27361 net.cpp:408] resnet1a_eltwise -> resnet1a_eltwise
I0825 17:21:28.845808 27361 net.cpp:150] Setting up resnet1a_eltwise
I0825 17:21:28.845819 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.845826 27361 net.cpp:165] Memory required for data: 242221056
I0825 17:21:28.845834 27361 layer_factory.hpp:77] Creating layer resnet1a_eltwise_relu
I0825 17:21:28.845844 27361 net.cpp:100] Creating Layer resnet1a_eltwise_relu
I0825 17:21:28.845850 27361 net.cpp:434] resnet1a_eltwise_relu <- resnet1a_eltwise
I0825 17:21:28.845860 27361 net.cpp:395] resnet1a_eltwise_relu -> resnet1a_eltwise (in-place)
I0825 17:21:28.845870 27361 net.cpp:150] Setting up resnet1a_eltwise_relu
I0825 17:21:28.845890 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.845897 27361 net.cpp:165] Memory required for data: 309329920
I0825 17:21:28.845904 27361 layer_factory.hpp:77] Creating layer resnet1a_eltwise_resnet1a_eltwise_relu_0_split
I0825 17:21:28.845913 27361 net.cpp:100] Creating Layer resnet1a_eltwise_resnet1a_eltwise_relu_0_split
I0825 17:21:28.845921 27361 net.cpp:434] resnet1a_eltwise_resnet1a_eltwise_relu_0_split <- resnet1a_eltwise
I0825 17:21:28.845930 27361 net.cpp:408] resnet1a_eltwise_resnet1a_eltwise_relu_0_split -> resnet1a_eltwise_resnet1a_eltwise_relu_0_split_0
I0825 17:21:28.845942 27361 net.cpp:408] resnet1a_eltwise_resnet1a_eltwise_relu_0_split -> resnet1a_eltwise_resnet1a_eltwise_relu_0_split_1
I0825 17:21:28.845996 27361 net.cpp:150] Setting up resnet1a_eltwise_resnet1a_eltwise_relu_0_split
I0825 17:21:28.846009 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.846017 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.846024 27361 net.cpp:165] Memory required for data: 443547648
I0825 17:21:28.846032 27361 layer_factory.hpp:77] Creating layer resnet1b_btlnk
I0825 17:21:28.846048 27361 net.cpp:100] Creating Layer resnet1b_btlnk
I0825 17:21:28.846056 27361 net.cpp:434] resnet1b_btlnk <- resnet1a_eltwise_resnet1a_eltwise_relu_0_split_0
I0825 17:21:28.846068 27361 net.cpp:408] resnet1b_btlnk -> resnet1b_btlnk
I0825 17:21:28.846349 27361 net.cpp:150] Setting up resnet1b_btlnk
I0825 17:21:28.846362 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.846369 27361 net.cpp:165] Memory required for data: 451936256
I0825 17:21:28.846382 27361 layer_factory.hpp:77] Creating layer resnet1b_btlnk_relu
I0825 17:21:28.846392 27361 net.cpp:100] Creating Layer resnet1b_btlnk_relu
I0825 17:21:28.846400 27361 net.cpp:434] resnet1b_btlnk_relu <- resnet1b_btlnk
I0825 17:21:28.846410 27361 net.cpp:395] resnet1b_btlnk_relu -> resnet1b_btlnk (in-place)
I0825 17:21:28.846420 27361 net.cpp:150] Setting up resnet1b_btlnk_relu
I0825 17:21:28.846428 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.846436 27361 net.cpp:165] Memory required for data: 460324864
I0825 17:21:28.846442 27361 layer_factory.hpp:77] Creating layer resnet1b_conv
I0825 17:21:28.846457 27361 net.cpp:100] Creating Layer resnet1b_conv
I0825 17:21:28.846465 27361 net.cpp:434] resnet1b_conv <- resnet1b_btlnk
I0825 17:21:28.846474 27361 net.cpp:408] resnet1b_conv -> resnet1b_conv
I0825 17:21:28.846787 27361 net.cpp:150] Setting up resnet1b_conv
I0825 17:21:28.846804 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.846812 27361 net.cpp:165] Memory required for data: 468713472
I0825 17:21:28.846822 27361 layer_factory.hpp:77] Creating layer resnet1b_conv_relu
I0825 17:21:28.846833 27361 net.cpp:100] Creating Layer resnet1b_conv_relu
I0825 17:21:28.846842 27361 net.cpp:434] resnet1b_conv_relu <- resnet1b_conv
I0825 17:21:28.846851 27361 net.cpp:395] resnet1b_conv_relu -> resnet1b_conv (in-place)
I0825 17:21:28.846861 27361 net.cpp:150] Setting up resnet1b_conv_relu
I0825 17:21:28.846870 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:28.846878 27361 net.cpp:165] Memory required for data: 477102080
I0825 17:21:28.846884 27361 layer_factory.hpp:77] Creating layer resnet1b_expnd
I0825 17:21:28.846900 27361 net.cpp:100] Creating Layer resnet1b_expnd
I0825 17:21:28.846909 27361 net.cpp:434] resnet1b_expnd <- resnet1b_conv
I0825 17:21:28.846918 27361 net.cpp:408] resnet1b_expnd -> resnet1b_expnd
I0825 17:21:28.847213 27361 net.cpp:150] Setting up resnet1b_expnd
I0825 17:21:28.847226 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.847234 27361 net.cpp:165] Memory required for data: 544210944
I0825 17:21:28.847244 27361 layer_factory.hpp:77] Creating layer resnet1b_eltwise
I0825 17:21:28.847255 27361 net.cpp:100] Creating Layer resnet1b_eltwise
I0825 17:21:28.847265 27361 net.cpp:434] resnet1b_eltwise <- resnet1a_eltwise_resnet1a_eltwise_relu_0_split_1
I0825 17:21:28.847273 27361 net.cpp:434] resnet1b_eltwise <- resnet1b_expnd
I0825 17:21:28.847295 27361 net.cpp:408] resnet1b_eltwise -> resnet1b_eltwise
I0825 17:21:28.847332 27361 net.cpp:150] Setting up resnet1b_eltwise
I0825 17:21:28.847344 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.847352 27361 net.cpp:165] Memory required for data: 611319808
I0825 17:21:28.847358 27361 layer_factory.hpp:77] Creating layer resnet1b_eltwise_relu
I0825 17:21:28.847369 27361 net.cpp:100] Creating Layer resnet1b_eltwise_relu
I0825 17:21:28.847378 27361 net.cpp:434] resnet1b_eltwise_relu <- resnet1b_eltwise
I0825 17:21:28.847386 27361 net.cpp:395] resnet1b_eltwise_relu -> resnet1b_eltwise (in-place)
I0825 17:21:28.847396 27361 net.cpp:150] Setting up resnet1b_eltwise_relu
I0825 17:21:28.847405 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.847412 27361 net.cpp:165] Memory required for data: 678428672
I0825 17:21:28.847419 27361 layer_factory.hpp:77] Creating layer resnet1b_eltwise_resnet1b_eltwise_relu_0_split
I0825 17:21:28.847429 27361 net.cpp:100] Creating Layer resnet1b_eltwise_resnet1b_eltwise_relu_0_split
I0825 17:21:28.847436 27361 net.cpp:434] resnet1b_eltwise_resnet1b_eltwise_relu_0_split <- resnet1b_eltwise
I0825 17:21:28.847445 27361 net.cpp:408] resnet1b_eltwise_resnet1b_eltwise_relu_0_split -> resnet1b_eltwise_resnet1b_eltwise_relu_0_split_0
I0825 17:21:28.847458 27361 net.cpp:408] resnet1b_eltwise_resnet1b_eltwise_relu_0_split -> resnet1b_eltwise_resnet1b_eltwise_relu_0_split_1
I0825 17:21:28.847512 27361 net.cpp:150] Setting up resnet1b_eltwise_resnet1b_eltwise_relu_0_split
I0825 17:21:28.847522 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.847530 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:28.847537 27361 net.cpp:165] Memory required for data: 812646400
I0825 17:21:28.847546 27361 layer_factory.hpp:77] Creating layer maxpool1
I0825 17:21:28.847563 27361 net.cpp:100] Creating Layer maxpool1
I0825 17:21:28.847573 27361 net.cpp:434] maxpool1 <- resnet1b_eltwise_resnet1b_eltwise_relu_0_split_0
I0825 17:21:28.847581 27361 net.cpp:408] maxpool1 -> maxpool1
I0825 17:21:28.847642 27361 net.cpp:150] Setting up maxpool1
I0825 17:21:28.847654 27361 net.cpp:157] Top shape: 1 64 256 256 (4194304)
I0825 17:21:28.847661 27361 net.cpp:165] Memory required for data: 829423616
I0825 17:21:28.847668 27361 layer_factory.hpp:77] Creating layer maxpool1_maxpool1_0_split
I0825 17:21:28.847677 27361 net.cpp:100] Creating Layer maxpool1_maxpool1_0_split
I0825 17:21:28.847690 27361 net.cpp:434] maxpool1_maxpool1_0_split <- maxpool1
I0825 17:21:28.847702 27361 net.cpp:408] maxpool1_maxpool1_0_split -> maxpool1_maxpool1_0_split_0
I0825 17:21:28.847714 27361 net.cpp:408] maxpool1_maxpool1_0_split -> maxpool1_maxpool1_0_split_1
I0825 17:21:28.847764 27361 net.cpp:150] Setting up maxpool1_maxpool1_0_split
I0825 17:21:28.847774 27361 net.cpp:157] Top shape: 1 64 256 256 (4194304)
I0825 17:21:28.847784 27361 net.cpp:157] Top shape: 1 64 256 256 (4194304)
I0825 17:21:28.847790 27361 net.cpp:165] Memory required for data: 862978048
I0825 17:21:28.847796 27361 layer_factory.hpp:77] Creating layer resnet2a_bypass
I0825 17:21:28.847811 27361 net.cpp:100] Creating Layer resnet2a_bypass
I0825 17:21:28.847820 27361 net.cpp:434] resnet2a_bypass <- maxpool1_maxpool1_0_split_0
I0825 17:21:28.847831 27361 net.cpp:408] resnet2a_bypass -> resnet2a_bypass
I0825 17:21:28.849239 27361 net.cpp:150] Setting up resnet2a_bypass
I0825 17:21:28.849264 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.849272 27361 net.cpp:165] Memory required for data: 896532480
I0825 17:21:28.849282 27361 layer_factory.hpp:77] Creating layer resnet2a_btlnk
I0825 17:21:28.849301 27361 net.cpp:100] Creating Layer resnet2a_btlnk
I0825 17:21:28.849310 27361 net.cpp:434] resnet2a_btlnk <- maxpool1_maxpool1_0_split_1
I0825 17:21:28.849321 27361 net.cpp:408] resnet2a_btlnk -> resnet2a_btlnk
I0825 17:21:28.849642 27361 net.cpp:150] Setting up resnet2a_btlnk
I0825 17:21:28.849656 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.849675 27361 net.cpp:165] Memory required for data: 900726784
I0825 17:21:28.849691 27361 layer_factory.hpp:77] Creating layer resnet2a_btlnk_relu
I0825 17:21:28.849702 27361 net.cpp:100] Creating Layer resnet2a_btlnk_relu
I0825 17:21:28.849710 27361 net.cpp:434] resnet2a_btlnk_relu <- resnet2a_btlnk
I0825 17:21:28.849720 27361 net.cpp:395] resnet2a_btlnk_relu -> resnet2a_btlnk (in-place)
I0825 17:21:28.849732 27361 net.cpp:150] Setting up resnet2a_btlnk_relu
I0825 17:21:28.849741 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.849748 27361 net.cpp:165] Memory required for data: 904921088
I0825 17:21:28.849756 27361 layer_factory.hpp:77] Creating layer resnet2a_conv
I0825 17:21:28.849768 27361 net.cpp:100] Creating Layer resnet2a_conv
I0825 17:21:28.849776 27361 net.cpp:434] resnet2a_conv <- resnet2a_btlnk
I0825 17:21:28.849789 27361 net.cpp:408] resnet2a_conv -> resnet2a_conv
I0825 17:21:28.850883 27361 net.cpp:150] Setting up resnet2a_conv
I0825 17:21:28.850909 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.850917 27361 net.cpp:165] Memory required for data: 909115392
I0825 17:21:28.850927 27361 layer_factory.hpp:77] Creating layer resnet2a_conv_relu
I0825 17:21:28.850940 27361 net.cpp:100] Creating Layer resnet2a_conv_relu
I0825 17:21:28.850950 27361 net.cpp:434] resnet2a_conv_relu <- resnet2a_conv
I0825 17:21:28.850960 27361 net.cpp:395] resnet2a_conv_relu -> resnet2a_conv (in-place)
I0825 17:21:28.850971 27361 net.cpp:150] Setting up resnet2a_conv_relu
I0825 17:21:28.850980 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.850999 27361 net.cpp:165] Memory required for data: 913309696
I0825 17:21:28.851006 27361 layer_factory.hpp:77] Creating layer resnet2a_expnd
I0825 17:21:28.851022 27361 net.cpp:100] Creating Layer resnet2a_expnd
I0825 17:21:28.851028 27361 net.cpp:434] resnet2a_expnd <- resnet2a_conv
I0825 17:21:28.851038 27361 net.cpp:408] resnet2a_expnd -> resnet2a_expnd
I0825 17:21:28.851394 27361 net.cpp:150] Setting up resnet2a_expnd
I0825 17:21:28.851408 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.851414 27361 net.cpp:165] Memory required for data: 946864128
I0825 17:21:28.851424 27361 layer_factory.hpp:77] Creating layer resnet2a_eltwise
I0825 17:21:28.851435 27361 net.cpp:100] Creating Layer resnet2a_eltwise
I0825 17:21:28.851443 27361 net.cpp:434] resnet2a_eltwise <- resnet2a_bypass
I0825 17:21:28.851451 27361 net.cpp:434] resnet2a_eltwise <- resnet2a_expnd
I0825 17:21:28.851471 27361 net.cpp:408] resnet2a_eltwise -> resnet2a_eltwise
I0825 17:21:28.851526 27361 net.cpp:150] Setting up resnet2a_eltwise
I0825 17:21:28.851537 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.851543 27361 net.cpp:165] Memory required for data: 980418560
I0825 17:21:28.851550 27361 layer_factory.hpp:77] Creating layer resnet2a_eltwise_relu
I0825 17:21:28.851559 27361 net.cpp:100] Creating Layer resnet2a_eltwise_relu
I0825 17:21:28.851567 27361 net.cpp:434] resnet2a_eltwise_relu <- resnet2a_eltwise
I0825 17:21:28.851575 27361 net.cpp:395] resnet2a_eltwise_relu -> resnet2a_eltwise (in-place)
I0825 17:21:28.851584 27361 net.cpp:150] Setting up resnet2a_eltwise_relu
I0825 17:21:28.851593 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.851599 27361 net.cpp:165] Memory required for data: 1013972992
I0825 17:21:28.851606 27361 layer_factory.hpp:77] Creating layer resnet2a_eltwise_resnet2a_eltwise_relu_0_split
I0825 17:21:28.851615 27361 net.cpp:100] Creating Layer resnet2a_eltwise_resnet2a_eltwise_relu_0_split
I0825 17:21:28.851622 27361 net.cpp:434] resnet2a_eltwise_resnet2a_eltwise_relu_0_split <- resnet2a_eltwise
I0825 17:21:28.851630 27361 net.cpp:408] resnet2a_eltwise_resnet2a_eltwise_relu_0_split -> resnet2a_eltwise_resnet2a_eltwise_relu_0_split_0
I0825 17:21:28.851641 27361 net.cpp:408] resnet2a_eltwise_resnet2a_eltwise_relu_0_split -> resnet2a_eltwise_resnet2a_eltwise_relu_0_split_1
I0825 17:21:28.851691 27361 net.cpp:150] Setting up resnet2a_eltwise_resnet2a_eltwise_relu_0_split
I0825 17:21:28.851702 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.851721 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.851727 27361 net.cpp:165] Memory required for data: 1081081856
I0825 17:21:28.851734 27361 layer_factory.hpp:77] Creating layer resnet2b_btlnk
I0825 17:21:28.851753 27361 net.cpp:100] Creating Layer resnet2b_btlnk
I0825 17:21:28.851761 27361 net.cpp:434] resnet2b_btlnk <- resnet2a_eltwise_resnet2a_eltwise_relu_0_split_0
I0825 17:21:28.851773 27361 net.cpp:408] resnet2b_btlnk -> resnet2b_btlnk
I0825 17:21:28.852128 27361 net.cpp:150] Setting up resnet2b_btlnk
I0825 17:21:28.852141 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.852149 27361 net.cpp:165] Memory required for data: 1085276160
I0825 17:21:28.852159 27361 layer_factory.hpp:77] Creating layer resnet2b_btlnk_relu
I0825 17:21:28.852170 27361 net.cpp:100] Creating Layer resnet2b_btlnk_relu
I0825 17:21:28.852177 27361 net.cpp:434] resnet2b_btlnk_relu <- resnet2b_btlnk
I0825 17:21:28.852186 27361 net.cpp:395] resnet2b_btlnk_relu -> resnet2b_btlnk (in-place)
I0825 17:21:28.852197 27361 net.cpp:150] Setting up resnet2b_btlnk_relu
I0825 17:21:28.852205 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.852212 27361 net.cpp:165] Memory required for data: 1089470464
I0825 17:21:28.852218 27361 layer_factory.hpp:77] Creating layer resnet2b_conv
I0825 17:21:28.852232 27361 net.cpp:100] Creating Layer resnet2b_conv
I0825 17:21:28.852241 27361 net.cpp:434] resnet2b_conv <- resnet2b_btlnk
I0825 17:21:28.852249 27361 net.cpp:408] resnet2b_conv -> resnet2b_conv
I0825 17:21:28.852618 27361 net.cpp:150] Setting up resnet2b_conv
I0825 17:21:28.852632 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.852638 27361 net.cpp:165] Memory required for data: 1093664768
I0825 17:21:28.852648 27361 layer_factory.hpp:77] Creating layer resnet2b_conv_relu
I0825 17:21:28.852658 27361 net.cpp:100] Creating Layer resnet2b_conv_relu
I0825 17:21:28.852666 27361 net.cpp:434] resnet2b_conv_relu <- resnet2b_conv
I0825 17:21:28.852675 27361 net.cpp:395] resnet2b_conv_relu -> resnet2b_conv (in-place)
I0825 17:21:28.852684 27361 net.cpp:150] Setting up resnet2b_conv_relu
I0825 17:21:28.852692 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:28.852699 27361 net.cpp:165] Memory required for data: 1097859072
I0825 17:21:28.852706 27361 layer_factory.hpp:77] Creating layer resnet2b_expnd
I0825 17:21:28.852720 27361 net.cpp:100] Creating Layer resnet2b_expnd
I0825 17:21:28.852732 27361 net.cpp:434] resnet2b_expnd <- resnet2b_conv
I0825 17:21:28.852742 27361 net.cpp:408] resnet2b_expnd -> resnet2b_expnd
I0825 17:21:28.853094 27361 net.cpp:150] Setting up resnet2b_expnd
I0825 17:21:28.853108 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.853116 27361 net.cpp:165] Memory required for data: 1131413504
I0825 17:21:28.853126 27361 layer_factory.hpp:77] Creating layer resnet2b_eltwise
I0825 17:21:28.853137 27361 net.cpp:100] Creating Layer resnet2b_eltwise
I0825 17:21:28.853143 27361 net.cpp:434] resnet2b_eltwise <- resnet2a_eltwise_resnet2a_eltwise_relu_0_split_1
I0825 17:21:28.853152 27361 net.cpp:434] resnet2b_eltwise <- resnet2b_expnd
I0825 17:21:28.853162 27361 net.cpp:408] resnet2b_eltwise -> resnet2b_eltwise
I0825 17:21:28.853194 27361 net.cpp:150] Setting up resnet2b_eltwise
I0825 17:21:28.853204 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.853211 27361 net.cpp:165] Memory required for data: 1164967936
I0825 17:21:28.853217 27361 layer_factory.hpp:77] Creating layer resnet2b_eltwise_relu
I0825 17:21:28.853229 27361 net.cpp:100] Creating Layer resnet2b_eltwise_relu
I0825 17:21:28.853236 27361 net.cpp:434] resnet2b_eltwise_relu <- resnet2b_eltwise
I0825 17:21:28.853245 27361 net.cpp:395] resnet2b_eltwise_relu -> resnet2b_eltwise (in-place)
I0825 17:21:28.853253 27361 net.cpp:150] Setting up resnet2b_eltwise_relu
I0825 17:21:28.853262 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.853268 27361 net.cpp:165] Memory required for data: 1198522368
I0825 17:21:28.853284 27361 layer_factory.hpp:77] Creating layer resnet2b_eltwise_resnet2b_eltwise_relu_0_split
I0825 17:21:28.853294 27361 net.cpp:100] Creating Layer resnet2b_eltwise_resnet2b_eltwise_relu_0_split
I0825 17:21:28.853302 27361 net.cpp:434] resnet2b_eltwise_resnet2b_eltwise_relu_0_split <- resnet2b_eltwise
I0825 17:21:28.853309 27361 net.cpp:408] resnet2b_eltwise_resnet2b_eltwise_relu_0_split -> resnet2b_eltwise_resnet2b_eltwise_relu_0_split_0
I0825 17:21:28.853319 27361 net.cpp:408] resnet2b_eltwise_resnet2b_eltwise_relu_0_split -> resnet2b_eltwise_resnet2b_eltwise_relu_0_split_1
I0825 17:21:28.853371 27361 net.cpp:150] Setting up resnet2b_eltwise_resnet2b_eltwise_relu_0_split
I0825 17:21:28.853381 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.853390 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:28.853396 27361 net.cpp:165] Memory required for data: 1265631232
I0825 17:21:28.853404 27361 layer_factory.hpp:77] Creating layer maxpool2
I0825 17:21:28.853415 27361 net.cpp:100] Creating Layer maxpool2
I0825 17:21:28.853422 27361 net.cpp:434] maxpool2 <- resnet2b_eltwise_resnet2b_eltwise_relu_0_split_0
I0825 17:21:28.853432 27361 net.cpp:408] maxpool2 -> maxpool2
I0825 17:21:28.853487 27361 net.cpp:150] Setting up maxpool2
I0825 17:21:28.853497 27361 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0825 17:21:28.853503 27361 net.cpp:165] Memory required for data: 1274019840
I0825 17:21:28.853512 27361 layer_factory.hpp:77] Creating layer maxpool2_maxpool2_0_split
I0825 17:21:28.853520 27361 net.cpp:100] Creating Layer maxpool2_maxpool2_0_split
I0825 17:21:28.853528 27361 net.cpp:434] maxpool2_maxpool2_0_split <- maxpool2
I0825 17:21:28.853538 27361 net.cpp:408] maxpool2_maxpool2_0_split -> maxpool2_maxpool2_0_split_0
I0825 17:21:28.853549 27361 net.cpp:408] maxpool2_maxpool2_0_split -> maxpool2_maxpool2_0_split_1
I0825 17:21:28.853595 27361 net.cpp:150] Setting up maxpool2_maxpool2_0_split
I0825 17:21:28.853605 27361 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0825 17:21:28.853613 27361 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0825 17:21:28.853620 27361 net.cpp:165] Memory required for data: 1290797056
I0825 17:21:28.853626 27361 layer_factory.hpp:77] Creating layer resnet3a_bypass
I0825 17:21:28.853637 27361 net.cpp:100] Creating Layer resnet3a_bypass
I0825 17:21:28.853644 27361 net.cpp:434] resnet3a_bypass <- maxpool2_maxpool2_0_split_0
I0825 17:21:28.853662 27361 net.cpp:408] resnet3a_bypass -> resnet3a_bypass
I0825 17:21:28.856333 27361 net.cpp:150] Setting up resnet3a_bypass
I0825 17:21:28.856360 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.856369 27361 net.cpp:165] Memory required for data: 1307574272
I0825 17:21:28.856379 27361 layer_factory.hpp:77] Creating layer resnet3a_btlnk
I0825 17:21:28.856395 27361 net.cpp:100] Creating Layer resnet3a_btlnk
I0825 17:21:28.856402 27361 net.cpp:434] resnet3a_btlnk <- maxpool2_maxpool2_0_split_1
I0825 17:21:28.856427 27361 net.cpp:408] resnet3a_btlnk -> resnet3a_btlnk
I0825 17:21:28.856901 27361 net.cpp:150] Setting up resnet3a_btlnk
I0825 17:21:28.856915 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.856922 27361 net.cpp:165] Memory required for data: 1309671424
I0825 17:21:28.856931 27361 layer_factory.hpp:77] Creating layer resnet3a_btlnk_relu
I0825 17:21:28.856943 27361 net.cpp:100] Creating Layer resnet3a_btlnk_relu
I0825 17:21:28.856951 27361 net.cpp:434] resnet3a_btlnk_relu <- resnet3a_btlnk
I0825 17:21:28.856961 27361 net.cpp:395] resnet3a_btlnk_relu -> resnet3a_btlnk (in-place)
I0825 17:21:28.856971 27361 net.cpp:150] Setting up resnet3a_btlnk_relu
I0825 17:21:28.856979 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.856986 27361 net.cpp:165] Memory required for data: 1311768576
I0825 17:21:28.856994 27361 layer_factory.hpp:77] Creating layer resnet3a_conv
I0825 17:21:28.857007 27361 net.cpp:100] Creating Layer resnet3a_conv
I0825 17:21:28.857013 27361 net.cpp:434] resnet3a_conv <- resnet3a_btlnk
I0825 17:21:28.857025 27361 net.cpp:408] resnet3a_conv -> resnet3a_conv
I0825 17:21:28.857787 27361 net.cpp:150] Setting up resnet3a_conv
I0825 17:21:28.857801 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.857808 27361 net.cpp:165] Memory required for data: 1313865728
I0825 17:21:28.857822 27361 layer_factory.hpp:77] Creating layer resnet3a_conv_relu
I0825 17:21:28.857834 27361 net.cpp:100] Creating Layer resnet3a_conv_relu
I0825 17:21:28.857842 27361 net.cpp:434] resnet3a_conv_relu <- resnet3a_conv
I0825 17:21:28.857851 27361 net.cpp:395] resnet3a_conv_relu -> resnet3a_conv (in-place)
I0825 17:21:28.857861 27361 net.cpp:150] Setting up resnet3a_conv_relu
I0825 17:21:28.857870 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.857877 27361 net.cpp:165] Memory required for data: 1315962880
I0825 17:21:28.857884 27361 layer_factory.hpp:77] Creating layer resnet3a_expnd
I0825 17:21:28.857897 27361 net.cpp:100] Creating Layer resnet3a_expnd
I0825 17:21:28.857903 27361 net.cpp:434] resnet3a_expnd <- resnet3a_conv
I0825 17:21:28.857914 27361 net.cpp:408] resnet3a_expnd -> resnet3a_expnd
I0825 17:21:28.858605 27361 net.cpp:150] Setting up resnet3a_expnd
I0825 17:21:28.858621 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.858628 27361 net.cpp:165] Memory required for data: 1332740096
I0825 17:21:28.858638 27361 layer_factory.hpp:77] Creating layer resnet3a_eltwise
I0825 17:21:28.858649 27361 net.cpp:100] Creating Layer resnet3a_eltwise
I0825 17:21:28.858657 27361 net.cpp:434] resnet3a_eltwise <- resnet3a_bypass
I0825 17:21:28.858666 27361 net.cpp:434] resnet3a_eltwise <- resnet3a_expnd
I0825 17:21:28.858676 27361 net.cpp:408] resnet3a_eltwise -> resnet3a_eltwise
I0825 17:21:28.858710 27361 net.cpp:150] Setting up resnet3a_eltwise
I0825 17:21:28.858719 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.858726 27361 net.cpp:165] Memory required for data: 1349517312
I0825 17:21:28.858734 27361 layer_factory.hpp:77] Creating layer resnet3a_eltwise_relu
I0825 17:21:28.858744 27361 net.cpp:100] Creating Layer resnet3a_eltwise_relu
I0825 17:21:28.858752 27361 net.cpp:434] resnet3a_eltwise_relu <- resnet3a_eltwise
I0825 17:21:28.858764 27361 net.cpp:395] resnet3a_eltwise_relu -> resnet3a_eltwise (in-place)
I0825 17:21:28.858774 27361 net.cpp:150] Setting up resnet3a_eltwise_relu
I0825 17:21:28.858783 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.858789 27361 net.cpp:165] Memory required for data: 1366294528
I0825 17:21:28.858801 27361 layer_factory.hpp:77] Creating layer resnet3a_eltwise_resnet3a_eltwise_relu_0_split
I0825 17:21:28.858811 27361 net.cpp:100] Creating Layer resnet3a_eltwise_resnet3a_eltwise_relu_0_split
I0825 17:21:28.858819 27361 net.cpp:434] resnet3a_eltwise_resnet3a_eltwise_relu_0_split <- resnet3a_eltwise
I0825 17:21:28.858827 27361 net.cpp:408] resnet3a_eltwise_resnet3a_eltwise_relu_0_split -> resnet3a_eltwise_resnet3a_eltwise_relu_0_split_0
I0825 17:21:28.858837 27361 net.cpp:408] resnet3a_eltwise_resnet3a_eltwise_relu_0_split -> resnet3a_eltwise_resnet3a_eltwise_relu_0_split_1
I0825 17:21:28.858887 27361 net.cpp:150] Setting up resnet3a_eltwise_resnet3a_eltwise_relu_0_split
I0825 17:21:28.858897 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.858906 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.858912 27361 net.cpp:165] Memory required for data: 1399848960
I0825 17:21:28.858919 27361 layer_factory.hpp:77] Creating layer resnet3b_btlnk
I0825 17:21:28.858933 27361 net.cpp:100] Creating Layer resnet3b_btlnk
I0825 17:21:28.858942 27361 net.cpp:434] resnet3b_btlnk <- resnet3a_eltwise_resnet3a_eltwise_relu_0_split_0
I0825 17:21:28.858953 27361 net.cpp:408] resnet3b_btlnk -> resnet3b_btlnk
I0825 17:21:28.859632 27361 net.cpp:150] Setting up resnet3b_btlnk
I0825 17:21:28.859647 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.859652 27361 net.cpp:165] Memory required for data: 1401946112
I0825 17:21:28.859661 27361 layer_factory.hpp:77] Creating layer resnet3b_btlnk_relu
I0825 17:21:28.859673 27361 net.cpp:100] Creating Layer resnet3b_btlnk_relu
I0825 17:21:28.859691 27361 net.cpp:434] resnet3b_btlnk_relu <- resnet3b_btlnk
I0825 17:21:28.859700 27361 net.cpp:395] resnet3b_btlnk_relu -> resnet3b_btlnk (in-place)
I0825 17:21:28.859711 27361 net.cpp:150] Setting up resnet3b_btlnk_relu
I0825 17:21:28.859719 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.859726 27361 net.cpp:165] Memory required for data: 1404043264
I0825 17:21:28.859735 27361 layer_factory.hpp:77] Creating layer resnet3b_conv
I0825 17:21:28.859746 27361 net.cpp:100] Creating Layer resnet3b_conv
I0825 17:21:28.859753 27361 net.cpp:434] resnet3b_conv <- resnet3b_btlnk
I0825 17:21:28.859763 27361 net.cpp:408] resnet3b_conv -> resnet3b_conv
I0825 17:21:28.860509 27361 net.cpp:150] Setting up resnet3b_conv
I0825 17:21:28.860523 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.860530 27361 net.cpp:165] Memory required for data: 1406140416
I0825 17:21:28.860539 27361 layer_factory.hpp:77] Creating layer resnet3b_conv_relu
I0825 17:21:28.860550 27361 net.cpp:100] Creating Layer resnet3b_conv_relu
I0825 17:21:28.860558 27361 net.cpp:434] resnet3b_conv_relu <- resnet3b_conv
I0825 17:21:28.860569 27361 net.cpp:395] resnet3b_conv_relu -> resnet3b_conv (in-place)
I0825 17:21:28.860579 27361 net.cpp:150] Setting up resnet3b_conv_relu
I0825 17:21:28.860587 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:28.860594 27361 net.cpp:165] Memory required for data: 1408237568
I0825 17:21:28.860600 27361 layer_factory.hpp:77] Creating layer resnet3b_expnd
I0825 17:21:28.860611 27361 net.cpp:100] Creating Layer resnet3b_expnd
I0825 17:21:28.860618 27361 net.cpp:434] resnet3b_expnd <- resnet3b_conv
I0825 17:21:28.860630 27361 net.cpp:408] resnet3b_expnd -> resnet3b_expnd
I0825 17:21:28.861316 27361 net.cpp:150] Setting up resnet3b_expnd
I0825 17:21:28.861330 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.861336 27361 net.cpp:165] Memory required for data: 1425014784
I0825 17:21:28.861344 27361 layer_factory.hpp:77] Creating layer resnet3b_eltwise
I0825 17:21:28.861356 27361 net.cpp:100] Creating Layer resnet3b_eltwise
I0825 17:21:28.861364 27361 net.cpp:434] resnet3b_eltwise <- resnet3a_eltwise_resnet3a_eltwise_relu_0_split_1
I0825 17:21:28.861372 27361 net.cpp:434] resnet3b_eltwise <- resnet3b_expnd
I0825 17:21:28.861382 27361 net.cpp:408] resnet3b_eltwise -> resnet3b_eltwise
I0825 17:21:28.861433 27361 net.cpp:150] Setting up resnet3b_eltwise
I0825 17:21:28.861449 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.861454 27361 net.cpp:165] Memory required for data: 1441792000
I0825 17:21:28.861464 27361 layer_factory.hpp:77] Creating layer resnet3b_eltwise_relu
I0825 17:21:28.861472 27361 net.cpp:100] Creating Layer resnet3b_eltwise_relu
I0825 17:21:28.861479 27361 net.cpp:434] resnet3b_eltwise_relu <- resnet3b_eltwise
I0825 17:21:28.861488 27361 net.cpp:395] resnet3b_eltwise_relu -> resnet3b_eltwise (in-place)
I0825 17:21:28.861497 27361 net.cpp:150] Setting up resnet3b_eltwise_relu
I0825 17:21:28.861506 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.861512 27361 net.cpp:165] Memory required for data: 1458569216
I0825 17:21:28.861520 27361 layer_factory.hpp:77] Creating layer resnet3b_eltwise_resnet3b_eltwise_relu_0_split
I0825 17:21:28.861529 27361 net.cpp:100] Creating Layer resnet3b_eltwise_resnet3b_eltwise_relu_0_split
I0825 17:21:28.861536 27361 net.cpp:434] resnet3b_eltwise_resnet3b_eltwise_relu_0_split <- resnet3b_eltwise
I0825 17:21:28.861546 27361 net.cpp:408] resnet3b_eltwise_resnet3b_eltwise_relu_0_split -> resnet3b_eltwise_resnet3b_eltwise_relu_0_split_0
I0825 17:21:28.861557 27361 net.cpp:408] resnet3b_eltwise_resnet3b_eltwise_relu_0_split -> resnet3b_eltwise_resnet3b_eltwise_relu_0_split_1
I0825 17:21:28.861605 27361 net.cpp:150] Setting up resnet3b_eltwise_resnet3b_eltwise_relu_0_split
I0825 17:21:28.861615 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.861624 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:28.861639 27361 net.cpp:165] Memory required for data: 1492123648
I0825 17:21:28.861646 27361 layer_factory.hpp:77] Creating layer maxpool3
I0825 17:21:28.861660 27361 net.cpp:100] Creating Layer maxpool3
I0825 17:21:28.861668 27361 net.cpp:434] maxpool3 <- resnet3b_eltwise_resnet3b_eltwise_relu_0_split_0
I0825 17:21:28.861680 27361 net.cpp:408] maxpool3 -> maxpool3
I0825 17:21:28.861729 27361 net.cpp:150] Setting up maxpool3
I0825 17:21:28.861739 27361 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0825 17:21:28.861747 27361 net.cpp:165] Memory required for data: 1496317952
I0825 17:21:28.861753 27361 layer_factory.hpp:77] Creating layer maxpool3_maxpool3_0_split
I0825 17:21:28.861763 27361 net.cpp:100] Creating Layer maxpool3_maxpool3_0_split
I0825 17:21:28.861771 27361 net.cpp:434] maxpool3_maxpool3_0_split <- maxpool3
I0825 17:21:28.861780 27361 net.cpp:408] maxpool3_maxpool3_0_split -> maxpool3_maxpool3_0_split_0
I0825 17:21:28.861790 27361 net.cpp:408] maxpool3_maxpool3_0_split -> maxpool3_maxpool3_0_split_1
I0825 17:21:28.861837 27361 net.cpp:150] Setting up maxpool3_maxpool3_0_split
I0825 17:21:28.861847 27361 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0825 17:21:28.861855 27361 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0825 17:21:28.861861 27361 net.cpp:165] Memory required for data: 1504706560
I0825 17:21:28.861870 27361 layer_factory.hpp:77] Creating layer resnet4a_bypass
I0825 17:21:28.861883 27361 net.cpp:100] Creating Layer resnet4a_bypass
I0825 17:21:28.861891 27361 net.cpp:434] resnet4a_bypass <- maxpool3_maxpool3_0_split_0
I0825 17:21:28.861903 27361 net.cpp:408] resnet4a_bypass -> resnet4a_bypass
I0825 17:21:28.869451 27361 net.cpp:150] Setting up resnet4a_bypass
I0825 17:21:28.869484 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.869493 27361 net.cpp:165] Memory required for data: 1513095168
I0825 17:21:28.869503 27361 layer_factory.hpp:77] Creating layer resnet4a_btlnk
I0825 17:21:28.869519 27361 net.cpp:100] Creating Layer resnet4a_btlnk
I0825 17:21:28.869529 27361 net.cpp:434] resnet4a_btlnk <- maxpool3_maxpool3_0_split_1
I0825 17:21:28.869539 27361 net.cpp:408] resnet4a_btlnk -> resnet4a_btlnk
I0825 17:21:28.870617 27361 net.cpp:150] Setting up resnet4a_btlnk
I0825 17:21:28.870632 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.870640 27361 net.cpp:165] Memory required for data: 1514143744
I0825 17:21:28.870647 27361 layer_factory.hpp:77] Creating layer resnet4a_btlnk_relu
I0825 17:21:28.870664 27361 net.cpp:100] Creating Layer resnet4a_btlnk_relu
I0825 17:21:28.870672 27361 net.cpp:434] resnet4a_btlnk_relu <- resnet4a_btlnk
I0825 17:21:28.870682 27361 net.cpp:395] resnet4a_btlnk_relu -> resnet4a_btlnk (in-place)
I0825 17:21:28.870692 27361 net.cpp:150] Setting up resnet4a_btlnk_relu
I0825 17:21:28.870700 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.870707 27361 net.cpp:165] Memory required for data: 1515192320
I0825 17:21:28.870712 27361 layer_factory.hpp:77] Creating layer resnet4a_conv
I0825 17:21:28.870724 27361 net.cpp:100] Creating Layer resnet4a_conv
I0825 17:21:28.870731 27361 net.cpp:434] resnet4a_conv <- resnet4a_btlnk
I0825 17:21:28.870748 27361 net.cpp:408] resnet4a_conv -> resnet4a_conv
I0825 17:21:28.872869 27361 net.cpp:150] Setting up resnet4a_conv
I0825 17:21:28.872885 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.872892 27361 net.cpp:165] Memory required for data: 1516240896
I0825 17:21:28.872902 27361 layer_factory.hpp:77] Creating layer resnet4a_conv_relu
I0825 17:21:28.872922 27361 net.cpp:100] Creating Layer resnet4a_conv_relu
I0825 17:21:28.872931 27361 net.cpp:434] resnet4a_conv_relu <- resnet4a_conv
I0825 17:21:28.872939 27361 net.cpp:395] resnet4a_conv_relu -> resnet4a_conv (in-place)
I0825 17:21:28.872951 27361 net.cpp:150] Setting up resnet4a_conv_relu
I0825 17:21:28.872958 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.872964 27361 net.cpp:165] Memory required for data: 1517289472
I0825 17:21:28.872972 27361 layer_factory.hpp:77] Creating layer resnet4a_expnd
I0825 17:21:28.872998 27361 net.cpp:100] Creating Layer resnet4a_expnd
I0825 17:21:28.873005 27361 net.cpp:434] resnet4a_expnd <- resnet4a_conv
I0825 17:21:28.873014 27361 net.cpp:408] resnet4a_expnd -> resnet4a_expnd
I0825 17:21:28.874918 27361 net.cpp:150] Setting up resnet4a_expnd
I0825 17:21:28.874934 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.874940 27361 net.cpp:165] Memory required for data: 1525678080
I0825 17:21:28.874948 27361 layer_factory.hpp:77] Creating layer resnet4a_eltwise
I0825 17:21:28.874959 27361 net.cpp:100] Creating Layer resnet4a_eltwise
I0825 17:21:28.874966 27361 net.cpp:434] resnet4a_eltwise <- resnet4a_bypass
I0825 17:21:28.874974 27361 net.cpp:434] resnet4a_eltwise <- resnet4a_expnd
I0825 17:21:28.874982 27361 net.cpp:408] resnet4a_eltwise -> resnet4a_eltwise
I0825 17:21:28.875013 27361 net.cpp:150] Setting up resnet4a_eltwise
I0825 17:21:28.875022 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.875028 27361 net.cpp:165] Memory required for data: 1534066688
I0825 17:21:28.875036 27361 layer_factory.hpp:77] Creating layer resnet4a_eltwise_relu
I0825 17:21:28.875049 27361 net.cpp:100] Creating Layer resnet4a_eltwise_relu
I0825 17:21:28.875056 27361 net.cpp:434] resnet4a_eltwise_relu <- resnet4a_eltwise
I0825 17:21:28.875063 27361 net.cpp:395] resnet4a_eltwise_relu -> resnet4a_eltwise (in-place)
I0825 17:21:28.875072 27361 net.cpp:150] Setting up resnet4a_eltwise_relu
I0825 17:21:28.875080 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.875087 27361 net.cpp:165] Memory required for data: 1542455296
I0825 17:21:28.875092 27361 layer_factory.hpp:77] Creating layer resnet4a_eltwise_resnet4a_eltwise_relu_0_split
I0825 17:21:28.875100 27361 net.cpp:100] Creating Layer resnet4a_eltwise_resnet4a_eltwise_relu_0_split
I0825 17:21:28.875108 27361 net.cpp:434] resnet4a_eltwise_resnet4a_eltwise_relu_0_split <- resnet4a_eltwise
I0825 17:21:28.875114 27361 net.cpp:408] resnet4a_eltwise_resnet4a_eltwise_relu_0_split -> resnet4a_eltwise_resnet4a_eltwise_relu_0_split_0
I0825 17:21:28.875123 27361 net.cpp:408] resnet4a_eltwise_resnet4a_eltwise_relu_0_split -> resnet4a_eltwise_resnet4a_eltwise_relu_0_split_1
I0825 17:21:28.875169 27361 net.cpp:150] Setting up resnet4a_eltwise_resnet4a_eltwise_relu_0_split
I0825 17:21:28.875179 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.875186 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.875191 27361 net.cpp:165] Memory required for data: 1559232512
I0825 17:21:28.875201 27361 layer_factory.hpp:77] Creating layer resnet4b_btlnk
I0825 17:21:28.875214 27361 net.cpp:100] Creating Layer resnet4b_btlnk
I0825 17:21:28.875221 27361 net.cpp:434] resnet4b_btlnk <- resnet4a_eltwise_resnet4a_eltwise_relu_0_split_0
I0825 17:21:28.875232 27361 net.cpp:408] resnet4b_btlnk -> resnet4b_btlnk
I0825 17:21:28.877012 27361 net.cpp:150] Setting up resnet4b_btlnk
I0825 17:21:28.877024 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.877032 27361 net.cpp:165] Memory required for data: 1560281088
I0825 17:21:28.877039 27361 layer_factory.hpp:77] Creating layer resnet4b_btlnk_relu
I0825 17:21:28.877048 27361 net.cpp:100] Creating Layer resnet4b_btlnk_relu
I0825 17:21:28.877054 27361 net.cpp:434] resnet4b_btlnk_relu <- resnet4b_btlnk
I0825 17:21:28.877063 27361 net.cpp:395] resnet4b_btlnk_relu -> resnet4b_btlnk (in-place)
I0825 17:21:28.877071 27361 net.cpp:150] Setting up resnet4b_btlnk_relu
I0825 17:21:28.877079 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.877085 27361 net.cpp:165] Memory required for data: 1561329664
I0825 17:21:28.877092 27361 layer_factory.hpp:77] Creating layer resnet4b_conv
I0825 17:21:28.877104 27361 net.cpp:100] Creating Layer resnet4b_conv
I0825 17:21:28.877110 27361 net.cpp:434] resnet4b_conv <- resnet4b_btlnk
I0825 17:21:28.877121 27361 net.cpp:408] resnet4b_conv -> resnet4b_conv
I0825 17:21:28.879134 27361 net.cpp:150] Setting up resnet4b_conv
I0825 17:21:28.879150 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.879156 27361 net.cpp:165] Memory required for data: 1562378240
I0825 17:21:28.879175 27361 layer_factory.hpp:77] Creating layer resnet4b_conv_relu
I0825 17:21:28.879187 27361 net.cpp:100] Creating Layer resnet4b_conv_relu
I0825 17:21:28.879195 27361 net.cpp:434] resnet4b_conv_relu <- resnet4b_conv
I0825 17:21:28.879204 27361 net.cpp:395] resnet4b_conv_relu -> resnet4b_conv (in-place)
I0825 17:21:28.879212 27361 net.cpp:150] Setting up resnet4b_conv_relu
I0825 17:21:28.879220 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:28.879226 27361 net.cpp:165] Memory required for data: 1563426816
I0825 17:21:28.879232 27361 layer_factory.hpp:77] Creating layer resnet4b_expnd
I0825 17:21:28.879242 27361 net.cpp:100] Creating Layer resnet4b_expnd
I0825 17:21:28.879250 27361 net.cpp:434] resnet4b_expnd <- resnet4b_conv
I0825 17:21:28.879259 27361 net.cpp:408] resnet4b_expnd -> resnet4b_expnd
I0825 17:21:28.881043 27361 net.cpp:150] Setting up resnet4b_expnd
I0825 17:21:28.881062 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.881069 27361 net.cpp:165] Memory required for data: 1571815424
I0825 17:21:28.881078 27361 layer_factory.hpp:77] Creating layer resnet4b_eltwise
I0825 17:21:28.881088 27361 net.cpp:100] Creating Layer resnet4b_eltwise
I0825 17:21:28.881095 27361 net.cpp:434] resnet4b_eltwise <- resnet4a_eltwise_resnet4a_eltwise_relu_0_split_1
I0825 17:21:28.881103 27361 net.cpp:434] resnet4b_eltwise <- resnet4b_expnd
I0825 17:21:28.881111 27361 net.cpp:408] resnet4b_eltwise -> resnet4b_eltwise
I0825 17:21:28.881145 27361 net.cpp:150] Setting up resnet4b_eltwise
I0825 17:21:28.881155 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.881160 27361 net.cpp:165] Memory required for data: 1580204032
I0825 17:21:28.881167 27361 layer_factory.hpp:77] Creating layer resnet4b_eltwise_relu
I0825 17:21:28.881175 27361 net.cpp:100] Creating Layer resnet4b_eltwise_relu
I0825 17:21:28.881182 27361 net.cpp:434] resnet4b_eltwise_relu <- resnet4b_eltwise
I0825 17:21:28.881189 27361 net.cpp:395] resnet4b_eltwise_relu -> resnet4b_eltwise (in-place)
I0825 17:21:28.881198 27361 net.cpp:150] Setting up resnet4b_eltwise_relu
I0825 17:21:28.881206 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.881211 27361 net.cpp:165] Memory required for data: 1588592640
I0825 17:21:28.881217 27361 layer_factory.hpp:77] Creating layer resnet4b_eltwise_resnet4b_eltwise_relu_0_split
I0825 17:21:28.881225 27361 net.cpp:100] Creating Layer resnet4b_eltwise_resnet4b_eltwise_relu_0_split
I0825 17:21:28.881237 27361 net.cpp:434] resnet4b_eltwise_resnet4b_eltwise_relu_0_split <- resnet4b_eltwise
I0825 17:21:28.881244 27361 net.cpp:408] resnet4b_eltwise_resnet4b_eltwise_relu_0_split -> resnet4b_eltwise_resnet4b_eltwise_relu_0_split_0
I0825 17:21:28.881254 27361 net.cpp:408] resnet4b_eltwise_resnet4b_eltwise_relu_0_split -> resnet4b_eltwise_resnet4b_eltwise_relu_0_split_1
I0825 17:21:28.881301 27361 net.cpp:150] Setting up resnet4b_eltwise_resnet4b_eltwise_relu_0_split
I0825 17:21:28.881310 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.881319 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:28.881325 27361 net.cpp:165] Memory required for data: 1605369856
I0825 17:21:28.881330 27361 layer_factory.hpp:77] Creating layer maxpool4
I0825 17:21:28.881341 27361 net.cpp:100] Creating Layer maxpool4
I0825 17:21:28.881347 27361 net.cpp:434] maxpool4 <- resnet4b_eltwise_resnet4b_eltwise_relu_0_split_0
I0825 17:21:28.881362 27361 net.cpp:408] maxpool4 -> maxpool4
I0825 17:21:28.881410 27361 net.cpp:150] Setting up maxpool4
I0825 17:21:28.881420 27361 net.cpp:157] Top shape: 1 512 32 32 (524288)
I0825 17:21:28.881427 27361 net.cpp:165] Memory required for data: 1607467008
I0825 17:21:28.881433 27361 layer_factory.hpp:77] Creating layer maxpool4_maxpool4_0_split
I0825 17:21:28.881440 27361 net.cpp:100] Creating Layer maxpool4_maxpool4_0_split
I0825 17:21:28.881448 27361 net.cpp:434] maxpool4_maxpool4_0_split <- maxpool4
I0825 17:21:28.881458 27361 net.cpp:408] maxpool4_maxpool4_0_split -> maxpool4_maxpool4_0_split_0
I0825 17:21:28.881475 27361 net.cpp:408] maxpool4_maxpool4_0_split -> maxpool4_maxpool4_0_split_1
I0825 17:21:28.881518 27361 net.cpp:150] Setting up maxpool4_maxpool4_0_split
I0825 17:21:28.881530 27361 net.cpp:157] Top shape: 1 512 32 32 (524288)
I0825 17:21:28.881536 27361 net.cpp:157] Top shape: 1 512 32 32 (524288)
I0825 17:21:28.881542 27361 net.cpp:165] Memory required for data: 1611661312
I0825 17:21:28.881549 27361 layer_factory.hpp:77] Creating layer resnet5a_bypass
I0825 17:21:28.881561 27361 net.cpp:100] Creating Layer resnet5a_bypass
I0825 17:21:28.881568 27361 net.cpp:434] resnet5a_bypass <- maxpool4_maxpool4_0_split_0
I0825 17:21:28.881579 27361 net.cpp:408] resnet5a_bypass -> resnet5a_bypass
I0825 17:21:28.906239 27361 net.cpp:150] Setting up resnet5a_bypass
I0825 17:21:28.906268 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.906275 27361 net.cpp:165] Memory required for data: 1615855616
I0825 17:21:28.906283 27361 layer_factory.hpp:77] Creating layer resnet5a_btlnk
I0825 17:21:28.906296 27361 net.cpp:100] Creating Layer resnet5a_btlnk
I0825 17:21:28.906303 27361 net.cpp:434] resnet5a_btlnk <- maxpool4_maxpool4_0_split_1
I0825 17:21:28.906314 27361 net.cpp:408] resnet5a_btlnk -> resnet5a_btlnk
I0825 17:21:28.909907 27361 net.cpp:150] Setting up resnet5a_btlnk
I0825 17:21:28.909930 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.909936 27361 net.cpp:165] Memory required for data: 1616379904
I0825 17:21:28.909945 27361 layer_factory.hpp:77] Creating layer resnet5a_btlnk_relu
I0825 17:21:28.909955 27361 net.cpp:100] Creating Layer resnet5a_btlnk_relu
I0825 17:21:28.909960 27361 net.cpp:434] resnet5a_btlnk_relu <- resnet5a_btlnk
I0825 17:21:28.909968 27361 net.cpp:395] resnet5a_btlnk_relu -> resnet5a_btlnk (in-place)
I0825 17:21:28.909978 27361 net.cpp:150] Setting up resnet5a_btlnk_relu
I0825 17:21:28.909986 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.909991 27361 net.cpp:165] Memory required for data: 1616904192
I0825 17:21:28.909996 27361 layer_factory.hpp:77] Creating layer resnet5a_conv
I0825 17:21:28.910008 27361 net.cpp:100] Creating Layer resnet5a_conv
I0825 17:21:28.910014 27361 net.cpp:434] resnet5a_conv <- resnet5a_btlnk
I0825 17:21:28.910024 27361 net.cpp:408] resnet5a_conv -> resnet5a_conv
I0825 17:21:28.916817 27361 net.cpp:150] Setting up resnet5a_conv
I0825 17:21:28.916843 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.916857 27361 net.cpp:165] Memory required for data: 1617428480
I0825 17:21:28.916867 27361 layer_factory.hpp:77] Creating layer resnet5a_conv_relu
I0825 17:21:28.916877 27361 net.cpp:100] Creating Layer resnet5a_conv_relu
I0825 17:21:28.916883 27361 net.cpp:434] resnet5a_conv_relu <- resnet5a_conv
I0825 17:21:28.916892 27361 net.cpp:395] resnet5a_conv_relu -> resnet5a_conv (in-place)
I0825 17:21:28.916900 27361 net.cpp:150] Setting up resnet5a_conv_relu
I0825 17:21:28.916908 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.916913 27361 net.cpp:165] Memory required for data: 1617952768
I0825 17:21:28.916918 27361 layer_factory.hpp:77] Creating layer resnet5a_expnd
I0825 17:21:28.916929 27361 net.cpp:100] Creating Layer resnet5a_expnd
I0825 17:21:28.916935 27361 net.cpp:434] resnet5a_expnd <- resnet5a_conv
I0825 17:21:28.916944 27361 net.cpp:408] resnet5a_expnd -> resnet5a_expnd
I0825 17:21:28.922513 27361 net.cpp:150] Setting up resnet5a_expnd
I0825 17:21:28.922528 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.922533 27361 net.cpp:165] Memory required for data: 1622147072
I0825 17:21:28.922539 27361 layer_factory.hpp:77] Creating layer resnet5a_eltwise
I0825 17:21:28.922550 27361 net.cpp:100] Creating Layer resnet5a_eltwise
I0825 17:21:28.922556 27361 net.cpp:434] resnet5a_eltwise <- resnet5a_bypass
I0825 17:21:28.922564 27361 net.cpp:434] resnet5a_eltwise <- resnet5a_expnd
I0825 17:21:28.922570 27361 net.cpp:408] resnet5a_eltwise -> resnet5a_eltwise
I0825 17:21:28.922607 27361 net.cpp:150] Setting up resnet5a_eltwise
I0825 17:21:28.922617 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.922633 27361 net.cpp:165] Memory required for data: 1626341376
I0825 17:21:28.922638 27361 layer_factory.hpp:77] Creating layer resnet5a_eltwise_relu
I0825 17:21:28.922648 27361 net.cpp:100] Creating Layer resnet5a_eltwise_relu
I0825 17:21:28.922655 27361 net.cpp:434] resnet5a_eltwise_relu <- resnet5a_eltwise
I0825 17:21:28.922662 27361 net.cpp:395] resnet5a_eltwise_relu -> resnet5a_eltwise (in-place)
I0825 17:21:28.922669 27361 net.cpp:150] Setting up resnet5a_eltwise_relu
I0825 17:21:28.922677 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.922682 27361 net.cpp:165] Memory required for data: 1630535680
I0825 17:21:28.922688 27361 layer_factory.hpp:77] Creating layer resnet5a_eltwise_resnet5a_eltwise_relu_0_split
I0825 17:21:28.922695 27361 net.cpp:100] Creating Layer resnet5a_eltwise_resnet5a_eltwise_relu_0_split
I0825 17:21:28.922700 27361 net.cpp:434] resnet5a_eltwise_resnet5a_eltwise_relu_0_split <- resnet5a_eltwise
I0825 17:21:28.922708 27361 net.cpp:408] resnet5a_eltwise_resnet5a_eltwise_relu_0_split -> resnet5a_eltwise_resnet5a_eltwise_relu_0_split_0
I0825 17:21:28.922715 27361 net.cpp:408] resnet5a_eltwise_resnet5a_eltwise_relu_0_split -> resnet5a_eltwise_resnet5a_eltwise_relu_0_split_1
I0825 17:21:28.922758 27361 net.cpp:150] Setting up resnet5a_eltwise_resnet5a_eltwise_relu_0_split
I0825 17:21:28.922777 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.922783 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.922787 27361 net.cpp:165] Memory required for data: 1638924288
I0825 17:21:28.922792 27361 layer_factory.hpp:77] Creating layer resnet5b_btlnk
I0825 17:21:28.922807 27361 net.cpp:100] Creating Layer resnet5b_btlnk
I0825 17:21:28.922813 27361 net.cpp:434] resnet5b_btlnk <- resnet5a_eltwise_resnet5a_eltwise_relu_0_split_0
I0825 17:21:28.922821 27361 net.cpp:408] resnet5b_btlnk -> resnet5b_btlnk
I0825 17:21:28.928664 27361 net.cpp:150] Setting up resnet5b_btlnk
I0825 17:21:28.928689 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.928695 27361 net.cpp:165] Memory required for data: 1639448576
I0825 17:21:28.928709 27361 layer_factory.hpp:77] Creating layer resnet5b_btlnk_relu
I0825 17:21:28.928717 27361 net.cpp:100] Creating Layer resnet5b_btlnk_relu
I0825 17:21:28.928724 27361 net.cpp:434] resnet5b_btlnk_relu <- resnet5b_btlnk
I0825 17:21:28.928731 27361 net.cpp:395] resnet5b_btlnk_relu -> resnet5b_btlnk (in-place)
I0825 17:21:28.928745 27361 net.cpp:150] Setting up resnet5b_btlnk_relu
I0825 17:21:28.928752 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.928757 27361 net.cpp:165] Memory required for data: 1639972864
I0825 17:21:28.928762 27361 layer_factory.hpp:77] Creating layer resnet5b_conv
I0825 17:21:28.928773 27361 net.cpp:100] Creating Layer resnet5b_conv
I0825 17:21:28.928778 27361 net.cpp:434] resnet5b_conv <- resnet5b_btlnk
I0825 17:21:28.928787 27361 net.cpp:408] resnet5b_conv -> resnet5b_conv
I0825 17:21:28.935266 27361 net.cpp:150] Setting up resnet5b_conv
I0825 17:21:28.935286 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.935291 27361 net.cpp:165] Memory required for data: 1640497152
I0825 17:21:28.935299 27361 layer_factory.hpp:77] Creating layer resnet5b_conv_relu
I0825 17:21:28.935308 27361 net.cpp:100] Creating Layer resnet5b_conv_relu
I0825 17:21:28.935314 27361 net.cpp:434] resnet5b_conv_relu <- resnet5b_conv
I0825 17:21:28.935320 27361 net.cpp:395] resnet5b_conv_relu -> resnet5b_conv (in-place)
I0825 17:21:28.935329 27361 net.cpp:150] Setting up resnet5b_conv_relu
I0825 17:21:28.935335 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:28.935340 27361 net.cpp:165] Memory required for data: 1641021440
I0825 17:21:28.935344 27361 layer_factory.hpp:77] Creating layer resnet5b_expnd
I0825 17:21:28.935355 27361 net.cpp:100] Creating Layer resnet5b_expnd
I0825 17:21:28.935361 27361 net.cpp:434] resnet5b_expnd <- resnet5b_conv
I0825 17:21:28.935367 27361 net.cpp:408] resnet5b_expnd -> resnet5b_expnd
I0825 17:21:28.940423 27361 net.cpp:150] Setting up resnet5b_expnd
I0825 17:21:28.940441 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.940446 27361 net.cpp:165] Memory required for data: 1645215744
I0825 17:21:28.940454 27361 layer_factory.hpp:77] Creating layer resnet5b_eltwise
I0825 17:21:28.940465 27361 net.cpp:100] Creating Layer resnet5b_eltwise
I0825 17:21:28.940472 27361 net.cpp:434] resnet5b_eltwise <- resnet5a_eltwise_resnet5a_eltwise_relu_0_split_1
I0825 17:21:28.940479 27361 net.cpp:434] resnet5b_eltwise <- resnet5b_expnd
I0825 17:21:28.940485 27361 net.cpp:408] resnet5b_eltwise -> resnet5b_eltwise
I0825 17:21:28.940512 27361 net.cpp:150] Setting up resnet5b_eltwise
I0825 17:21:28.940521 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.940526 27361 net.cpp:165] Memory required for data: 1649410048
I0825 17:21:28.940529 27361 layer_factory.hpp:77] Creating layer resnet5b_eltwise_relu
I0825 17:21:28.940538 27361 net.cpp:100] Creating Layer resnet5b_eltwise_relu
I0825 17:21:28.940543 27361 net.cpp:434] resnet5b_eltwise_relu <- resnet5b_eltwise
I0825 17:21:28.940549 27361 net.cpp:395] resnet5b_eltwise_relu -> resnet5b_eltwise (in-place)
I0825 17:21:28.940557 27361 net.cpp:150] Setting up resnet5b_eltwise_relu
I0825 17:21:28.940562 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:28.940567 27361 net.cpp:165] Memory required for data: 1653604352
I0825 17:21:28.940573 27361 layer_factory.hpp:77] Creating layer unpool4
I0825 17:21:28.940582 27361 net.cpp:100] Creating Layer unpool4
I0825 17:21:28.940587 27361 net.cpp:434] unpool4 <- resnet5b_eltwise
I0825 17:21:28.940596 27361 net.cpp:408] unpool4 -> unpool4
I0825 17:21:29.072377 27361 net.cpp:150] Setting up unpool4
I0825 17:21:29.072413 27361 net.cpp:157] Top shape: 1 1024 64 64 (4194304)
I0825 17:21:29.072417 27361 net.cpp:165] Memory required for data: 1670381568
I0825 17:21:29.072427 27361 layer_factory.hpp:77] Creating layer concat56_concat
I0825 17:21:29.072445 27361 net.cpp:100] Creating Layer concat56_concat
I0825 17:21:29.072451 27361 net.cpp:434] concat56_concat <- resnet4b_eltwise_resnet4b_eltwise_relu_0_split_1
I0825 17:21:29.072458 27361 net.cpp:434] concat56_concat <- unpool4
I0825 17:21:29.072464 27361 net.cpp:408] concat56_concat -> concat56_concat
I0825 17:21:29.072490 27361 net.cpp:150] Setting up concat56_concat
I0825 17:21:29.072496 27361 net.cpp:157] Top shape: 1 1536 64 64 (6291456)
I0825 17:21:29.072500 27361 net.cpp:165] Memory required for data: 1695547392
I0825 17:21:29.072510 27361 layer_factory.hpp:77] Creating layer concat56_concat_concat56_concat_0_split
I0825 17:21:29.072517 27361 net.cpp:100] Creating Layer concat56_concat_concat56_concat_0_split
I0825 17:21:29.072521 27361 net.cpp:434] concat56_concat_concat56_concat_0_split <- concat56_concat
I0825 17:21:29.072525 27361 net.cpp:408] concat56_concat_concat56_concat_0_split -> concat56_concat_concat56_concat_0_split_0
I0825 17:21:29.072531 27361 net.cpp:408] concat56_concat_concat56_concat_0_split -> concat56_concat_concat56_concat_0_split_1
I0825 17:21:29.072561 27361 net.cpp:150] Setting up concat56_concat_concat56_concat_0_split
I0825 17:21:29.072566 27361 net.cpp:157] Top shape: 1 1536 64 64 (6291456)
I0825 17:21:29.072571 27361 net.cpp:157] Top shape: 1 1536 64 64 (6291456)
I0825 17:21:29.072573 27361 net.cpp:165] Memory required for data: 1745879040
I0825 17:21:29.072577 27361 layer_factory.hpp:77] Creating layer resnet6a_bypass
I0825 17:21:29.072593 27361 net.cpp:100] Creating Layer resnet6a_bypass
I0825 17:21:29.072598 27361 net.cpp:434] resnet6a_bypass <- concat56_concat_concat56_concat_0_split_0
I0825 17:21:29.072604 27361 net.cpp:408] resnet6a_bypass -> resnet6a_bypass
I0825 17:21:29.094053 27361 net.cpp:150] Setting up resnet6a_bypass
I0825 17:21:29.094070 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.094074 27361 net.cpp:165] Memory required for data: 1754267648
I0825 17:21:29.094080 27361 layer_factory.hpp:77] Creating layer resnet6a_btlnk
I0825 17:21:29.094089 27361 net.cpp:100] Creating Layer resnet6a_btlnk
I0825 17:21:29.094105 27361 net.cpp:434] resnet6a_btlnk <- concat56_concat_concat56_concat_0_split_1
I0825 17:21:29.094110 27361 net.cpp:408] resnet6a_btlnk -> resnet6a_btlnk
I0825 17:21:29.096810 27361 net.cpp:150] Setting up resnet6a_btlnk
I0825 17:21:29.096820 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.096823 27361 net.cpp:165] Memory required for data: 1755316224
I0825 17:21:29.096828 27361 layer_factory.hpp:77] Creating layer resnet6a_btlnk_relu
I0825 17:21:29.096835 27361 net.cpp:100] Creating Layer resnet6a_btlnk_relu
I0825 17:21:29.096839 27361 net.cpp:434] resnet6a_btlnk_relu <- resnet6a_btlnk
I0825 17:21:29.096844 27361 net.cpp:395] resnet6a_btlnk_relu -> resnet6a_btlnk (in-place)
I0825 17:21:29.096850 27361 net.cpp:150] Setting up resnet6a_btlnk_relu
I0825 17:21:29.096854 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.096858 27361 net.cpp:165] Memory required for data: 1756364800
I0825 17:21:29.096861 27361 layer_factory.hpp:77] Creating layer resnet6a_conv
I0825 17:21:29.096868 27361 net.cpp:100] Creating Layer resnet6a_conv
I0825 17:21:29.096871 27361 net.cpp:434] resnet6a_conv <- resnet6a_btlnk
I0825 17:21:29.096878 27361 net.cpp:408] resnet6a_conv -> resnet6a_conv
I0825 17:21:29.097971 27361 net.cpp:150] Setting up resnet6a_conv
I0825 17:21:29.097980 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.097982 27361 net.cpp:165] Memory required for data: 1757413376
I0825 17:21:29.097987 27361 layer_factory.hpp:77] Creating layer resnet6a_conv_relu
I0825 17:21:29.097995 27361 net.cpp:100] Creating Layer resnet6a_conv_relu
I0825 17:21:29.098000 27361 net.cpp:434] resnet6a_conv_relu <- resnet6a_conv
I0825 17:21:29.098003 27361 net.cpp:395] resnet6a_conv_relu -> resnet6a_conv (in-place)
I0825 17:21:29.098009 27361 net.cpp:150] Setting up resnet6a_conv_relu
I0825 17:21:29.098013 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.098016 27361 net.cpp:165] Memory required for data: 1758461952
I0825 17:21:29.098019 27361 layer_factory.hpp:77] Creating layer resnet6a_expnd
I0825 17:21:29.098026 27361 net.cpp:100] Creating Layer resnet6a_expnd
I0825 17:21:29.098031 27361 net.cpp:434] resnet6a_expnd <- resnet6a_conv
I0825 17:21:29.098037 27361 net.cpp:408] resnet6a_expnd -> resnet6a_expnd
I0825 17:21:29.099031 27361 net.cpp:150] Setting up resnet6a_expnd
I0825 17:21:29.099040 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.099045 27361 net.cpp:165] Memory required for data: 1766850560
I0825 17:21:29.099051 27361 layer_factory.hpp:77] Creating layer resnet6a_eltwise
I0825 17:21:29.099058 27361 net.cpp:100] Creating Layer resnet6a_eltwise
I0825 17:21:29.099062 27361 net.cpp:434] resnet6a_eltwise <- resnet6a_bypass
I0825 17:21:29.099067 27361 net.cpp:434] resnet6a_eltwise <- resnet6a_expnd
I0825 17:21:29.099072 27361 net.cpp:408] resnet6a_eltwise -> resnet6a_eltwise
I0825 17:21:29.099092 27361 net.cpp:150] Setting up resnet6a_eltwise
I0825 17:21:29.099097 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.099100 27361 net.cpp:165] Memory required for data: 1775239168
I0825 17:21:29.099104 27361 layer_factory.hpp:77] Creating layer resnet6a_eltwise_relu
I0825 17:21:29.099109 27361 net.cpp:100] Creating Layer resnet6a_eltwise_relu
I0825 17:21:29.099112 27361 net.cpp:434] resnet6a_eltwise_relu <- resnet6a_eltwise
I0825 17:21:29.099118 27361 net.cpp:395] resnet6a_eltwise_relu -> resnet6a_eltwise (in-place)
I0825 17:21:29.099123 27361 net.cpp:150] Setting up resnet6a_eltwise_relu
I0825 17:21:29.099128 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.099130 27361 net.cpp:165] Memory required for data: 1783627776
I0825 17:21:29.099134 27361 layer_factory.hpp:77] Creating layer resnet6a_eltwise_resnet6a_eltwise_relu_0_split
I0825 17:21:29.099139 27361 net.cpp:100] Creating Layer resnet6a_eltwise_resnet6a_eltwise_relu_0_split
I0825 17:21:29.099143 27361 net.cpp:434] resnet6a_eltwise_resnet6a_eltwise_relu_0_split <- resnet6a_eltwise
I0825 17:21:29.099148 27361 net.cpp:408] resnet6a_eltwise_resnet6a_eltwise_relu_0_split -> resnet6a_eltwise_resnet6a_eltwise_relu_0_split_0
I0825 17:21:29.099159 27361 net.cpp:408] resnet6a_eltwise_resnet6a_eltwise_relu_0_split -> resnet6a_eltwise_resnet6a_eltwise_relu_0_split_1
I0825 17:21:29.099185 27361 net.cpp:150] Setting up resnet6a_eltwise_resnet6a_eltwise_relu_0_split
I0825 17:21:29.099190 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.099195 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.099198 27361 net.cpp:165] Memory required for data: 1800404992
I0825 17:21:29.099201 27361 layer_factory.hpp:77] Creating layer resnet6b_btlnk
I0825 17:21:29.099210 27361 net.cpp:100] Creating Layer resnet6b_btlnk
I0825 17:21:29.099213 27361 net.cpp:434] resnet6b_btlnk <- resnet6a_eltwise_resnet6a_eltwise_relu_0_split_0
I0825 17:21:29.099218 27361 net.cpp:408] resnet6b_btlnk -> resnet6b_btlnk
I0825 17:21:29.100205 27361 net.cpp:150] Setting up resnet6b_btlnk
I0825 17:21:29.100214 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.100217 27361 net.cpp:165] Memory required for data: 1801453568
I0825 17:21:29.100222 27361 layer_factory.hpp:77] Creating layer resnet6b_btlnk_relu
I0825 17:21:29.100227 27361 net.cpp:100] Creating Layer resnet6b_btlnk_relu
I0825 17:21:29.100231 27361 net.cpp:434] resnet6b_btlnk_relu <- resnet6b_btlnk
I0825 17:21:29.100236 27361 net.cpp:395] resnet6b_btlnk_relu -> resnet6b_btlnk (in-place)
I0825 17:21:29.100241 27361 net.cpp:150] Setting up resnet6b_btlnk_relu
I0825 17:21:29.100246 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.100250 27361 net.cpp:165] Memory required for data: 1802502144
I0825 17:21:29.100252 27361 layer_factory.hpp:77] Creating layer resnet6b_conv
I0825 17:21:29.100258 27361 net.cpp:100] Creating Layer resnet6b_conv
I0825 17:21:29.100261 27361 net.cpp:434] resnet6b_conv <- resnet6b_btlnk
I0825 17:21:29.100266 27361 net.cpp:408] resnet6b_conv -> resnet6b_conv
I0825 17:21:29.101359 27361 net.cpp:150] Setting up resnet6b_conv
I0825 17:21:29.101367 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.101371 27361 net.cpp:165] Memory required for data: 1803550720
I0825 17:21:29.101377 27361 layer_factory.hpp:77] Creating layer resnet6b_conv_relu
I0825 17:21:29.101382 27361 net.cpp:100] Creating Layer resnet6b_conv_relu
I0825 17:21:29.101385 27361 net.cpp:434] resnet6b_conv_relu <- resnet6b_conv
I0825 17:21:29.101392 27361 net.cpp:395] resnet6b_conv_relu -> resnet6b_conv (in-place)
I0825 17:21:29.101399 27361 net.cpp:150] Setting up resnet6b_conv_relu
I0825 17:21:29.101403 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.101408 27361 net.cpp:165] Memory required for data: 1804599296
I0825 17:21:29.101410 27361 layer_factory.hpp:77] Creating layer resnet6b_expnd
I0825 17:21:29.101416 27361 net.cpp:100] Creating Layer resnet6b_expnd
I0825 17:21:29.101420 27361 net.cpp:434] resnet6b_expnd <- resnet6b_conv
I0825 17:21:29.101424 27361 net.cpp:408] resnet6b_expnd -> resnet6b_expnd
I0825 17:21:29.102409 27361 net.cpp:150] Setting up resnet6b_expnd
I0825 17:21:29.102417 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.102421 27361 net.cpp:165] Memory required for data: 1812987904
I0825 17:21:29.102424 27361 layer_factory.hpp:77] Creating layer resnet6b_eltwise
I0825 17:21:29.102430 27361 net.cpp:100] Creating Layer resnet6b_eltwise
I0825 17:21:29.102434 27361 net.cpp:434] resnet6b_eltwise <- resnet6a_eltwise_resnet6a_eltwise_relu_0_split_1
I0825 17:21:29.102438 27361 net.cpp:434] resnet6b_eltwise <- resnet6b_expnd
I0825 17:21:29.102443 27361 net.cpp:408] resnet6b_eltwise -> resnet6b_eltwise
I0825 17:21:29.102461 27361 net.cpp:150] Setting up resnet6b_eltwise
I0825 17:21:29.102468 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.102470 27361 net.cpp:165] Memory required for data: 1821376512
I0825 17:21:29.102473 27361 layer_factory.hpp:77] Creating layer resnet6b_eltwise_relu
I0825 17:21:29.102479 27361 net.cpp:100] Creating Layer resnet6b_eltwise_relu
I0825 17:21:29.102483 27361 net.cpp:434] resnet6b_eltwise_relu <- resnet6b_eltwise
I0825 17:21:29.102493 27361 net.cpp:395] resnet6b_eltwise_relu -> resnet6b_eltwise (in-place)
I0825 17:21:29.102497 27361 net.cpp:150] Setting up resnet6b_eltwise_relu
I0825 17:21:29.102502 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.102505 27361 net.cpp:165] Memory required for data: 1829765120
I0825 17:21:29.102509 27361 layer_factory.hpp:77] Creating layer unpool3
I0825 17:21:29.102517 27361 net.cpp:100] Creating Layer unpool3
I0825 17:21:29.102521 27361 net.cpp:434] unpool3 <- resnet6b_eltwise
I0825 17:21:29.102530 27361 net.cpp:408] unpool3 -> unpool3
I0825 17:21:29.130956 27361 net.cpp:150] Setting up unpool3
I0825 17:21:29.130973 27361 net.cpp:157] Top shape: 1 512 128 128 (8388608)
I0825 17:21:29.130977 27361 net.cpp:165] Memory required for data: 1863319552
I0825 17:21:29.130983 27361 layer_factory.hpp:77] Creating layer concat37_concat
I0825 17:21:29.130991 27361 net.cpp:100] Creating Layer concat37_concat
I0825 17:21:29.130995 27361 net.cpp:434] concat37_concat <- resnet3b_eltwise_resnet3b_eltwise_relu_0_split_1
I0825 17:21:29.131000 27361 net.cpp:434] concat37_concat <- unpool3
I0825 17:21:29.131006 27361 net.cpp:408] concat37_concat -> concat37_concat
I0825 17:21:29.131029 27361 net.cpp:150] Setting up concat37_concat
I0825 17:21:29.131036 27361 net.cpp:157] Top shape: 1 768 128 128 (12582912)
I0825 17:21:29.131038 27361 net.cpp:165] Memory required for data: 1913651200
I0825 17:21:29.131042 27361 layer_factory.hpp:77] Creating layer concat37_concat_concat37_concat_0_split
I0825 17:21:29.131047 27361 net.cpp:100] Creating Layer concat37_concat_concat37_concat_0_split
I0825 17:21:29.131050 27361 net.cpp:434] concat37_concat_concat37_concat_0_split <- concat37_concat
I0825 17:21:29.131057 27361 net.cpp:408] concat37_concat_concat37_concat_0_split -> concat37_concat_concat37_concat_0_split_0
I0825 17:21:29.131062 27361 net.cpp:408] concat37_concat_concat37_concat_0_split -> concat37_concat_concat37_concat_0_split_1
I0825 17:21:29.131090 27361 net.cpp:150] Setting up concat37_concat_concat37_concat_0_split
I0825 17:21:29.131096 27361 net.cpp:157] Top shape: 1 768 128 128 (12582912)
I0825 17:21:29.131100 27361 net.cpp:157] Top shape: 1 768 128 128 (12582912)
I0825 17:21:29.131103 27361 net.cpp:165] Memory required for data: 2014314496
I0825 17:21:29.131108 27361 layer_factory.hpp:77] Creating layer resnet7a_bypass
I0825 17:21:29.131116 27361 net.cpp:100] Creating Layer resnet7a_bypass
I0825 17:21:29.131120 27361 net.cpp:434] resnet7a_bypass <- concat37_concat_concat37_concat_0_split_0
I0825 17:21:29.131129 27361 net.cpp:408] resnet7a_bypass -> resnet7a_bypass
I0825 17:21:29.136724 27361 net.cpp:150] Setting up resnet7a_bypass
I0825 17:21:29.136739 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.136742 27361 net.cpp:165] Memory required for data: 2031091712
I0825 17:21:29.136747 27361 layer_factory.hpp:77] Creating layer resnet7a_btlnk
I0825 17:21:29.136759 27361 net.cpp:100] Creating Layer resnet7a_btlnk
I0825 17:21:29.136764 27361 net.cpp:434] resnet7a_btlnk <- concat37_concat_concat37_concat_0_split_1
I0825 17:21:29.136768 27361 net.cpp:408] resnet7a_btlnk -> resnet7a_btlnk
I0825 17:21:29.137549 27361 net.cpp:150] Setting up resnet7a_btlnk
I0825 17:21:29.137557 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.137562 27361 net.cpp:165] Memory required for data: 2033188864
I0825 17:21:29.137565 27361 layer_factory.hpp:77] Creating layer resnet7a_btlnk_relu
I0825 17:21:29.137572 27361 net.cpp:100] Creating Layer resnet7a_btlnk_relu
I0825 17:21:29.137574 27361 net.cpp:434] resnet7a_btlnk_relu <- resnet7a_btlnk
I0825 17:21:29.137579 27361 net.cpp:395] resnet7a_btlnk_relu -> resnet7a_btlnk (in-place)
I0825 17:21:29.137585 27361 net.cpp:150] Setting up resnet7a_btlnk_relu
I0825 17:21:29.137589 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.137593 27361 net.cpp:165] Memory required for data: 2035286016
I0825 17:21:29.137595 27361 layer_factory.hpp:77] Creating layer resnet7a_conv
I0825 17:21:29.137604 27361 net.cpp:100] Creating Layer resnet7a_conv
I0825 17:21:29.137614 27361 net.cpp:434] resnet7a_conv <- resnet7a_btlnk
I0825 17:21:29.137619 27361 net.cpp:408] resnet7a_conv -> resnet7a_conv
I0825 17:21:29.137998 27361 net.cpp:150] Setting up resnet7a_conv
I0825 17:21:29.138006 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.138010 27361 net.cpp:165] Memory required for data: 2037383168
I0825 17:21:29.138015 27361 layer_factory.hpp:77] Creating layer resnet7a_conv_relu
I0825 17:21:29.138020 27361 net.cpp:100] Creating Layer resnet7a_conv_relu
I0825 17:21:29.138023 27361 net.cpp:434] resnet7a_conv_relu <- resnet7a_conv
I0825 17:21:29.138028 27361 net.cpp:395] resnet7a_conv_relu -> resnet7a_conv (in-place)
I0825 17:21:29.138033 27361 net.cpp:150] Setting up resnet7a_conv_relu
I0825 17:21:29.138037 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.138041 27361 net.cpp:165] Memory required for data: 2039480320
I0825 17:21:29.138044 27361 layer_factory.hpp:77] Creating layer resnet7a_expnd
I0825 17:21:29.138051 27361 net.cpp:100] Creating Layer resnet7a_expnd
I0825 17:21:29.138053 27361 net.cpp:434] resnet7a_expnd <- resnet7a_conv
I0825 17:21:29.138059 27361 net.cpp:408] resnet7a_expnd -> resnet7a_expnd
I0825 17:21:29.138402 27361 net.cpp:150] Setting up resnet7a_expnd
I0825 17:21:29.138411 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.138413 27361 net.cpp:165] Memory required for data: 2056257536
I0825 17:21:29.138418 27361 layer_factory.hpp:77] Creating layer resnet7a_eltwise
I0825 17:21:29.138425 27361 net.cpp:100] Creating Layer resnet7a_eltwise
I0825 17:21:29.138429 27361 net.cpp:434] resnet7a_eltwise <- resnet7a_bypass
I0825 17:21:29.138434 27361 net.cpp:434] resnet7a_eltwise <- resnet7a_expnd
I0825 17:21:29.138438 27361 net.cpp:408] resnet7a_eltwise -> resnet7a_eltwise
I0825 17:21:29.138456 27361 net.cpp:150] Setting up resnet7a_eltwise
I0825 17:21:29.138461 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.138465 27361 net.cpp:165] Memory required for data: 2073034752
I0825 17:21:29.138468 27361 layer_factory.hpp:77] Creating layer resnet7a_eltwise_relu
I0825 17:21:29.138473 27361 net.cpp:100] Creating Layer resnet7a_eltwise_relu
I0825 17:21:29.138476 27361 net.cpp:434] resnet7a_eltwise_relu <- resnet7a_eltwise
I0825 17:21:29.138484 27361 net.cpp:395] resnet7a_eltwise_relu -> resnet7a_eltwise (in-place)
I0825 17:21:29.138489 27361 net.cpp:150] Setting up resnet7a_eltwise_relu
I0825 17:21:29.138492 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.138497 27361 net.cpp:165] Memory required for data: 2089811968
I0825 17:21:29.138502 27361 layer_factory.hpp:77] Creating layer resnet7a_eltwise_resnet7a_eltwise_relu_0_split
I0825 17:21:29.138506 27361 net.cpp:100] Creating Layer resnet7a_eltwise_resnet7a_eltwise_relu_0_split
I0825 17:21:29.138510 27361 net.cpp:434] resnet7a_eltwise_resnet7a_eltwise_relu_0_split <- resnet7a_eltwise
I0825 17:21:29.138514 27361 net.cpp:408] resnet7a_eltwise_resnet7a_eltwise_relu_0_split -> resnet7a_eltwise_resnet7a_eltwise_relu_0_split_0
I0825 17:21:29.138520 27361 net.cpp:408] resnet7a_eltwise_resnet7a_eltwise_relu_0_split -> resnet7a_eltwise_resnet7a_eltwise_relu_0_split_1
I0825 17:21:29.138546 27361 net.cpp:150] Setting up resnet7a_eltwise_resnet7a_eltwise_relu_0_split
I0825 17:21:29.138553 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.138557 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.138561 27361 net.cpp:165] Memory required for data: 2123366400
I0825 17:21:29.138563 27361 layer_factory.hpp:77] Creating layer resnet7b_btlnk
I0825 17:21:29.138571 27361 net.cpp:100] Creating Layer resnet7b_btlnk
I0825 17:21:29.138574 27361 net.cpp:434] resnet7b_btlnk <- resnet7a_eltwise_resnet7a_eltwise_relu_0_split_0
I0825 17:21:29.138579 27361 net.cpp:408] resnet7b_btlnk -> resnet7b_btlnk
I0825 17:21:29.138929 27361 net.cpp:150] Setting up resnet7b_btlnk
I0825 17:21:29.138938 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.138942 27361 net.cpp:165] Memory required for data: 2125463552
I0825 17:21:29.138952 27361 layer_factory.hpp:77] Creating layer resnet7b_btlnk_relu
I0825 17:21:29.138958 27361 net.cpp:100] Creating Layer resnet7b_btlnk_relu
I0825 17:21:29.138963 27361 net.cpp:434] resnet7b_btlnk_relu <- resnet7b_btlnk
I0825 17:21:29.138967 27361 net.cpp:395] resnet7b_btlnk_relu -> resnet7b_btlnk (in-place)
I0825 17:21:29.138972 27361 net.cpp:150] Setting up resnet7b_btlnk_relu
I0825 17:21:29.138978 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.138980 27361 net.cpp:165] Memory required for data: 2127560704
I0825 17:21:29.138983 27361 layer_factory.hpp:77] Creating layer resnet7b_conv
I0825 17:21:29.138993 27361 net.cpp:100] Creating Layer resnet7b_conv
I0825 17:21:29.138998 27361 net.cpp:434] resnet7b_conv <- resnet7b_btlnk
I0825 17:21:29.139003 27361 net.cpp:408] resnet7b_conv -> resnet7b_conv
I0825 17:21:29.139379 27361 net.cpp:150] Setting up resnet7b_conv
I0825 17:21:29.139387 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.139390 27361 net.cpp:165] Memory required for data: 2129657856
I0825 17:21:29.139396 27361 layer_factory.hpp:77] Creating layer resnet7b_conv_relu
I0825 17:21:29.139401 27361 net.cpp:100] Creating Layer resnet7b_conv_relu
I0825 17:21:29.139405 27361 net.cpp:434] resnet7b_conv_relu <- resnet7b_conv
I0825 17:21:29.139410 27361 net.cpp:395] resnet7b_conv_relu -> resnet7b_conv (in-place)
I0825 17:21:29.139415 27361 net.cpp:150] Setting up resnet7b_conv_relu
I0825 17:21:29.139420 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.139422 27361 net.cpp:165] Memory required for data: 2131755008
I0825 17:21:29.139425 27361 layer_factory.hpp:77] Creating layer resnet7b_expnd
I0825 17:21:29.139433 27361 net.cpp:100] Creating Layer resnet7b_expnd
I0825 17:21:29.139436 27361 net.cpp:434] resnet7b_expnd <- resnet7b_conv
I0825 17:21:29.139441 27361 net.cpp:408] resnet7b_expnd -> resnet7b_expnd
I0825 17:21:29.139786 27361 net.cpp:150] Setting up resnet7b_expnd
I0825 17:21:29.139792 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.139796 27361 net.cpp:165] Memory required for data: 2148532224
I0825 17:21:29.139801 27361 layer_factory.hpp:77] Creating layer resnet7b_eltwise
I0825 17:21:29.139806 27361 net.cpp:100] Creating Layer resnet7b_eltwise
I0825 17:21:29.139809 27361 net.cpp:434] resnet7b_eltwise <- resnet7a_eltwise_resnet7a_eltwise_relu_0_split_1
I0825 17:21:29.139814 27361 net.cpp:434] resnet7b_eltwise <- resnet7b_expnd
I0825 17:21:29.139822 27361 net.cpp:408] resnet7b_eltwise -> resnet7b_eltwise
I0825 17:21:29.139842 27361 net.cpp:150] Setting up resnet7b_eltwise
I0825 17:21:29.139847 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.139852 27361 net.cpp:165] Memory required for data: 2165309440
I0825 17:21:29.139855 27361 layer_factory.hpp:77] Creating layer resnet7b_eltwise_relu
I0825 17:21:29.139860 27361 net.cpp:100] Creating Layer resnet7b_eltwise_relu
I0825 17:21:29.139863 27361 net.cpp:434] resnet7b_eltwise_relu <- resnet7b_eltwise
I0825 17:21:29.139868 27361 net.cpp:395] resnet7b_eltwise_relu -> resnet7b_eltwise (in-place)
I0825 17:21:29.139873 27361 net.cpp:150] Setting up resnet7b_eltwise_relu
I0825 17:21:29.139876 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.139880 27361 net.cpp:165] Memory required for data: 2182086656
I0825 17:21:29.139883 27361 layer_factory.hpp:77] Creating layer unpool2
I0825 17:21:29.139891 27361 net.cpp:100] Creating Layer unpool2
I0825 17:21:29.139894 27361 net.cpp:434] unpool2 <- resnet7b_eltwise
I0825 17:21:29.139900 27361 net.cpp:408] unpool2 -> unpool2
I0825 17:21:29.144255 27361 net.cpp:150] Setting up unpool2
I0825 17:21:29.144273 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.144278 27361 net.cpp:165] Memory required for data: 2215641088
I0825 17:21:29.144284 27361 layer_factory.hpp:77] Creating layer concat28_concat
I0825 17:21:29.144290 27361 net.cpp:100] Creating Layer concat28_concat
I0825 17:21:29.144294 27361 net.cpp:434] concat28_concat <- resnet2b_eltwise_resnet2b_eltwise_relu_0_split_1
I0825 17:21:29.144306 27361 net.cpp:434] concat28_concat <- unpool2
I0825 17:21:29.144311 27361 net.cpp:408] concat28_concat -> concat28_concat
I0825 17:21:29.144337 27361 net.cpp:150] Setting up concat28_concat
I0825 17:21:29.144345 27361 net.cpp:157] Top shape: 1 256 256 256 (16777216)
I0825 17:21:29.144347 27361 net.cpp:165] Memory required for data: 2282749952
I0825 17:21:29.144351 27361 layer_factory.hpp:77] Creating layer concat28_concat_concat28_concat_0_split
I0825 17:21:29.144357 27361 net.cpp:100] Creating Layer concat28_concat_concat28_concat_0_split
I0825 17:21:29.144361 27361 net.cpp:434] concat28_concat_concat28_concat_0_split <- concat28_concat
I0825 17:21:29.144366 27361 net.cpp:408] concat28_concat_concat28_concat_0_split -> concat28_concat_concat28_concat_0_split_0
I0825 17:21:29.144371 27361 net.cpp:408] concat28_concat_concat28_concat_0_split -> concat28_concat_concat28_concat_0_split_1
I0825 17:21:29.144400 27361 net.cpp:150] Setting up concat28_concat_concat28_concat_0_split
I0825 17:21:29.144405 27361 net.cpp:157] Top shape: 1 256 256 256 (16777216)
I0825 17:21:29.144409 27361 net.cpp:157] Top shape: 1 256 256 256 (16777216)
I0825 17:21:29.144412 27361 net.cpp:165] Memory required for data: 2416967680
I0825 17:21:29.144417 27361 layer_factory.hpp:77] Creating layer resnet8a_bypass
I0825 17:21:29.144425 27361 net.cpp:100] Creating Layer resnet8a_bypass
I0825 17:21:29.144428 27361 net.cpp:434] resnet8a_bypass <- concat28_concat_concat28_concat_0_split_0
I0825 17:21:29.144433 27361 net.cpp:408] resnet8a_bypass -> resnet8a_bypass
I0825 17:21:29.145416 27361 net.cpp:150] Setting up resnet8a_bypass
I0825 17:21:29.145424 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.145427 27361 net.cpp:165] Memory required for data: 2450522112
I0825 17:21:29.145432 27361 layer_factory.hpp:77] Creating layer resnet8a_btlnk
I0825 17:21:29.145440 27361 net.cpp:100] Creating Layer resnet8a_btlnk
I0825 17:21:29.145444 27361 net.cpp:434] resnet8a_btlnk <- concat28_concat_concat28_concat_0_split_1
I0825 17:21:29.145449 27361 net.cpp:408] resnet8a_btlnk -> resnet8a_btlnk
I0825 17:21:29.145695 27361 net.cpp:150] Setting up resnet8a_btlnk
I0825 17:21:29.145702 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.145705 27361 net.cpp:165] Memory required for data: 2454716416
I0825 17:21:29.145710 27361 layer_factory.hpp:77] Creating layer resnet8a_btlnk_relu
I0825 17:21:29.145715 27361 net.cpp:100] Creating Layer resnet8a_btlnk_relu
I0825 17:21:29.145722 27361 net.cpp:434] resnet8a_btlnk_relu <- resnet8a_btlnk
I0825 17:21:29.145730 27361 net.cpp:395] resnet8a_btlnk_relu -> resnet8a_btlnk (in-place)
I0825 17:21:29.145736 27361 net.cpp:150] Setting up resnet8a_btlnk_relu
I0825 17:21:29.145741 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.145745 27361 net.cpp:165] Memory required for data: 2458910720
I0825 17:21:29.145747 27361 layer_factory.hpp:77] Creating layer resnet8a_conv
I0825 17:21:29.145755 27361 net.cpp:100] Creating Layer resnet8a_conv
I0825 17:21:29.145758 27361 net.cpp:434] resnet8a_conv <- resnet8a_btlnk
I0825 17:21:29.145762 27361 net.cpp:408] resnet8a_conv -> resnet8a_conv
I0825 17:21:29.145961 27361 net.cpp:150] Setting up resnet8a_conv
I0825 17:21:29.145968 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.145972 27361 net.cpp:165] Memory required for data: 2463105024
I0825 17:21:29.145977 27361 layer_factory.hpp:77] Creating layer resnet8a_conv_relu
I0825 17:21:29.145982 27361 net.cpp:100] Creating Layer resnet8a_conv_relu
I0825 17:21:29.145987 27361 net.cpp:434] resnet8a_conv_relu <- resnet8a_conv
I0825 17:21:29.145992 27361 net.cpp:395] resnet8a_conv_relu -> resnet8a_conv (in-place)
I0825 17:21:29.145997 27361 net.cpp:150] Setting up resnet8a_conv_relu
I0825 17:21:29.146000 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.146003 27361 net.cpp:165] Memory required for data: 2467299328
I0825 17:21:29.146006 27361 layer_factory.hpp:77] Creating layer resnet8a_expnd
I0825 17:21:29.146018 27361 net.cpp:100] Creating Layer resnet8a_expnd
I0825 17:21:29.146028 27361 net.cpp:434] resnet8a_expnd <- resnet8a_conv
I0825 17:21:29.146033 27361 net.cpp:408] resnet8a_expnd -> resnet8a_expnd
I0825 17:21:29.146220 27361 net.cpp:150] Setting up resnet8a_expnd
I0825 17:21:29.146229 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.146231 27361 net.cpp:165] Memory required for data: 2500853760
I0825 17:21:29.146235 27361 layer_factory.hpp:77] Creating layer resnet8a_eltwise
I0825 17:21:29.146241 27361 net.cpp:100] Creating Layer resnet8a_eltwise
I0825 17:21:29.146245 27361 net.cpp:434] resnet8a_eltwise <- resnet8a_bypass
I0825 17:21:29.146250 27361 net.cpp:434] resnet8a_eltwise <- resnet8a_expnd
I0825 17:21:29.146255 27361 net.cpp:408] resnet8a_eltwise -> resnet8a_eltwise
I0825 17:21:29.146275 27361 net.cpp:150] Setting up resnet8a_eltwise
I0825 17:21:29.146280 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.146283 27361 net.cpp:165] Memory required for data: 2534408192
I0825 17:21:29.146286 27361 layer_factory.hpp:77] Creating layer resnet8a_eltwise_relu
I0825 17:21:29.146291 27361 net.cpp:100] Creating Layer resnet8a_eltwise_relu
I0825 17:21:29.146296 27361 net.cpp:434] resnet8a_eltwise_relu <- resnet8a_eltwise
I0825 17:21:29.146299 27361 net.cpp:395] resnet8a_eltwise_relu -> resnet8a_eltwise (in-place)
I0825 17:21:29.146304 27361 net.cpp:150] Setting up resnet8a_eltwise_relu
I0825 17:21:29.146308 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.146311 27361 net.cpp:165] Memory required for data: 2567962624
I0825 17:21:29.146316 27361 layer_factory.hpp:77] Creating layer resnet8a_eltwise_resnet8a_eltwise_relu_0_split
I0825 17:21:29.146320 27361 net.cpp:100] Creating Layer resnet8a_eltwise_resnet8a_eltwise_relu_0_split
I0825 17:21:29.146323 27361 net.cpp:434] resnet8a_eltwise_resnet8a_eltwise_relu_0_split <- resnet8a_eltwise
I0825 17:21:29.146327 27361 net.cpp:408] resnet8a_eltwise_resnet8a_eltwise_relu_0_split -> resnet8a_eltwise_resnet8a_eltwise_relu_0_split_0
I0825 17:21:29.146333 27361 net.cpp:408] resnet8a_eltwise_resnet8a_eltwise_relu_0_split -> resnet8a_eltwise_resnet8a_eltwise_relu_0_split_1
I0825 17:21:29.146360 27361 net.cpp:150] Setting up resnet8a_eltwise_resnet8a_eltwise_relu_0_split
I0825 17:21:29.146366 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.146370 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.146373 27361 net.cpp:165] Memory required for data: 2635071488
I0825 17:21:29.146380 27361 layer_factory.hpp:77] Creating layer resnet8b_btlnk
I0825 17:21:29.146389 27361 net.cpp:100] Creating Layer resnet8b_btlnk
I0825 17:21:29.146392 27361 net.cpp:434] resnet8b_btlnk <- resnet8a_eltwise_resnet8a_eltwise_relu_0_split_0
I0825 17:21:29.146399 27361 net.cpp:408] resnet8b_btlnk -> resnet8b_btlnk
I0825 17:21:29.146584 27361 net.cpp:150] Setting up resnet8b_btlnk
I0825 17:21:29.146595 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.146600 27361 net.cpp:165] Memory required for data: 2639265792
I0825 17:21:29.146603 27361 layer_factory.hpp:77] Creating layer resnet8b_btlnk_relu
I0825 17:21:29.146610 27361 net.cpp:100] Creating Layer resnet8b_btlnk_relu
I0825 17:21:29.146613 27361 net.cpp:434] resnet8b_btlnk_relu <- resnet8b_btlnk
I0825 17:21:29.146617 27361 net.cpp:395] resnet8b_btlnk_relu -> resnet8b_btlnk (in-place)
I0825 17:21:29.146622 27361 net.cpp:150] Setting up resnet8b_btlnk_relu
I0825 17:21:29.146626 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.146631 27361 net.cpp:165] Memory required for data: 2643460096
I0825 17:21:29.146633 27361 layer_factory.hpp:77] Creating layer resnet8b_conv
I0825 17:21:29.146641 27361 net.cpp:100] Creating Layer resnet8b_conv
I0825 17:21:29.146644 27361 net.cpp:434] resnet8b_conv <- resnet8b_btlnk
I0825 17:21:29.146649 27361 net.cpp:408] resnet8b_conv -> resnet8b_conv
I0825 17:21:29.146845 27361 net.cpp:150] Setting up resnet8b_conv
I0825 17:21:29.146852 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.146855 27361 net.cpp:165] Memory required for data: 2647654400
I0825 17:21:29.146867 27361 layer_factory.hpp:77] Creating layer resnet8b_conv_relu
I0825 17:21:29.146873 27361 net.cpp:100] Creating Layer resnet8b_conv_relu
I0825 17:21:29.146878 27361 net.cpp:434] resnet8b_conv_relu <- resnet8b_conv
I0825 17:21:29.146883 27361 net.cpp:395] resnet8b_conv_relu -> resnet8b_conv (in-place)
I0825 17:21:29.146888 27361 net.cpp:150] Setting up resnet8b_conv_relu
I0825 17:21:29.146891 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.146894 27361 net.cpp:165] Memory required for data: 2651848704
I0825 17:21:29.146898 27361 layer_factory.hpp:77] Creating layer resnet8b_expnd
I0825 17:21:29.146903 27361 net.cpp:100] Creating Layer resnet8b_expnd
I0825 17:21:29.146908 27361 net.cpp:434] resnet8b_expnd <- resnet8b_conv
I0825 17:21:29.146913 27361 net.cpp:408] resnet8b_expnd -> resnet8b_expnd
I0825 17:21:29.147105 27361 net.cpp:150] Setting up resnet8b_expnd
I0825 17:21:29.147114 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.147116 27361 net.cpp:165] Memory required for data: 2685403136
I0825 17:21:29.147121 27361 layer_factory.hpp:77] Creating layer resnet8b_eltwise
I0825 17:21:29.147128 27361 net.cpp:100] Creating Layer resnet8b_eltwise
I0825 17:21:29.147132 27361 net.cpp:434] resnet8b_eltwise <- resnet8a_eltwise_resnet8a_eltwise_relu_0_split_1
I0825 17:21:29.147137 27361 net.cpp:434] resnet8b_eltwise <- resnet8b_expnd
I0825 17:21:29.147141 27361 net.cpp:408] resnet8b_eltwise -> resnet8b_eltwise
I0825 17:21:29.147159 27361 net.cpp:150] Setting up resnet8b_eltwise
I0825 17:21:29.147166 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.147168 27361 net.cpp:165] Memory required for data: 2718957568
I0825 17:21:29.147171 27361 layer_factory.hpp:77] Creating layer resnet8b_eltwise_relu
I0825 17:21:29.147177 27361 net.cpp:100] Creating Layer resnet8b_eltwise_relu
I0825 17:21:29.147181 27361 net.cpp:434] resnet8b_eltwise_relu <- resnet8b_eltwise
I0825 17:21:29.147186 27361 net.cpp:395] resnet8b_eltwise_relu -> resnet8b_eltwise (in-place)
I0825 17:21:29.147191 27361 net.cpp:150] Setting up resnet8b_eltwise_relu
I0825 17:21:29.147194 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.147197 27361 net.cpp:165] Memory required for data: 2752512000
I0825 17:21:29.147200 27361 layer_factory.hpp:77] Creating layer unpool1
I0825 17:21:29.147207 27361 net.cpp:100] Creating Layer unpool1
I0825 17:21:29.147210 27361 net.cpp:434] unpool1 <- resnet8b_eltwise
I0825 17:21:29.147220 27361 net.cpp:408] unpool1 -> unpool1
I0825 17:21:29.148766 27361 net.cpp:150] Setting up unpool1
I0825 17:21:29.148778 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.148782 27361 net.cpp:165] Memory required for data: 2819620864
I0825 17:21:29.148788 27361 layer_factory.hpp:77] Creating layer concat19_concat
I0825 17:21:29.148797 27361 net.cpp:100] Creating Layer concat19_concat
I0825 17:21:29.148800 27361 net.cpp:434] concat19_concat <- resnet1b_eltwise_resnet1b_eltwise_relu_0_split_1
I0825 17:21:29.148805 27361 net.cpp:434] concat19_concat <- unpool1
I0825 17:21:29.148813 27361 net.cpp:408] concat19_concat -> concat19_concat
I0825 17:21:29.148841 27361 net.cpp:150] Setting up concat19_concat
I0825 17:21:29.148849 27361 net.cpp:157] Top shape: 1 128 512 512 (33554432)
I0825 17:21:29.148852 27361 net.cpp:165] Memory required for data: 2953838592
I0825 17:21:29.148856 27361 layer_factory.hpp:77] Creating layer concat19_concat_concat19_concat_0_split
I0825 17:21:29.148861 27361 net.cpp:100] Creating Layer concat19_concat_concat19_concat_0_split
I0825 17:21:29.148865 27361 net.cpp:434] concat19_concat_concat19_concat_0_split <- concat19_concat
I0825 17:21:29.148870 27361 net.cpp:408] concat19_concat_concat19_concat_0_split -> concat19_concat_concat19_concat_0_split_0
I0825 17:21:29.148875 27361 net.cpp:408] concat19_concat_concat19_concat_0_split -> concat19_concat_concat19_concat_0_split_1
I0825 17:21:29.148905 27361 net.cpp:150] Setting up concat19_concat_concat19_concat_0_split
I0825 17:21:29.148910 27361 net.cpp:157] Top shape: 1 128 512 512 (33554432)
I0825 17:21:29.148921 27361 net.cpp:157] Top shape: 1 128 512 512 (33554432)
I0825 17:21:29.148926 27361 net.cpp:165] Memory required for data: 3222274048
I0825 17:21:29.148928 27361 layer_factory.hpp:77] Creating layer resnet9a_bypass
I0825 17:21:29.148936 27361 net.cpp:100] Creating Layer resnet9a_bypass
I0825 17:21:29.148941 27361 net.cpp:434] resnet9a_bypass <- concat19_concat_concat19_concat_0_split_0
I0825 17:21:29.148947 27361 net.cpp:408] resnet9a_bypass -> resnet9a_bypass
I0825 17:21:29.149298 27361 net.cpp:150] Setting up resnet9a_bypass
I0825 17:21:29.149305 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.149309 27361 net.cpp:165] Memory required for data: 3289382912
I0825 17:21:29.149322 27361 layer_factory.hpp:77] Creating layer resnet9a_btlnk
I0825 17:21:29.149330 27361 net.cpp:100] Creating Layer resnet9a_btlnk
I0825 17:21:29.149334 27361 net.cpp:434] resnet9a_btlnk <- concat19_concat_concat19_concat_0_split_1
I0825 17:21:29.149340 27361 net.cpp:408] resnet9a_btlnk -> resnet9a_btlnk
I0825 17:21:29.149505 27361 net.cpp:150] Setting up resnet9a_btlnk
I0825 17:21:29.149513 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.149515 27361 net.cpp:165] Memory required for data: 3297771520
I0825 17:21:29.149520 27361 layer_factory.hpp:77] Creating layer resnet9a_btlnk_relu
I0825 17:21:29.149525 27361 net.cpp:100] Creating Layer resnet9a_btlnk_relu
I0825 17:21:29.149529 27361 net.cpp:434] resnet9a_btlnk_relu <- resnet9a_btlnk
I0825 17:21:29.149534 27361 net.cpp:395] resnet9a_btlnk_relu -> resnet9a_btlnk (in-place)
I0825 17:21:29.149540 27361 net.cpp:150] Setting up resnet9a_btlnk_relu
I0825 17:21:29.149544 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.149547 27361 net.cpp:165] Memory required for data: 3306160128
I0825 17:21:29.149550 27361 layer_factory.hpp:77] Creating layer resnet9a_conv
I0825 17:21:29.149556 27361 net.cpp:100] Creating Layer resnet9a_conv
I0825 17:21:29.149560 27361 net.cpp:434] resnet9a_conv <- resnet9a_btlnk
I0825 17:21:29.149565 27361 net.cpp:408] resnet9a_conv -> resnet9a_conv
I0825 17:21:29.149715 27361 net.cpp:150] Setting up resnet9a_conv
I0825 17:21:29.149724 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.149726 27361 net.cpp:165] Memory required for data: 3314548736
I0825 17:21:29.149731 27361 layer_factory.hpp:77] Creating layer resnet9a_conv_relu
I0825 17:21:29.149736 27361 net.cpp:100] Creating Layer resnet9a_conv_relu
I0825 17:21:29.149744 27361 net.cpp:434] resnet9a_conv_relu <- resnet9a_conv
I0825 17:21:29.149749 27361 net.cpp:395] resnet9a_conv_relu -> resnet9a_conv (in-place)
I0825 17:21:29.149754 27361 net.cpp:150] Setting up resnet9a_conv_relu
I0825 17:21:29.149757 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.149760 27361 net.cpp:165] Memory required for data: 3322937344
I0825 17:21:29.149763 27361 layer_factory.hpp:77] Creating layer resnet9a_expnd
I0825 17:21:29.149772 27361 net.cpp:100] Creating Layer resnet9a_expnd
I0825 17:21:29.149775 27361 net.cpp:434] resnet9a_expnd <- resnet9a_conv
I0825 17:21:29.149780 27361 net.cpp:408] resnet9a_expnd -> resnet9a_expnd
I0825 17:21:29.149933 27361 net.cpp:150] Setting up resnet9a_expnd
I0825 17:21:29.149940 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.149943 27361 net.cpp:165] Memory required for data: 3390046208
I0825 17:21:29.149948 27361 layer_factory.hpp:77] Creating layer resnet9a_eltwise
I0825 17:21:29.149953 27361 net.cpp:100] Creating Layer resnet9a_eltwise
I0825 17:21:29.149957 27361 net.cpp:434] resnet9a_eltwise <- resnet9a_bypass
I0825 17:21:29.149962 27361 net.cpp:434] resnet9a_eltwise <- resnet9a_expnd
I0825 17:21:29.149966 27361 net.cpp:408] resnet9a_eltwise -> resnet9a_eltwise
I0825 17:21:29.149986 27361 net.cpp:150] Setting up resnet9a_eltwise
I0825 17:21:29.149992 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.149996 27361 net.cpp:165] Memory required for data: 3457155072
I0825 17:21:29.149998 27361 layer_factory.hpp:77] Creating layer resnet9a_eltwise_relu
I0825 17:21:29.150009 27361 net.cpp:100] Creating Layer resnet9a_eltwise_relu
I0825 17:21:29.150012 27361 net.cpp:434] resnet9a_eltwise_relu <- resnet9a_eltwise
I0825 17:21:29.150017 27361 net.cpp:395] resnet9a_eltwise_relu -> resnet9a_eltwise (in-place)
I0825 17:21:29.150022 27361 net.cpp:150] Setting up resnet9a_eltwise_relu
I0825 17:21:29.150027 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.150029 27361 net.cpp:165] Memory required for data: 3524263936
I0825 17:21:29.150032 27361 layer_factory.hpp:77] Creating layer resnet9a_eltwise_resnet9a_eltwise_relu_0_split
I0825 17:21:29.150038 27361 net.cpp:100] Creating Layer resnet9a_eltwise_resnet9a_eltwise_relu_0_split
I0825 17:21:29.150040 27361 net.cpp:434] resnet9a_eltwise_resnet9a_eltwise_relu_0_split <- resnet9a_eltwise
I0825 17:21:29.150045 27361 net.cpp:408] resnet9a_eltwise_resnet9a_eltwise_relu_0_split -> resnet9a_eltwise_resnet9a_eltwise_relu_0_split_0
I0825 17:21:29.150051 27361 net.cpp:408] resnet9a_eltwise_resnet9a_eltwise_relu_0_split -> resnet9a_eltwise_resnet9a_eltwise_relu_0_split_1
I0825 17:21:29.150079 27361 net.cpp:150] Setting up resnet9a_eltwise_resnet9a_eltwise_relu_0_split
I0825 17:21:29.150084 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.150089 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.150091 27361 net.cpp:165] Memory required for data: 3658481664
I0825 17:21:29.150095 27361 layer_factory.hpp:77] Creating layer resnet9b_bypass
I0825 17:21:29.150104 27361 net.cpp:100] Creating Layer resnet9b_bypass
I0825 17:21:29.150108 27361 net.cpp:434] resnet9b_bypass <- resnet9a_eltwise_resnet9a_eltwise_relu_0_split_0
I0825 17:21:29.150113 27361 net.cpp:408] resnet9b_bypass -> resnet9b_bypass
I0825 17:21:29.150354 27361 net.cpp:150] Setting up resnet9b_bypass
I0825 17:21:29.150362 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.150365 27361 net.cpp:165] Memory required for data: 3725590528
I0825 17:21:29.150369 27361 layer_factory.hpp:77] Creating layer resnet9b_btlnk
I0825 17:21:29.150377 27361 net.cpp:100] Creating Layer resnet9b_btlnk
I0825 17:21:29.150382 27361 net.cpp:434] resnet9b_btlnk <- resnet9a_eltwise_resnet9a_eltwise_relu_0_split_1
I0825 17:21:29.150387 27361 net.cpp:408] resnet9b_btlnk -> resnet9b_btlnk
I0825 17:21:29.150533 27361 net.cpp:150] Setting up resnet9b_btlnk
I0825 17:21:29.150540 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.150543 27361 net.cpp:165] Memory required for data: 3733979136
I0825 17:21:29.150552 27361 layer_factory.hpp:77] Creating layer resnet9b_btlnk_relu
I0825 17:21:29.150558 27361 net.cpp:100] Creating Layer resnet9b_btlnk_relu
I0825 17:21:29.150563 27361 net.cpp:434] resnet9b_btlnk_relu <- resnet9b_btlnk
I0825 17:21:29.150566 27361 net.cpp:395] resnet9b_btlnk_relu -> resnet9b_btlnk (in-place)
I0825 17:21:29.150571 27361 net.cpp:150] Setting up resnet9b_btlnk_relu
I0825 17:21:29.150576 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.150579 27361 net.cpp:165] Memory required for data: 3742367744
I0825 17:21:29.150583 27361 layer_factory.hpp:77] Creating layer resnet9b_conv
I0825 17:21:29.150595 27361 net.cpp:100] Creating Layer resnet9b_conv
I0825 17:21:29.150599 27361 net.cpp:434] resnet9b_conv <- resnet9b_btlnk
I0825 17:21:29.150606 27361 net.cpp:408] resnet9b_conv -> resnet9b_conv
I0825 17:21:29.150756 27361 net.cpp:150] Setting up resnet9b_conv
I0825 17:21:29.150764 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.150768 27361 net.cpp:165] Memory required for data: 3750756352
I0825 17:21:29.150773 27361 layer_factory.hpp:77] Creating layer resnet9b_conv_relu
I0825 17:21:29.150779 27361 net.cpp:100] Creating Layer resnet9b_conv_relu
I0825 17:21:29.150784 27361 net.cpp:434] resnet9b_conv_relu <- resnet9b_conv
I0825 17:21:29.150787 27361 net.cpp:395] resnet9b_conv_relu -> resnet9b_conv (in-place)
I0825 17:21:29.150792 27361 net.cpp:150] Setting up resnet9b_conv_relu
I0825 17:21:29.150796 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.150800 27361 net.cpp:165] Memory required for data: 3759144960
I0825 17:21:29.150810 27361 layer_factory.hpp:77] Creating layer resnet9b_expnd
I0825 17:21:29.150815 27361 net.cpp:100] Creating Layer resnet9b_expnd
I0825 17:21:29.150818 27361 net.cpp:434] resnet9b_expnd <- resnet9b_conv
I0825 17:21:29.150823 27361 net.cpp:408] resnet9b_expnd -> resnet9b_expnd
I0825 17:21:29.150975 27361 net.cpp:150] Setting up resnet9b_expnd
I0825 17:21:29.150984 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.150986 27361 net.cpp:165] Memory required for data: 3826253824
I0825 17:21:29.150990 27361 layer_factory.hpp:77] Creating layer resnet9b_eltwise
I0825 17:21:29.150998 27361 net.cpp:100] Creating Layer resnet9b_eltwise
I0825 17:21:29.151002 27361 net.cpp:434] resnet9b_eltwise <- resnet9b_bypass
I0825 17:21:29.151006 27361 net.cpp:434] resnet9b_eltwise <- resnet9b_expnd
I0825 17:21:29.151011 27361 net.cpp:408] resnet9b_eltwise -> resnet9b_eltwise
I0825 17:21:29.151029 27361 net.cpp:150] Setting up resnet9b_eltwise
I0825 17:21:29.151036 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.151038 27361 net.cpp:165] Memory required for data: 3893362688
I0825 17:21:29.151041 27361 layer_factory.hpp:77] Creating layer resnet9b_eltwise_relu
I0825 17:21:29.151046 27361 net.cpp:100] Creating Layer resnet9b_eltwise_relu
I0825 17:21:29.151051 27361 net.cpp:434] resnet9b_eltwise_relu <- resnet9b_eltwise
I0825 17:21:29.151056 27361 net.cpp:395] resnet9b_eltwise_relu -> resnet9b_eltwise (in-place)
I0825 17:21:29.151060 27361 net.cpp:150] Setting up resnet9b_eltwise_relu
I0825 17:21:29.151064 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.151067 27361 net.cpp:165] Memory required for data: 3960471552
I0825 17:21:29.151072 27361 layer_factory.hpp:77] Creating layer score_conv
I0825 17:21:29.151079 27361 net.cpp:100] Creating Layer score_conv
I0825 17:21:29.151082 27361 net.cpp:434] score_conv <- resnet9b_eltwise
I0825 17:21:29.151087 27361 net.cpp:408] score_conv -> score_conv
I0825 17:21:29.151789 27361 net.cpp:150] Setting up score_conv
I0825 17:21:29.151803 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.151806 27361 net.cpp:165] Memory required for data: 3964665856
I0825 17:21:29.151813 27361 layer_factory.hpp:77] Creating layer score_relu
I0825 17:21:29.151819 27361 net.cpp:100] Creating Layer score_relu
I0825 17:21:29.151823 27361 net.cpp:434] score_relu <- score_conv
I0825 17:21:29.151829 27361 net.cpp:395] score_relu -> score_conv (in-place)
I0825 17:21:29.151839 27361 net.cpp:150] Setting up score_relu
I0825 17:21:29.151842 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.151846 27361 net.cpp:165] Memory required for data: 3968860160
I0825 17:21:29.151849 27361 layer_factory.hpp:77] Creating layer crop_score
I0825 17:21:29.151860 27361 net.cpp:100] Creating Layer crop_score
I0825 17:21:29.151865 27361 net.cpp:434] crop_score <- score_conv
I0825 17:21:29.151868 27361 net.cpp:434] crop_score <- label_data_1_split_0
I0825 17:21:29.151875 27361 net.cpp:408] crop_score -> crop_score
I0825 17:21:29.151901 27361 net.cpp:150] Setting up crop_score
I0825 17:21:29.151907 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.151911 27361 net.cpp:165] Memory required for data: 3973054464
I0825 17:21:29.151913 27361 layer_factory.hpp:77] Creating layer crop_score_crop_score_0_split
I0825 17:21:29.151918 27361 net.cpp:100] Creating Layer crop_score_crop_score_0_split
I0825 17:21:29.151922 27361 net.cpp:434] crop_score_crop_score_0_split <- crop_score
I0825 17:21:29.151928 27361 net.cpp:408] crop_score_crop_score_0_split -> crop_score_crop_score_0_split_0
I0825 17:21:29.151933 27361 net.cpp:408] crop_score_crop_score_0_split -> crop_score_crop_score_0_split_1
I0825 17:21:29.151962 27361 net.cpp:150] Setting up crop_score_crop_score_0_split
I0825 17:21:29.151968 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.151971 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.151974 27361 net.cpp:165] Memory required for data: 3981443072
I0825 17:21:29.151983 27361 layer_factory.hpp:77] Creating layer softmaxloss
I0825 17:21:29.151990 27361 net.cpp:100] Creating Layer softmaxloss
I0825 17:21:29.151994 27361 net.cpp:434] softmaxloss <- crop_score_crop_score_0_split_0
I0825 17:21:29.151998 27361 net.cpp:434] softmaxloss <- label_data_1_split_1
I0825 17:21:29.152004 27361 net.cpp:408] softmaxloss -> softmaxloss
I0825 17:21:29.152011 27361 layer_factory.hpp:77] Creating layer softmaxloss
I0825 17:21:29.153836 27361 softmax_loss_layer.cpp:47] class_loss_weights[0] = 1
I0825 17:21:29.153862 27361 softmax_loss_layer.cpp:47] class_loss_weights[1] = 100
I0825 17:21:29.153868 27361 softmax_loss_layer.cpp:47] class_loss_weights[2] = 100
I0825 17:21:29.153872 27361 softmax_loss_layer.cpp:47] class_loss_weights[3] = 100
I0825 17:21:29.153899 27361 net.cpp:150] Setting up softmaxloss
I0825 17:21:29.153906 27361 net.cpp:157] Top shape: (1)
I0825 17:21:29.153909 27361 net.cpp:160]     with loss weight 1
I0825 17:21:29.153914 27361 net.cpp:165] Memory required for data: 3981443076
I0825 17:21:29.153918 27361 layer_factory.hpp:77] Creating layer accuracy
I0825 17:21:29.153925 27361 net.cpp:100] Creating Layer accuracy
I0825 17:21:29.153929 27361 net.cpp:434] accuracy <- crop_score_crop_score_0_split_1
I0825 17:21:29.153934 27361 net.cpp:434] accuracy <- label_data_1_split_2
I0825 17:21:29.153939 27361 net.cpp:408] accuracy -> accuracy
I0825 17:21:29.153945 27361 net.cpp:150] Setting up accuracy
I0825 17:21:29.153949 27361 net.cpp:157] Top shape: (1)
I0825 17:21:29.153954 27361 net.cpp:165] Memory required for data: 3981443080
I0825 17:21:29.153956 27361 net.cpp:228] accuracy does not need backward computation.
I0825 17:21:29.153960 27361 net.cpp:226] softmaxloss needs backward computation.
I0825 17:21:29.153964 27361 net.cpp:226] crop_score_crop_score_0_split needs backward computation.
I0825 17:21:29.153969 27361 net.cpp:226] crop_score needs backward computation.
I0825 17:21:29.153973 27361 net.cpp:226] score_relu needs backward computation.
I0825 17:21:29.153976 27361 net.cpp:226] score_conv needs backward computation.
I0825 17:21:29.153980 27361 net.cpp:226] resnet9b_eltwise_relu needs backward computation.
I0825 17:21:29.153983 27361 net.cpp:226] resnet9b_eltwise needs backward computation.
I0825 17:21:29.153987 27361 net.cpp:226] resnet9b_expnd needs backward computation.
I0825 17:21:29.153991 27361 net.cpp:226] resnet9b_conv_relu needs backward computation.
I0825 17:21:29.153997 27361 net.cpp:226] resnet9b_conv needs backward computation.
I0825 17:21:29.154001 27361 net.cpp:226] resnet9b_btlnk_relu needs backward computation.
I0825 17:21:29.154005 27361 net.cpp:226] resnet9b_btlnk needs backward computation.
I0825 17:21:29.154008 27361 net.cpp:226] resnet9b_bypass needs backward computation.
I0825 17:21:29.154012 27361 net.cpp:226] resnet9a_eltwise_resnet9a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154016 27361 net.cpp:226] resnet9a_eltwise_relu needs backward computation.
I0825 17:21:29.154019 27361 net.cpp:226] resnet9a_eltwise needs backward computation.
I0825 17:21:29.154022 27361 net.cpp:226] resnet9a_expnd needs backward computation.
I0825 17:21:29.154026 27361 net.cpp:226] resnet9a_conv_relu needs backward computation.
I0825 17:21:29.154029 27361 net.cpp:226] resnet9a_conv needs backward computation.
I0825 17:21:29.154032 27361 net.cpp:226] resnet9a_btlnk_relu needs backward computation.
I0825 17:21:29.154036 27361 net.cpp:226] resnet9a_btlnk needs backward computation.
I0825 17:21:29.154039 27361 net.cpp:226] resnet9a_bypass needs backward computation.
I0825 17:21:29.154042 27361 net.cpp:226] concat19_concat_concat19_concat_0_split needs backward computation.
I0825 17:21:29.154047 27361 net.cpp:226] concat19_concat needs backward computation.
I0825 17:21:29.154050 27361 net.cpp:226] unpool1 needs backward computation.
I0825 17:21:29.154053 27361 net.cpp:226] resnet8b_eltwise_relu needs backward computation.
I0825 17:21:29.154057 27361 net.cpp:226] resnet8b_eltwise needs backward computation.
I0825 17:21:29.154060 27361 net.cpp:226] resnet8b_expnd needs backward computation.
I0825 17:21:29.154069 27361 net.cpp:226] resnet8b_conv_relu needs backward computation.
I0825 17:21:29.154072 27361 net.cpp:226] resnet8b_conv needs backward computation.
I0825 17:21:29.154076 27361 net.cpp:226] resnet8b_btlnk_relu needs backward computation.
I0825 17:21:29.154079 27361 net.cpp:226] resnet8b_btlnk needs backward computation.
I0825 17:21:29.154083 27361 net.cpp:226] resnet8a_eltwise_resnet8a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154086 27361 net.cpp:226] resnet8a_eltwise_relu needs backward computation.
I0825 17:21:29.154089 27361 net.cpp:226] resnet8a_eltwise needs backward computation.
I0825 17:21:29.154093 27361 net.cpp:226] resnet8a_expnd needs backward computation.
I0825 17:21:29.154096 27361 net.cpp:226] resnet8a_conv_relu needs backward computation.
I0825 17:21:29.154100 27361 net.cpp:226] resnet8a_conv needs backward computation.
I0825 17:21:29.154103 27361 net.cpp:226] resnet8a_btlnk_relu needs backward computation.
I0825 17:21:29.154108 27361 net.cpp:226] resnet8a_btlnk needs backward computation.
I0825 17:21:29.154110 27361 net.cpp:226] resnet8a_bypass needs backward computation.
I0825 17:21:29.154114 27361 net.cpp:226] concat28_concat_concat28_concat_0_split needs backward computation.
I0825 17:21:29.154117 27361 net.cpp:226] concat28_concat needs backward computation.
I0825 17:21:29.154121 27361 net.cpp:226] unpool2 needs backward computation.
I0825 17:21:29.154125 27361 net.cpp:226] resnet7b_eltwise_relu needs backward computation.
I0825 17:21:29.154129 27361 net.cpp:226] resnet7b_eltwise needs backward computation.
I0825 17:21:29.154132 27361 net.cpp:226] resnet7b_expnd needs backward computation.
I0825 17:21:29.154136 27361 net.cpp:226] resnet7b_conv_relu needs backward computation.
I0825 17:21:29.154139 27361 net.cpp:226] resnet7b_conv needs backward computation.
I0825 17:21:29.154144 27361 net.cpp:226] resnet7b_btlnk_relu needs backward computation.
I0825 17:21:29.154146 27361 net.cpp:226] resnet7b_btlnk needs backward computation.
I0825 17:21:29.154150 27361 net.cpp:226] resnet7a_eltwise_resnet7a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154153 27361 net.cpp:226] resnet7a_eltwise_relu needs backward computation.
I0825 17:21:29.154157 27361 net.cpp:226] resnet7a_eltwise needs backward computation.
I0825 17:21:29.154161 27361 net.cpp:226] resnet7a_expnd needs backward computation.
I0825 17:21:29.154165 27361 net.cpp:226] resnet7a_conv_relu needs backward computation.
I0825 17:21:29.154170 27361 net.cpp:226] resnet7a_conv needs backward computation.
I0825 17:21:29.154175 27361 net.cpp:226] resnet7a_btlnk_relu needs backward computation.
I0825 17:21:29.154177 27361 net.cpp:226] resnet7a_btlnk needs backward computation.
I0825 17:21:29.154181 27361 net.cpp:226] resnet7a_bypass needs backward computation.
I0825 17:21:29.154184 27361 net.cpp:226] concat37_concat_concat37_concat_0_split needs backward computation.
I0825 17:21:29.154188 27361 net.cpp:226] concat37_concat needs backward computation.
I0825 17:21:29.154192 27361 net.cpp:226] unpool3 needs backward computation.
I0825 17:21:29.154196 27361 net.cpp:226] resnet6b_eltwise_relu needs backward computation.
I0825 17:21:29.154199 27361 net.cpp:226] resnet6b_eltwise needs backward computation.
I0825 17:21:29.154203 27361 net.cpp:226] resnet6b_expnd needs backward computation.
I0825 17:21:29.154207 27361 net.cpp:226] resnet6b_conv_relu needs backward computation.
I0825 17:21:29.154211 27361 net.cpp:226] resnet6b_conv needs backward computation.
I0825 17:21:29.154214 27361 net.cpp:226] resnet6b_btlnk_relu needs backward computation.
I0825 17:21:29.154218 27361 net.cpp:226] resnet6b_btlnk needs backward computation.
I0825 17:21:29.154222 27361 net.cpp:226] resnet6a_eltwise_resnet6a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154225 27361 net.cpp:226] resnet6a_eltwise_relu needs backward computation.
I0825 17:21:29.154229 27361 net.cpp:226] resnet6a_eltwise needs backward computation.
I0825 17:21:29.154233 27361 net.cpp:226] resnet6a_expnd needs backward computation.
I0825 17:21:29.154240 27361 net.cpp:226] resnet6a_conv_relu needs backward computation.
I0825 17:21:29.154244 27361 net.cpp:226] resnet6a_conv needs backward computation.
I0825 17:21:29.154248 27361 net.cpp:226] resnet6a_btlnk_relu needs backward computation.
I0825 17:21:29.154252 27361 net.cpp:226] resnet6a_btlnk needs backward computation.
I0825 17:21:29.154255 27361 net.cpp:226] resnet6a_bypass needs backward computation.
I0825 17:21:29.154259 27361 net.cpp:226] concat56_concat_concat56_concat_0_split needs backward computation.
I0825 17:21:29.154263 27361 net.cpp:226] concat56_concat needs backward computation.
I0825 17:21:29.154268 27361 net.cpp:226] unpool4 needs backward computation.
I0825 17:21:29.154271 27361 net.cpp:226] resnet5b_eltwise_relu needs backward computation.
I0825 17:21:29.154274 27361 net.cpp:226] resnet5b_eltwise needs backward computation.
I0825 17:21:29.154279 27361 net.cpp:226] resnet5b_expnd needs backward computation.
I0825 17:21:29.154283 27361 net.cpp:226] resnet5b_conv_relu needs backward computation.
I0825 17:21:29.154286 27361 net.cpp:226] resnet5b_conv needs backward computation.
I0825 17:21:29.154289 27361 net.cpp:226] resnet5b_btlnk_relu needs backward computation.
I0825 17:21:29.154294 27361 net.cpp:226] resnet5b_btlnk needs backward computation.
I0825 17:21:29.154297 27361 net.cpp:226] resnet5a_eltwise_resnet5a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154301 27361 net.cpp:226] resnet5a_eltwise_relu needs backward computation.
I0825 17:21:29.154304 27361 net.cpp:226] resnet5a_eltwise needs backward computation.
I0825 17:21:29.154309 27361 net.cpp:226] resnet5a_expnd needs backward computation.
I0825 17:21:29.154312 27361 net.cpp:226] resnet5a_conv_relu needs backward computation.
I0825 17:21:29.154316 27361 net.cpp:226] resnet5a_conv needs backward computation.
I0825 17:21:29.154320 27361 net.cpp:226] resnet5a_btlnk_relu needs backward computation.
I0825 17:21:29.154323 27361 net.cpp:226] resnet5a_btlnk needs backward computation.
I0825 17:21:29.154327 27361 net.cpp:226] resnet5a_bypass needs backward computation.
I0825 17:21:29.154331 27361 net.cpp:226] maxpool4_maxpool4_0_split needs backward computation.
I0825 17:21:29.154335 27361 net.cpp:226] maxpool4 needs backward computation.
I0825 17:21:29.154340 27361 net.cpp:226] resnet4b_eltwise_resnet4b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154343 27361 net.cpp:226] resnet4b_eltwise_relu needs backward computation.
I0825 17:21:29.154348 27361 net.cpp:226] resnet4b_eltwise needs backward computation.
I0825 17:21:29.154353 27361 net.cpp:226] resnet4b_expnd needs backward computation.
I0825 17:21:29.154357 27361 net.cpp:226] resnet4b_conv_relu needs backward computation.
I0825 17:21:29.154361 27361 net.cpp:226] resnet4b_conv needs backward computation.
I0825 17:21:29.154364 27361 net.cpp:226] resnet4b_btlnk_relu needs backward computation.
I0825 17:21:29.154368 27361 net.cpp:226] resnet4b_btlnk needs backward computation.
I0825 17:21:29.154373 27361 net.cpp:226] resnet4a_eltwise_resnet4a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154377 27361 net.cpp:226] resnet4a_eltwise_relu needs backward computation.
I0825 17:21:29.154381 27361 net.cpp:226] resnet4a_eltwise needs backward computation.
I0825 17:21:29.154386 27361 net.cpp:226] resnet4a_expnd needs backward computation.
I0825 17:21:29.154388 27361 net.cpp:226] resnet4a_conv_relu needs backward computation.
I0825 17:21:29.154392 27361 net.cpp:226] resnet4a_conv needs backward computation.
I0825 17:21:29.154397 27361 net.cpp:226] resnet4a_btlnk_relu needs backward computation.
I0825 17:21:29.154400 27361 net.cpp:226] resnet4a_btlnk needs backward computation.
I0825 17:21:29.154404 27361 net.cpp:226] resnet4a_bypass needs backward computation.
I0825 17:21:29.154408 27361 net.cpp:226] maxpool3_maxpool3_0_split needs backward computation.
I0825 17:21:29.154412 27361 net.cpp:226] maxpool3 needs backward computation.
I0825 17:21:29.154417 27361 net.cpp:226] resnet3b_eltwise_resnet3b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154424 27361 net.cpp:226] resnet3b_eltwise_relu needs backward computation.
I0825 17:21:29.154428 27361 net.cpp:226] resnet3b_eltwise needs backward computation.
I0825 17:21:29.154431 27361 net.cpp:226] resnet3b_expnd needs backward computation.
I0825 17:21:29.154435 27361 net.cpp:226] resnet3b_conv_relu needs backward computation.
I0825 17:21:29.154439 27361 net.cpp:226] resnet3b_conv needs backward computation.
I0825 17:21:29.154443 27361 net.cpp:226] resnet3b_btlnk_relu needs backward computation.
I0825 17:21:29.154448 27361 net.cpp:226] resnet3b_btlnk needs backward computation.
I0825 17:21:29.154450 27361 net.cpp:226] resnet3a_eltwise_resnet3a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154454 27361 net.cpp:226] resnet3a_eltwise_relu needs backward computation.
I0825 17:21:29.154458 27361 net.cpp:226] resnet3a_eltwise needs backward computation.
I0825 17:21:29.154462 27361 net.cpp:226] resnet3a_expnd needs backward computation.
I0825 17:21:29.154466 27361 net.cpp:226] resnet3a_conv_relu needs backward computation.
I0825 17:21:29.154470 27361 net.cpp:226] resnet3a_conv needs backward computation.
I0825 17:21:29.154474 27361 net.cpp:226] resnet3a_btlnk_relu needs backward computation.
I0825 17:21:29.154477 27361 net.cpp:226] resnet3a_btlnk needs backward computation.
I0825 17:21:29.154481 27361 net.cpp:226] resnet3a_bypass needs backward computation.
I0825 17:21:29.154485 27361 net.cpp:226] maxpool2_maxpool2_0_split needs backward computation.
I0825 17:21:29.154489 27361 net.cpp:226] maxpool2 needs backward computation.
I0825 17:21:29.154494 27361 net.cpp:226] resnet2b_eltwise_resnet2b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154497 27361 net.cpp:226] resnet2b_eltwise_relu needs backward computation.
I0825 17:21:29.154500 27361 net.cpp:226] resnet2b_eltwise needs backward computation.
I0825 17:21:29.154505 27361 net.cpp:226] resnet2b_expnd needs backward computation.
I0825 17:21:29.154508 27361 net.cpp:226] resnet2b_conv_relu needs backward computation.
I0825 17:21:29.154512 27361 net.cpp:226] resnet2b_conv needs backward computation.
I0825 17:21:29.154516 27361 net.cpp:226] resnet2b_btlnk_relu needs backward computation.
I0825 17:21:29.154520 27361 net.cpp:226] resnet2b_btlnk needs backward computation.
I0825 17:21:29.154523 27361 net.cpp:226] resnet2a_eltwise_resnet2a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154527 27361 net.cpp:226] resnet2a_eltwise_relu needs backward computation.
I0825 17:21:29.154536 27361 net.cpp:226] resnet2a_eltwise needs backward computation.
I0825 17:21:29.154541 27361 net.cpp:226] resnet2a_expnd needs backward computation.
I0825 17:21:29.154544 27361 net.cpp:226] resnet2a_conv_relu needs backward computation.
I0825 17:21:29.154548 27361 net.cpp:226] resnet2a_conv needs backward computation.
I0825 17:21:29.154552 27361 net.cpp:226] resnet2a_btlnk_relu needs backward computation.
I0825 17:21:29.154556 27361 net.cpp:226] resnet2a_btlnk needs backward computation.
I0825 17:21:29.154559 27361 net.cpp:226] resnet2a_bypass needs backward computation.
I0825 17:21:29.154564 27361 net.cpp:226] maxpool1_maxpool1_0_split needs backward computation.
I0825 17:21:29.154567 27361 net.cpp:226] maxpool1 needs backward computation.
I0825 17:21:29.154572 27361 net.cpp:226] resnet1b_eltwise_resnet1b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154575 27361 net.cpp:226] resnet1b_eltwise_relu needs backward computation.
I0825 17:21:29.154579 27361 net.cpp:226] resnet1b_eltwise needs backward computation.
I0825 17:21:29.154583 27361 net.cpp:226] resnet1b_expnd needs backward computation.
I0825 17:21:29.154587 27361 net.cpp:226] resnet1b_conv_relu needs backward computation.
I0825 17:21:29.154597 27361 net.cpp:226] resnet1b_conv needs backward computation.
I0825 17:21:29.154600 27361 net.cpp:226] resnet1b_btlnk_relu needs backward computation.
I0825 17:21:29.154604 27361 net.cpp:226] resnet1b_btlnk needs backward computation.
I0825 17:21:29.154608 27361 net.cpp:226] resnet1a_eltwise_resnet1a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.154618 27361 net.cpp:226] resnet1a_eltwise_relu needs backward computation.
I0825 17:21:29.154623 27361 net.cpp:226] resnet1a_eltwise needs backward computation.
I0825 17:21:29.154626 27361 net.cpp:226] resnet1a_expnd needs backward computation.
I0825 17:21:29.154630 27361 net.cpp:226] resnet1a_conv_relu needs backward computation.
I0825 17:21:29.154634 27361 net.cpp:226] resnet1a_conv needs backward computation.
I0825 17:21:29.154639 27361 net.cpp:226] resnet1a_btlnk_relu needs backward computation.
I0825 17:21:29.154641 27361 net.cpp:226] resnet1a_btlnk needs backward computation.
I0825 17:21:29.154646 27361 net.cpp:226] resnet1a_bypass needs backward computation.
I0825 17:21:29.154650 27361 net.cpp:228] label_data_1_split does not need backward computation.
I0825 17:21:29.154655 27361 net.cpp:228] data_data_0_split does not need backward computation.
I0825 17:21:29.154660 27361 net.cpp:228] data does not need backward computation.
I0825 17:21:29.154664 27361 net.cpp:270] This network produces output accuracy
I0825 17:21:29.154667 27361 net.cpp:270] This network produces output softmaxloss
I0825 17:21:29.154757 27361 net.cpp:283] Network initialization done.
I0825 17:21:29.156857 27361 solver.cpp:181] Creating test net (#0) specified by test_net file: ub_uresnet_test.prototxt
I0825 17:21:29.157459 27361 net.cpp:58] Initializing net from parameters: 
name: "uB-U-ResNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ROOTData"
  top: "data"
  top: "label"
  root_data_param {
    batch_size: 1
    filler_config: "filler.cfg"
    filler_name: "test"
  }
}
layer {
  name: "resnet1a_bypass"
  type: "Convolution"
  bottom: "data"
  top: "resnet1a_bypass"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_btlnk"
  type: "Convolution"
  bottom: "data"
  top: "resnet1a_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet1a_btlnk"
  top: "resnet1a_btlnk"
}
layer {
  name: "resnet1a_conv"
  type: "Convolution"
  bottom: "resnet1a_btlnk"
  top: "resnet1a_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_conv_relu"
  type: "ReLU"
  bottom: "resnet1a_conv"
  top: "resnet1a_conv"
}
layer {
  name: "resnet1a_expnd"
  type: "Convolution"
  bottom: "resnet1a_conv"
  top: "resnet1a_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1a_eltwise"
  type: "Eltwise"
  bottom: "resnet1a_bypass"
  bottom: "resnet1a_expnd"
  top: "resnet1a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet1a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet1a_eltwise"
  top: "resnet1a_eltwise"
}
layer {
  name: "resnet1b_btlnk"
  type: "Convolution"
  bottom: "resnet1a_eltwise"
  top: "resnet1b_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet1b_btlnk"
  top: "resnet1b_btlnk"
}
layer {
  name: "resnet1b_conv"
  type: "Convolution"
  bottom: "resnet1b_btlnk"
  top: "resnet1b_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1b_conv_relu"
  type: "ReLU"
  bottom: "resnet1b_conv"
  top: "resnet1b_conv"
}
layer {
  name: "resnet1b_expnd"
  type: "Convolution"
  bottom: "resnet1b_conv"
  top: "resnet1b_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet1b_eltwise"
  type: "Eltwise"
  bottom: "resnet1a_eltwise"
  bottom: "resnet1b_expnd"
  top: "resnet1b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet1b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet1b_eltwise"
  top: "resnet1b_eltwise"
}
layer {
  name: "maxpool1"
  type: "Pooling"
  bottom: "resnet1b_eltwise"
  top: "maxpool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet2a_bypass"
  type: "Convolution"
  bottom: "maxpool1"
  top: "resnet2a_bypass"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_btlnk"
  type: "Convolution"
  bottom: "maxpool1"
  top: "resnet2a_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet2a_btlnk"
  top: "resnet2a_btlnk"
}
layer {
  name: "resnet2a_conv"
  type: "Convolution"
  bottom: "resnet2a_btlnk"
  top: "resnet2a_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_conv_relu"
  type: "ReLU"
  bottom: "resnet2a_conv"
  top: "resnet2a_conv"
}
layer {
  name: "resnet2a_expnd"
  type: "Convolution"
  bottom: "resnet2a_conv"
  top: "resnet2a_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2a_eltwise"
  type: "Eltwise"
  bottom: "resnet2a_bypass"
  bottom: "resnet2a_expnd"
  top: "resnet2a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet2a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet2a_eltwise"
  top: "resnet2a_eltwise"
}
layer {
  name: "resnet2b_btlnk"
  type: "Convolution"
  bottom: "resnet2a_eltwise"
  top: "resnet2b_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet2b_btlnk"
  top: "resnet2b_btlnk"
}
layer {
  name: "resnet2b_conv"
  type: "Convolution"
  bottom: "resnet2b_btlnk"
  top: "resnet2b_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2b_conv_relu"
  type: "ReLU"
  bottom: "resnet2b_conv"
  top: "resnet2b_conv"
}
layer {
  name: "resnet2b_expnd"
  type: "Convolution"
  bottom: "resnet2b_conv"
  top: "resnet2b_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet2b_eltwise"
  type: "Eltwise"
  bottom: "resnet2a_eltwise"
  bottom: "resnet2b_expnd"
  top: "resnet2b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet2b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet2b_eltwise"
  top: "resnet2b_eltwise"
}
layer {
  name: "maxpool2"
  type: "Pooling"
  bottom: "resnet2b_eltwise"
  top: "maxpool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet3a_bypass"
  type: "Convolution"
  bottom: "maxpool2"
  top: "resnet3a_bypass"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_btlnk"
  type: "Convolution"
  bottom: "maxpool2"
  top: "resnet3a_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet3a_btlnk"
  top: "resnet3a_btlnk"
}
layer {
  name: "resnet3a_conv"
  type: "Convolution"
  bottom: "resnet3a_btlnk"
  top: "resnet3a_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_conv_relu"
  type: "ReLU"
  bottom: "resnet3a_conv"
  top: "resnet3a_conv"
}
layer {
  name: "resnet3a_expnd"
  type: "Convolution"
  bottom: "resnet3a_conv"
  top: "resnet3a_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3a_eltwise"
  type: "Eltwise"
  bottom: "resnet3a_bypass"
  bottom: "resnet3a_expnd"
  top: "resnet3a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet3a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet3a_eltwise"
  top: "resnet3a_eltwise"
}
layer {
  name: "resnet3b_btlnk"
  type: "Convolution"
  bottom: "resnet3a_eltwise"
  top: "resnet3b_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet3b_btlnk"
  top: "resnet3b_btlnk"
}
layer {
  name: "resnet3b_conv"
  type: "Convolution"
  bottom: "resnet3b_btlnk"
  top: "resnet3b_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3b_conv_relu"
  type: "ReLU"
  bottom: "resnet3b_conv"
  top: "resnet3b_conv"
}
layer {
  name: "resnet3b_expnd"
  type: "Convolution"
  bottom: "resnet3b_conv"
  top: "resnet3b_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet3b_eltwise"
  type: "Eltwise"
  bottom: "resnet3a_eltwise"
  bottom: "resnet3b_expnd"
  top: "resnet3b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet3b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet3b_eltwise"
  top: "resnet3b_eltwise"
}
layer {
  name: "maxpool3"
  type: "Pooling"
  bottom: "resnet3b_eltwise"
  top: "maxpool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet4a_bypass"
  type: "Convolution"
  bottom: "maxpool3"
  top: "resnet4a_bypass"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_btlnk"
  type: "Convolution"
  bottom: "maxpool3"
  top: "resnet4a_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet4a_btlnk"
  top: "resnet4a_btlnk"
}
layer {
  name: "resnet4a_conv"
  type: "Convolution"
  bottom: "resnet4a_btlnk"
  top: "resnet4a_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_conv_relu"
  type: "ReLU"
  bottom: "resnet4a_conv"
  top: "resnet4a_conv"
}
layer {
  name: "resnet4a_expnd"
  type: "Convolution"
  bottom: "resnet4a_conv"
  top: "resnet4a_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4a_eltwise"
  type: "Eltwise"
  bottom: "resnet4a_bypass"
  bottom: "resnet4a_expnd"
  top: "resnet4a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet4a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet4a_eltwise"
  top: "resnet4a_eltwise"
}
layer {
  name: "resnet4b_btlnk"
  type: "Convolution"
  bottom: "resnet4a_eltwise"
  top: "resnet4b_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet4b_btlnk"
  top: "resnet4b_btlnk"
}
layer {
  name: "resnet4b_conv"
  type: "Convolution"
  bottom: "resnet4b_btlnk"
  top: "resnet4b_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4b_conv_relu"
  type: "ReLU"
  bottom: "resnet4b_conv"
  top: "resnet4b_conv"
}
layer {
  name: "resnet4b_expnd"
  type: "Convolution"
  bottom: "resnet4b_conv"
  top: "resnet4b_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet4b_eltwise"
  type: "Eltwise"
  bottom: "resnet4a_eltwise"
  bottom: "resnet4b_expnd"
  top: "resnet4b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet4b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet4b_eltwise"
  top: "resnet4b_eltwise"
}
layer {
  name: "maxpool4"
  type: "Pooling"
  bottom: "resnet4b_eltwise"
  top: "maxpool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "resnet5a_bypass"
  type: "Convolution"
  bottom: "maxpool4"
  top: "resnet5a_bypass"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_btlnk"
  type: "Convolution"
  bottom: "maxpool4"
  top: "resnet5a_btlnk"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet5a_btlnk"
  top: "resnet5a_btlnk"
}
layer {
  name: "resnet5a_conv"
  type: "Convolution"
  bottom: "resnet5a_btlnk"
  top: "resnet5a_conv"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_conv_relu"
  type: "ReLU"
  bottom: "resnet5a_conv"
  top: "resnet5a_conv"
}
layer {
  name: "resnet5a_expnd"
  type: "Convolution"
  bottom: "resnet5a_conv"
  top: "resnet5a_expnd"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5a_eltwise"
  type: "Eltwise"
  bottom: "resnet5a_bypass"
  bottom: "resnet5a_expnd"
  top: "resnet5a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet5a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet5a_eltwise"
  top: "resnet5a_eltwise"
}
layer {
  name: "resnet5b_btlnk"
  type: "Convolution"
  bottom: "resnet5a_eltwise"
  top: "resnet5b_btlnk"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet5b_btlnk"
  top: "resnet5b_btlnk"
}
layer {
  name: "resnet5b_conv"
  type: "Convolution"
  bottom: "resnet5b_btlnk"
  top: "resnet5b_conv"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5b_conv_relu"
  type: "ReLU"
  bottom: "resnet5b_conv"
  top: "resnet5b_conv"
}
layer {
  name: "resnet5b_expnd"
  type: "Convolution"
  bottom: "resnet5b_conv"
  top: "resnet5b_expnd"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet5b_eltwise"
  type: "Eltwise"
  bottom: "resnet5a_eltwise"
  bottom: "resnet5b_expnd"
  top: "resnet5b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet5b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet5b_eltwise"
  top: "resnet5b_eltwise"
}
layer {
  name: "unpool4"
  type: "Deconvolution"
  bottom: "resnet5b_eltwise"
  top: "unpool4"
  param {
    name: "par_unpool4_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool4_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat56_concat"
  type: "Concat"
  bottom: "resnet4b_eltwise"
  bottom: "unpool4"
  top: "concat56_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet6a_bypass"
  type: "Convolution"
  bottom: "concat56_concat"
  top: "resnet6a_bypass"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_btlnk"
  type: "Convolution"
  bottom: "concat56_concat"
  top: "resnet6a_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet6a_btlnk"
  top: "resnet6a_btlnk"
}
layer {
  name: "resnet6a_conv"
  type: "Convolution"
  bottom: "resnet6a_btlnk"
  top: "resnet6a_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_conv_relu"
  type: "ReLU"
  bottom: "resnet6a_conv"
  top: "resnet6a_conv"
}
layer {
  name: "resnet6a_expnd"
  type: "Convolution"
  bottom: "resnet6a_conv"
  top: "resnet6a_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6a_eltwise"
  type: "Eltwise"
  bottom: "resnet6a_bypass"
  bottom: "resnet6a_expnd"
  top: "resnet6a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet6a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet6a_eltwise"
  top: "resnet6a_eltwise"
}
layer {
  name: "resnet6b_btlnk"
  type: "Convolution"
  bottom: "resnet6a_eltwise"
  top: "resnet6b_btlnk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet6b_btlnk"
  top: "resnet6b_btlnk"
}
layer {
  name: "resnet6b_conv"
  type: "Convolution"
  bottom: "resnet6b_btlnk"
  top: "resnet6b_conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6b_conv_relu"
  type: "ReLU"
  bottom: "resnet6b_conv"
  top: "resnet6b_conv"
}
layer {
  name: "resnet6b_expnd"
  type: "Convolution"
  bottom: "resnet6b_conv"
  top: "resnet6b_expnd"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet6b_eltwise"
  type: "Eltwise"
  bottom: "resnet6a_eltwise"
  bottom: "resnet6b_expnd"
  top: "resnet6b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet6b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet6b_eltwise"
  top: "resnet6b_eltwise"
}
layer {
  name: "unpool3"
  type: "Deconvolution"
  bottom: "resnet6b_eltwise"
  top: "unpool3"
  param {
    name: "par_unpool3_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool3_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat37_concat"
  type: "Concat"
  bottom: "resnet3b_eltwise"
  bottom: "unpool3"
  top: "concat37_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet7a_bypass"
  type: "Convolution"
  bottom: "concat37_concat"
  top: "resnet7a_bypass"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_btlnk"
  type: "Convolution"
  bottom: "concat37_concat"
  top: "resnet7a_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet7a_btlnk"
  top: "resnet7a_btlnk"
}
layer {
  name: "resnet7a_conv"
  type: "Convolution"
  bottom: "resnet7a_btlnk"
  top: "resnet7a_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_conv_relu"
  type: "ReLU"
  bottom: "resnet7a_conv"
  top: "resnet7a_conv"
}
layer {
  name: "resnet7a_expnd"
  type: "Convolution"
  bottom: "resnet7a_conv"
  top: "resnet7a_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7a_eltwise"
  type: "Eltwise"
  bottom: "resnet7a_bypass"
  bottom: "resnet7a_expnd"
  top: "resnet7a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet7a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet7a_eltwise"
  top: "resnet7a_eltwise"
}
layer {
  name: "resnet7b_btlnk"
  type: "Convolution"
  bottom: "resnet7a_eltwise"
  top: "resnet7b_btlnk"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet7b_btlnk"
  top: "resnet7b_btlnk"
}
layer {
  name: "resnet7b_conv"
  type: "Convolution"
  bottom: "resnet7b_btlnk"
  top: "resnet7b_conv"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7b_conv_relu"
  type: "ReLU"
  bottom: "resnet7b_conv"
  top: "resnet7b_conv"
}
layer {
  name: "resnet7b_expnd"
  type: "Convolution"
  bottom: "resnet7b_conv"
  top: "resnet7b_expnd"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet7b_eltwise"
  type: "Eltwise"
  bottom: "resnet7a_eltwise"
  bottom: "resnet7b_expnd"
  top: "resnet7b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet7b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet7b_eltwise"
  top: "resnet7b_eltwise"
}
layer {
  name: "unpool2"
  type: "Deconvolution"
  bottom: "resnet7b_eltwise"
  top: "unpool2"
  param {
    name: "par_unpool2_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool2_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat28_concat"
  type: "Concat"
  bottom: "resnet2b_eltwise"
  bottom: "unpool2"
  top: "concat28_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet8a_bypass"
  type: "Convolution"
  bottom: "concat28_concat"
  top: "resnet8a_bypass"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_btlnk"
  type: "Convolution"
  bottom: "concat28_concat"
  top: "resnet8a_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet8a_btlnk"
  top: "resnet8a_btlnk"
}
layer {
  name: "resnet8a_conv"
  type: "Convolution"
  bottom: "resnet8a_btlnk"
  top: "resnet8a_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_conv_relu"
  type: "ReLU"
  bottom: "resnet8a_conv"
  top: "resnet8a_conv"
}
layer {
  name: "resnet8a_expnd"
  type: "Convolution"
  bottom: "resnet8a_conv"
  top: "resnet8a_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8a_eltwise"
  type: "Eltwise"
  bottom: "resnet8a_bypass"
  bottom: "resnet8a_expnd"
  top: "resnet8a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet8a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet8a_eltwise"
  top: "resnet8a_eltwise"
}
layer {
  name: "resnet8b_btlnk"
  type: "Convolution"
  bottom: "resnet8a_eltwise"
  top: "resnet8b_btlnk"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet8b_btlnk"
  top: "resnet8b_btlnk"
}
layer {
  name: "resnet8b_conv"
  type: "Convolution"
  bottom: "resnet8b_btlnk"
  top: "resnet8b_conv"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8b_conv_relu"
  type: "ReLU"
  bottom: "resnet8b_conv"
  top: "resnet8b_conv"
}
layer {
  name: "resnet8b_expnd"
  type: "Convolution"
  bottom: "resnet8b_conv"
  top: "resnet8b_expnd"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet8b_eltwise"
  type: "Eltwise"
  bottom: "resnet8a_eltwise"
  bottom: "resnet8b_expnd"
  top: "resnet8b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet8b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet8b_eltwise"
  top: "resnet8b_eltwise"
}
layer {
  name: "unpool1"
  type: "Deconvolution"
  bottom: "resnet8b_eltwise"
  top: "unpool1"
  param {
    name: "par_unpool1_deconv_w"
    lr_mult: 1
  }
  param {
    name: "par_unpool1_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat19_concat"
  type: "Concat"
  bottom: "resnet1b_eltwise"
  bottom: "unpool1"
  top: "concat19_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "resnet9a_bypass"
  type: "Convolution"
  bottom: "concat19_concat"
  top: "resnet9a_bypass"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_btlnk"
  type: "Convolution"
  bottom: "concat19_concat"
  top: "resnet9a_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_btlnk_relu"
  type: "ReLU"
  bottom: "resnet9a_btlnk"
  top: "resnet9a_btlnk"
}
layer {
  name: "resnet9a_conv"
  type: "Convolution"
  bottom: "resnet9a_btlnk"
  top: "resnet9a_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_conv_relu"
  type: "ReLU"
  bottom: "resnet9a_conv"
  top: "resnet9a_conv"
}
layer {
  name: "resnet9a_expnd"
  type: "Convolution"
  bottom: "resnet9a_conv"
  top: "resnet9a_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9a_eltwise"
  type: "Eltwise"
  bottom: "resnet9a_bypass"
  bottom: "resnet9a_expnd"
  top: "resnet9a_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet9a_eltwise_relu"
  type: "ReLU"
  bottom: "resnet9a_eltwise"
  top: "resnet9a_eltwise"
}
layer {
  name: "resnet9b_bypass"
  type: "Convolution"
  bottom: "resnet9a_eltwise"
  top: "resnet9b_bypass"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_btlnk"
  type: "Convolution"
  bottom: "resnet9a_eltwise"
  top: "resnet9b_btlnk"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_btlnk_relu"
  type: "ReLU"
  bottom: "resnet9b_btlnk"
  top: "resnet9b_btlnk"
}
layer {
  name: "resnet9b_conv"
  type: "Convolution"
  bottom: "resnet9b_btlnk"
  top: "resnet9b_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_conv_relu"
  type: "ReLU"
  bottom: "resnet9b_conv"
  top: "resnet9b_conv"
}
layer {
  name: "resnet9b_expnd"
  type: "Convolution"
  bottom: "resnet9b_conv"
  top: "resnet9b_expnd"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "resnet9b_eltwise"
  type: "Eltwise"
  bottom: "resnet9b_bypass"
  bottom: "resnet9b_expnd"
  top: "resnet9b_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resnet9b_eltwise_relu"
  type: "ReLU"
  bottom: "resnet9b_eltwise"
  top: "resnet9b_eltwise"
}
layer {
  name: "score_conv"
  type: "Convolution"
  bottom: "resnet9b_eltwise"
  top: "score_conv"
  param {
    name: "par_score_conv_w"
    lr_mult: 1
  }
  param {
    name: "par_score_conv_b"
    lr_mult: 1
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "score_relu"
  type: "ReLU"
  bottom: "score_conv"
  top: "score_conv"
}
layer {
  name: "crop_score"
  type: "Crop"
  bottom: "score_conv"
  bottom: "label"
  top: "crop_score"
  crop_param {
    axis: 2
    offset: 0
  }
}
layer {
  name: "softmaxloss"
  type: "SoftmaxWithLoss"
  bottom: "crop_score"
  bottom: "label"
  top: "softmaxloss"
  loss_param {
    normalize: true
    class_loss_weights: 1
    class_loss_weights: 100
    class_loss_wei
I0825 17:21:29.157977 27361 layer_factory.hpp:77] Creating layer data
I0825 17:21:29.157989 27361 net.cpp:100] Creating Layer data
I0825 17:21:29.157992 27361 net.cpp:408] data -> data
I0825 17:21:29.157999 27361 net.cpp:408] data -> label
    [95m[NORMAL][00m [0m [94m<test::configure>[00m IOManager configuration will be ignored...
    [95m[NORMAL][00m [0m [94m<testProcessDriver::configure>[00m Instantiating Process ID=0 Type: ADCThreshold w/ Name: ADCThres
    [95m[NORMAL][00m [0m [94m<testProcessDriver::configure>[00m Instantiating Process ID=1 Type: EmbedImage w/ Name: EmbedTPC
    [95m[NORMAL][00m [0m [94m<testProcessDriver::configure>[00m Instantiating Process ID=2 Type: EmbedImage w/ Name: EmbedLabels
    [95m[NORMAL][00m [0m [94m<testProcessDriver::configure>[00m Instantiating Process ID=3 Type: SegFiller w/ Name: SegFiller
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Opening a file in READ mode: /mnt/raid0/taritree/v0/hires_test/bnb_mc_hirescrop_valid.root
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Skipping: producer=tpc_int00 type= image2d
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Skipping: producer=tpc type= image2d
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Skipping: producer=tpc type= partroi
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Skipping: producer=pmt type= image2d
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Skipping: producer=segment type= image2d
    [95m[NORMAL][00m [0m [94m<testIOManager::prepare_input>[00m Skipping: producer=tpc_hires_crop type= partroi
    [95m[NORMAL][00m [0m [94m<testIOManager::initialize>[00m Prepared input with 4035 entries...
I0825 17:21:29.226775 27361 net.cpp:150] Setting up data
I0825 17:21:29.226819 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.226826 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.226830 27361 net.cpp:165] Memory required for data: 2097152
I0825 17:21:29.226835 27361 layer_factory.hpp:77] Creating layer data_data_0_split
I0825 17:21:29.226847 27361 net.cpp:100] Creating Layer data_data_0_split
I0825 17:21:29.226851 27361 net.cpp:434] data_data_0_split <- data
I0825 17:21:29.226858 27361 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0825 17:21:29.226866 27361 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0825 17:21:29.226902 27361 net.cpp:150] Setting up data_data_0_split
I0825 17:21:29.226907 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.226912 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.226915 27361 net.cpp:165] Memory required for data: 4194304
I0825 17:21:29.226918 27361 layer_factory.hpp:77] Creating layer label_data_1_split
I0825 17:21:29.226927 27361 net.cpp:100] Creating Layer label_data_1_split
I0825 17:21:29.226930 27361 net.cpp:434] label_data_1_split <- label
I0825 17:21:29.226948 27361 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0825 17:21:29.226954 27361 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0825 17:21:29.226959 27361 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0825 17:21:29.226997 27361 net.cpp:150] Setting up label_data_1_split
I0825 17:21:29.227005 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.227008 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.227012 27361 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0825 17:21:29.227015 27361 net.cpp:165] Memory required for data: 7340032
I0825 17:21:29.227018 27361 layer_factory.hpp:77] Creating layer resnet1a_bypass
I0825 17:21:29.227035 27361 net.cpp:100] Creating Layer resnet1a_bypass
I0825 17:21:29.227038 27361 net.cpp:434] resnet1a_bypass <- data_data_0_split_0
I0825 17:21:29.227043 27361 net.cpp:408] resnet1a_bypass -> resnet1a_bypass
I0825 17:21:29.227222 27361 net.cpp:150] Setting up resnet1a_bypass
I0825 17:21:29.227231 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.227236 27361 net.cpp:165] Memory required for data: 74448896
I0825 17:21:29.227242 27361 layer_factory.hpp:77] Creating layer resnet1a_btlnk
I0825 17:21:29.227252 27361 net.cpp:100] Creating Layer resnet1a_btlnk
I0825 17:21:29.227255 27361 net.cpp:434] resnet1a_btlnk <- data_data_0_split_1
I0825 17:21:29.227260 27361 net.cpp:408] resnet1a_btlnk -> resnet1a_btlnk
I0825 17:21:29.227414 27361 net.cpp:150] Setting up resnet1a_btlnk
I0825 17:21:29.227423 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.227427 27361 net.cpp:165] Memory required for data: 82837504
I0825 17:21:29.227432 27361 layer_factory.hpp:77] Creating layer resnet1a_btlnk_relu
I0825 17:21:29.227439 27361 net.cpp:100] Creating Layer resnet1a_btlnk_relu
I0825 17:21:29.227443 27361 net.cpp:434] resnet1a_btlnk_relu <- resnet1a_btlnk
I0825 17:21:29.227448 27361 net.cpp:395] resnet1a_btlnk_relu -> resnet1a_btlnk (in-place)
I0825 17:21:29.227453 27361 net.cpp:150] Setting up resnet1a_btlnk_relu
I0825 17:21:29.227458 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.227461 27361 net.cpp:165] Memory required for data: 91226112
I0825 17:21:29.227465 27361 layer_factory.hpp:77] Creating layer resnet1a_conv
I0825 17:21:29.227473 27361 net.cpp:100] Creating Layer resnet1a_conv
I0825 17:21:29.227478 27361 net.cpp:434] resnet1a_conv <- resnet1a_btlnk
I0825 17:21:29.227483 27361 net.cpp:408] resnet1a_conv -> resnet1a_conv
I0825 17:21:29.227648 27361 net.cpp:150] Setting up resnet1a_conv
I0825 17:21:29.227656 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.227659 27361 net.cpp:165] Memory required for data: 99614720
I0825 17:21:29.227666 27361 layer_factory.hpp:77] Creating layer resnet1a_conv_relu
I0825 17:21:29.227671 27361 net.cpp:100] Creating Layer resnet1a_conv_relu
I0825 17:21:29.227675 27361 net.cpp:434] resnet1a_conv_relu <- resnet1a_conv
I0825 17:21:29.227680 27361 net.cpp:395] resnet1a_conv_relu -> resnet1a_conv (in-place)
I0825 17:21:29.227685 27361 net.cpp:150] Setting up resnet1a_conv_relu
I0825 17:21:29.227689 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.227692 27361 net.cpp:165] Memory required for data: 108003328
I0825 17:21:29.227696 27361 layer_factory.hpp:77] Creating layer resnet1a_expnd
I0825 17:21:29.227705 27361 net.cpp:100] Creating Layer resnet1a_expnd
I0825 17:21:29.227708 27361 net.cpp:434] resnet1a_expnd <- resnet1a_conv
I0825 17:21:29.227713 27361 net.cpp:408] resnet1a_expnd -> resnet1a_expnd
I0825 17:21:29.227880 27361 net.cpp:150] Setting up resnet1a_expnd
I0825 17:21:29.227888 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.227892 27361 net.cpp:165] Memory required for data: 175112192
I0825 17:21:29.227896 27361 layer_factory.hpp:77] Creating layer resnet1a_eltwise
I0825 17:21:29.227903 27361 net.cpp:100] Creating Layer resnet1a_eltwise
I0825 17:21:29.227907 27361 net.cpp:434] resnet1a_eltwise <- resnet1a_bypass
I0825 17:21:29.227911 27361 net.cpp:434] resnet1a_eltwise <- resnet1a_expnd
I0825 17:21:29.227923 27361 net.cpp:408] resnet1a_eltwise -> resnet1a_eltwise
I0825 17:21:29.227946 27361 net.cpp:150] Setting up resnet1a_eltwise
I0825 17:21:29.227952 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.227955 27361 net.cpp:165] Memory required for data: 242221056
I0825 17:21:29.227958 27361 layer_factory.hpp:77] Creating layer resnet1a_eltwise_relu
I0825 17:21:29.227965 27361 net.cpp:100] Creating Layer resnet1a_eltwise_relu
I0825 17:21:29.227969 27361 net.cpp:434] resnet1a_eltwise_relu <- resnet1a_eltwise
I0825 17:21:29.227973 27361 net.cpp:395] resnet1a_eltwise_relu -> resnet1a_eltwise (in-place)
I0825 17:21:29.227978 27361 net.cpp:150] Setting up resnet1a_eltwise_relu
I0825 17:21:29.227982 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.227985 27361 net.cpp:165] Memory required for data: 309329920
I0825 17:21:29.227989 27361 layer_factory.hpp:77] Creating layer resnet1a_eltwise_resnet1a_eltwise_relu_0_split
I0825 17:21:29.227996 27361 net.cpp:100] Creating Layer resnet1a_eltwise_resnet1a_eltwise_relu_0_split
I0825 17:21:29.228000 27361 net.cpp:434] resnet1a_eltwise_resnet1a_eltwise_relu_0_split <- resnet1a_eltwise
I0825 17:21:29.228004 27361 net.cpp:408] resnet1a_eltwise_resnet1a_eltwise_relu_0_split -> resnet1a_eltwise_resnet1a_eltwise_relu_0_split_0
I0825 17:21:29.228009 27361 net.cpp:408] resnet1a_eltwise_resnet1a_eltwise_relu_0_split -> resnet1a_eltwise_resnet1a_eltwise_relu_0_split_1
I0825 17:21:29.228040 27361 net.cpp:150] Setting up resnet1a_eltwise_resnet1a_eltwise_relu_0_split
I0825 17:21:29.228046 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228050 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228054 27361 net.cpp:165] Memory required for data: 443547648
I0825 17:21:29.228057 27361 layer_factory.hpp:77] Creating layer resnet1b_btlnk
I0825 17:21:29.228065 27361 net.cpp:100] Creating Layer resnet1b_btlnk
I0825 17:21:29.228068 27361 net.cpp:434] resnet1b_btlnk <- resnet1a_eltwise_resnet1a_eltwise_relu_0_split_0
I0825 17:21:29.228075 27361 net.cpp:408] resnet1b_btlnk -> resnet1b_btlnk
I0825 17:21:29.228229 27361 net.cpp:150] Setting up resnet1b_btlnk
I0825 17:21:29.228236 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.228240 27361 net.cpp:165] Memory required for data: 451936256
I0825 17:21:29.228245 27361 layer_factory.hpp:77] Creating layer resnet1b_btlnk_relu
I0825 17:21:29.228250 27361 net.cpp:100] Creating Layer resnet1b_btlnk_relu
I0825 17:21:29.228255 27361 net.cpp:434] resnet1b_btlnk_relu <- resnet1b_btlnk
I0825 17:21:29.228260 27361 net.cpp:395] resnet1b_btlnk_relu -> resnet1b_btlnk (in-place)
I0825 17:21:29.228265 27361 net.cpp:150] Setting up resnet1b_btlnk_relu
I0825 17:21:29.228268 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.228271 27361 net.cpp:165] Memory required for data: 460324864
I0825 17:21:29.228276 27361 layer_factory.hpp:77] Creating layer resnet1b_conv
I0825 17:21:29.228283 27361 net.cpp:100] Creating Layer resnet1b_conv
I0825 17:21:29.228287 27361 net.cpp:434] resnet1b_conv <- resnet1b_btlnk
I0825 17:21:29.228292 27361 net.cpp:408] resnet1b_conv -> resnet1b_conv
I0825 17:21:29.228451 27361 net.cpp:150] Setting up resnet1b_conv
I0825 17:21:29.228458 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.228462 27361 net.cpp:165] Memory required for data: 468713472
I0825 17:21:29.228467 27361 layer_factory.hpp:77] Creating layer resnet1b_conv_relu
I0825 17:21:29.228472 27361 net.cpp:100] Creating Layer resnet1b_conv_relu
I0825 17:21:29.228477 27361 net.cpp:434] resnet1b_conv_relu <- resnet1b_conv
I0825 17:21:29.228480 27361 net.cpp:395] resnet1b_conv_relu -> resnet1b_conv (in-place)
I0825 17:21:29.228485 27361 net.cpp:150] Setting up resnet1b_conv_relu
I0825 17:21:29.228489 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.228492 27361 net.cpp:165] Memory required for data: 477102080
I0825 17:21:29.228495 27361 layer_factory.hpp:77] Creating layer resnet1b_expnd
I0825 17:21:29.228510 27361 net.cpp:100] Creating Layer resnet1b_expnd
I0825 17:21:29.228513 27361 net.cpp:434] resnet1b_expnd <- resnet1b_conv
I0825 17:21:29.228518 27361 net.cpp:408] resnet1b_expnd -> resnet1b_expnd
I0825 17:21:29.228683 27361 net.cpp:150] Setting up resnet1b_expnd
I0825 17:21:29.228693 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228695 27361 net.cpp:165] Memory required for data: 544210944
I0825 17:21:29.228700 27361 layer_factory.hpp:77] Creating layer resnet1b_eltwise
I0825 17:21:29.228706 27361 net.cpp:100] Creating Layer resnet1b_eltwise
I0825 17:21:29.228710 27361 net.cpp:434] resnet1b_eltwise <- resnet1a_eltwise_resnet1a_eltwise_relu_0_split_1
I0825 17:21:29.228714 27361 net.cpp:434] resnet1b_eltwise <- resnet1b_expnd
I0825 17:21:29.228719 27361 net.cpp:408] resnet1b_eltwise -> resnet1b_eltwise
I0825 17:21:29.228741 27361 net.cpp:150] Setting up resnet1b_eltwise
I0825 17:21:29.228749 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228755 27361 net.cpp:165] Memory required for data: 611319808
I0825 17:21:29.228759 27361 layer_factory.hpp:77] Creating layer resnet1b_eltwise_relu
I0825 17:21:29.228765 27361 net.cpp:100] Creating Layer resnet1b_eltwise_relu
I0825 17:21:29.228767 27361 net.cpp:434] resnet1b_eltwise_relu <- resnet1b_eltwise
I0825 17:21:29.228772 27361 net.cpp:395] resnet1b_eltwise_relu -> resnet1b_eltwise (in-place)
I0825 17:21:29.228776 27361 net.cpp:150] Setting up resnet1b_eltwise_relu
I0825 17:21:29.228781 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228785 27361 net.cpp:165] Memory required for data: 678428672
I0825 17:21:29.228787 27361 layer_factory.hpp:77] Creating layer resnet1b_eltwise_resnet1b_eltwise_relu_0_split
I0825 17:21:29.228792 27361 net.cpp:100] Creating Layer resnet1b_eltwise_resnet1b_eltwise_relu_0_split
I0825 17:21:29.228796 27361 net.cpp:434] resnet1b_eltwise_resnet1b_eltwise_relu_0_split <- resnet1b_eltwise
I0825 17:21:29.228801 27361 net.cpp:408] resnet1b_eltwise_resnet1b_eltwise_relu_0_split -> resnet1b_eltwise_resnet1b_eltwise_relu_0_split_0
I0825 17:21:29.228806 27361 net.cpp:408] resnet1b_eltwise_resnet1b_eltwise_relu_0_split -> resnet1b_eltwise_resnet1b_eltwise_relu_0_split_1
I0825 17:21:29.228837 27361 net.cpp:150] Setting up resnet1b_eltwise_resnet1b_eltwise_relu_0_split
I0825 17:21:29.228842 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228847 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.228849 27361 net.cpp:165] Memory required for data: 812646400
I0825 17:21:29.228853 27361 layer_factory.hpp:77] Creating layer maxpool1
I0825 17:21:29.228860 27361 net.cpp:100] Creating Layer maxpool1
I0825 17:21:29.228863 27361 net.cpp:434] maxpool1 <- resnet1b_eltwise_resnet1b_eltwise_relu_0_split_0
I0825 17:21:29.228871 27361 net.cpp:408] maxpool1 -> maxpool1
I0825 17:21:29.228904 27361 net.cpp:150] Setting up maxpool1
I0825 17:21:29.228909 27361 net.cpp:157] Top shape: 1 64 256 256 (4194304)
I0825 17:21:29.228912 27361 net.cpp:165] Memory required for data: 829423616
I0825 17:21:29.228916 27361 layer_factory.hpp:77] Creating layer maxpool1_maxpool1_0_split
I0825 17:21:29.228921 27361 net.cpp:100] Creating Layer maxpool1_maxpool1_0_split
I0825 17:21:29.228924 27361 net.cpp:434] maxpool1_maxpool1_0_split <- maxpool1
I0825 17:21:29.228930 27361 net.cpp:408] maxpool1_maxpool1_0_split -> maxpool1_maxpool1_0_split_0
I0825 17:21:29.228935 27361 net.cpp:408] maxpool1_maxpool1_0_split -> maxpool1_maxpool1_0_split_1
I0825 17:21:29.228963 27361 net.cpp:150] Setting up maxpool1_maxpool1_0_split
I0825 17:21:29.228971 27361 net.cpp:157] Top shape: 1 64 256 256 (4194304)
I0825 17:21:29.228974 27361 net.cpp:157] Top shape: 1 64 256 256 (4194304)
I0825 17:21:29.228977 27361 net.cpp:165] Memory required for data: 862978048
I0825 17:21:29.228981 27361 layer_factory.hpp:77] Creating layer resnet2a_bypass
I0825 17:21:29.228987 27361 net.cpp:100] Creating Layer resnet2a_bypass
I0825 17:21:29.228991 27361 net.cpp:434] resnet2a_bypass <- maxpool1_maxpool1_0_split_0
I0825 17:21:29.228997 27361 net.cpp:408] resnet2a_bypass -> resnet2a_bypass
I0825 17:21:29.229358 27361 net.cpp:150] Setting up resnet2a_bypass
I0825 17:21:29.229367 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.229370 27361 net.cpp:165] Memory required for data: 896532480
I0825 17:21:29.229375 27361 layer_factory.hpp:77] Creating layer resnet2a_btlnk
I0825 17:21:29.229384 27361 net.cpp:100] Creating Layer resnet2a_btlnk
I0825 17:21:29.229388 27361 net.cpp:434] resnet2a_btlnk <- maxpool1_maxpool1_0_split_1
I0825 17:21:29.229394 27361 net.cpp:408] resnet2a_btlnk -> resnet2a_btlnk
I0825 17:21:29.229562 27361 net.cpp:150] Setting up resnet2a_btlnk
I0825 17:21:29.229570 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.229573 27361 net.cpp:165] Memory required for data: 900726784
I0825 17:21:29.229579 27361 layer_factory.hpp:77] Creating layer resnet2a_btlnk_relu
I0825 17:21:29.229585 27361 net.cpp:100] Creating Layer resnet2a_btlnk_relu
I0825 17:21:29.229593 27361 net.cpp:434] resnet2a_btlnk_relu <- resnet2a_btlnk
I0825 17:21:29.229598 27361 net.cpp:395] resnet2a_btlnk_relu -> resnet2a_btlnk (in-place)
I0825 17:21:29.229604 27361 net.cpp:150] Setting up resnet2a_btlnk_relu
I0825 17:21:29.229609 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.229611 27361 net.cpp:165] Memory required for data: 904921088
I0825 17:21:29.229615 27361 layer_factory.hpp:77] Creating layer resnet2a_conv
I0825 17:21:29.229624 27361 net.cpp:100] Creating Layer resnet2a_conv
I0825 17:21:29.229626 27361 net.cpp:434] resnet2a_conv <- resnet2a_btlnk
I0825 17:21:29.229631 27361 net.cpp:408] resnet2a_conv -> resnet2a_conv
I0825 17:21:29.229841 27361 net.cpp:150] Setting up resnet2a_conv
I0825 17:21:29.229849 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.229852 27361 net.cpp:165] Memory required for data: 909115392
I0825 17:21:29.229857 27361 layer_factory.hpp:77] Creating layer resnet2a_conv_relu
I0825 17:21:29.229862 27361 net.cpp:100] Creating Layer resnet2a_conv_relu
I0825 17:21:29.229866 27361 net.cpp:434] resnet2a_conv_relu <- resnet2a_conv
I0825 17:21:29.229871 27361 net.cpp:395] resnet2a_conv_relu -> resnet2a_conv (in-place)
I0825 17:21:29.229876 27361 net.cpp:150] Setting up resnet2a_conv_relu
I0825 17:21:29.229881 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.229883 27361 net.cpp:165] Memory required for data: 913309696
I0825 17:21:29.229887 27361 layer_factory.hpp:77] Creating layer resnet2a_expnd
I0825 17:21:29.229895 27361 net.cpp:100] Creating Layer resnet2a_expnd
I0825 17:21:29.229898 27361 net.cpp:434] resnet2a_expnd <- resnet2a_conv
I0825 17:21:29.229903 27361 net.cpp:408] resnet2a_expnd -> resnet2a_expnd
I0825 17:21:29.230100 27361 net.cpp:150] Setting up resnet2a_expnd
I0825 17:21:29.230108 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.230111 27361 net.cpp:165] Memory required for data: 946864128
I0825 17:21:29.230116 27361 layer_factory.hpp:77] Creating layer resnet2a_eltwise
I0825 17:21:29.230123 27361 net.cpp:100] Creating Layer resnet2a_eltwise
I0825 17:21:29.230126 27361 net.cpp:434] resnet2a_eltwise <- resnet2a_bypass
I0825 17:21:29.230131 27361 net.cpp:434] resnet2a_eltwise <- resnet2a_expnd
I0825 17:21:29.230136 27361 net.cpp:408] resnet2a_eltwise -> resnet2a_eltwise
I0825 17:21:29.230155 27361 net.cpp:150] Setting up resnet2a_eltwise
I0825 17:21:29.230161 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.230165 27361 net.cpp:165] Memory required for data: 980418560
I0825 17:21:29.230167 27361 layer_factory.hpp:77] Creating layer resnet2a_eltwise_relu
I0825 17:21:29.230180 27361 net.cpp:100] Creating Layer resnet2a_eltwise_relu
I0825 17:21:29.230183 27361 net.cpp:434] resnet2a_eltwise_relu <- resnet2a_eltwise
I0825 17:21:29.230188 27361 net.cpp:395] resnet2a_eltwise_relu -> resnet2a_eltwise (in-place)
I0825 17:21:29.230193 27361 net.cpp:150] Setting up resnet2a_eltwise_relu
I0825 17:21:29.230197 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.230201 27361 net.cpp:165] Memory required for data: 1013972992
I0825 17:21:29.230211 27361 layer_factory.hpp:77] Creating layer resnet2a_eltwise_resnet2a_eltwise_relu_0_split
I0825 17:21:29.230216 27361 net.cpp:100] Creating Layer resnet2a_eltwise_resnet2a_eltwise_relu_0_split
I0825 17:21:29.230218 27361 net.cpp:434] resnet2a_eltwise_resnet2a_eltwise_relu_0_split <- resnet2a_eltwise
I0825 17:21:29.230223 27361 net.cpp:408] resnet2a_eltwise_resnet2a_eltwise_relu_0_split -> resnet2a_eltwise_resnet2a_eltwise_relu_0_split_0
I0825 17:21:29.230228 27361 net.cpp:408] resnet2a_eltwise_resnet2a_eltwise_relu_0_split -> resnet2a_eltwise_resnet2a_eltwise_relu_0_split_1
I0825 17:21:29.230260 27361 net.cpp:150] Setting up resnet2a_eltwise_resnet2a_eltwise_relu_0_split
I0825 17:21:29.230267 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.230270 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.230273 27361 net.cpp:165] Memory required for data: 1081081856
I0825 17:21:29.230280 27361 layer_factory.hpp:77] Creating layer resnet2b_btlnk
I0825 17:21:29.230288 27361 net.cpp:100] Creating Layer resnet2b_btlnk
I0825 17:21:29.230293 27361 net.cpp:434] resnet2b_btlnk <- resnet2a_eltwise_resnet2a_eltwise_relu_0_split_0
I0825 17:21:29.230299 27361 net.cpp:408] resnet2b_btlnk -> resnet2b_btlnk
I0825 17:21:29.230494 27361 net.cpp:150] Setting up resnet2b_btlnk
I0825 17:21:29.230502 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.230506 27361 net.cpp:165] Memory required for data: 1085276160
I0825 17:21:29.230510 27361 layer_factory.hpp:77] Creating layer resnet2b_btlnk_relu
I0825 17:21:29.230517 27361 net.cpp:100] Creating Layer resnet2b_btlnk_relu
I0825 17:21:29.230521 27361 net.cpp:434] resnet2b_btlnk_relu <- resnet2b_btlnk
I0825 17:21:29.230525 27361 net.cpp:395] resnet2b_btlnk_relu -> resnet2b_btlnk (in-place)
I0825 17:21:29.230530 27361 net.cpp:150] Setting up resnet2b_btlnk_relu
I0825 17:21:29.230535 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.230538 27361 net.cpp:165] Memory required for data: 1089470464
I0825 17:21:29.230541 27361 layer_factory.hpp:77] Creating layer resnet2b_conv
I0825 17:21:29.230550 27361 net.cpp:100] Creating Layer resnet2b_conv
I0825 17:21:29.230552 27361 net.cpp:434] resnet2b_conv <- resnet2b_btlnk
I0825 17:21:29.230557 27361 net.cpp:408] resnet2b_conv -> resnet2b_conv
I0825 17:21:29.230775 27361 net.cpp:150] Setting up resnet2b_conv
I0825 17:21:29.230803 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.230810 27361 net.cpp:165] Memory required for data: 1093664768
I0825 17:21:29.230819 27361 layer_factory.hpp:77] Creating layer resnet2b_conv_relu
I0825 17:21:29.230829 27361 net.cpp:100] Creating Layer resnet2b_conv_relu
I0825 17:21:29.230835 27361 net.cpp:434] resnet2b_conv_relu <- resnet2b_conv
I0825 17:21:29.230844 27361 net.cpp:395] resnet2b_conv_relu -> resnet2b_conv (in-place)
I0825 17:21:29.230854 27361 net.cpp:150] Setting up resnet2b_conv_relu
I0825 17:21:29.230861 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.230867 27361 net.cpp:165] Memory required for data: 1097859072
I0825 17:21:29.230873 27361 layer_factory.hpp:77] Creating layer resnet2b_expnd
I0825 17:21:29.230886 27361 net.cpp:100] Creating Layer resnet2b_expnd
I0825 17:21:29.230893 27361 net.cpp:434] resnet2b_expnd <- resnet2b_conv
I0825 17:21:29.230902 27361 net.cpp:408] resnet2b_expnd -> resnet2b_expnd
I0825 17:21:29.231262 27361 net.cpp:150] Setting up resnet2b_expnd
I0825 17:21:29.231276 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.231282 27361 net.cpp:165] Memory required for data: 1131413504
I0825 17:21:29.231290 27361 layer_factory.hpp:77] Creating layer resnet2b_eltwise
I0825 17:21:29.231302 27361 net.cpp:100] Creating Layer resnet2b_eltwise
I0825 17:21:29.231308 27361 net.cpp:434] resnet2b_eltwise <- resnet2a_eltwise_resnet2a_eltwise_relu_0_split_1
I0825 17:21:29.231317 27361 net.cpp:434] resnet2b_eltwise <- resnet2b_expnd
I0825 17:21:29.231325 27361 net.cpp:408] resnet2b_eltwise -> resnet2b_eltwise
I0825 17:21:29.231360 27361 net.cpp:150] Setting up resnet2b_eltwise
I0825 17:21:29.231380 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.231386 27361 net.cpp:165] Memory required for data: 1164967936
I0825 17:21:29.231394 27361 layer_factory.hpp:77] Creating layer resnet2b_eltwise_relu
I0825 17:21:29.231402 27361 net.cpp:100] Creating Layer resnet2b_eltwise_relu
I0825 17:21:29.231408 27361 net.cpp:434] resnet2b_eltwise_relu <- resnet2b_eltwise
I0825 17:21:29.231417 27361 net.cpp:395] resnet2b_eltwise_relu -> resnet2b_eltwise (in-place)
I0825 17:21:29.231426 27361 net.cpp:150] Setting up resnet2b_eltwise_relu
I0825 17:21:29.231434 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.231441 27361 net.cpp:165] Memory required for data: 1198522368
I0825 17:21:29.231446 27361 layer_factory.hpp:77] Creating layer resnet2b_eltwise_resnet2b_eltwise_relu_0_split
I0825 17:21:29.231454 27361 net.cpp:100] Creating Layer resnet2b_eltwise_resnet2b_eltwise_relu_0_split
I0825 17:21:29.231464 27361 net.cpp:434] resnet2b_eltwise_resnet2b_eltwise_relu_0_split <- resnet2b_eltwise
I0825 17:21:29.231472 27361 net.cpp:408] resnet2b_eltwise_resnet2b_eltwise_relu_0_split -> resnet2b_eltwise_resnet2b_eltwise_relu_0_split_0
I0825 17:21:29.231482 27361 net.cpp:408] resnet2b_eltwise_resnet2b_eltwise_relu_0_split -> resnet2b_eltwise_resnet2b_eltwise_relu_0_split_1
I0825 17:21:29.231535 27361 net.cpp:150] Setting up resnet2b_eltwise_resnet2b_eltwise_relu_0_split
I0825 17:21:29.231545 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.231554 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.231559 27361 net.cpp:165] Memory required for data: 1265631232
I0825 17:21:29.231565 27361 layer_factory.hpp:77] Creating layer maxpool2
I0825 17:21:29.231577 27361 net.cpp:100] Creating Layer maxpool2
I0825 17:21:29.231585 27361 net.cpp:434] maxpool2 <- resnet2b_eltwise_resnet2b_eltwise_relu_0_split_0
I0825 17:21:29.231592 27361 net.cpp:408] maxpool2 -> maxpool2
I0825 17:21:29.231647 27361 net.cpp:150] Setting up maxpool2
I0825 17:21:29.231657 27361 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0825 17:21:29.231663 27361 net.cpp:165] Memory required for data: 1274019840
I0825 17:21:29.231669 27361 layer_factory.hpp:77] Creating layer maxpool2_maxpool2_0_split
I0825 17:21:29.231678 27361 net.cpp:100] Creating Layer maxpool2_maxpool2_0_split
I0825 17:21:29.231684 27361 net.cpp:434] maxpool2_maxpool2_0_split <- maxpool2
I0825 17:21:29.231694 27361 net.cpp:408] maxpool2_maxpool2_0_split -> maxpool2_maxpool2_0_split_0
I0825 17:21:29.231704 27361 net.cpp:408] maxpool2_maxpool2_0_split -> maxpool2_maxpool2_0_split_1
I0825 17:21:29.231751 27361 net.cpp:150] Setting up maxpool2_maxpool2_0_split
I0825 17:21:29.231765 27361 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0825 17:21:29.231771 27361 net.cpp:157] Top shape: 1 128 128 128 (2097152)
I0825 17:21:29.231778 27361 net.cpp:165] Memory required for data: 1290797056
I0825 17:21:29.231784 27361 layer_factory.hpp:77] Creating layer resnet3a_bypass
I0825 17:21:29.231796 27361 net.cpp:100] Creating Layer resnet3a_bypass
I0825 17:21:29.231802 27361 net.cpp:434] resnet3a_bypass <- maxpool2_maxpool2_0_split_0
I0825 17:21:29.231814 27361 net.cpp:408] resnet3a_bypass -> resnet3a_bypass
I0825 17:21:29.233723 27361 net.cpp:150] Setting up resnet3a_bypass
I0825 17:21:29.233737 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.233743 27361 net.cpp:165] Memory required for data: 1307574272
I0825 17:21:29.233752 27361 layer_factory.hpp:77] Creating layer resnet3a_btlnk
I0825 17:21:29.233765 27361 net.cpp:100] Creating Layer resnet3a_btlnk
I0825 17:21:29.233772 27361 net.cpp:434] resnet3a_btlnk <- maxpool2_maxpool2_0_split_1
I0825 17:21:29.233783 27361 net.cpp:408] resnet3a_btlnk -> resnet3a_btlnk
I0825 17:21:29.234249 27361 net.cpp:150] Setting up resnet3a_btlnk
I0825 17:21:29.234262 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.234268 27361 net.cpp:165] Memory required for data: 1309671424
I0825 17:21:29.234277 27361 layer_factory.hpp:77] Creating layer resnet3a_btlnk_relu
I0825 17:21:29.234295 27361 net.cpp:100] Creating Layer resnet3a_btlnk_relu
I0825 17:21:29.234302 27361 net.cpp:434] resnet3a_btlnk_relu <- resnet3a_btlnk
I0825 17:21:29.234311 27361 net.cpp:395] resnet3a_btlnk_relu -> resnet3a_btlnk (in-place)
I0825 17:21:29.234320 27361 net.cpp:150] Setting up resnet3a_btlnk_relu
I0825 17:21:29.234329 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.234335 27361 net.cpp:165] Memory required for data: 1311768576
I0825 17:21:29.234341 27361 layer_factory.hpp:77] Creating layer resnet3a_conv
I0825 17:21:29.234354 27361 net.cpp:100] Creating Layer resnet3a_conv
I0825 17:21:29.234361 27361 net.cpp:434] resnet3a_conv <- resnet3a_btlnk
I0825 17:21:29.234369 27361 net.cpp:408] resnet3a_conv -> resnet3a_conv
I0825 17:21:29.235108 27361 net.cpp:150] Setting up resnet3a_conv
I0825 17:21:29.235124 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.235136 27361 net.cpp:165] Memory required for data: 1313865728
I0825 17:21:29.235147 27361 layer_factory.hpp:77] Creating layer resnet3a_conv_relu
I0825 17:21:29.235157 27361 net.cpp:100] Creating Layer resnet3a_conv_relu
I0825 17:21:29.235164 27361 net.cpp:434] resnet3a_conv_relu <- resnet3a_conv
I0825 17:21:29.235173 27361 net.cpp:395] resnet3a_conv_relu -> resnet3a_conv (in-place)
I0825 17:21:29.235183 27361 net.cpp:150] Setting up resnet3a_conv_relu
I0825 17:21:29.235191 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.235198 27361 net.cpp:165] Memory required for data: 1315962880
I0825 17:21:29.235203 27361 layer_factory.hpp:77] Creating layer resnet3a_expnd
I0825 17:21:29.235218 27361 net.cpp:100] Creating Layer resnet3a_expnd
I0825 17:21:29.235224 27361 net.cpp:434] resnet3a_expnd <- resnet3a_conv
I0825 17:21:29.235234 27361 net.cpp:408] resnet3a_expnd -> resnet3a_expnd
I0825 17:21:29.235906 27361 net.cpp:150] Setting up resnet3a_expnd
I0825 17:21:29.235919 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.235925 27361 net.cpp:165] Memory required for data: 1332740096
I0825 17:21:29.235934 27361 layer_factory.hpp:77] Creating layer resnet3a_eltwise
I0825 17:21:29.235944 27361 net.cpp:100] Creating Layer resnet3a_eltwise
I0825 17:21:29.235951 27361 net.cpp:434] resnet3a_eltwise <- resnet3a_bypass
I0825 17:21:29.235960 27361 net.cpp:434] resnet3a_eltwise <- resnet3a_expnd
I0825 17:21:29.235968 27361 net.cpp:408] resnet3a_eltwise -> resnet3a_eltwise
I0825 17:21:29.236003 27361 net.cpp:150] Setting up resnet3a_eltwise
I0825 17:21:29.236013 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.236019 27361 net.cpp:165] Memory required for data: 1349517312
I0825 17:21:29.236026 27361 layer_factory.hpp:77] Creating layer resnet3a_eltwise_relu
I0825 17:21:29.236034 27361 net.cpp:100] Creating Layer resnet3a_eltwise_relu
I0825 17:21:29.236042 27361 net.cpp:434] resnet3a_eltwise_relu <- resnet3a_eltwise
I0825 17:21:29.236048 27361 net.cpp:395] resnet3a_eltwise_relu -> resnet3a_eltwise (in-place)
I0825 17:21:29.236057 27361 net.cpp:150] Setting up resnet3a_eltwise_relu
I0825 17:21:29.236065 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.236071 27361 net.cpp:165] Memory required for data: 1366294528
I0825 17:21:29.236078 27361 layer_factory.hpp:77] Creating layer resnet3a_eltwise_resnet3a_eltwise_relu_0_split
I0825 17:21:29.236086 27361 net.cpp:100] Creating Layer resnet3a_eltwise_resnet3a_eltwise_relu_0_split
I0825 17:21:29.236093 27361 net.cpp:434] resnet3a_eltwise_resnet3a_eltwise_relu_0_split <- resnet3a_eltwise
I0825 17:21:29.236101 27361 net.cpp:408] resnet3a_eltwise_resnet3a_eltwise_relu_0_split -> resnet3a_eltwise_resnet3a_eltwise_relu_0_split_0
I0825 17:21:29.236110 27361 net.cpp:408] resnet3a_eltwise_resnet3a_eltwise_relu_0_split -> resnet3a_eltwise_resnet3a_eltwise_relu_0_split_1
I0825 17:21:29.236166 27361 net.cpp:150] Setting up resnet3a_eltwise_resnet3a_eltwise_relu_0_split
I0825 17:21:29.236176 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.236183 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.236199 27361 net.cpp:165] Memory required for data: 1399848960
I0825 17:21:29.236207 27361 layer_factory.hpp:77] Creating layer resnet3b_btlnk
I0825 17:21:29.236219 27361 net.cpp:100] Creating Layer resnet3b_btlnk
I0825 17:21:29.236227 27361 net.cpp:434] resnet3b_btlnk <- resnet3a_eltwise_resnet3a_eltwise_relu_0_split_0
I0825 17:21:29.236238 27361 net.cpp:408] resnet3b_btlnk -> resnet3b_btlnk
I0825 17:21:29.236913 27361 net.cpp:150] Setting up resnet3b_btlnk
I0825 17:21:29.236927 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.236933 27361 net.cpp:165] Memory required for data: 1401946112
I0825 17:21:29.236941 27361 layer_factory.hpp:77] Creating layer resnet3b_btlnk_relu
I0825 17:21:29.236951 27361 net.cpp:100] Creating Layer resnet3b_btlnk_relu
I0825 17:21:29.236958 27361 net.cpp:434] resnet3b_btlnk_relu <- resnet3b_btlnk
I0825 17:21:29.236966 27361 net.cpp:395] resnet3b_btlnk_relu -> resnet3b_btlnk (in-place)
I0825 17:21:29.236979 27361 net.cpp:150] Setting up resnet3b_btlnk_relu
I0825 17:21:29.236989 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.236995 27361 net.cpp:165] Memory required for data: 1404043264
I0825 17:21:29.237002 27361 layer_factory.hpp:77] Creating layer resnet3b_conv
I0825 17:21:29.237015 27361 net.cpp:100] Creating Layer resnet3b_conv
I0825 17:21:29.237021 27361 net.cpp:434] resnet3b_conv <- resnet3b_btlnk
I0825 17:21:29.237030 27361 net.cpp:408] resnet3b_conv -> resnet3b_conv
I0825 17:21:29.237776 27361 net.cpp:150] Setting up resnet3b_conv
I0825 17:21:29.237790 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.237797 27361 net.cpp:165] Memory required for data: 1406140416
I0825 17:21:29.237804 27361 layer_factory.hpp:77] Creating layer resnet3b_conv_relu
I0825 17:21:29.237814 27361 net.cpp:100] Creating Layer resnet3b_conv_relu
I0825 17:21:29.237821 27361 net.cpp:434] resnet3b_conv_relu <- resnet3b_conv
I0825 17:21:29.237829 27361 net.cpp:395] resnet3b_conv_relu -> resnet3b_conv (in-place)
I0825 17:21:29.237838 27361 net.cpp:150] Setting up resnet3b_conv_relu
I0825 17:21:29.237846 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.237853 27361 net.cpp:165] Memory required for data: 1408237568
I0825 17:21:29.237859 27361 layer_factory.hpp:77] Creating layer resnet3b_expnd
I0825 17:21:29.237869 27361 net.cpp:100] Creating Layer resnet3b_expnd
I0825 17:21:29.237876 27361 net.cpp:434] resnet3b_expnd <- resnet3b_conv
I0825 17:21:29.237887 27361 net.cpp:408] resnet3b_expnd -> resnet3b_expnd
I0825 17:21:29.238564 27361 net.cpp:150] Setting up resnet3b_expnd
I0825 17:21:29.238577 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.238584 27361 net.cpp:165] Memory required for data: 1425014784
I0825 17:21:29.238598 27361 layer_factory.hpp:77] Creating layer resnet3b_eltwise
I0825 17:21:29.238612 27361 net.cpp:100] Creating Layer resnet3b_eltwise
I0825 17:21:29.238620 27361 net.cpp:434] resnet3b_eltwise <- resnet3a_eltwise_resnet3a_eltwise_relu_0_split_1
I0825 17:21:29.238628 27361 net.cpp:434] resnet3b_eltwise <- resnet3b_expnd
I0825 17:21:29.238637 27361 net.cpp:408] resnet3b_eltwise -> resnet3b_eltwise
I0825 17:21:29.238672 27361 net.cpp:150] Setting up resnet3b_eltwise
I0825 17:21:29.238682 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.238688 27361 net.cpp:165] Memory required for data: 1441792000
I0825 17:21:29.238694 27361 layer_factory.hpp:77] Creating layer resnet3b_eltwise_relu
I0825 17:21:29.238705 27361 net.cpp:100] Creating Layer resnet3b_eltwise_relu
I0825 17:21:29.238713 27361 net.cpp:434] resnet3b_eltwise_relu <- resnet3b_eltwise
I0825 17:21:29.238720 27361 net.cpp:395] resnet3b_eltwise_relu -> resnet3b_eltwise (in-place)
I0825 17:21:29.238729 27361 net.cpp:150] Setting up resnet3b_eltwise_relu
I0825 17:21:29.238737 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.238744 27361 net.cpp:165] Memory required for data: 1458569216
I0825 17:21:29.238749 27361 layer_factory.hpp:77] Creating layer resnet3b_eltwise_resnet3b_eltwise_relu_0_split
I0825 17:21:29.238770 27361 net.cpp:100] Creating Layer resnet3b_eltwise_resnet3b_eltwise_relu_0_split
I0825 17:21:29.238776 27361 net.cpp:434] resnet3b_eltwise_resnet3b_eltwise_relu_0_split <- resnet3b_eltwise
I0825 17:21:29.238785 27361 net.cpp:408] resnet3b_eltwise_resnet3b_eltwise_relu_0_split -> resnet3b_eltwise_resnet3b_eltwise_relu_0_split_0
I0825 17:21:29.238793 27361 net.cpp:408] resnet3b_eltwise_resnet3b_eltwise_relu_0_split -> resnet3b_eltwise_resnet3b_eltwise_relu_0_split_1
I0825 17:21:29.238845 27361 net.cpp:150] Setting up resnet3b_eltwise_resnet3b_eltwise_relu_0_split
I0825 17:21:29.238857 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.238865 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.238872 27361 net.cpp:165] Memory required for data: 1492123648
I0825 17:21:29.238878 27361 layer_factory.hpp:77] Creating layer maxpool3
I0825 17:21:29.238888 27361 net.cpp:100] Creating Layer maxpool3
I0825 17:21:29.238900 27361 net.cpp:434] maxpool3 <- resnet3b_eltwise_resnet3b_eltwise_relu_0_split_0
I0825 17:21:29.238914 27361 net.cpp:408] maxpool3 -> maxpool3
I0825 17:21:29.238971 27361 net.cpp:150] Setting up maxpool3
I0825 17:21:29.238981 27361 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0825 17:21:29.238987 27361 net.cpp:165] Memory required for data: 1496317952
I0825 17:21:29.238993 27361 layer_factory.hpp:77] Creating layer maxpool3_maxpool3_0_split
I0825 17:21:29.239002 27361 net.cpp:100] Creating Layer maxpool3_maxpool3_0_split
I0825 17:21:29.239009 27361 net.cpp:434] maxpool3_maxpool3_0_split <- maxpool3
I0825 17:21:29.239019 27361 net.cpp:408] maxpool3_maxpool3_0_split -> maxpool3_maxpool3_0_split_0
I0825 17:21:29.239030 27361 net.cpp:408] maxpool3_maxpool3_0_split -> maxpool3_maxpool3_0_split_1
I0825 17:21:29.239080 27361 net.cpp:150] Setting up maxpool3_maxpool3_0_split
I0825 17:21:29.239089 27361 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0825 17:21:29.239097 27361 net.cpp:157] Top shape: 1 256 64 64 (1048576)
I0825 17:21:29.239104 27361 net.cpp:165] Memory required for data: 1504706560
I0825 17:21:29.239109 27361 layer_factory.hpp:77] Creating layer resnet4a_bypass
I0825 17:21:29.239123 27361 net.cpp:100] Creating Layer resnet4a_bypass
I0825 17:21:29.239130 27361 net.cpp:434] resnet4a_bypass <- maxpool3_maxpool3_0_split_0
I0825 17:21:29.239140 27361 net.cpp:408] resnet4a_bypass -> resnet4a_bypass
I0825 17:21:29.245822 27361 net.cpp:150] Setting up resnet4a_bypass
I0825 17:21:29.245839 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.245846 27361 net.cpp:165] Memory required for data: 1513095168
I0825 17:21:29.245854 27361 layer_factory.hpp:77] Creating layer resnet4a_btlnk
I0825 17:21:29.245867 27361 net.cpp:100] Creating Layer resnet4a_btlnk
I0825 17:21:29.245872 27361 net.cpp:434] resnet4a_btlnk <- maxpool3_maxpool3_0_split_1
I0825 17:21:29.245884 27361 net.cpp:408] resnet4a_btlnk -> resnet4a_btlnk
I0825 17:21:29.246933 27361 net.cpp:150] Setting up resnet4a_btlnk
I0825 17:21:29.246948 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.246954 27361 net.cpp:165] Memory required for data: 1514143744
I0825 17:21:29.246963 27361 layer_factory.hpp:77] Creating layer resnet4a_btlnk_relu
I0825 17:21:29.246973 27361 net.cpp:100] Creating Layer resnet4a_btlnk_relu
I0825 17:21:29.246980 27361 net.cpp:434] resnet4a_btlnk_relu <- resnet4a_btlnk
I0825 17:21:29.246989 27361 net.cpp:395] resnet4a_btlnk_relu -> resnet4a_btlnk (in-place)
I0825 17:21:29.246999 27361 net.cpp:150] Setting up resnet4a_btlnk_relu
I0825 17:21:29.247006 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.247012 27361 net.cpp:165] Memory required for data: 1515192320
I0825 17:21:29.247019 27361 layer_factory.hpp:77] Creating layer resnet4a_conv
I0825 17:21:29.247028 27361 net.cpp:100] Creating Layer resnet4a_conv
I0825 17:21:29.247035 27361 net.cpp:434] resnet4a_conv <- resnet4a_btlnk
I0825 17:21:29.247045 27361 net.cpp:408] resnet4a_conv -> resnet4a_conv
I0825 17:21:29.249063 27361 net.cpp:150] Setting up resnet4a_conv
I0825 17:21:29.249085 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.249107 27361 net.cpp:165] Memory required for data: 1516240896
I0825 17:21:29.249115 27361 layer_factory.hpp:77] Creating layer resnet4a_conv_relu
I0825 17:21:29.249130 27361 net.cpp:100] Creating Layer resnet4a_conv_relu
I0825 17:21:29.249137 27361 net.cpp:434] resnet4a_conv_relu <- resnet4a_conv
I0825 17:21:29.249146 27361 net.cpp:395] resnet4a_conv_relu -> resnet4a_conv (in-place)
I0825 17:21:29.249155 27361 net.cpp:150] Setting up resnet4a_conv_relu
I0825 17:21:29.249162 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.249168 27361 net.cpp:165] Memory required for data: 1517289472
I0825 17:21:29.249176 27361 layer_factory.hpp:77] Creating layer resnet4a_expnd
I0825 17:21:29.249186 27361 net.cpp:100] Creating Layer resnet4a_expnd
I0825 17:21:29.249192 27361 net.cpp:434] resnet4a_expnd <- resnet4a_conv
I0825 17:21:29.249207 27361 net.cpp:408] resnet4a_expnd -> resnet4a_expnd
I0825 17:21:29.251042 27361 net.cpp:150] Setting up resnet4a_expnd
I0825 17:21:29.251058 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.251065 27361 net.cpp:165] Memory required for data: 1525678080
I0825 17:21:29.251073 27361 layer_factory.hpp:77] Creating layer resnet4a_eltwise
I0825 17:21:29.251085 27361 net.cpp:100] Creating Layer resnet4a_eltwise
I0825 17:21:29.251093 27361 net.cpp:434] resnet4a_eltwise <- resnet4a_bypass
I0825 17:21:29.251101 27361 net.cpp:434] resnet4a_eltwise <- resnet4a_expnd
I0825 17:21:29.251111 27361 net.cpp:408] resnet4a_eltwise -> resnet4a_eltwise
I0825 17:21:29.251147 27361 net.cpp:150] Setting up resnet4a_eltwise
I0825 17:21:29.251155 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.251162 27361 net.cpp:165] Memory required for data: 1534066688
I0825 17:21:29.251168 27361 layer_factory.hpp:77] Creating layer resnet4a_eltwise_relu
I0825 17:21:29.251178 27361 net.cpp:100] Creating Layer resnet4a_eltwise_relu
I0825 17:21:29.251185 27361 net.cpp:434] resnet4a_eltwise_relu <- resnet4a_eltwise
I0825 17:21:29.251194 27361 net.cpp:395] resnet4a_eltwise_relu -> resnet4a_eltwise (in-place)
I0825 17:21:29.251201 27361 net.cpp:150] Setting up resnet4a_eltwise_relu
I0825 17:21:29.251209 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.251215 27361 net.cpp:165] Memory required for data: 1542455296
I0825 17:21:29.251221 27361 layer_factory.hpp:77] Creating layer resnet4a_eltwise_resnet4a_eltwise_relu_0_split
I0825 17:21:29.251230 27361 net.cpp:100] Creating Layer resnet4a_eltwise_resnet4a_eltwise_relu_0_split
I0825 17:21:29.251235 27361 net.cpp:434] resnet4a_eltwise_resnet4a_eltwise_relu_0_split <- resnet4a_eltwise
I0825 17:21:29.251243 27361 net.cpp:408] resnet4a_eltwise_resnet4a_eltwise_relu_0_split -> resnet4a_eltwise_resnet4a_eltwise_relu_0_split_0
I0825 17:21:29.251252 27361 net.cpp:408] resnet4a_eltwise_resnet4a_eltwise_relu_0_split -> resnet4a_eltwise_resnet4a_eltwise_relu_0_split_1
I0825 17:21:29.251305 27361 net.cpp:150] Setting up resnet4a_eltwise_resnet4a_eltwise_relu_0_split
I0825 17:21:29.251317 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.251323 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.251329 27361 net.cpp:165] Memory required for data: 1559232512
I0825 17:21:29.251335 27361 layer_factory.hpp:77] Creating layer resnet4b_btlnk
I0825 17:21:29.251346 27361 net.cpp:100] Creating Layer resnet4b_btlnk
I0825 17:21:29.251353 27361 net.cpp:434] resnet4b_btlnk <- resnet4a_eltwise_resnet4a_eltwise_relu_0_split_0
I0825 17:21:29.251363 27361 net.cpp:408] resnet4b_btlnk -> resnet4b_btlnk
I0825 17:21:29.253172 27361 net.cpp:150] Setting up resnet4b_btlnk
I0825 17:21:29.253185 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.253191 27361 net.cpp:165] Memory required for data: 1560281088
I0825 17:21:29.253199 27361 layer_factory.hpp:77] Creating layer resnet4b_btlnk_relu
I0825 17:21:29.253211 27361 net.cpp:100] Creating Layer resnet4b_btlnk_relu
I0825 17:21:29.253217 27361 net.cpp:434] resnet4b_btlnk_relu <- resnet4b_btlnk
I0825 17:21:29.253226 27361 net.cpp:395] resnet4b_btlnk_relu -> resnet4b_btlnk (in-place)
I0825 17:21:29.253244 27361 net.cpp:150] Setting up resnet4b_btlnk_relu
I0825 17:21:29.253253 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.253258 27361 net.cpp:165] Memory required for data: 1561329664
I0825 17:21:29.253264 27361 layer_factory.hpp:77] Creating layer resnet4b_conv
I0825 17:21:29.253275 27361 net.cpp:100] Creating Layer resnet4b_conv
I0825 17:21:29.253281 27361 net.cpp:434] resnet4b_conv <- resnet4b_btlnk
I0825 17:21:29.253293 27361 net.cpp:408] resnet4b_conv -> resnet4b_conv
I0825 17:21:29.256000 27361 net.cpp:150] Setting up resnet4b_conv
I0825 17:21:29.256026 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.256032 27361 net.cpp:165] Memory required for data: 1562378240
I0825 17:21:29.256042 27361 layer_factory.hpp:77] Creating layer resnet4b_conv_relu
I0825 17:21:29.256052 27361 net.cpp:100] Creating Layer resnet4b_conv_relu
I0825 17:21:29.256065 27361 net.cpp:434] resnet4b_conv_relu <- resnet4b_conv
I0825 17:21:29.256073 27361 net.cpp:395] resnet4b_conv_relu -> resnet4b_conv (in-place)
I0825 17:21:29.256084 27361 net.cpp:150] Setting up resnet4b_conv_relu
I0825 17:21:29.256093 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.256098 27361 net.cpp:165] Memory required for data: 1563426816
I0825 17:21:29.256103 27361 layer_factory.hpp:77] Creating layer resnet4b_expnd
I0825 17:21:29.256114 27361 net.cpp:100] Creating Layer resnet4b_expnd
I0825 17:21:29.256120 27361 net.cpp:434] resnet4b_expnd <- resnet4b_conv
I0825 17:21:29.256130 27361 net.cpp:408] resnet4b_expnd -> resnet4b_expnd
I0825 17:21:29.257859 27361 net.cpp:150] Setting up resnet4b_expnd
I0825 17:21:29.257872 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.257879 27361 net.cpp:165] Memory required for data: 1571815424
I0825 17:21:29.257886 27361 layer_factory.hpp:77] Creating layer resnet4b_eltwise
I0825 17:21:29.257896 27361 net.cpp:100] Creating Layer resnet4b_eltwise
I0825 17:21:29.257903 27361 net.cpp:434] resnet4b_eltwise <- resnet4a_eltwise_resnet4a_eltwise_relu_0_split_1
I0825 17:21:29.257910 27361 net.cpp:434] resnet4b_eltwise <- resnet4b_expnd
I0825 17:21:29.257920 27361 net.cpp:408] resnet4b_eltwise -> resnet4b_eltwise
I0825 17:21:29.257957 27361 net.cpp:150] Setting up resnet4b_eltwise
I0825 17:21:29.257967 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.257973 27361 net.cpp:165] Memory required for data: 1580204032
I0825 17:21:29.257978 27361 layer_factory.hpp:77] Creating layer resnet4b_eltwise_relu
I0825 17:21:29.257987 27361 net.cpp:100] Creating Layer resnet4b_eltwise_relu
I0825 17:21:29.257992 27361 net.cpp:434] resnet4b_eltwise_relu <- resnet4b_eltwise
I0825 17:21:29.258000 27361 net.cpp:395] resnet4b_eltwise_relu -> resnet4b_eltwise (in-place)
I0825 17:21:29.258008 27361 net.cpp:150] Setting up resnet4b_eltwise_relu
I0825 17:21:29.258015 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.258021 27361 net.cpp:165] Memory required for data: 1588592640
I0825 17:21:29.258026 27361 layer_factory.hpp:77] Creating layer resnet4b_eltwise_resnet4b_eltwise_relu_0_split
I0825 17:21:29.258034 27361 net.cpp:100] Creating Layer resnet4b_eltwise_resnet4b_eltwise_relu_0_split
I0825 17:21:29.258040 27361 net.cpp:434] resnet4b_eltwise_resnet4b_eltwise_relu_0_split <- resnet4b_eltwise
I0825 17:21:29.258047 27361 net.cpp:408] resnet4b_eltwise_resnet4b_eltwise_relu_0_split -> resnet4b_eltwise_resnet4b_eltwise_relu_0_split_0
I0825 17:21:29.258059 27361 net.cpp:408] resnet4b_eltwise_resnet4b_eltwise_relu_0_split -> resnet4b_eltwise_resnet4b_eltwise_relu_0_split_1
I0825 17:21:29.258107 27361 net.cpp:150] Setting up resnet4b_eltwise_resnet4b_eltwise_relu_0_split
I0825 17:21:29.258116 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.258123 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.258129 27361 net.cpp:165] Memory required for data: 1605369856
I0825 17:21:29.258134 27361 layer_factory.hpp:77] Creating layer maxpool4
I0825 17:21:29.258147 27361 net.cpp:100] Creating Layer maxpool4
I0825 17:21:29.258163 27361 net.cpp:434] maxpool4 <- resnet4b_eltwise_resnet4b_eltwise_relu_0_split_0
I0825 17:21:29.258172 27361 net.cpp:408] maxpool4 -> maxpool4
I0825 17:21:29.258227 27361 net.cpp:150] Setting up maxpool4
I0825 17:21:29.258237 27361 net.cpp:157] Top shape: 1 512 32 32 (524288)
I0825 17:21:29.258244 27361 net.cpp:165] Memory required for data: 1607467008
I0825 17:21:29.258249 27361 layer_factory.hpp:77] Creating layer maxpool4_maxpool4_0_split
I0825 17:21:29.258258 27361 net.cpp:100] Creating Layer maxpool4_maxpool4_0_split
I0825 17:21:29.258265 27361 net.cpp:434] maxpool4_maxpool4_0_split <- maxpool4
I0825 17:21:29.258273 27361 net.cpp:408] maxpool4_maxpool4_0_split -> maxpool4_maxpool4_0_split_0
I0825 17:21:29.258282 27361 net.cpp:408] maxpool4_maxpool4_0_split -> maxpool4_maxpool4_0_split_1
I0825 17:21:29.258329 27361 net.cpp:150] Setting up maxpool4_maxpool4_0_split
I0825 17:21:29.258343 27361 net.cpp:157] Top shape: 1 512 32 32 (524288)
I0825 17:21:29.258350 27361 net.cpp:157] Top shape: 1 512 32 32 (524288)
I0825 17:21:29.258355 27361 net.cpp:165] Memory required for data: 1611661312
I0825 17:21:29.258361 27361 layer_factory.hpp:77] Creating layer resnet5a_bypass
I0825 17:21:29.258374 27361 net.cpp:100] Creating Layer resnet5a_bypass
I0825 17:21:29.258380 27361 net.cpp:434] resnet5a_bypass <- maxpool4_maxpool4_0_split_0
I0825 17:21:29.258389 27361 net.cpp:408] resnet5a_bypass -> resnet5a_bypass
I0825 17:21:29.282168 27361 net.cpp:150] Setting up resnet5a_bypass
I0825 17:21:29.282198 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.282204 27361 net.cpp:165] Memory required for data: 1615855616
I0825 17:21:29.282213 27361 layer_factory.hpp:77] Creating layer resnet5a_btlnk
I0825 17:21:29.282227 27361 net.cpp:100] Creating Layer resnet5a_btlnk
I0825 17:21:29.282234 27361 net.cpp:434] resnet5a_btlnk <- maxpool4_maxpool4_0_split_1
I0825 17:21:29.282243 27361 net.cpp:408] resnet5a_btlnk -> resnet5a_btlnk
I0825 17:21:29.285159 27361 net.cpp:150] Setting up resnet5a_btlnk
I0825 17:21:29.285173 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.285179 27361 net.cpp:165] Memory required for data: 1616379904
I0825 17:21:29.285187 27361 layer_factory.hpp:77] Creating layer resnet5a_btlnk_relu
I0825 17:21:29.285197 27361 net.cpp:100] Creating Layer resnet5a_btlnk_relu
I0825 17:21:29.285202 27361 net.cpp:434] resnet5a_btlnk_relu <- resnet5a_btlnk
I0825 17:21:29.285210 27361 net.cpp:395] resnet5a_btlnk_relu -> resnet5a_btlnk (in-place)
I0825 17:21:29.285219 27361 net.cpp:150] Setting up resnet5a_btlnk_relu
I0825 17:21:29.285225 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.285230 27361 net.cpp:165] Memory required for data: 1616904192
I0825 17:21:29.285236 27361 layer_factory.hpp:77] Creating layer resnet5a_conv
I0825 17:21:29.285246 27361 net.cpp:100] Creating Layer resnet5a_conv
I0825 17:21:29.285251 27361 net.cpp:434] resnet5a_conv <- resnet5a_btlnk
I0825 17:21:29.285260 27361 net.cpp:408] resnet5a_conv -> resnet5a_conv
I0825 17:21:29.291981 27361 net.cpp:150] Setting up resnet5a_conv
I0825 17:21:29.292003 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.292008 27361 net.cpp:165] Memory required for data: 1617428480
I0825 17:21:29.292016 27361 layer_factory.hpp:77] Creating layer resnet5a_conv_relu
I0825 17:21:29.292026 27361 net.cpp:100] Creating Layer resnet5a_conv_relu
I0825 17:21:29.292032 27361 net.cpp:434] resnet5a_conv_relu <- resnet5a_conv
I0825 17:21:29.292038 27361 net.cpp:395] resnet5a_conv_relu -> resnet5a_conv (in-place)
I0825 17:21:29.292047 27361 net.cpp:150] Setting up resnet5a_conv_relu
I0825 17:21:29.292054 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.292058 27361 net.cpp:165] Memory required for data: 1617952768
I0825 17:21:29.292063 27361 layer_factory.hpp:77] Creating layer resnet5a_expnd
I0825 17:21:29.292073 27361 net.cpp:100] Creating Layer resnet5a_expnd
I0825 17:21:29.292078 27361 net.cpp:434] resnet5a_expnd <- resnet5a_conv
I0825 17:21:29.292088 27361 net.cpp:408] resnet5a_expnd -> resnet5a_expnd
I0825 17:21:29.297909 27361 net.cpp:150] Setting up resnet5a_expnd
I0825 17:21:29.297933 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.297940 27361 net.cpp:165] Memory required for data: 1622147072
I0825 17:21:29.297947 27361 layer_factory.hpp:77] Creating layer resnet5a_eltwise
I0825 17:21:29.297957 27361 net.cpp:100] Creating Layer resnet5a_eltwise
I0825 17:21:29.297965 27361 net.cpp:434] resnet5a_eltwise <- resnet5a_bypass
I0825 17:21:29.297971 27361 net.cpp:434] resnet5a_eltwise <- resnet5a_expnd
I0825 17:21:29.297978 27361 net.cpp:408] resnet5a_eltwise -> resnet5a_eltwise
I0825 17:21:29.298014 27361 net.cpp:150] Setting up resnet5a_eltwise
I0825 17:21:29.298023 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.298028 27361 net.cpp:165] Memory required for data: 1626341376
I0825 17:21:29.298033 27361 layer_factory.hpp:77] Creating layer resnet5a_eltwise_relu
I0825 17:21:29.298045 27361 net.cpp:100] Creating Layer resnet5a_eltwise_relu
I0825 17:21:29.298051 27361 net.cpp:434] resnet5a_eltwise_relu <- resnet5a_eltwise
I0825 17:21:29.298058 27361 net.cpp:395] resnet5a_eltwise_relu -> resnet5a_eltwise (in-place)
I0825 17:21:29.298065 27361 net.cpp:150] Setting up resnet5a_eltwise_relu
I0825 17:21:29.298072 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.298077 27361 net.cpp:165] Memory required for data: 1630535680
I0825 17:21:29.298081 27361 layer_factory.hpp:77] Creating layer resnet5a_eltwise_resnet5a_eltwise_relu_0_split
I0825 17:21:29.298089 27361 net.cpp:100] Creating Layer resnet5a_eltwise_resnet5a_eltwise_relu_0_split
I0825 17:21:29.298094 27361 net.cpp:434] resnet5a_eltwise_resnet5a_eltwise_relu_0_split <- resnet5a_eltwise
I0825 17:21:29.298102 27361 net.cpp:408] resnet5a_eltwise_resnet5a_eltwise_relu_0_split -> resnet5a_eltwise_resnet5a_eltwise_relu_0_split_0
I0825 17:21:29.298110 27361 net.cpp:408] resnet5a_eltwise_resnet5a_eltwise_relu_0_split -> resnet5a_eltwise_resnet5a_eltwise_relu_0_split_1
I0825 17:21:29.298156 27361 net.cpp:150] Setting up resnet5a_eltwise_resnet5a_eltwise_relu_0_split
I0825 17:21:29.298163 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.298169 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.298174 27361 net.cpp:165] Memory required for data: 1638924288
I0825 17:21:29.298179 27361 layer_factory.hpp:77] Creating layer resnet5b_btlnk
I0825 17:21:29.298193 27361 net.cpp:100] Creating Layer resnet5b_btlnk
I0825 17:21:29.298199 27361 net.cpp:434] resnet5b_btlnk <- resnet5a_eltwise_resnet5a_eltwise_relu_0_split_0
I0825 17:21:29.298207 27361 net.cpp:408] resnet5b_btlnk -> resnet5b_btlnk
I0825 17:21:29.303514 27361 net.cpp:150] Setting up resnet5b_btlnk
I0825 17:21:29.303527 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.303532 27361 net.cpp:165] Memory required for data: 1639448576
I0825 17:21:29.303544 27361 layer_factory.hpp:77] Creating layer resnet5b_btlnk_relu
I0825 17:21:29.303552 27361 net.cpp:100] Creating Layer resnet5b_btlnk_relu
I0825 17:21:29.303558 27361 net.cpp:434] resnet5b_btlnk_relu <- resnet5b_btlnk
I0825 17:21:29.303565 27361 net.cpp:395] resnet5b_btlnk_relu -> resnet5b_btlnk (in-place)
I0825 17:21:29.303573 27361 net.cpp:150] Setting up resnet5b_btlnk_relu
I0825 17:21:29.303580 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.303583 27361 net.cpp:165] Memory required for data: 1639972864
I0825 17:21:29.303588 27361 layer_factory.hpp:77] Creating layer resnet5b_conv
I0825 17:21:29.303597 27361 net.cpp:100] Creating Layer resnet5b_conv
I0825 17:21:29.303601 27361 net.cpp:434] resnet5b_conv <- resnet5b_btlnk
I0825 17:21:29.303608 27361 net.cpp:408] resnet5b_conv -> resnet5b_conv
I0825 17:21:29.309774 27361 net.cpp:150] Setting up resnet5b_conv
I0825 17:21:29.309798 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.309804 27361 net.cpp:165] Memory required for data: 1640497152
I0825 17:21:29.309811 27361 layer_factory.hpp:77] Creating layer resnet5b_conv_relu
I0825 17:21:29.309824 27361 net.cpp:100] Creating Layer resnet5b_conv_relu
I0825 17:21:29.309840 27361 net.cpp:434] resnet5b_conv_relu <- resnet5b_conv
I0825 17:21:29.309847 27361 net.cpp:395] resnet5b_conv_relu -> resnet5b_conv (in-place)
I0825 17:21:29.309855 27361 net.cpp:150] Setting up resnet5b_conv_relu
I0825 17:21:29.309862 27361 net.cpp:157] Top shape: 1 128 32 32 (131072)
I0825 17:21:29.309867 27361 net.cpp:165] Memory required for data: 1641021440
I0825 17:21:29.309871 27361 layer_factory.hpp:77] Creating layer resnet5b_expnd
I0825 17:21:29.309881 27361 net.cpp:100] Creating Layer resnet5b_expnd
I0825 17:21:29.309886 27361 net.cpp:434] resnet5b_expnd <- resnet5b_conv
I0825 17:21:29.309895 27361 net.cpp:408] resnet5b_expnd -> resnet5b_expnd
I0825 17:21:29.315455 27361 net.cpp:150] Setting up resnet5b_expnd
I0825 17:21:29.315474 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.315479 27361 net.cpp:165] Memory required for data: 1645215744
I0825 17:21:29.315490 27361 layer_factory.hpp:77] Creating layer resnet5b_eltwise
I0825 17:21:29.315500 27361 net.cpp:100] Creating Layer resnet5b_eltwise
I0825 17:21:29.315506 27361 net.cpp:434] resnet5b_eltwise <- resnet5a_eltwise_resnet5a_eltwise_relu_0_split_1
I0825 17:21:29.315513 27361 net.cpp:434] resnet5b_eltwise <- resnet5b_expnd
I0825 17:21:29.315520 27361 net.cpp:408] resnet5b_eltwise -> resnet5b_eltwise
I0825 17:21:29.315552 27361 net.cpp:150] Setting up resnet5b_eltwise
I0825 17:21:29.315562 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.315565 27361 net.cpp:165] Memory required for data: 1649410048
I0825 17:21:29.315570 27361 layer_factory.hpp:77] Creating layer resnet5b_eltwise_relu
I0825 17:21:29.315577 27361 net.cpp:100] Creating Layer resnet5b_eltwise_relu
I0825 17:21:29.315582 27361 net.cpp:434] resnet5b_eltwise_relu <- resnet5b_eltwise
I0825 17:21:29.315588 27361 net.cpp:395] resnet5b_eltwise_relu -> resnet5b_eltwise (in-place)
I0825 17:21:29.315595 27361 net.cpp:150] Setting up resnet5b_eltwise_relu
I0825 17:21:29.315600 27361 net.cpp:157] Top shape: 1 1024 32 32 (1048576)
I0825 17:21:29.315605 27361 net.cpp:165] Memory required for data: 1653604352
I0825 17:21:29.315609 27361 layer_factory.hpp:77] Creating layer unpool4
I0825 17:21:29.315620 27361 net.cpp:100] Creating Layer unpool4
I0825 17:21:29.315625 27361 net.cpp:434] unpool4 <- resnet5b_eltwise
I0825 17:21:29.315634 27361 net.cpp:408] unpool4 -> unpool4
I0825 17:21:29.445194 27361 net.cpp:150] Setting up unpool4
I0825 17:21:29.445227 27361 net.cpp:157] Top shape: 1 1024 64 64 (4194304)
I0825 17:21:29.445232 27361 net.cpp:165] Memory required for data: 1670381568
I0825 17:21:29.445240 27361 layer_factory.hpp:77] Creating layer concat56_concat
I0825 17:21:29.445250 27361 net.cpp:100] Creating Layer concat56_concat
I0825 17:21:29.445255 27361 net.cpp:434] concat56_concat <- resnet4b_eltwise_resnet4b_eltwise_relu_0_split_1
I0825 17:21:29.445261 27361 net.cpp:434] concat56_concat <- unpool4
I0825 17:21:29.445271 27361 net.cpp:408] concat56_concat -> concat56_concat
I0825 17:21:29.445297 27361 net.cpp:150] Setting up concat56_concat
I0825 17:21:29.445302 27361 net.cpp:157] Top shape: 1 1536 64 64 (6291456)
I0825 17:21:29.445307 27361 net.cpp:165] Memory required for data: 1695547392
I0825 17:21:29.445309 27361 layer_factory.hpp:77] Creating layer concat56_concat_concat56_concat_0_split
I0825 17:21:29.445317 27361 net.cpp:100] Creating Layer concat56_concat_concat56_concat_0_split
I0825 17:21:29.445320 27361 net.cpp:434] concat56_concat_concat56_concat_0_split <- concat56_concat
I0825 17:21:29.445325 27361 net.cpp:408] concat56_concat_concat56_concat_0_split -> concat56_concat_concat56_concat_0_split_0
I0825 17:21:29.445332 27361 net.cpp:408] concat56_concat_concat56_concat_0_split -> concat56_concat_concat56_concat_0_split_1
I0825 17:21:29.445363 27361 net.cpp:150] Setting up concat56_concat_concat56_concat_0_split
I0825 17:21:29.445369 27361 net.cpp:157] Top shape: 1 1536 64 64 (6291456)
I0825 17:21:29.445374 27361 net.cpp:157] Top shape: 1 1536 64 64 (6291456)
I0825 17:21:29.445376 27361 net.cpp:165] Memory required for data: 1745879040
I0825 17:21:29.445389 27361 layer_factory.hpp:77] Creating layer resnet6a_bypass
I0825 17:21:29.445399 27361 net.cpp:100] Creating Layer resnet6a_bypass
I0825 17:21:29.445402 27361 net.cpp:434] resnet6a_bypass <- concat56_concat_concat56_concat_0_split_0
I0825 17:21:29.445407 27361 net.cpp:408] resnet6a_bypass -> resnet6a_bypass
I0825 17:21:29.466760 27361 net.cpp:150] Setting up resnet6a_bypass
I0825 17:21:29.466778 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.466781 27361 net.cpp:165] Memory required for data: 1754267648
I0825 17:21:29.466787 27361 layer_factory.hpp:77] Creating layer resnet6a_btlnk
I0825 17:21:29.466796 27361 net.cpp:100] Creating Layer resnet6a_btlnk
I0825 17:21:29.466800 27361 net.cpp:434] resnet6a_btlnk <- concat56_concat_concat56_concat_0_split_1
I0825 17:21:29.466806 27361 net.cpp:408] resnet6a_btlnk -> resnet6a_btlnk
I0825 17:21:29.469519 27361 net.cpp:150] Setting up resnet6a_btlnk
I0825 17:21:29.469528 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.469532 27361 net.cpp:165] Memory required for data: 1755316224
I0825 17:21:29.469537 27361 layer_factory.hpp:77] Creating layer resnet6a_btlnk_relu
I0825 17:21:29.469542 27361 net.cpp:100] Creating Layer resnet6a_btlnk_relu
I0825 17:21:29.469547 27361 net.cpp:434] resnet6a_btlnk_relu <- resnet6a_btlnk
I0825 17:21:29.469550 27361 net.cpp:395] resnet6a_btlnk_relu -> resnet6a_btlnk (in-place)
I0825 17:21:29.469557 27361 net.cpp:150] Setting up resnet6a_btlnk_relu
I0825 17:21:29.469560 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.469563 27361 net.cpp:165] Memory required for data: 1756364800
I0825 17:21:29.469568 27361 layer_factory.hpp:77] Creating layer resnet6a_conv
I0825 17:21:29.469575 27361 net.cpp:100] Creating Layer resnet6a_conv
I0825 17:21:29.469578 27361 net.cpp:434] resnet6a_conv <- resnet6a_btlnk
I0825 17:21:29.469583 27361 net.cpp:408] resnet6a_conv -> resnet6a_conv
I0825 17:21:29.470700 27361 net.cpp:150] Setting up resnet6a_conv
I0825 17:21:29.470708 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.470711 27361 net.cpp:165] Memory required for data: 1757413376
I0825 17:21:29.470716 27361 layer_factory.hpp:77] Creating layer resnet6a_conv_relu
I0825 17:21:29.470721 27361 net.cpp:100] Creating Layer resnet6a_conv_relu
I0825 17:21:29.470726 27361 net.cpp:434] resnet6a_conv_relu <- resnet6a_conv
I0825 17:21:29.470731 27361 net.cpp:395] resnet6a_conv_relu -> resnet6a_conv (in-place)
I0825 17:21:29.470736 27361 net.cpp:150] Setting up resnet6a_conv_relu
I0825 17:21:29.470739 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.470742 27361 net.cpp:165] Memory required for data: 1758461952
I0825 17:21:29.470746 27361 layer_factory.hpp:77] Creating layer resnet6a_expnd
I0825 17:21:29.470753 27361 net.cpp:100] Creating Layer resnet6a_expnd
I0825 17:21:29.470757 27361 net.cpp:434] resnet6a_expnd <- resnet6a_conv
I0825 17:21:29.470762 27361 net.cpp:408] resnet6a_expnd -> resnet6a_expnd
I0825 17:21:29.471762 27361 net.cpp:150] Setting up resnet6a_expnd
I0825 17:21:29.471771 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.471773 27361 net.cpp:165] Memory required for data: 1766850560
I0825 17:21:29.471778 27361 layer_factory.hpp:77] Creating layer resnet6a_eltwise
I0825 17:21:29.471784 27361 net.cpp:100] Creating Layer resnet6a_eltwise
I0825 17:21:29.471788 27361 net.cpp:434] resnet6a_eltwise <- resnet6a_bypass
I0825 17:21:29.471793 27361 net.cpp:434] resnet6a_eltwise <- resnet6a_expnd
I0825 17:21:29.471797 27361 net.cpp:408] resnet6a_eltwise -> resnet6a_eltwise
I0825 17:21:29.471817 27361 net.cpp:150] Setting up resnet6a_eltwise
I0825 17:21:29.471822 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.471825 27361 net.cpp:165] Memory required for data: 1775239168
I0825 17:21:29.471829 27361 layer_factory.hpp:77] Creating layer resnet6a_eltwise_relu
I0825 17:21:29.471835 27361 net.cpp:100] Creating Layer resnet6a_eltwise_relu
I0825 17:21:29.471839 27361 net.cpp:434] resnet6a_eltwise_relu <- resnet6a_eltwise
I0825 17:21:29.471850 27361 net.cpp:395] resnet6a_eltwise_relu -> resnet6a_eltwise (in-place)
I0825 17:21:29.471855 27361 net.cpp:150] Setting up resnet6a_eltwise_relu
I0825 17:21:29.471859 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.471863 27361 net.cpp:165] Memory required for data: 1783627776
I0825 17:21:29.471866 27361 layer_factory.hpp:77] Creating layer resnet6a_eltwise_resnet6a_eltwise_relu_0_split
I0825 17:21:29.471871 27361 net.cpp:100] Creating Layer resnet6a_eltwise_resnet6a_eltwise_relu_0_split
I0825 17:21:29.471874 27361 net.cpp:434] resnet6a_eltwise_resnet6a_eltwise_relu_0_split <- resnet6a_eltwise
I0825 17:21:29.471879 27361 net.cpp:408] resnet6a_eltwise_resnet6a_eltwise_relu_0_split -> resnet6a_eltwise_resnet6a_eltwise_relu_0_split_0
I0825 17:21:29.471884 27361 net.cpp:408] resnet6a_eltwise_resnet6a_eltwise_relu_0_split -> resnet6a_eltwise_resnet6a_eltwise_relu_0_split_1
I0825 17:21:29.471917 27361 net.cpp:150] Setting up resnet6a_eltwise_resnet6a_eltwise_relu_0_split
I0825 17:21:29.471923 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.471927 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.471930 27361 net.cpp:165] Memory required for data: 1800404992
I0825 17:21:29.471935 27361 layer_factory.hpp:77] Creating layer resnet6b_btlnk
I0825 17:21:29.471943 27361 net.cpp:100] Creating Layer resnet6b_btlnk
I0825 17:21:29.471947 27361 net.cpp:434] resnet6b_btlnk <- resnet6a_eltwise_resnet6a_eltwise_relu_0_split_0
I0825 17:21:29.471952 27361 net.cpp:408] resnet6b_btlnk -> resnet6b_btlnk
I0825 17:21:29.472954 27361 net.cpp:150] Setting up resnet6b_btlnk
I0825 17:21:29.472962 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.472965 27361 net.cpp:165] Memory required for data: 1801453568
I0825 17:21:29.472970 27361 layer_factory.hpp:77] Creating layer resnet6b_btlnk_relu
I0825 17:21:29.472975 27361 net.cpp:100] Creating Layer resnet6b_btlnk_relu
I0825 17:21:29.472978 27361 net.cpp:434] resnet6b_btlnk_relu <- resnet6b_btlnk
I0825 17:21:29.472983 27361 net.cpp:395] resnet6b_btlnk_relu -> resnet6b_btlnk (in-place)
I0825 17:21:29.472988 27361 net.cpp:150] Setting up resnet6b_btlnk_relu
I0825 17:21:29.472992 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.472995 27361 net.cpp:165] Memory required for data: 1802502144
I0825 17:21:29.472998 27361 layer_factory.hpp:77] Creating layer resnet6b_conv
I0825 17:21:29.473004 27361 net.cpp:100] Creating Layer resnet6b_conv
I0825 17:21:29.473008 27361 net.cpp:434] resnet6b_conv <- resnet6b_btlnk
I0825 17:21:29.473013 27361 net.cpp:408] resnet6b_conv -> resnet6b_conv
I0825 17:21:29.474483 27361 net.cpp:150] Setting up resnet6b_conv
I0825 17:21:29.474495 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.474499 27361 net.cpp:165] Memory required for data: 1803550720
I0825 17:21:29.474504 27361 layer_factory.hpp:77] Creating layer resnet6b_conv_relu
I0825 17:21:29.474509 27361 net.cpp:100] Creating Layer resnet6b_conv_relu
I0825 17:21:29.474514 27361 net.cpp:434] resnet6b_conv_relu <- resnet6b_conv
I0825 17:21:29.474519 27361 net.cpp:395] resnet6b_conv_relu -> resnet6b_conv (in-place)
I0825 17:21:29.474524 27361 net.cpp:150] Setting up resnet6b_conv_relu
I0825 17:21:29.474529 27361 net.cpp:157] Top shape: 1 64 64 64 (262144)
I0825 17:21:29.474531 27361 net.cpp:165] Memory required for data: 1804599296
I0825 17:21:29.474535 27361 layer_factory.hpp:77] Creating layer resnet6b_expnd
I0825 17:21:29.474544 27361 net.cpp:100] Creating Layer resnet6b_expnd
I0825 17:21:29.474546 27361 net.cpp:434] resnet6b_expnd <- resnet6b_conv
I0825 17:21:29.474551 27361 net.cpp:408] resnet6b_expnd -> resnet6b_expnd
I0825 17:21:29.475553 27361 net.cpp:150] Setting up resnet6b_expnd
I0825 17:21:29.475563 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.475566 27361 net.cpp:165] Memory required for data: 1812987904
I0825 17:21:29.475570 27361 layer_factory.hpp:77] Creating layer resnet6b_eltwise
I0825 17:21:29.475576 27361 net.cpp:100] Creating Layer resnet6b_eltwise
I0825 17:21:29.475589 27361 net.cpp:434] resnet6b_eltwise <- resnet6a_eltwise_resnet6a_eltwise_relu_0_split_1
I0825 17:21:29.475592 27361 net.cpp:434] resnet6b_eltwise <- resnet6b_expnd
I0825 17:21:29.475597 27361 net.cpp:408] resnet6b_eltwise -> resnet6b_eltwise
I0825 17:21:29.475618 27361 net.cpp:150] Setting up resnet6b_eltwise
I0825 17:21:29.475625 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.475627 27361 net.cpp:165] Memory required for data: 1821376512
I0825 17:21:29.475630 27361 layer_factory.hpp:77] Creating layer resnet6b_eltwise_relu
I0825 17:21:29.475637 27361 net.cpp:100] Creating Layer resnet6b_eltwise_relu
I0825 17:21:29.475641 27361 net.cpp:434] resnet6b_eltwise_relu <- resnet6b_eltwise
I0825 17:21:29.475646 27361 net.cpp:395] resnet6b_eltwise_relu -> resnet6b_eltwise (in-place)
I0825 17:21:29.475649 27361 net.cpp:150] Setting up resnet6b_eltwise_relu
I0825 17:21:29.475654 27361 net.cpp:157] Top shape: 1 512 64 64 (2097152)
I0825 17:21:29.475659 27361 net.cpp:165] Memory required for data: 1829765120
I0825 17:21:29.475663 27361 layer_factory.hpp:77] Creating layer unpool3
I0825 17:21:29.475670 27361 net.cpp:100] Creating Layer unpool3
I0825 17:21:29.475673 27361 net.cpp:434] unpool3 <- resnet6b_eltwise
I0825 17:21:29.475682 27361 net.cpp:408] unpool3 -> unpool3
I0825 17:21:29.504034 27361 net.cpp:150] Setting up unpool3
I0825 17:21:29.504051 27361 net.cpp:157] Top shape: 1 512 128 128 (8388608)
I0825 17:21:29.504056 27361 net.cpp:165] Memory required for data: 1863319552
I0825 17:21:29.504062 27361 layer_factory.hpp:77] Creating layer concat37_concat
I0825 17:21:29.504070 27361 net.cpp:100] Creating Layer concat37_concat
I0825 17:21:29.504073 27361 net.cpp:434] concat37_concat <- resnet3b_eltwise_resnet3b_eltwise_relu_0_split_1
I0825 17:21:29.504078 27361 net.cpp:434] concat37_concat <- unpool3
I0825 17:21:29.504086 27361 net.cpp:408] concat37_concat -> concat37_concat
I0825 17:21:29.504112 27361 net.cpp:150] Setting up concat37_concat
I0825 17:21:29.504117 27361 net.cpp:157] Top shape: 1 768 128 128 (12582912)
I0825 17:21:29.504120 27361 net.cpp:165] Memory required for data: 1913651200
I0825 17:21:29.504123 27361 layer_factory.hpp:77] Creating layer concat37_concat_concat37_concat_0_split
I0825 17:21:29.504129 27361 net.cpp:100] Creating Layer concat37_concat_concat37_concat_0_split
I0825 17:21:29.504132 27361 net.cpp:434] concat37_concat_concat37_concat_0_split <- concat37_concat
I0825 17:21:29.504138 27361 net.cpp:408] concat37_concat_concat37_concat_0_split -> concat37_concat_concat37_concat_0_split_0
I0825 17:21:29.504144 27361 net.cpp:408] concat37_concat_concat37_concat_0_split -> concat37_concat_concat37_concat_0_split_1
I0825 17:21:29.504173 27361 net.cpp:150] Setting up concat37_concat_concat37_concat_0_split
I0825 17:21:29.504179 27361 net.cpp:157] Top shape: 1 768 128 128 (12582912)
I0825 17:21:29.504184 27361 net.cpp:157] Top shape: 1 768 128 128 (12582912)
I0825 17:21:29.504186 27361 net.cpp:165] Memory required for data: 2014314496
I0825 17:21:29.504189 27361 layer_factory.hpp:77] Creating layer resnet7a_bypass
I0825 17:21:29.504197 27361 net.cpp:100] Creating Layer resnet7a_bypass
I0825 17:21:29.504201 27361 net.cpp:434] resnet7a_bypass <- concat37_concat_concat37_concat_0_split_0
I0825 17:21:29.504207 27361 net.cpp:408] resnet7a_bypass -> resnet7a_bypass
I0825 17:21:29.509791 27361 net.cpp:150] Setting up resnet7a_bypass
I0825 17:21:29.509805 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.509809 27361 net.cpp:165] Memory required for data: 2031091712
I0825 17:21:29.509814 27361 layer_factory.hpp:77] Creating layer resnet7a_btlnk
I0825 17:21:29.509824 27361 net.cpp:100] Creating Layer resnet7a_btlnk
I0825 17:21:29.509827 27361 net.cpp:434] resnet7a_btlnk <- concat37_concat_concat37_concat_0_split_1
I0825 17:21:29.509834 27361 net.cpp:408] resnet7a_btlnk -> resnet7a_btlnk
I0825 17:21:29.510632 27361 net.cpp:150] Setting up resnet7a_btlnk
I0825 17:21:29.510642 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.510644 27361 net.cpp:165] Memory required for data: 2033188864
I0825 17:21:29.510655 27361 layer_factory.hpp:77] Creating layer resnet7a_btlnk_relu
I0825 17:21:29.510661 27361 net.cpp:100] Creating Layer resnet7a_btlnk_relu
I0825 17:21:29.510665 27361 net.cpp:434] resnet7a_btlnk_relu <- resnet7a_btlnk
I0825 17:21:29.510670 27361 net.cpp:395] resnet7a_btlnk_relu -> resnet7a_btlnk (in-place)
I0825 17:21:29.510676 27361 net.cpp:150] Setting up resnet7a_btlnk_relu
I0825 17:21:29.510680 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.510684 27361 net.cpp:165] Memory required for data: 2035286016
I0825 17:21:29.510687 27361 layer_factory.hpp:77] Creating layer resnet7a_conv
I0825 17:21:29.510697 27361 net.cpp:100] Creating Layer resnet7a_conv
I0825 17:21:29.510701 27361 net.cpp:434] resnet7a_conv <- resnet7a_btlnk
I0825 17:21:29.510706 27361 net.cpp:408] resnet7a_conv -> resnet7a_conv
I0825 17:21:29.511101 27361 net.cpp:150] Setting up resnet7a_conv
I0825 17:21:29.511111 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.511114 27361 net.cpp:165] Memory required for data: 2037383168
I0825 17:21:29.511119 27361 layer_factory.hpp:77] Creating layer resnet7a_conv_relu
I0825 17:21:29.511124 27361 net.cpp:100] Creating Layer resnet7a_conv_relu
I0825 17:21:29.511128 27361 net.cpp:434] resnet7a_conv_relu <- resnet7a_conv
I0825 17:21:29.511133 27361 net.cpp:395] resnet7a_conv_relu -> resnet7a_conv (in-place)
I0825 17:21:29.511138 27361 net.cpp:150] Setting up resnet7a_conv_relu
I0825 17:21:29.511142 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.511145 27361 net.cpp:165] Memory required for data: 2039480320
I0825 17:21:29.511148 27361 layer_factory.hpp:77] Creating layer resnet7a_expnd
I0825 17:21:29.511155 27361 net.cpp:100] Creating Layer resnet7a_expnd
I0825 17:21:29.511158 27361 net.cpp:434] resnet7a_expnd <- resnet7a_conv
I0825 17:21:29.511164 27361 net.cpp:408] resnet7a_expnd -> resnet7a_expnd
I0825 17:21:29.511526 27361 net.cpp:150] Setting up resnet7a_expnd
I0825 17:21:29.511534 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.511538 27361 net.cpp:165] Memory required for data: 2056257536
I0825 17:21:29.511543 27361 layer_factory.hpp:77] Creating layer resnet7a_eltwise
I0825 17:21:29.511550 27361 net.cpp:100] Creating Layer resnet7a_eltwise
I0825 17:21:29.511554 27361 net.cpp:434] resnet7a_eltwise <- resnet7a_bypass
I0825 17:21:29.511559 27361 net.cpp:434] resnet7a_eltwise <- resnet7a_expnd
I0825 17:21:29.511564 27361 net.cpp:408] resnet7a_eltwise -> resnet7a_eltwise
I0825 17:21:29.511584 27361 net.cpp:150] Setting up resnet7a_eltwise
I0825 17:21:29.511590 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.511592 27361 net.cpp:165] Memory required for data: 2073034752
I0825 17:21:29.511595 27361 layer_factory.hpp:77] Creating layer resnet7a_eltwise_relu
I0825 17:21:29.511600 27361 net.cpp:100] Creating Layer resnet7a_eltwise_relu
I0825 17:21:29.511605 27361 net.cpp:434] resnet7a_eltwise_relu <- resnet7a_eltwise
I0825 17:21:29.511610 27361 net.cpp:395] resnet7a_eltwise_relu -> resnet7a_eltwise (in-place)
I0825 17:21:29.511615 27361 net.cpp:150] Setting up resnet7a_eltwise_relu
I0825 17:21:29.511618 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.511622 27361 net.cpp:165] Memory required for data: 2089811968
I0825 17:21:29.511626 27361 layer_factory.hpp:77] Creating layer resnet7a_eltwise_resnet7a_eltwise_relu_0_split
I0825 17:21:29.511631 27361 net.cpp:100] Creating Layer resnet7a_eltwise_resnet7a_eltwise_relu_0_split
I0825 17:21:29.511633 27361 net.cpp:434] resnet7a_eltwise_resnet7a_eltwise_relu_0_split <- resnet7a_eltwise
I0825 17:21:29.511638 27361 net.cpp:408] resnet7a_eltwise_resnet7a_eltwise_relu_0_split -> resnet7a_eltwise_resnet7a_eltwise_relu_0_split_0
I0825 17:21:29.511643 27361 net.cpp:408] resnet7a_eltwise_resnet7a_eltwise_relu_0_split -> resnet7a_eltwise_resnet7a_eltwise_relu_0_split_1
I0825 17:21:29.511672 27361 net.cpp:150] Setting up resnet7a_eltwise_resnet7a_eltwise_relu_0_split
I0825 17:21:29.511678 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.511687 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.511692 27361 net.cpp:165] Memory required for data: 2123366400
I0825 17:21:29.511694 27361 layer_factory.hpp:77] Creating layer resnet7b_btlnk
I0825 17:21:29.511701 27361 net.cpp:100] Creating Layer resnet7b_btlnk
I0825 17:21:29.511705 27361 net.cpp:434] resnet7b_btlnk <- resnet7a_eltwise_resnet7a_eltwise_relu_0_split_0
I0825 17:21:29.511711 27361 net.cpp:408] resnet7b_btlnk -> resnet7b_btlnk
I0825 17:21:29.512069 27361 net.cpp:150] Setting up resnet7b_btlnk
I0825 17:21:29.512078 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.512080 27361 net.cpp:165] Memory required for data: 2125463552
I0825 17:21:29.512085 27361 layer_factory.hpp:77] Creating layer resnet7b_btlnk_relu
I0825 17:21:29.512091 27361 net.cpp:100] Creating Layer resnet7b_btlnk_relu
I0825 17:21:29.512095 27361 net.cpp:434] resnet7b_btlnk_relu <- resnet7b_btlnk
I0825 17:21:29.512104 27361 net.cpp:395] resnet7b_btlnk_relu -> resnet7b_btlnk (in-place)
I0825 17:21:29.512109 27361 net.cpp:150] Setting up resnet7b_btlnk_relu
I0825 17:21:29.512112 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.512116 27361 net.cpp:165] Memory required for data: 2127560704
I0825 17:21:29.512120 27361 layer_factory.hpp:77] Creating layer resnet7b_conv
I0825 17:21:29.512130 27361 net.cpp:100] Creating Layer resnet7b_conv
I0825 17:21:29.512132 27361 net.cpp:434] resnet7b_conv <- resnet7b_btlnk
I0825 17:21:29.512137 27361 net.cpp:408] resnet7b_conv -> resnet7b_conv
I0825 17:21:29.512527 27361 net.cpp:150] Setting up resnet7b_conv
I0825 17:21:29.512536 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.512538 27361 net.cpp:165] Memory required for data: 2129657856
I0825 17:21:29.512543 27361 layer_factory.hpp:77] Creating layer resnet7b_conv_relu
I0825 17:21:29.512549 27361 net.cpp:100] Creating Layer resnet7b_conv_relu
I0825 17:21:29.512552 27361 net.cpp:434] resnet7b_conv_relu <- resnet7b_conv
I0825 17:21:29.512557 27361 net.cpp:395] resnet7b_conv_relu -> resnet7b_conv (in-place)
I0825 17:21:29.512562 27361 net.cpp:150] Setting up resnet7b_conv_relu
I0825 17:21:29.512567 27361 net.cpp:157] Top shape: 1 32 128 128 (524288)
I0825 17:21:29.512569 27361 net.cpp:165] Memory required for data: 2131755008
I0825 17:21:29.512573 27361 layer_factory.hpp:77] Creating layer resnet7b_expnd
I0825 17:21:29.512580 27361 net.cpp:100] Creating Layer resnet7b_expnd
I0825 17:21:29.512583 27361 net.cpp:434] resnet7b_expnd <- resnet7b_conv
I0825 17:21:29.512588 27361 net.cpp:408] resnet7b_expnd -> resnet7b_expnd
I0825 17:21:29.512948 27361 net.cpp:150] Setting up resnet7b_expnd
I0825 17:21:29.512956 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.512959 27361 net.cpp:165] Memory required for data: 2148532224
I0825 17:21:29.512964 27361 layer_factory.hpp:77] Creating layer resnet7b_eltwise
I0825 17:21:29.512970 27361 net.cpp:100] Creating Layer resnet7b_eltwise
I0825 17:21:29.512974 27361 net.cpp:434] resnet7b_eltwise <- resnet7a_eltwise_resnet7a_eltwise_relu_0_split_1
I0825 17:21:29.512979 27361 net.cpp:434] resnet7b_eltwise <- resnet7b_expnd
I0825 17:21:29.512984 27361 net.cpp:408] resnet7b_eltwise -> resnet7b_eltwise
I0825 17:21:29.513003 27361 net.cpp:150] Setting up resnet7b_eltwise
I0825 17:21:29.513008 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.513011 27361 net.cpp:165] Memory required for data: 2165309440
I0825 17:21:29.513015 27361 layer_factory.hpp:77] Creating layer resnet7b_eltwise_relu
I0825 17:21:29.513021 27361 net.cpp:100] Creating Layer resnet7b_eltwise_relu
I0825 17:21:29.513025 27361 net.cpp:434] resnet7b_eltwise_relu <- resnet7b_eltwise
I0825 17:21:29.513030 27361 net.cpp:395] resnet7b_eltwise_relu -> resnet7b_eltwise (in-place)
I0825 17:21:29.513033 27361 net.cpp:150] Setting up resnet7b_eltwise_relu
I0825 17:21:29.513037 27361 net.cpp:157] Top shape: 1 256 128 128 (4194304)
I0825 17:21:29.513041 27361 net.cpp:165] Memory required for data: 2182086656
I0825 17:21:29.513051 27361 layer_factory.hpp:77] Creating layer unpool2
I0825 17:21:29.513057 27361 net.cpp:100] Creating Layer unpool2
I0825 17:21:29.513062 27361 net.cpp:434] unpool2 <- resnet7b_eltwise
I0825 17:21:29.513067 27361 net.cpp:408] unpool2 -> unpool2
I0825 17:21:29.517035 27361 net.cpp:150] Setting up unpool2
I0825 17:21:29.517051 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.517055 27361 net.cpp:165] Memory required for data: 2215641088
I0825 17:21:29.517062 27361 layer_factory.hpp:77] Creating layer concat28_concat
I0825 17:21:29.517071 27361 net.cpp:100] Creating Layer concat28_concat
I0825 17:21:29.517076 27361 net.cpp:434] concat28_concat <- resnet2b_eltwise_resnet2b_eltwise_relu_0_split_1
I0825 17:21:29.517081 27361 net.cpp:434] concat28_concat <- unpool2
I0825 17:21:29.517086 27361 net.cpp:408] concat28_concat -> concat28_concat
I0825 17:21:29.517112 27361 net.cpp:150] Setting up concat28_concat
I0825 17:21:29.517120 27361 net.cpp:157] Top shape: 1 256 256 256 (16777216)
I0825 17:21:29.517124 27361 net.cpp:165] Memory required for data: 2282749952
I0825 17:21:29.517127 27361 layer_factory.hpp:77] Creating layer concat28_concat_concat28_concat_0_split
I0825 17:21:29.517133 27361 net.cpp:100] Creating Layer concat28_concat_concat28_concat_0_split
I0825 17:21:29.517138 27361 net.cpp:434] concat28_concat_concat28_concat_0_split <- concat28_concat
I0825 17:21:29.517145 27361 net.cpp:408] concat28_concat_concat28_concat_0_split -> concat28_concat_concat28_concat_0_split_0
I0825 17:21:29.517150 27361 net.cpp:408] concat28_concat_concat28_concat_0_split -> concat28_concat_concat28_concat_0_split_1
I0825 17:21:29.517181 27361 net.cpp:150] Setting up concat28_concat_concat28_concat_0_split
I0825 17:21:29.517187 27361 net.cpp:157] Top shape: 1 256 256 256 (16777216)
I0825 17:21:29.517191 27361 net.cpp:157] Top shape: 1 256 256 256 (16777216)
I0825 17:21:29.517194 27361 net.cpp:165] Memory required for data: 2416967680
I0825 17:21:29.517199 27361 layer_factory.hpp:77] Creating layer resnet8a_bypass
I0825 17:21:29.517207 27361 net.cpp:100] Creating Layer resnet8a_bypass
I0825 17:21:29.517210 27361 net.cpp:434] resnet8a_bypass <- concat28_concat_concat28_concat_0_split_0
I0825 17:21:29.517216 27361 net.cpp:408] resnet8a_bypass -> resnet8a_bypass
I0825 17:21:29.518210 27361 net.cpp:150] Setting up resnet8a_bypass
I0825 17:21:29.518219 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.518223 27361 net.cpp:165] Memory required for data: 2450522112
I0825 17:21:29.518227 27361 layer_factory.hpp:77] Creating layer resnet8a_btlnk
I0825 17:21:29.518234 27361 net.cpp:100] Creating Layer resnet8a_btlnk
I0825 17:21:29.518237 27361 net.cpp:434] resnet8a_btlnk <- concat28_concat_concat28_concat_0_split_1
I0825 17:21:29.518244 27361 net.cpp:408] resnet8a_btlnk -> resnet8a_btlnk
I0825 17:21:29.518501 27361 net.cpp:150] Setting up resnet8a_btlnk
I0825 17:21:29.518507 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.518510 27361 net.cpp:165] Memory required for data: 2454716416
I0825 17:21:29.518515 27361 layer_factory.hpp:77] Creating layer resnet8a_btlnk_relu
I0825 17:21:29.518522 27361 net.cpp:100] Creating Layer resnet8a_btlnk_relu
I0825 17:21:29.518527 27361 net.cpp:434] resnet8a_btlnk_relu <- resnet8a_btlnk
I0825 17:21:29.518530 27361 net.cpp:395] resnet8a_btlnk_relu -> resnet8a_btlnk (in-place)
I0825 17:21:29.518537 27361 net.cpp:150] Setting up resnet8a_btlnk_relu
I0825 17:21:29.518540 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.518543 27361 net.cpp:165] Memory required for data: 2458910720
I0825 17:21:29.518548 27361 layer_factory.hpp:77] Creating layer resnet8a_conv
I0825 17:21:29.518553 27361 net.cpp:100] Creating Layer resnet8a_conv
I0825 17:21:29.518558 27361 net.cpp:434] resnet8a_conv <- resnet8a_btlnk
I0825 17:21:29.518563 27361 net.cpp:408] resnet8a_conv -> resnet8a_conv
I0825 17:21:29.518779 27361 net.cpp:150] Setting up resnet8a_conv
I0825 17:21:29.518787 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.518791 27361 net.cpp:165] Memory required for data: 2463105024
I0825 17:21:29.518802 27361 layer_factory.hpp:77] Creating layer resnet8a_conv_relu
I0825 17:21:29.518807 27361 net.cpp:100] Creating Layer resnet8a_conv_relu
I0825 17:21:29.518811 27361 net.cpp:434] resnet8a_conv_relu <- resnet8a_conv
I0825 17:21:29.518816 27361 net.cpp:395] resnet8a_conv_relu -> resnet8a_conv (in-place)
I0825 17:21:29.518822 27361 net.cpp:150] Setting up resnet8a_conv_relu
I0825 17:21:29.518826 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.518829 27361 net.cpp:165] Memory required for data: 2467299328
I0825 17:21:29.518833 27361 layer_factory.hpp:77] Creating layer resnet8a_expnd
I0825 17:21:29.518839 27361 net.cpp:100] Creating Layer resnet8a_expnd
I0825 17:21:29.518842 27361 net.cpp:434] resnet8a_expnd <- resnet8a_conv
I0825 17:21:29.518847 27361 net.cpp:408] resnet8a_expnd -> resnet8a_expnd
I0825 17:21:29.519052 27361 net.cpp:150] Setting up resnet8a_expnd
I0825 17:21:29.519063 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.519067 27361 net.cpp:165] Memory required for data: 2500853760
I0825 17:21:29.519071 27361 layer_factory.hpp:77] Creating layer resnet8a_eltwise
I0825 17:21:29.519076 27361 net.cpp:100] Creating Layer resnet8a_eltwise
I0825 17:21:29.519081 27361 net.cpp:434] resnet8a_eltwise <- resnet8a_bypass
I0825 17:21:29.519085 27361 net.cpp:434] resnet8a_eltwise <- resnet8a_expnd
I0825 17:21:29.519091 27361 net.cpp:408] resnet8a_eltwise -> resnet8a_eltwise
I0825 17:21:29.519114 27361 net.cpp:150] Setting up resnet8a_eltwise
I0825 17:21:29.519119 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.519122 27361 net.cpp:165] Memory required for data: 2534408192
I0825 17:21:29.519125 27361 layer_factory.hpp:77] Creating layer resnet8a_eltwise_relu
I0825 17:21:29.519130 27361 net.cpp:100] Creating Layer resnet8a_eltwise_relu
I0825 17:21:29.519134 27361 net.cpp:434] resnet8a_eltwise_relu <- resnet8a_eltwise
I0825 17:21:29.519139 27361 net.cpp:395] resnet8a_eltwise_relu -> resnet8a_eltwise (in-place)
I0825 17:21:29.519143 27361 net.cpp:150] Setting up resnet8a_eltwise_relu
I0825 17:21:29.519147 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.519150 27361 net.cpp:165] Memory required for data: 2567962624
I0825 17:21:29.519153 27361 layer_factory.hpp:77] Creating layer resnet8a_eltwise_resnet8a_eltwise_relu_0_split
I0825 17:21:29.519158 27361 net.cpp:100] Creating Layer resnet8a_eltwise_resnet8a_eltwise_relu_0_split
I0825 17:21:29.519161 27361 net.cpp:434] resnet8a_eltwise_resnet8a_eltwise_relu_0_split <- resnet8a_eltwise
I0825 17:21:29.519170 27361 net.cpp:408] resnet8a_eltwise_resnet8a_eltwise_relu_0_split -> resnet8a_eltwise_resnet8a_eltwise_relu_0_split_0
I0825 17:21:29.519174 27361 net.cpp:408] resnet8a_eltwise_resnet8a_eltwise_relu_0_split -> resnet8a_eltwise_resnet8a_eltwise_relu_0_split_1
I0825 17:21:29.519207 27361 net.cpp:150] Setting up resnet8a_eltwise_resnet8a_eltwise_relu_0_split
I0825 17:21:29.519212 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.519217 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.519219 27361 net.cpp:165] Memory required for data: 2635071488
I0825 17:21:29.519222 27361 layer_factory.hpp:77] Creating layer resnet8b_btlnk
I0825 17:21:29.519230 27361 net.cpp:100] Creating Layer resnet8b_btlnk
I0825 17:21:29.519234 27361 net.cpp:434] resnet8b_btlnk <- resnet8a_eltwise_resnet8a_eltwise_relu_0_split_0
I0825 17:21:29.519239 27361 net.cpp:408] resnet8b_btlnk -> resnet8b_btlnk
I0825 17:21:29.519439 27361 net.cpp:150] Setting up resnet8b_btlnk
I0825 17:21:29.519448 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.519450 27361 net.cpp:165] Memory required for data: 2639265792
I0825 17:21:29.519454 27361 layer_factory.hpp:77] Creating layer resnet8b_btlnk_relu
I0825 17:21:29.519459 27361 net.cpp:100] Creating Layer resnet8b_btlnk_relu
I0825 17:21:29.519464 27361 net.cpp:434] resnet8b_btlnk_relu <- resnet8b_btlnk
I0825 17:21:29.519469 27361 net.cpp:395] resnet8b_btlnk_relu -> resnet8b_btlnk (in-place)
I0825 17:21:29.519480 27361 net.cpp:150] Setting up resnet8b_btlnk_relu
I0825 17:21:29.519484 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.519487 27361 net.cpp:165] Memory required for data: 2643460096
I0825 17:21:29.519491 27361 layer_factory.hpp:77] Creating layer resnet8b_conv
I0825 17:21:29.519497 27361 net.cpp:100] Creating Layer resnet8b_conv
I0825 17:21:29.519501 27361 net.cpp:434] resnet8b_conv <- resnet8b_btlnk
I0825 17:21:29.519505 27361 net.cpp:408] resnet8b_conv -> resnet8b_conv
I0825 17:21:29.519713 27361 net.cpp:150] Setting up resnet8b_conv
I0825 17:21:29.519721 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.519724 27361 net.cpp:165] Memory required for data: 2647654400
I0825 17:21:29.519728 27361 layer_factory.hpp:77] Creating layer resnet8b_conv_relu
I0825 17:21:29.519733 27361 net.cpp:100] Creating Layer resnet8b_conv_relu
I0825 17:21:29.519737 27361 net.cpp:434] resnet8b_conv_relu <- resnet8b_conv
I0825 17:21:29.519744 27361 net.cpp:395] resnet8b_conv_relu -> resnet8b_conv (in-place)
I0825 17:21:29.519750 27361 net.cpp:150] Setting up resnet8b_conv_relu
I0825 17:21:29.519754 27361 net.cpp:157] Top shape: 1 16 256 256 (1048576)
I0825 17:21:29.519757 27361 net.cpp:165] Memory required for data: 2651848704
I0825 17:21:29.519760 27361 layer_factory.hpp:77] Creating layer resnet8b_expnd
I0825 17:21:29.519768 27361 net.cpp:100] Creating Layer resnet8b_expnd
I0825 17:21:29.519773 27361 net.cpp:434] resnet8b_expnd <- resnet8b_conv
I0825 17:21:29.519778 27361 net.cpp:408] resnet8b_expnd -> resnet8b_expnd
I0825 17:21:29.519979 27361 net.cpp:150] Setting up resnet8b_expnd
I0825 17:21:29.519987 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.519990 27361 net.cpp:165] Memory required for data: 2685403136
I0825 17:21:29.519995 27361 layer_factory.hpp:77] Creating layer resnet8b_eltwise
I0825 17:21:29.520000 27361 net.cpp:100] Creating Layer resnet8b_eltwise
I0825 17:21:29.520004 27361 net.cpp:434] resnet8b_eltwise <- resnet8a_eltwise_resnet8a_eltwise_relu_0_split_1
I0825 17:21:29.520009 27361 net.cpp:434] resnet8b_eltwise <- resnet8b_expnd
I0825 17:21:29.520014 27361 net.cpp:408] resnet8b_eltwise -> resnet8b_eltwise
I0825 17:21:29.520035 27361 net.cpp:150] Setting up resnet8b_eltwise
I0825 17:21:29.520040 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.520043 27361 net.cpp:165] Memory required for data: 2718957568
I0825 17:21:29.520046 27361 layer_factory.hpp:77] Creating layer resnet8b_eltwise_relu
I0825 17:21:29.520051 27361 net.cpp:100] Creating Layer resnet8b_eltwise_relu
I0825 17:21:29.520056 27361 net.cpp:434] resnet8b_eltwise_relu <- resnet8b_eltwise
I0825 17:21:29.520059 27361 net.cpp:395] resnet8b_eltwise_relu -> resnet8b_eltwise (in-place)
I0825 17:21:29.520064 27361 net.cpp:150] Setting up resnet8b_eltwise_relu
I0825 17:21:29.520068 27361 net.cpp:157] Top shape: 1 128 256 256 (8388608)
I0825 17:21:29.520071 27361 net.cpp:165] Memory required for data: 2752512000
I0825 17:21:29.520074 27361 layer_factory.hpp:77] Creating layer unpool1
I0825 17:21:29.520081 27361 net.cpp:100] Creating Layer unpool1
I0825 17:21:29.520084 27361 net.cpp:434] unpool1 <- resnet8b_eltwise
I0825 17:21:29.520090 27361 net.cpp:408] unpool1 -> unpool1
I0825 17:21:29.521648 27361 net.cpp:150] Setting up unpool1
I0825 17:21:29.521662 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.521666 27361 net.cpp:165] Memory required for data: 2819620864
I0825 17:21:29.521672 27361 layer_factory.hpp:77] Creating layer concat19_concat
I0825 17:21:29.521679 27361 net.cpp:100] Creating Layer concat19_concat
I0825 17:21:29.521683 27361 net.cpp:434] concat19_concat <- resnet1b_eltwise_resnet1b_eltwise_relu_0_split_1
I0825 17:21:29.521688 27361 net.cpp:434] concat19_concat <- unpool1
I0825 17:21:29.521694 27361 net.cpp:408] concat19_concat -> concat19_concat
I0825 17:21:29.521728 27361 net.cpp:150] Setting up concat19_concat
I0825 17:21:29.521734 27361 net.cpp:157] Top shape: 1 128 512 512 (33554432)
I0825 17:21:29.521738 27361 net.cpp:165] Memory required for data: 2953838592
I0825 17:21:29.521747 27361 layer_factory.hpp:77] Creating layer concat19_concat_concat19_concat_0_split
I0825 17:21:29.521754 27361 net.cpp:100] Creating Layer concat19_concat_concat19_concat_0_split
I0825 17:21:29.521759 27361 net.cpp:434] concat19_concat_concat19_concat_0_split <- concat19_concat
I0825 17:21:29.521764 27361 net.cpp:408] concat19_concat_concat19_concat_0_split -> concat19_concat_concat19_concat_0_split_0
I0825 17:21:29.521769 27361 net.cpp:408] concat19_concat_concat19_concat_0_split -> concat19_concat_concat19_concat_0_split_1
I0825 17:21:29.521802 27361 net.cpp:150] Setting up concat19_concat_concat19_concat_0_split
I0825 17:21:29.521808 27361 net.cpp:157] Top shape: 1 128 512 512 (33554432)
I0825 17:21:29.521812 27361 net.cpp:157] Top shape: 1 128 512 512 (33554432)
I0825 17:21:29.521816 27361 net.cpp:165] Memory required for data: 3222274048
I0825 17:21:29.521822 27361 layer_factory.hpp:77] Creating layer resnet9a_bypass
I0825 17:21:29.521831 27361 net.cpp:100] Creating Layer resnet9a_bypass
I0825 17:21:29.521834 27361 net.cpp:434] resnet9a_bypass <- concat19_concat_concat19_concat_0_split_0
I0825 17:21:29.521839 27361 net.cpp:408] resnet9a_bypass -> resnet9a_bypass
I0825 17:21:29.522568 27361 net.cpp:150] Setting up resnet9a_bypass
I0825 17:21:29.522580 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.522584 27361 net.cpp:165] Memory required for data: 3289382912
I0825 17:21:29.522599 27361 layer_factory.hpp:77] Creating layer resnet9a_btlnk
I0825 17:21:29.522611 27361 net.cpp:100] Creating Layer resnet9a_btlnk
I0825 17:21:29.522617 27361 net.cpp:434] resnet9a_btlnk <- concat19_concat_concat19_concat_0_split_1
I0825 17:21:29.522624 27361 net.cpp:408] resnet9a_btlnk -> resnet9a_btlnk
I0825 17:21:29.522807 27361 net.cpp:150] Setting up resnet9a_btlnk
I0825 17:21:29.522815 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.522819 27361 net.cpp:165] Memory required for data: 3297771520
I0825 17:21:29.522824 27361 layer_factory.hpp:77] Creating layer resnet9a_btlnk_relu
I0825 17:21:29.522830 27361 net.cpp:100] Creating Layer resnet9a_btlnk_relu
I0825 17:21:29.522832 27361 net.cpp:434] resnet9a_btlnk_relu <- resnet9a_btlnk
I0825 17:21:29.522837 27361 net.cpp:395] resnet9a_btlnk_relu -> resnet9a_btlnk (in-place)
I0825 17:21:29.522842 27361 net.cpp:150] Setting up resnet9a_btlnk_relu
I0825 17:21:29.522847 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.522850 27361 net.cpp:165] Memory required for data: 3306160128
I0825 17:21:29.522853 27361 layer_factory.hpp:77] Creating layer resnet9a_conv
I0825 17:21:29.522861 27361 net.cpp:100] Creating Layer resnet9a_conv
I0825 17:21:29.522864 27361 net.cpp:434] resnet9a_conv <- resnet9a_btlnk
I0825 17:21:29.522869 27361 net.cpp:408] resnet9a_conv -> resnet9a_conv
I0825 17:21:29.523036 27361 net.cpp:150] Setting up resnet9a_conv
I0825 17:21:29.523042 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.523046 27361 net.cpp:165] Memory required for data: 3314548736
I0825 17:21:29.523051 27361 layer_factory.hpp:77] Creating layer resnet9a_conv_relu
I0825 17:21:29.523056 27361 net.cpp:100] Creating Layer resnet9a_conv_relu
I0825 17:21:29.523059 27361 net.cpp:434] resnet9a_conv_relu <- resnet9a_conv
I0825 17:21:29.523063 27361 net.cpp:395] resnet9a_conv_relu -> resnet9a_conv (in-place)
I0825 17:21:29.523068 27361 net.cpp:150] Setting up resnet9a_conv_relu
I0825 17:21:29.523073 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.523077 27361 net.cpp:165] Memory required for data: 3322937344
I0825 17:21:29.523079 27361 layer_factory.hpp:77] Creating layer resnet9a_expnd
I0825 17:21:29.523085 27361 net.cpp:100] Creating Layer resnet9a_expnd
I0825 17:21:29.523088 27361 net.cpp:434] resnet9a_expnd <- resnet9a_conv
I0825 17:21:29.523094 27361 net.cpp:408] resnet9a_expnd -> resnet9a_expnd
I0825 17:21:29.523267 27361 net.cpp:150] Setting up resnet9a_expnd
I0825 17:21:29.523273 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.523277 27361 net.cpp:165] Memory required for data: 3390046208
I0825 17:21:29.523288 27361 layer_factory.hpp:77] Creating layer resnet9a_eltwise
I0825 17:21:29.523294 27361 net.cpp:100] Creating Layer resnet9a_eltwise
I0825 17:21:29.523298 27361 net.cpp:434] resnet9a_eltwise <- resnet9a_bypass
I0825 17:21:29.523303 27361 net.cpp:434] resnet9a_eltwise <- resnet9a_expnd
I0825 17:21:29.523308 27361 net.cpp:408] resnet9a_eltwise -> resnet9a_eltwise
I0825 17:21:29.523329 27361 net.cpp:150] Setting up resnet9a_eltwise
I0825 17:21:29.523334 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.523337 27361 net.cpp:165] Memory required for data: 3457155072
I0825 17:21:29.523341 27361 layer_factory.hpp:77] Creating layer resnet9a_eltwise_relu
I0825 17:21:29.523349 27361 net.cpp:100] Creating Layer resnet9a_eltwise_relu
I0825 17:21:29.523351 27361 net.cpp:434] resnet9a_eltwise_relu <- resnet9a_eltwise
I0825 17:21:29.523356 27361 net.cpp:395] resnet9a_eltwise_relu -> resnet9a_eltwise (in-place)
I0825 17:21:29.523363 27361 net.cpp:150] Setting up resnet9a_eltwise_relu
I0825 17:21:29.523368 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.523371 27361 net.cpp:165] Memory required for data: 3524263936
I0825 17:21:29.523375 27361 layer_factory.hpp:77] Creating layer resnet9a_eltwise_resnet9a_eltwise_relu_0_split
I0825 17:21:29.523380 27361 net.cpp:100] Creating Layer resnet9a_eltwise_resnet9a_eltwise_relu_0_split
I0825 17:21:29.523382 27361 net.cpp:434] resnet9a_eltwise_resnet9a_eltwise_relu_0_split <- resnet9a_eltwise
I0825 17:21:29.523387 27361 net.cpp:408] resnet9a_eltwise_resnet9a_eltwise_relu_0_split -> resnet9a_eltwise_resnet9a_eltwise_relu_0_split_0
I0825 17:21:29.523392 27361 net.cpp:408] resnet9a_eltwise_resnet9a_eltwise_relu_0_split -> resnet9a_eltwise_resnet9a_eltwise_relu_0_split_1
I0825 17:21:29.523425 27361 net.cpp:150] Setting up resnet9a_eltwise_resnet9a_eltwise_relu_0_split
I0825 17:21:29.523432 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.523435 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.523439 27361 net.cpp:165] Memory required for data: 3658481664
I0825 17:21:29.523442 27361 layer_factory.hpp:77] Creating layer resnet9b_bypass
I0825 17:21:29.523450 27361 net.cpp:100] Creating Layer resnet9b_bypass
I0825 17:21:29.523454 27361 net.cpp:434] resnet9b_bypass <- resnet9a_eltwise_resnet9a_eltwise_relu_0_split_0
I0825 17:21:29.523460 27361 net.cpp:408] resnet9b_bypass -> resnet9b_bypass
I0825 17:21:29.523716 27361 net.cpp:150] Setting up resnet9b_bypass
I0825 17:21:29.523723 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.523727 27361 net.cpp:165] Memory required for data: 3725590528
I0825 17:21:29.523731 27361 layer_factory.hpp:77] Creating layer resnet9b_btlnk
I0825 17:21:29.523738 27361 net.cpp:100] Creating Layer resnet9b_btlnk
I0825 17:21:29.523742 27361 net.cpp:434] resnet9b_btlnk <- resnet9a_eltwise_resnet9a_eltwise_relu_0_split_1
I0825 17:21:29.523747 27361 net.cpp:408] resnet9b_btlnk -> resnet9b_btlnk
I0825 17:21:29.523910 27361 net.cpp:150] Setting up resnet9b_btlnk
I0825 17:21:29.523916 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.523919 27361 net.cpp:165] Memory required for data: 3733979136
I0825 17:21:29.523924 27361 layer_factory.hpp:77] Creating layer resnet9b_btlnk_relu
I0825 17:21:29.523929 27361 net.cpp:100] Creating Layer resnet9b_btlnk_relu
I0825 17:21:29.523933 27361 net.cpp:434] resnet9b_btlnk_relu <- resnet9b_btlnk
I0825 17:21:29.523938 27361 net.cpp:395] resnet9b_btlnk_relu -> resnet9b_btlnk (in-place)
I0825 17:21:29.523944 27361 net.cpp:150] Setting up resnet9b_btlnk_relu
I0825 17:21:29.523948 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.523952 27361 net.cpp:165] Memory required for data: 3742367744
I0825 17:21:29.523954 27361 layer_factory.hpp:77] Creating layer resnet9b_conv
I0825 17:21:29.523960 27361 net.cpp:100] Creating Layer resnet9b_conv
I0825 17:21:29.523964 27361 net.cpp:434] resnet9b_conv <- resnet9b_btlnk
I0825 17:21:29.523968 27361 net.cpp:408] resnet9b_conv -> resnet9b_conv
I0825 17:21:29.524137 27361 net.cpp:150] Setting up resnet9b_conv
I0825 17:21:29.524144 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.524147 27361 net.cpp:165] Memory required for data: 3750756352
I0825 17:21:29.524152 27361 layer_factory.hpp:77] Creating layer resnet9b_conv_relu
I0825 17:21:29.524158 27361 net.cpp:100] Creating Layer resnet9b_conv_relu
I0825 17:21:29.524160 27361 net.cpp:434] resnet9b_conv_relu <- resnet9b_conv
I0825 17:21:29.524165 27361 net.cpp:395] resnet9b_conv_relu -> resnet9b_conv (in-place)
I0825 17:21:29.524170 27361 net.cpp:150] Setting up resnet9b_conv_relu
I0825 17:21:29.524174 27361 net.cpp:157] Top shape: 1 8 512 512 (2097152)
I0825 17:21:29.524178 27361 net.cpp:165] Memory required for data: 3759144960
I0825 17:21:29.524180 27361 layer_factory.hpp:77] Creating layer resnet9b_expnd
I0825 17:21:29.524188 27361 net.cpp:100] Creating Layer resnet9b_expnd
I0825 17:21:29.524194 27361 net.cpp:434] resnet9b_expnd <- resnet9b_conv
I0825 17:21:29.524199 27361 net.cpp:408] resnet9b_expnd -> resnet9b_expnd
I0825 17:21:29.524366 27361 net.cpp:150] Setting up resnet9b_expnd
I0825 17:21:29.524374 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.524376 27361 net.cpp:165] Memory required for data: 3826253824
I0825 17:21:29.524381 27361 layer_factory.hpp:77] Creating layer resnet9b_eltwise
I0825 17:21:29.524386 27361 net.cpp:100] Creating Layer resnet9b_eltwise
I0825 17:21:29.524390 27361 net.cpp:434] resnet9b_eltwise <- resnet9b_bypass
I0825 17:21:29.524395 27361 net.cpp:434] resnet9b_eltwise <- resnet9b_expnd
I0825 17:21:29.524399 27361 net.cpp:408] resnet9b_eltwise -> resnet9b_eltwise
I0825 17:21:29.524420 27361 net.cpp:150] Setting up resnet9b_eltwise
I0825 17:21:29.524426 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.524430 27361 net.cpp:165] Memory required for data: 3893362688
I0825 17:21:29.524432 27361 layer_factory.hpp:77] Creating layer resnet9b_eltwise_relu
I0825 17:21:29.524437 27361 net.cpp:100] Creating Layer resnet9b_eltwise_relu
I0825 17:21:29.524441 27361 net.cpp:434] resnet9b_eltwise_relu <- resnet9b_eltwise
I0825 17:21:29.524446 27361 net.cpp:395] resnet9b_eltwise_relu -> resnet9b_eltwise (in-place)
I0825 17:21:29.524449 27361 net.cpp:150] Setting up resnet9b_eltwise_relu
I0825 17:21:29.524453 27361 net.cpp:157] Top shape: 1 64 512 512 (16777216)
I0825 17:21:29.524456 27361 net.cpp:165] Memory required for data: 3960471552
I0825 17:21:29.524461 27361 layer_factory.hpp:77] Creating layer score_conv
I0825 17:21:29.524468 27361 net.cpp:100] Creating Layer score_conv
I0825 17:21:29.524471 27361 net.cpp:434] score_conv <- resnet9b_eltwise
I0825 17:21:29.524477 27361 net.cpp:408] score_conv -> score_conv
I0825 17:21:29.525173 27361 net.cpp:150] Setting up score_conv
I0825 17:21:29.525187 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.525190 27361 net.cpp:165] Memory required for data: 3964665856
I0825 17:21:29.525197 27361 layer_factory.hpp:77] Creating layer score_relu
I0825 17:21:29.525203 27361 net.cpp:100] Creating Layer score_relu
I0825 17:21:29.525207 27361 net.cpp:434] score_relu <- score_conv
I0825 17:21:29.525213 27361 net.cpp:395] score_relu -> score_conv (in-place)
I0825 17:21:29.525218 27361 net.cpp:150] Setting up score_relu
I0825 17:21:29.525223 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.525226 27361 net.cpp:165] Memory required for data: 3968860160
I0825 17:21:29.525229 27361 layer_factory.hpp:77] Creating layer crop_score
I0825 17:21:29.525234 27361 net.cpp:100] Creating Layer crop_score
I0825 17:21:29.525238 27361 net.cpp:434] crop_score <- score_conv
I0825 17:21:29.525243 27361 net.cpp:434] crop_score <- label_data_1_split_0
I0825 17:21:29.525249 27361 net.cpp:408] crop_score -> crop_score
I0825 17:21:29.525275 27361 net.cpp:150] Setting up crop_score
I0825 17:21:29.525284 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.525286 27361 net.cpp:165] Memory required for data: 3973054464
I0825 17:21:29.525290 27361 layer_factory.hpp:77] Creating layer crop_score_crop_score_0_split
I0825 17:21:29.525300 27361 net.cpp:100] Creating Layer crop_score_crop_score_0_split
I0825 17:21:29.525305 27361 net.cpp:434] crop_score_crop_score_0_split <- crop_score
I0825 17:21:29.525310 27361 net.cpp:408] crop_score_crop_score_0_split -> crop_score_crop_score_0_split_0
I0825 17:21:29.525315 27361 net.cpp:408] crop_score_crop_score_0_split -> crop_score_crop_score_0_split_1
I0825 17:21:29.525347 27361 net.cpp:150] Setting up crop_score_crop_score_0_split
I0825 17:21:29.525353 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.525357 27361 net.cpp:157] Top shape: 1 4 512 512 (1048576)
I0825 17:21:29.525360 27361 net.cpp:165] Memory required for data: 3981443072
I0825 17:21:29.525363 27361 layer_factory.hpp:77] Creating layer softmaxloss
I0825 17:21:29.525370 27361 net.cpp:100] Creating Layer softmaxloss
I0825 17:21:29.525374 27361 net.cpp:434] softmaxloss <- crop_score_crop_score_0_split_0
I0825 17:21:29.525382 27361 net.cpp:434] softmaxloss <- label_data_1_split_1
I0825 17:21:29.525387 27361 net.cpp:408] softmaxloss -> softmaxloss
I0825 17:21:29.525393 27361 layer_factory.hpp:77] Creating layer softmaxloss
I0825 17:21:29.527144 27361 softmax_loss_layer.cpp:47] class_loss_weights[0] = 1
I0825 17:21:29.527164 27361 softmax_loss_layer.cpp:47] class_loss_weights[1] = 100
I0825 17:21:29.527169 27361 softmax_loss_layer.cpp:47] class_loss_weights[2] = 100
I0825 17:21:29.527173 27361 softmax_loss_layer.cpp:47] class_loss_weights[3] = 100
I0825 17:21:29.527204 27361 net.cpp:150] Setting up softmaxloss
I0825 17:21:29.527215 27361 net.cpp:157] Top shape: (1)
I0825 17:21:29.527218 27361 net.cpp:160]     with loss weight 1
I0825 17:21:29.527223 27361 net.cpp:165] Memory required for data: 3981443076
I0825 17:21:29.527226 27361 layer_factory.hpp:77] Creating layer accuracy
I0825 17:21:29.527235 27361 net.cpp:100] Creating Layer accuracy
I0825 17:21:29.527240 27361 net.cpp:434] accuracy <- crop_score_crop_score_0_split_1
I0825 17:21:29.527243 27361 net.cpp:434] accuracy <- label_data_1_split_2
I0825 17:21:29.527248 27361 net.cpp:408] accuracy -> accuracy
I0825 17:21:29.527256 27361 net.cpp:150] Setting up accuracy
I0825 17:21:29.527261 27361 net.cpp:157] Top shape: (1)
I0825 17:21:29.527264 27361 net.cpp:165] Memory required for data: 3981443080
I0825 17:21:29.527267 27361 net.cpp:228] accuracy does not need backward computation.
I0825 17:21:29.527271 27361 net.cpp:226] softmaxloss needs backward computation.
I0825 17:21:29.527276 27361 net.cpp:226] crop_score_crop_score_0_split needs backward computation.
I0825 17:21:29.527278 27361 net.cpp:226] crop_score needs backward computation.
I0825 17:21:29.527282 27361 net.cpp:226] score_relu needs backward computation.
I0825 17:21:29.527285 27361 net.cpp:226] score_conv needs backward computation.
I0825 17:21:29.527289 27361 net.cpp:226] resnet9b_eltwise_relu needs backward computation.
I0825 17:21:29.527292 27361 net.cpp:226] resnet9b_eltwise needs backward computation.
I0825 17:21:29.527297 27361 net.cpp:226] resnet9b_expnd needs backward computation.
I0825 17:21:29.527299 27361 net.cpp:226] resnet9b_conv_relu needs backward computation.
I0825 17:21:29.527303 27361 net.cpp:226] resnet9b_conv needs backward computation.
I0825 17:21:29.527307 27361 net.cpp:226] resnet9b_btlnk_relu needs backward computation.
I0825 17:21:29.527310 27361 net.cpp:226] resnet9b_btlnk needs backward computation.
I0825 17:21:29.527313 27361 net.cpp:226] resnet9b_bypass needs backward computation.
I0825 17:21:29.527318 27361 net.cpp:226] resnet9a_eltwise_resnet9a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527320 27361 net.cpp:226] resnet9a_eltwise_relu needs backward computation.
I0825 17:21:29.527324 27361 net.cpp:226] resnet9a_eltwise needs backward computation.
I0825 17:21:29.527328 27361 net.cpp:226] resnet9a_expnd needs backward computation.
I0825 17:21:29.527331 27361 net.cpp:226] resnet9a_conv_relu needs backward computation.
I0825 17:21:29.527334 27361 net.cpp:226] resnet9a_conv needs backward computation.
I0825 17:21:29.527345 27361 net.cpp:226] resnet9a_btlnk_relu needs backward computation.
I0825 17:21:29.527348 27361 net.cpp:226] resnet9a_btlnk needs backward computation.
I0825 17:21:29.527353 27361 net.cpp:226] resnet9a_bypass needs backward computation.
I0825 17:21:29.527355 27361 net.cpp:226] concat19_concat_concat19_concat_0_split needs backward computation.
I0825 17:21:29.527359 27361 net.cpp:226] concat19_concat needs backward computation.
I0825 17:21:29.527364 27361 net.cpp:226] unpool1 needs backward computation.
I0825 17:21:29.527367 27361 net.cpp:226] resnet8b_eltwise_relu needs backward computation.
I0825 17:21:29.527371 27361 net.cpp:226] resnet8b_eltwise needs backward computation.
I0825 17:21:29.527375 27361 net.cpp:226] resnet8b_expnd needs backward computation.
I0825 17:21:29.527379 27361 net.cpp:226] resnet8b_conv_relu needs backward computation.
I0825 17:21:29.527382 27361 net.cpp:226] resnet8b_conv needs backward computation.
I0825 17:21:29.527387 27361 net.cpp:226] resnet8b_btlnk_relu needs backward computation.
I0825 17:21:29.527391 27361 net.cpp:226] resnet8b_btlnk needs backward computation.
I0825 17:21:29.527395 27361 net.cpp:226] resnet8a_eltwise_resnet8a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527398 27361 net.cpp:226] resnet8a_eltwise_relu needs backward computation.
I0825 17:21:29.527401 27361 net.cpp:226] resnet8a_eltwise needs backward computation.
I0825 17:21:29.527405 27361 net.cpp:226] resnet8a_expnd needs backward computation.
I0825 17:21:29.527410 27361 net.cpp:226] resnet8a_conv_relu needs backward computation.
I0825 17:21:29.527412 27361 net.cpp:226] resnet8a_conv needs backward computation.
I0825 17:21:29.527415 27361 net.cpp:226] resnet8a_btlnk_relu needs backward computation.
I0825 17:21:29.527420 27361 net.cpp:226] resnet8a_btlnk needs backward computation.
I0825 17:21:29.527423 27361 net.cpp:226] resnet8a_bypass needs backward computation.
I0825 17:21:29.527426 27361 net.cpp:226] concat28_concat_concat28_concat_0_split needs backward computation.
I0825 17:21:29.527431 27361 net.cpp:226] concat28_concat needs backward computation.
I0825 17:21:29.527434 27361 net.cpp:226] unpool2 needs backward computation.
I0825 17:21:29.527437 27361 net.cpp:226] resnet7b_eltwise_relu needs backward computation.
I0825 17:21:29.527441 27361 net.cpp:226] resnet7b_eltwise needs backward computation.
I0825 17:21:29.527444 27361 net.cpp:226] resnet7b_expnd needs backward computation.
I0825 17:21:29.527448 27361 net.cpp:226] resnet7b_conv_relu needs backward computation.
I0825 17:21:29.527451 27361 net.cpp:226] resnet7b_conv needs backward computation.
I0825 17:21:29.527456 27361 net.cpp:226] resnet7b_btlnk_relu needs backward computation.
I0825 17:21:29.527458 27361 net.cpp:226] resnet7b_btlnk needs backward computation.
I0825 17:21:29.527462 27361 net.cpp:226] resnet7a_eltwise_resnet7a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527467 27361 net.cpp:226] resnet7a_eltwise_relu needs backward computation.
I0825 17:21:29.527469 27361 net.cpp:226] resnet7a_eltwise needs backward computation.
I0825 17:21:29.527473 27361 net.cpp:226] resnet7a_expnd needs backward computation.
I0825 17:21:29.527477 27361 net.cpp:226] resnet7a_conv_relu needs backward computation.
I0825 17:21:29.527480 27361 net.cpp:226] resnet7a_conv needs backward computation.
I0825 17:21:29.527484 27361 net.cpp:226] resnet7a_btlnk_relu needs backward computation.
I0825 17:21:29.527487 27361 net.cpp:226] resnet7a_btlnk needs backward computation.
I0825 17:21:29.527492 27361 net.cpp:226] resnet7a_bypass needs backward computation.
I0825 17:21:29.527494 27361 net.cpp:226] concat37_concat_concat37_concat_0_split needs backward computation.
I0825 17:21:29.527498 27361 net.cpp:226] concat37_concat needs backward computation.
I0825 17:21:29.527503 27361 net.cpp:226] unpool3 needs backward computation.
I0825 17:21:29.527506 27361 net.cpp:226] resnet6b_eltwise_relu needs backward computation.
I0825 17:21:29.527509 27361 net.cpp:226] resnet6b_eltwise needs backward computation.
I0825 17:21:29.527513 27361 net.cpp:226] resnet6b_expnd needs backward computation.
I0825 17:21:29.527521 27361 net.cpp:226] resnet6b_conv_relu needs backward computation.
I0825 17:21:29.527524 27361 net.cpp:226] resnet6b_conv needs backward computation.
I0825 17:21:29.527529 27361 net.cpp:226] resnet6b_btlnk_relu needs backward computation.
I0825 17:21:29.527532 27361 net.cpp:226] resnet6b_btlnk needs backward computation.
I0825 17:21:29.527535 27361 net.cpp:226] resnet6a_eltwise_resnet6a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527539 27361 net.cpp:226] resnet6a_eltwise_relu needs backward computation.
I0825 17:21:29.527542 27361 net.cpp:226] resnet6a_eltwise needs backward computation.
I0825 17:21:29.527546 27361 net.cpp:226] resnet6a_expnd needs backward computation.
I0825 17:21:29.527550 27361 net.cpp:226] resnet6a_conv_relu needs backward computation.
I0825 17:21:29.527554 27361 net.cpp:226] resnet6a_conv needs backward computation.
I0825 17:21:29.527559 27361 net.cpp:226] resnet6a_btlnk_relu needs backward computation.
I0825 17:21:29.527564 27361 net.cpp:226] resnet6a_btlnk needs backward computation.
I0825 17:21:29.527566 27361 net.cpp:226] resnet6a_bypass needs backward computation.
I0825 17:21:29.527570 27361 net.cpp:226] concat56_concat_concat56_concat_0_split needs backward computation.
I0825 17:21:29.527575 27361 net.cpp:226] concat56_concat needs backward computation.
I0825 17:21:29.527578 27361 net.cpp:226] unpool4 needs backward computation.
I0825 17:21:29.527582 27361 net.cpp:226] resnet5b_eltwise_relu needs backward computation.
I0825 17:21:29.527586 27361 net.cpp:226] resnet5b_eltwise needs backward computation.
I0825 17:21:29.527590 27361 net.cpp:226] resnet5b_expnd needs backward computation.
I0825 17:21:29.527595 27361 net.cpp:226] resnet5b_conv_relu needs backward computation.
I0825 17:21:29.527597 27361 net.cpp:226] resnet5b_conv needs backward computation.
I0825 17:21:29.527601 27361 net.cpp:226] resnet5b_btlnk_relu needs backward computation.
I0825 17:21:29.527606 27361 net.cpp:226] resnet5b_btlnk needs backward computation.
I0825 17:21:29.527609 27361 net.cpp:226] resnet5a_eltwise_resnet5a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527613 27361 net.cpp:226] resnet5a_eltwise_relu needs backward computation.
I0825 17:21:29.527616 27361 net.cpp:226] resnet5a_eltwise needs backward computation.
I0825 17:21:29.527621 27361 net.cpp:226] resnet5a_expnd needs backward computation.
I0825 17:21:29.527624 27361 net.cpp:226] resnet5a_conv_relu needs backward computation.
I0825 17:21:29.527627 27361 net.cpp:226] resnet5a_conv needs backward computation.
I0825 17:21:29.527631 27361 net.cpp:226] resnet5a_btlnk_relu needs backward computation.
I0825 17:21:29.527636 27361 net.cpp:226] resnet5a_btlnk needs backward computation.
I0825 17:21:29.527639 27361 net.cpp:226] resnet5a_bypass needs backward computation.
I0825 17:21:29.527643 27361 net.cpp:226] maxpool4_maxpool4_0_split needs backward computation.
I0825 17:21:29.527647 27361 net.cpp:226] maxpool4 needs backward computation.
I0825 17:21:29.527650 27361 net.cpp:226] resnet4b_eltwise_resnet4b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527654 27361 net.cpp:226] resnet4b_eltwise_relu needs backward computation.
I0825 17:21:29.527658 27361 net.cpp:226] resnet4b_eltwise needs backward computation.
I0825 17:21:29.527662 27361 net.cpp:226] resnet4b_expnd needs backward computation.
I0825 17:21:29.527667 27361 net.cpp:226] resnet4b_conv_relu needs backward computation.
I0825 17:21:29.527669 27361 net.cpp:226] resnet4b_conv needs backward computation.
I0825 17:21:29.527673 27361 net.cpp:226] resnet4b_btlnk_relu needs backward computation.
I0825 17:21:29.527678 27361 net.cpp:226] resnet4b_btlnk needs backward computation.
I0825 17:21:29.527680 27361 net.cpp:226] resnet4a_eltwise_resnet4a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527684 27361 net.cpp:226] resnet4a_eltwise_relu needs backward computation.
I0825 17:21:29.527688 27361 net.cpp:226] resnet4a_eltwise needs backward computation.
I0825 17:21:29.527693 27361 net.cpp:226] resnet4a_expnd needs backward computation.
I0825 17:21:29.527700 27361 net.cpp:226] resnet4a_conv_relu needs backward computation.
I0825 17:21:29.527704 27361 net.cpp:226] resnet4a_conv needs backward computation.
I0825 17:21:29.527707 27361 net.cpp:226] resnet4a_btlnk_relu needs backward computation.
I0825 17:21:29.527711 27361 net.cpp:226] resnet4a_btlnk needs backward computation.
I0825 17:21:29.527714 27361 net.cpp:226] resnet4a_bypass needs backward computation.
I0825 17:21:29.527719 27361 net.cpp:226] maxpool3_maxpool3_0_split needs backward computation.
I0825 17:21:29.527722 27361 net.cpp:226] maxpool3 needs backward computation.
I0825 17:21:29.527726 27361 net.cpp:226] resnet3b_eltwise_resnet3b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527730 27361 net.cpp:226] resnet3b_eltwise_relu needs backward computation.
I0825 17:21:29.527734 27361 net.cpp:226] resnet3b_eltwise needs backward computation.
I0825 17:21:29.527740 27361 net.cpp:226] resnet3b_expnd needs backward computation.
I0825 17:21:29.527745 27361 net.cpp:226] resnet3b_conv_relu needs backward computation.
I0825 17:21:29.527747 27361 net.cpp:226] resnet3b_conv needs backward computation.
I0825 17:21:29.527751 27361 net.cpp:226] resnet3b_btlnk_relu needs backward computation.
I0825 17:21:29.527755 27361 net.cpp:226] resnet3b_btlnk needs backward computation.
I0825 17:21:29.527758 27361 net.cpp:226] resnet3a_eltwise_resnet3a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527762 27361 net.cpp:226] resnet3a_eltwise_relu needs backward computation.
I0825 17:21:29.527766 27361 net.cpp:226] resnet3a_eltwise needs backward computation.
I0825 17:21:29.527771 27361 net.cpp:226] resnet3a_expnd needs backward computation.
I0825 17:21:29.527776 27361 net.cpp:226] resnet3a_conv_relu needs backward computation.
I0825 17:21:29.527779 27361 net.cpp:226] resnet3a_conv needs backward computation.
I0825 17:21:29.527782 27361 net.cpp:226] resnet3a_btlnk_relu needs backward computation.
I0825 17:21:29.527786 27361 net.cpp:226] resnet3a_btlnk needs backward computation.
I0825 17:21:29.527791 27361 net.cpp:226] resnet3a_bypass needs backward computation.
I0825 17:21:29.527794 27361 net.cpp:226] maxpool2_maxpool2_0_split needs backward computation.
I0825 17:21:29.527798 27361 net.cpp:226] maxpool2 needs backward computation.
I0825 17:21:29.527802 27361 net.cpp:226] resnet2b_eltwise_resnet2b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527806 27361 net.cpp:226] resnet2b_eltwise_relu needs backward computation.
I0825 17:21:29.527809 27361 net.cpp:226] resnet2b_eltwise needs backward computation.
I0825 17:21:29.527813 27361 net.cpp:226] resnet2b_expnd needs backward computation.
I0825 17:21:29.527817 27361 net.cpp:226] resnet2b_conv_relu needs backward computation.
I0825 17:21:29.527822 27361 net.cpp:226] resnet2b_conv needs backward computation.
I0825 17:21:29.527824 27361 net.cpp:226] resnet2b_btlnk_relu needs backward computation.
I0825 17:21:29.527828 27361 net.cpp:226] resnet2b_btlnk needs backward computation.
I0825 17:21:29.527832 27361 net.cpp:226] resnet2a_eltwise_resnet2a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527837 27361 net.cpp:226] resnet2a_eltwise_relu needs backward computation.
I0825 17:21:29.527839 27361 net.cpp:226] resnet2a_eltwise needs backward computation.
I0825 17:21:29.527844 27361 net.cpp:226] resnet2a_expnd needs backward computation.
I0825 17:21:29.527848 27361 net.cpp:226] resnet2a_conv_relu needs backward computation.
I0825 17:21:29.527851 27361 net.cpp:226] resnet2a_conv needs backward computation.
I0825 17:21:29.527855 27361 net.cpp:226] resnet2a_btlnk_relu needs backward computation.
I0825 17:21:29.527858 27361 net.cpp:226] resnet2a_btlnk needs backward computation.
I0825 17:21:29.527863 27361 net.cpp:226] resnet2a_bypass needs backward computation.
I0825 17:21:29.527866 27361 net.cpp:226] maxpool1_maxpool1_0_split needs backward computation.
I0825 17:21:29.527870 27361 net.cpp:226] maxpool1 needs backward computation.
I0825 17:21:29.527874 27361 net.cpp:226] resnet1b_eltwise_resnet1b_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527884 27361 net.cpp:226] resnet1b_eltwise_relu needs backward computation.
I0825 17:21:29.527887 27361 net.cpp:226] resnet1b_eltwise needs backward computation.
I0825 17:21:29.527891 27361 net.cpp:226] resnet1b_expnd needs backward computation.
I0825 17:21:29.527895 27361 net.cpp:226] resnet1b_conv_relu needs backward computation.
I0825 17:21:29.527899 27361 net.cpp:226] resnet1b_conv needs backward computation.
I0825 17:21:29.527904 27361 net.cpp:226] resnet1b_btlnk_relu needs backward computation.
I0825 17:21:29.527907 27361 net.cpp:226] resnet1b_btlnk needs backward computation.
I0825 17:21:29.527911 27361 net.cpp:226] resnet1a_eltwise_resnet1a_eltwise_relu_0_split needs backward computation.
I0825 17:21:29.527915 27361 net.cpp:226] resnet1a_eltwise_relu needs backward computation.
I0825 17:21:29.527918 27361 net.cpp:226] resnet1a_eltwise needs backward computation.
I0825 17:21:29.527925 27361 net.cpp:226] resnet1a_expnd needs backward computation.
I0825 17:21:29.527930 27361 net.cpp:226] resnet1a_conv_relu needs backward computation.
I0825 17:21:29.527933 27361 net.cpp:226] resnet1a_conv needs backward computation.
I0825 17:21:29.527937 27361 net.cpp:226] resnet1a_btlnk_relu needs backward computation.
I0825 17:21:29.527940 27361 net.cpp:226] resnet1a_btlnk needs backward computation.
I0825 17:21:29.527945 27361 net.cpp:226] resnet1a_bypass needs backward computation.
I0825 17:21:29.527950 27361 net.cpp:228] label_data_1_split does not need backward computation.
I0825 17:21:29.527954 27361 net.cpp:228] data_data_0_split does not need backward computation.
I0825 17:21:29.527958 27361 net.cpp:228] data does not need backward computation.
I0825 17:21:29.527961 27361 net.cpp:270] This network produces output accuracy
I0825 17:21:29.527966 27361 net.cpp:270] This network produces output softmaxloss
I0825 17:21:29.528053 27361 net.cpp:283] Network initialization done.
I0825 17:21:29.528489 27361 solver.cpp:60] Solver scaffolding done.
I0825 17:21:29.530673 27361 caffe.cpp:251] Starting Optimization
I0825 17:21:29.530686 27361 solver.cpp:279] Solving uB-U-ResNet
I0825 17:21:29.530689 27361 solver.cpp:280] Learning Rate Policy: inv
I0825 17:21:29.532879 27361 solver.cpp:337] Iteration 0, Testing net (#0)
I0825 17:21:33.684916 27361 solver.cpp:404]     Test net output #0: accuracy = 0.00152626
I0825 17:21:33.684963 27361 solver.cpp:404]     Test net output #1: softmaxloss = 36.1463 (* 1 = 36.1463 loss)
I0825 17:21:35.723273 27361 solver.cpp:228] Iteration 0, loss = 32.4609
I0825 17:21:35.723315 27361 solver.cpp:244]     Train net output #0: accuracy = 0.00148773
I0825 17:21:35.723326 27361 solver.cpp:244]     Train net output #1: softmaxloss = 43.9918 (* 1 = 43.9918 loss)
I0825 17:21:35.723345 27361 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0825 17:21:56.909622 27361 solver.cpp:228] Iteration 10, loss = 27.4325
I0825 17:21:56.909665 27361 solver.cpp:244]     Train net output #0: accuracy = 0.621593
I0825 17:21:56.909675 27361 solver.cpp:244]     Train net output #1: softmaxloss = 27.2001 (* 1 = 27.2001 loss)
I0825 17:21:56.909683 27361 sgd_solver.cpp:106] Iteration 10, lr = 9.98503e-06
I0825 17:22:18.174695 27361 solver.cpp:228] Iteration 20, loss = 33.953
I0825 17:22:18.174795 27361 solver.cpp:244]     Train net output #0: accuracy = 0.496643
I0825 17:22:18.174806 27361 solver.cpp:244]     Train net output #1: softmaxloss = 115.723 (* 1 = 115.723 loss)
I0825 17:22:18.174814 27361 sgd_solver.cpp:106] Iteration 20, lr = 9.9701e-06
I0825 17:22:39.456359 27361 solver.cpp:228] Iteration 30, loss = 26.397
I0825 17:22:39.456406 27361 solver.cpp:244]     Train net output #0: accuracy = 0.825489
I0825 17:22:39.456418 27361 solver.cpp:244]     Train net output #1: softmaxloss = 11.6121 (* 1 = 11.6121 loss)
I0825 17:22:39.456425 27361 sgd_solver.cpp:106] Iteration 30, lr = 9.95523e-06
I0825 17:23:00.867416 27361 solver.cpp:228] Iteration 40, loss = 17.2049
I0825 17:23:00.867559 27361 solver.cpp:244]     Train net output #0: accuracy = 0.696758
I0825 17:23:00.867571 27361 solver.cpp:244]     Train net output #1: softmaxloss = 19.8586 (* 1 = 19.8586 loss)
I0825 17:23:00.867580 27361 sgd_solver.cpp:106] Iteration 40, lr = 9.94042e-06
I0825 17:23:22.303691 27361 solver.cpp:228] Iteration 50, loss = 21.3529
I0825 17:23:22.303740 27361 solver.cpp:244]     Train net output #0: accuracy = 0.5042
I0825 17:23:22.303750 27361 solver.cpp:244]     Train net output #1: softmaxloss = 30.6209 (* 1 = 30.6209 loss)
I0825 17:23:22.303757 27361 sgd_solver.cpp:106] Iteration 50, lr = 9.92565e-06
I0825 17:23:43.687342 27361 solver.cpp:228] Iteration 60, loss = 23.6304
I0825 17:23:43.687458 27361 solver.cpp:244]     Train net output #0: accuracy = 0.77103
I0825 17:23:43.687470 27361 solver.cpp:244]     Train net output #1: softmaxloss = 8.24467 (* 1 = 8.24467 loss)
I0825 17:23:43.687479 27361 sgd_solver.cpp:106] Iteration 60, lr = 9.91093e-06
I0825 17:24:05.124502 27361 solver.cpp:228] Iteration 70, loss = 22.6959
I0825 17:24:05.124557 27361 solver.cpp:244]     Train net output #0: accuracy = 0.531864
I0825 17:24:05.124568 27361 solver.cpp:244]     Train net output #1: softmaxloss = 20.0378 (* 1 = 20.0378 loss)
I0825 17:24:05.124577 27361 sgd_solver.cpp:106] Iteration 70, lr = 9.89627e-06
I0825 17:24:26.509058 27361 solver.cpp:228] Iteration 80, loss = 11.4941
I0825 17:24:26.509167 27361 solver.cpp:244]     Train net output #0: accuracy = 0.743244
I0825 17:24:26.509178 27361 solver.cpp:244]     Train net output #1: softmaxloss = 13.3381 (* 1 = 13.3381 loss)
I0825 17:24:26.509186 27361 sgd_solver.cpp:106] Iteration 80, lr = 9.88166e-06
I0825 17:24:47.893671 27361 solver.cpp:228] Iteration 90, loss = 11.4809
I0825 17:24:47.893717 27361 solver.cpp:244]     Train net output #0: accuracy = 0.739441
I0825 17:24:47.893726 27361 solver.cpp:244]     Train net output #1: softmaxloss = 6.5485 (* 1 = 6.5485 loss)
I0825 17:24:47.893734 27361 sgd_solver.cpp:106] Iteration 90, lr = 9.86709e-06
I0825 17:25:07.167939 27361 solver.cpp:337] Iteration 100, Testing net (#0)
I0825 17:25:11.357055 27361 solver.cpp:404]     Test net output #0: accuracy = 0.668347
I0825 17:25:11.357100 27361 solver.cpp:404]     Test net output #1: softmaxloss = 7.57509 (* 1 = 7.57509 loss)
I0825 17:25:13.376919 27361 solver.cpp:228] Iteration 100, loss = 7.84086
I0825 17:25:13.376961 27361 solver.cpp:244]     Train net output #0: accuracy = 0.825878
I0825 17:25:13.376972 27361 solver.cpp:244]     Train net output #1: softmaxloss = 4.45102 (* 1 = 4.45102 loss)
I0825 17:25:13.376979 27361 sgd_solver.cpp:106] Iteration 100, lr = 9.85258e-06
I0825 17:25:34.774448 27361 solver.cpp:228] Iteration 110, loss = 9.09046
I0825 17:25:34.774487 27361 solver.cpp:244]     Train net output #0: accuracy = 0.722511
I0825 17:25:34.774497 27361 solver.cpp:244]     Train net output #1: softmaxloss = 6.67524 (* 1 = 6.67524 loss)
I0825 17:25:34.774505 27361 sgd_solver.cpp:106] Iteration 110, lr = 9.83811e-06
I0825 17:25:56.172030 27361 solver.cpp:228] Iteration 120, loss = 5.40561
I0825 17:25:56.172127 27361 solver.cpp:244]     Train net output #0: accuracy = 0.601696
I0825 17:25:56.172137 27361 solver.cpp:244]     Train net output #1: softmaxloss = 6.86956 (* 1 = 6.86956 loss)
I0825 17:25:56.172145 27361 sgd_solver.cpp:106] Iteration 120, lr = 9.8237e-06
I0825 17:26:17.615578 27361 solver.cpp:228] Iteration 130, loss = 4.14047
I0825 17:26:17.615624 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86005
I0825 17:26:17.615634 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.59035 (* 1 = 2.59035 loss)
I0825 17:26:17.615643 27361 sgd_solver.cpp:106] Iteration 130, lr = 9.80933e-06
I0825 17:26:39.051779 27361 solver.cpp:228] Iteration 140, loss = 3.56375
I0825 17:26:39.051864 27361 solver.cpp:244]     Train net output #0: accuracy = 0.591736
I0825 17:26:39.051877 27361 solver.cpp:244]     Train net output #1: softmaxloss = 6.34566 (* 1 = 6.34566 loss)
I0825 17:26:39.051883 27361 sgd_solver.cpp:106] Iteration 140, lr = 9.79502e-06
I0825 17:27:00.498411 27361 solver.cpp:228] Iteration 150, loss = 2.85466
I0825 17:27:00.498456 27361 solver.cpp:244]     Train net output #0: accuracy = 0.606773
I0825 17:27:00.498466 27361 solver.cpp:244]     Train net output #1: softmaxloss = 3.46786 (* 1 = 3.46786 loss)
I0825 17:27:00.498474 27361 sgd_solver.cpp:106] Iteration 150, lr = 9.78075e-06
I0825 17:27:21.936044 27361 solver.cpp:228] Iteration 160, loss = 2.09377
I0825 17:27:21.936152 27361 solver.cpp:244]     Train net output #0: accuracy = 0.814022
I0825 17:27:21.936164 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.90558 (* 1 = 2.90558 loss)
I0825 17:27:21.936172 27361 sgd_solver.cpp:106] Iteration 160, lr = 9.76653e-06
I0825 17:27:43.321292 27361 solver.cpp:228] Iteration 170, loss = 2.01384
I0825 17:27:43.321336 27361 solver.cpp:244]     Train net output #0: accuracy = 0.7561
I0825 17:27:43.321346 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.17741 (* 1 = 2.17741 loss)
I0825 17:27:43.321353 27361 sgd_solver.cpp:106] Iteration 170, lr = 9.75236e-06
I0825 17:28:04.698693 27361 solver.cpp:228] Iteration 180, loss = 1.82831
I0825 17:28:04.698768 27361 solver.cpp:244]     Train net output #0: accuracy = 0.64674
I0825 17:28:04.698779 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.21212 (* 1 = 2.21212 loss)
I0825 17:28:04.698787 27361 sgd_solver.cpp:106] Iteration 180, lr = 9.73823e-06
I0825 17:28:26.130503 27361 solver.cpp:228] Iteration 190, loss = 1.95526
I0825 17:28:26.130548 27361 solver.cpp:244]     Train net output #0: accuracy = 0.734112
I0825 17:28:26.130556 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.88689 (* 1 = 1.88689 loss)
I0825 17:28:26.130564 27361 sgd_solver.cpp:106] Iteration 190, lr = 9.72416e-06
I0825 17:28:45.395267 27361 solver.cpp:337] Iteration 200, Testing net (#0)
I0825 17:28:49.570979 27361 solver.cpp:404]     Test net output #0: accuracy = 0.681284
I0825 17:28:49.571023 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.91903 (* 1 = 1.91903 loss)
I0825 17:28:51.591562 27361 solver.cpp:228] Iteration 200, loss = 1.72381
I0825 17:28:51.591604 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889145
I0825 17:28:51.591615 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.58411 (* 1 = 1.58411 loss)
I0825 17:28:51.591624 27361 sgd_solver.cpp:106] Iteration 200, lr = 9.71013e-06
I0825 17:29:12.991431 27361 solver.cpp:228] Iteration 210, loss = 1.64006
I0825 17:29:12.991475 27361 solver.cpp:244]     Train net output #0: accuracy = 0.589401
I0825 17:29:12.991485 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.7121 (* 1 = 1.7121 loss)
I0825 17:29:12.991493 27361 sgd_solver.cpp:106] Iteration 210, lr = 9.69615e-06
I0825 17:29:34.411003 27361 solver.cpp:228] Iteration 220, loss = 1.72627
I0825 17:29:34.411111 27361 solver.cpp:244]     Train net output #0: accuracy = 0.821407
I0825 17:29:34.411123 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.49757 (* 1 = 1.49757 loss)
I0825 17:29:34.411129 27361 sgd_solver.cpp:106] Iteration 220, lr = 9.68221e-06
I0825 17:29:55.804193 27361 solver.cpp:228] Iteration 230, loss = 1.76386
I0825 17:29:55.804240 27361 solver.cpp:244]     Train net output #0: accuracy = 0.785671
I0825 17:29:55.804250 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.66474 (* 1 = 1.66474 loss)
I0825 17:29:55.804257 27361 sgd_solver.cpp:106] Iteration 230, lr = 9.66832e-06
I0825 17:30:17.205107 27361 solver.cpp:228] Iteration 240, loss = 1.68373
I0825 17:30:17.205168 27361 solver.cpp:244]     Train net output #0: accuracy = 0.813759
I0825 17:30:17.205178 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.62823 (* 1 = 1.62823 loss)
I0825 17:30:17.205184 27361 sgd_solver.cpp:106] Iteration 240, lr = 9.65448e-06
I0825 17:30:38.630386 27361 solver.cpp:228] Iteration 250, loss = 1.78143
I0825 17:30:38.630434 27361 solver.cpp:244]     Train net output #0: accuracy = 0.72366
I0825 17:30:38.630445 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.57483 (* 1 = 1.57483 loss)
I0825 17:30:38.630451 27361 sgd_solver.cpp:106] Iteration 250, lr = 9.64069e-06
I0825 17:31:00.032268 27361 solver.cpp:228] Iteration 260, loss = 1.7685
I0825 17:31:00.032405 27361 solver.cpp:244]     Train net output #0: accuracy = 0.595715
I0825 17:31:00.032423 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.97704 (* 1 = 1.97704 loss)
I0825 17:31:00.032430 27361 sgd_solver.cpp:106] Iteration 260, lr = 9.62694e-06
I0825 17:31:21.431839 27361 solver.cpp:228] Iteration 270, loss = 1.82469
I0825 17:31:21.431884 27361 solver.cpp:244]     Train net output #0: accuracy = 0.785358
I0825 17:31:21.431895 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.50121 (* 1 = 1.50121 loss)
I0825 17:31:21.431901 27361 sgd_solver.cpp:106] Iteration 270, lr = 9.61323e-06
I0825 17:31:42.828207 27361 solver.cpp:228] Iteration 280, loss = 1.74537
I0825 17:31:42.828310 27361 solver.cpp:244]     Train net output #0: accuracy = 0.692696
I0825 17:31:42.828321 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.75894 (* 1 = 1.75894 loss)
I0825 17:31:42.828336 27361 sgd_solver.cpp:106] Iteration 280, lr = 9.59958e-06
I0825 17:32:04.231608 27361 solver.cpp:228] Iteration 290, loss = 1.87911
I0825 17:32:04.231650 27361 solver.cpp:244]     Train net output #0: accuracy = 0.626362
I0825 17:32:04.231662 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.77438 (* 1 = 2.77438 loss)
I0825 17:32:04.231668 27361 sgd_solver.cpp:106] Iteration 290, lr = 9.58596e-06
I0825 17:32:23.540467 27361 solver.cpp:337] Iteration 300, Testing net (#0)
I0825 17:32:27.715982 27361 solver.cpp:404]     Test net output #0: accuracy = 0.64074
I0825 17:32:27.716025 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.82337 (* 1 = 1.82337 loss)
I0825 17:32:29.736078 27361 solver.cpp:228] Iteration 300, loss = 1.85357
I0825 17:32:29.736120 27361 solver.cpp:244]     Train net output #0: accuracy = 0.658974
I0825 17:32:29.736131 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56581 (* 1 = 1.56581 loss)
I0825 17:32:29.736140 27361 sgd_solver.cpp:106] Iteration 300, lr = 9.5724e-06
I0825 17:32:51.314522 27361 solver.cpp:228] Iteration 310, loss = 1.7356
I0825 17:32:51.314565 27361 solver.cpp:244]     Train net output #0: accuracy = 0.688812
I0825 17:32:51.314575 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56792 (* 1 = 1.56792 loss)
I0825 17:32:51.314584 27361 sgd_solver.cpp:106] Iteration 310, lr = 9.55887e-06
I0825 17:33:12.758045 27361 solver.cpp:228] Iteration 320, loss = 1.68353
I0825 17:33:12.758118 27361 solver.cpp:244]     Train net output #0: accuracy = 0.752254
I0825 17:33:12.758131 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.77794 (* 1 = 1.77794 loss)
I0825 17:33:12.758137 27361 sgd_solver.cpp:106] Iteration 320, lr = 9.54539e-06
I0825 17:33:34.189079 27361 solver.cpp:228] Iteration 330, loss = 1.559
I0825 17:33:34.189121 27361 solver.cpp:244]     Train net output #0: accuracy = 0.848351
I0825 17:33:34.189131 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.50703 (* 1 = 1.50703 loss)
I0825 17:33:34.189139 27361 sgd_solver.cpp:106] Iteration 330, lr = 9.53196e-06
I0825 17:33:55.638468 27361 solver.cpp:228] Iteration 340, loss = 1.8105
I0825 17:33:55.638553 27361 solver.cpp:244]     Train net output #0: accuracy = 0.815895
I0825 17:33:55.638566 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.66223 (* 1 = 1.66223 loss)
I0825 17:33:55.638573 27361 sgd_solver.cpp:106] Iteration 340, lr = 9.51857e-06
I0825 17:34:17.025665 27361 solver.cpp:228] Iteration 350, loss = 1.64301
I0825 17:34:17.025710 27361 solver.cpp:244]     Train net output #0: accuracy = 0.795856
I0825 17:34:17.025720 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.46473 (* 1 = 1.46473 loss)
I0825 17:34:17.025728 27361 sgd_solver.cpp:106] Iteration 350, lr = 9.50522e-06
I0825 17:34:38.421712 27361 solver.cpp:228] Iteration 360, loss = 1.6563
I0825 17:34:38.421771 27361 solver.cpp:244]     Train net output #0: accuracy = 0.755997
I0825 17:34:38.421782 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.66769 (* 1 = 1.66769 loss)
I0825 17:34:38.421789 27361 sgd_solver.cpp:106] Iteration 360, lr = 9.49192e-06
I0825 17:34:59.948781 27361 solver.cpp:228] Iteration 370, loss = 1.76969
I0825 17:34:59.948828 27361 solver.cpp:244]     Train net output #0: accuracy = 0.825798
I0825 17:34:59.948843 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.77533 (* 1 = 1.77533 loss)
I0825 17:34:59.948855 27361 sgd_solver.cpp:106] Iteration 370, lr = 9.47866e-06
I0825 17:35:21.460155 27361 solver.cpp:228] Iteration 380, loss = 1.75295
I0825 17:35:21.460240 27361 solver.cpp:244]     Train net output #0: accuracy = 0.71114
I0825 17:35:21.460252 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.86525 (* 1 = 1.86525 loss)
I0825 17:35:21.460259 27361 sgd_solver.cpp:106] Iteration 380, lr = 9.46544e-06
I0825 17:35:42.841259 27361 solver.cpp:228] Iteration 390, loss = 1.88211
I0825 17:35:42.841305 27361 solver.cpp:244]     Train net output #0: accuracy = 0.756874
I0825 17:35:42.841326 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.38777 (* 1 = 1.38777 loss)
I0825 17:35:42.841334 27361 sgd_solver.cpp:106] Iteration 390, lr = 9.45227e-06
I0825 17:36:02.083118 27361 solver.cpp:337] Iteration 400, Testing net (#0)
I0825 17:36:06.251775 27361 solver.cpp:404]     Test net output #0: accuracy = 0.652187
I0825 17:36:06.251817 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.87596 (* 1 = 1.87596 loss)
I0825 17:36:08.270395 27361 solver.cpp:228] Iteration 400, loss = 1.63299
I0825 17:36:08.270438 27361 solver.cpp:244]     Train net output #0: accuracy = 0.782631
I0825 17:36:08.270448 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.85625 (* 1 = 1.85625 loss)
I0825 17:36:08.270457 27361 sgd_solver.cpp:106] Iteration 400, lr = 9.43913e-06
I0825 17:36:29.653955 27361 solver.cpp:228] Iteration 410, loss = 1.81098
I0825 17:36:29.654000 27361 solver.cpp:244]     Train net output #0: accuracy = 0.593487
I0825 17:36:29.654011 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.88664 (* 1 = 1.88664 loss)
I0825 17:36:29.654019 27361 sgd_solver.cpp:106] Iteration 410, lr = 9.42605e-06
I0825 17:36:51.032950 27361 solver.cpp:228] Iteration 420, loss = 1.62478
I0825 17:36:51.033020 27361 solver.cpp:244]     Train net output #0: accuracy = 0.791065
I0825 17:36:51.033030 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.6094 (* 1 = 1.6094 loss)
I0825 17:36:51.033038 27361 sgd_solver.cpp:106] Iteration 420, lr = 9.413e-06
I0825 17:37:12.484962 27361 solver.cpp:228] Iteration 430, loss = 1.87784
I0825 17:37:12.485008 27361 solver.cpp:244]     Train net output #0: accuracy = 0.53598
I0825 17:37:12.485018 27361 solver.cpp:244]     Train net output #1: softmaxloss = 3.49994 (* 1 = 3.49994 loss)
I0825 17:37:12.485025 27361 sgd_solver.cpp:106] Iteration 430, lr = 9.4e-06
I0825 17:37:33.952716 27361 solver.cpp:228] Iteration 440, loss = 2.16486
I0825 17:37:33.952817 27361 solver.cpp:244]     Train net output #0: accuracy = 0.481411
I0825 17:37:33.952828 27361 solver.cpp:244]     Train net output #1: softmaxloss = 4.602 (* 1 = 4.602 loss)
I0825 17:37:33.952836 27361 sgd_solver.cpp:106] Iteration 440, lr = 9.38703e-06
I0825 17:37:55.349458 27361 solver.cpp:228] Iteration 450, loss = 1.70902
I0825 17:37:55.349501 27361 solver.cpp:244]     Train net output #0: accuracy = 0.891335
I0825 17:37:55.349511 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.57134 (* 1 = 1.57134 loss)
I0825 17:37:55.349519 27361 sgd_solver.cpp:106] Iteration 450, lr = 9.37411e-06
I0825 17:38:16.829690 27361 solver.cpp:228] Iteration 460, loss = 1.73111
I0825 17:38:16.829763 27361 solver.cpp:244]     Train net output #0: accuracy = 0.788288
I0825 17:38:16.829779 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56931 (* 1 = 1.56931 loss)
I0825 17:38:16.829787 27361 sgd_solver.cpp:106] Iteration 460, lr = 9.36123e-06
I0825 17:38:38.204455 27361 solver.cpp:228] Iteration 470, loss = 1.72186
I0825 17:38:38.204501 27361 solver.cpp:244]     Train net output #0: accuracy = 0.482193
I0825 17:38:38.204516 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.35743 (* 1 = 2.35743 loss)
I0825 17:38:38.204526 27361 sgd_solver.cpp:106] Iteration 470, lr = 9.34839e-06
I0825 17:38:59.578198 27361 solver.cpp:228] Iteration 480, loss = 1.70224
I0825 17:38:59.578301 27361 solver.cpp:244]     Train net output #0: accuracy = 0.688927
I0825 17:38:59.578318 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.47738 (* 1 = 1.47738 loss)
I0825 17:38:59.578327 27361 sgd_solver.cpp:106] Iteration 480, lr = 9.3356e-06
I0825 17:39:20.950729 27361 solver.cpp:228] Iteration 490, loss = 1.72077
I0825 17:39:20.950773 27361 solver.cpp:244]     Train net output #0: accuracy = 0.829685
I0825 17:39:20.950789 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.52704 (* 1 = 1.52704 loss)
I0825 17:39:20.950799 27361 sgd_solver.cpp:106] Iteration 490, lr = 9.32284e-06
I0825 17:39:40.188462 27361 solver.cpp:337] Iteration 500, Testing net (#0)
I0825 17:39:44.353655 27361 solver.cpp:404]     Test net output #0: accuracy = 0.703945
I0825 17:39:44.353700 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.73976 (* 1 = 1.73976 loss)
I0825 17:39:46.372920 27361 solver.cpp:228] Iteration 500, loss = 1.66205
I0825 17:39:46.372962 27361 solver.cpp:244]     Train net output #0: accuracy = 0.740189
I0825 17:39:46.372977 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.68583 (* 1 = 1.68583 loss)
I0825 17:39:46.372987 27361 sgd_solver.cpp:106] Iteration 500, lr = 9.31012e-06
I0825 17:40:07.751621 27361 solver.cpp:228] Iteration 510, loss = 1.77225
I0825 17:40:07.751658 27361 solver.cpp:244]     Train net output #0: accuracy = 0.737797
I0825 17:40:07.751673 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.77734 (* 1 = 1.77734 loss)
I0825 17:40:07.751683 27361 sgd_solver.cpp:106] Iteration 510, lr = 9.29745e-06
I0825 17:40:29.178772 27361 solver.cpp:228] Iteration 520, loss = 1.95012
I0825 17:40:29.178853 27361 solver.cpp:244]     Train net output #0: accuracy = 0.646896
I0825 17:40:29.178865 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.4806 (* 1 = 1.4806 loss)
I0825 17:40:29.178872 27361 sgd_solver.cpp:106] Iteration 520, lr = 9.28481e-06
I0825 17:40:50.575832 27361 solver.cpp:228] Iteration 530, loss = 1.79217
I0825 17:40:50.575876 27361 solver.cpp:244]     Train net output #0: accuracy = 0.78775
I0825 17:40:50.575886 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56076 (* 1 = 1.56076 loss)
I0825 17:40:50.575894 27361 sgd_solver.cpp:106] Iteration 530, lr = 9.27222e-06
I0825 17:41:12.021548 27361 solver.cpp:228] Iteration 540, loss = 1.8473
I0825 17:41:12.021646 27361 solver.cpp:244]     Train net output #0: accuracy = 0.773403
I0825 17:41:12.021657 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.37871 (* 1 = 1.37871 loss)
I0825 17:41:12.021666 27361 sgd_solver.cpp:106] Iteration 540, lr = 9.25966e-06
I0825 17:41:33.503109 27361 solver.cpp:228] Iteration 550, loss = 1.79801
I0825 17:41:33.503151 27361 solver.cpp:244]     Train net output #0: accuracy = 0.660656
I0825 17:41:33.503161 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.82033 (* 1 = 1.82033 loss)
I0825 17:41:33.503170 27361 sgd_solver.cpp:106] Iteration 550, lr = 9.24715e-06
I0825 17:41:54.935678 27361 solver.cpp:228] Iteration 560, loss = 1.74534
I0825 17:41:54.935791 27361 solver.cpp:244]     Train net output #0: accuracy = 0.899582
I0825 17:41:54.935803 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.57105 (* 1 = 1.57105 loss)
I0825 17:41:54.935811 27361 sgd_solver.cpp:106] Iteration 560, lr = 9.23467e-06
I0825 17:42:16.425032 27361 solver.cpp:228] Iteration 570, loss = 1.77905
I0825 17:42:16.425078 27361 solver.cpp:244]     Train net output #0: accuracy = 0.780342
I0825 17:42:16.425088 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.4834 (* 1 = 1.4834 loss)
I0825 17:42:16.425096 27361 sgd_solver.cpp:106] Iteration 570, lr = 9.22223e-06
I0825 17:42:37.814081 27361 solver.cpp:228] Iteration 580, loss = 1.8678
I0825 17:42:37.814211 27361 solver.cpp:244]     Train net output #0: accuracy = 0.637112
I0825 17:42:37.814224 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.95228 (* 1 = 2.95228 loss)
I0825 17:42:37.814231 27361 sgd_solver.cpp:106] Iteration 580, lr = 9.20984e-06
I0825 17:42:59.207226 27361 solver.cpp:228] Iteration 590, loss = 1.91389
I0825 17:42:59.207271 27361 solver.cpp:244]     Train net output #0: accuracy = 0.605927
I0825 17:42:59.207281 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.50777 (* 1 = 1.50777 loss)
I0825 17:42:59.207288 27361 sgd_solver.cpp:106] Iteration 590, lr = 9.19748e-06
I0825 17:43:18.507695 27361 solver.cpp:337] Iteration 600, Testing net (#0)
I0825 17:43:22.676635 27361 solver.cpp:404]     Test net output #0: accuracy = 0.689925
I0825 17:43:22.676681 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.80744 (* 1 = 1.80744 loss)
I0825 17:43:24.695741 27361 solver.cpp:228] Iteration 600, loss = 1.64077
I0825 17:43:24.695785 27361 solver.cpp:244]     Train net output #0: accuracy = 0.678078
I0825 17:43:24.695802 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.41811 (* 1 = 1.41811 loss)
I0825 17:43:24.695811 27361 sgd_solver.cpp:106] Iteration 600, lr = 9.18515e-06
I0825 17:43:46.077014 27361 solver.cpp:228] Iteration 610, loss = 1.72605
I0825 17:43:46.077059 27361 solver.cpp:244]     Train net output #0: accuracy = 0.824562
I0825 17:43:46.077069 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.44784 (* 1 = 1.44784 loss)
I0825 17:43:46.077076 27361 sgd_solver.cpp:106] Iteration 610, lr = 9.17287e-06
I0825 17:44:07.616689 27361 solver.cpp:228] Iteration 620, loss = 1.78053
I0825 17:44:07.616803 27361 solver.cpp:244]     Train net output #0: accuracy = 0.751949
I0825 17:44:07.616814 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56958 (* 1 = 1.56958 loss)
I0825 17:44:07.616822 27361 sgd_solver.cpp:106] Iteration 620, lr = 9.16063e-06
I0825 17:44:29.117981 27361 solver.cpp:228] Iteration 630, loss = 1.5238
I0825 17:44:29.118027 27361 solver.cpp:244]     Train net output #0: accuracy = 0.80389
I0825 17:44:29.118037 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.62459 (* 1 = 1.62459 loss)
I0825 17:44:29.118046 27361 sgd_solver.cpp:106] Iteration 630, lr = 9.14842e-06
I0825 17:44:50.505363 27361 solver.cpp:228] Iteration 640, loss = 1.89554
I0825 17:44:50.505475 27361 solver.cpp:244]     Train net output #0: accuracy = 0.601269
I0825 17:44:50.505486 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.20521 (* 1 = 2.20521 loss)
I0825 17:44:50.505494 27361 sgd_solver.cpp:106] Iteration 640, lr = 9.13625e-06
I0825 17:45:11.929153 27361 solver.cpp:228] Iteration 650, loss = 1.68911
I0825 17:45:11.929200 27361 solver.cpp:244]     Train net output #0: accuracy = 0.747154
I0825 17:45:11.929210 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.50884 (* 1 = 1.50884 loss)
I0825 17:45:11.929219 27361 sgd_solver.cpp:106] Iteration 650, lr = 9.12412e-06
I0825 17:45:33.322525 27361 solver.cpp:228] Iteration 660, loss = 1.69281
I0825 17:45:33.322631 27361 solver.cpp:244]     Train net output #0: accuracy = 0.704128
I0825 17:45:33.322643 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.01404 (* 1 = 2.01404 loss)
I0825 17:45:33.322650 27361 sgd_solver.cpp:106] Iteration 660, lr = 9.11203e-06
I0825 17:45:54.715559 27361 solver.cpp:228] Iteration 670, loss = 1.76508
I0825 17:45:54.715607 27361 solver.cpp:244]     Train net output #0: accuracy = 0.738304
I0825 17:45:54.715617 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.77535 (* 1 = 1.77535 loss)
I0825 17:45:54.715625 27361 sgd_solver.cpp:106] Iteration 670, lr = 9.09997e-06
I0825 17:46:16.129330 27361 solver.cpp:228] Iteration 680, loss = 1.72949
I0825 17:46:16.129429 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90583
I0825 17:46:16.129441 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.6698 (* 1 = 1.6698 loss)
I0825 17:46:16.129447 27361 sgd_solver.cpp:106] Iteration 680, lr = 9.08796e-06
I0825 17:46:37.512675 27361 solver.cpp:228] Iteration 690, loss = 1.71678
I0825 17:46:37.512719 27361 solver.cpp:244]     Train net output #0: accuracy = 0.578751
I0825 17:46:37.512728 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.07518 (* 1 = 2.07518 loss)
I0825 17:46:37.512737 27361 sgd_solver.cpp:106] Iteration 690, lr = 9.07597e-06
I0825 17:46:56.767179 27361 solver.cpp:337] Iteration 700, Testing net (#0)
I0825 17:47:00.941066 27361 solver.cpp:404]     Test net output #0: accuracy = 0.698026
I0825 17:47:00.941110 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.79962 (* 1 = 1.79962 loss)
I0825 17:47:02.962667 27361 solver.cpp:228] Iteration 700, loss = 1.76754
I0825 17:47:02.962713 27361 solver.cpp:244]     Train net output #0: accuracy = 0.735355
I0825 17:47:02.962723 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.52337 (* 1 = 1.52337 loss)
I0825 17:47:02.962729 27361 sgd_solver.cpp:106] Iteration 700, lr = 9.06403e-06
I0825 17:47:24.349699 27361 solver.cpp:228] Iteration 710, loss = 1.67941
I0825 17:47:24.349745 27361 solver.cpp:244]     Train net output #0: accuracy = 0.831421
I0825 17:47:24.349756 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36662 (* 1 = 1.36662 loss)
I0825 17:47:24.349763 27361 sgd_solver.cpp:106] Iteration 710, lr = 9.05212e-06
I0825 17:47:45.735162 27361 solver.cpp:228] Iteration 720, loss = 1.56812
I0825 17:47:45.735270 27361 solver.cpp:244]     Train net output #0: accuracy = 1
I0825 17:47:45.735280 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.34101 (* 1 = 1.34101 loss)
I0825 17:47:45.735288 27361 sgd_solver.cpp:106] Iteration 720, lr = 9.04025e-06
I0825 17:48:07.126335 27361 solver.cpp:228] Iteration 730, loss = 1.75888
I0825 17:48:07.126382 27361 solver.cpp:244]     Train net output #0: accuracy = 0.750664
I0825 17:48:07.126392 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.60612 (* 1 = 1.60612 loss)
I0825 17:48:07.126399 27361 sgd_solver.cpp:106] Iteration 730, lr = 9.02841e-06
I0825 17:48:28.516002 27361 solver.cpp:228] Iteration 740, loss = 1.58434
I0825 17:48:28.516103 27361 solver.cpp:244]     Train net output #0: accuracy = 0.681213
I0825 17:48:28.516114 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.87203 (* 1 = 1.87203 loss)
I0825 17:48:28.516122 27361 sgd_solver.cpp:106] Iteration 740, lr = 9.01662e-06
I0825 17:48:49.903687 27361 solver.cpp:228] Iteration 750, loss = 1.54455
I0825 17:48:49.903733 27361 solver.cpp:244]     Train net output #0: accuracy = 0.752686
I0825 17:48:49.903743 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36914 (* 1 = 1.36914 loss)
I0825 17:48:49.903749 27361 sgd_solver.cpp:106] Iteration 750, lr = 9.00485e-06
I0825 17:49:11.389700 27361 solver.cpp:228] Iteration 760, loss = 1.65788
I0825 17:49:11.389802 27361 solver.cpp:244]     Train net output #0: accuracy = 0.506641
I0825 17:49:11.389813 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.9567 (* 1 = 1.9567 loss)
I0825 17:49:11.389822 27361 sgd_solver.cpp:106] Iteration 760, lr = 8.99313e-06
I0825 17:49:32.779516 27361 solver.cpp:228] Iteration 770, loss = 1.80172
I0825 17:49:32.779561 27361 solver.cpp:244]     Train net output #0: accuracy = 0.813629
I0825 17:49:32.779572 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.51953 (* 1 = 1.51953 loss)
I0825 17:49:32.779579 27361 sgd_solver.cpp:106] Iteration 770, lr = 8.98143e-06
I0825 17:49:54.200875 27361 solver.cpp:228] Iteration 780, loss = 1.57143
I0825 17:49:54.200985 27361 solver.cpp:244]     Train net output #0: accuracy = 0.841679
I0825 17:49:54.200996 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.42051 (* 1 = 1.42051 loss)
I0825 17:49:54.201004 27361 sgd_solver.cpp:106] Iteration 780, lr = 8.96978e-06
I0825 17:50:15.591060 27361 solver.cpp:228] Iteration 790, loss = 1.69201
I0825 17:50:15.591106 27361 solver.cpp:244]     Train net output #0: accuracy = 0.560242
I0825 17:50:15.591116 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.78305 (* 1 = 1.78305 loss)
I0825 17:50:15.591123 27361 sgd_solver.cpp:106] Iteration 790, lr = 8.95816e-06
I0825 17:50:34.841645 27361 solver.cpp:337] Iteration 800, Testing net (#0)
I0825 17:50:39.011194 27361 solver.cpp:404]     Test net output #0: accuracy = 0.714303
I0825 17:50:39.011242 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.75271 (* 1 = 1.75271 loss)
I0825 17:50:41.032477 27361 solver.cpp:228] Iteration 800, loss = 1.75104
I0825 17:50:41.032524 27361 solver.cpp:244]     Train net output #0: accuracy = 0.610096
I0825 17:50:41.032534 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.66412 (* 1 = 1.66412 loss)
I0825 17:50:41.032542 27361 sgd_solver.cpp:106] Iteration 800, lr = 8.94657e-06
I0825 17:51:02.416422 27361 solver.cpp:228] Iteration 810, loss = 1.92718
I0825 17:51:02.416468 27361 solver.cpp:244]     Train net output #0: accuracy = 0.517273
I0825 17:51:02.416478 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.87318 (* 1 = 1.87318 loss)
I0825 17:51:02.416486 27361 sgd_solver.cpp:106] Iteration 810, lr = 8.93502e-06
I0825 17:51:23.802450 27361 solver.cpp:228] Iteration 820, loss = 1.65302
I0825 17:51:23.802562 27361 solver.cpp:244]     Train net output #0: accuracy = 0.669193
I0825 17:51:23.802572 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.8448 (* 1 = 1.8448 loss)
I0825 17:51:23.802580 27361 sgd_solver.cpp:106] Iteration 820, lr = 8.9235e-06
I0825 17:51:45.345895 27361 solver.cpp:228] Iteration 830, loss = 1.89244
I0825 17:51:45.345939 27361 solver.cpp:244]     Train net output #0: accuracy = 0.708725
I0825 17:51:45.345949 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.91748 (* 1 = 1.91748 loss)
I0825 17:51:45.345957 27361 sgd_solver.cpp:106] Iteration 830, lr = 8.91202e-06
I0825 17:52:06.778599 27361 solver.cpp:228] Iteration 840, loss = 1.61478
I0825 17:52:06.778707 27361 solver.cpp:244]     Train net output #0: accuracy = 0.74012
I0825 17:52:06.778717 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.69757 (* 1 = 1.69757 loss)
I0825 17:52:06.778725 27361 sgd_solver.cpp:106] Iteration 840, lr = 8.90057e-06
I0825 17:52:28.152892 27361 solver.cpp:228] Iteration 850, loss = 2.25517
I0825 17:52:28.152938 27361 solver.cpp:244]     Train net output #0: accuracy = 0.759796
I0825 17:52:28.152948 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.38021 (* 1 = 1.38021 loss)
I0825 17:52:28.152956 27361 sgd_solver.cpp:106] Iteration 850, lr = 8.88916e-06
I0825 17:52:49.527451 27361 solver.cpp:228] Iteration 860, loss = 1.56485
I0825 17:52:49.527554 27361 solver.cpp:244]     Train net output #0: accuracy = 0.83326
I0825 17:52:49.527565 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.41972 (* 1 = 1.41972 loss)
I0825 17:52:49.527572 27361 sgd_solver.cpp:106] Iteration 860, lr = 8.87778e-06
I0825 17:53:10.901872 27361 solver.cpp:228] Iteration 870, loss = 1.62333
I0825 17:53:10.901918 27361 solver.cpp:244]     Train net output #0: accuracy = 0.566593
I0825 17:53:10.901928 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.71027 (* 1 = 1.71027 loss)
I0825 17:53:10.901935 27361 sgd_solver.cpp:106] Iteration 870, lr = 8.86643e-06
I0825 17:53:32.279443 27361 solver.cpp:228] Iteration 880, loss = 1.50513
I0825 17:53:32.279505 27361 solver.cpp:244]     Train net output #0: accuracy = 0.778488
I0825 17:53:32.279520 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.55669 (* 1 = 1.55669 loss)
I0825 17:53:32.279527 27361 sgd_solver.cpp:106] Iteration 880, lr = 8.85512e-06
I0825 17:53:53.679899 27361 solver.cpp:228] Iteration 890, loss = 1.7497
I0825 17:53:53.679944 27361 solver.cpp:244]     Train net output #0: accuracy = 0.520111
I0825 17:53:53.679955 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.05239 (* 1 = 2.05239 loss)
I0825 17:53:53.679962 27361 sgd_solver.cpp:106] Iteration 890, lr = 8.84384e-06
I0825 17:54:12.922725 27361 solver.cpp:337] Iteration 900, Testing net (#0)
I0825 17:54:17.082089 27361 solver.cpp:404]     Test net output #0: accuracy = 0.744003
I0825 17:54:17.082132 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.71858 (* 1 = 1.71858 loss)
I0825 17:54:19.104455 27361 solver.cpp:228] Iteration 900, loss = 1.77973
I0825 17:54:19.104498 27361 solver.cpp:244]     Train net output #0: accuracy = 0.582737
I0825 17:54:19.104508 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.65203 (* 1 = 1.65203 loss)
I0825 17:54:19.104516 27361 sgd_solver.cpp:106] Iteration 900, lr = 8.8326e-06
I0825 17:54:40.493199 27361 solver.cpp:228] Iteration 910, loss = 1.90146
I0825 17:54:40.493247 27361 solver.cpp:244]     Train net output #0: accuracy = 0.787254
I0825 17:54:40.493257 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.73093 (* 1 = 1.73093 loss)
I0825 17:54:40.493265 27361 sgd_solver.cpp:106] Iteration 910, lr = 8.82139e-06
I0825 17:55:01.883616 27361 solver.cpp:228] Iteration 920, loss = 1.81778
I0825 17:55:01.883720 27361 solver.cpp:244]     Train net output #0: accuracy = 0.827671
I0825 17:55:01.883731 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.53352 (* 1 = 1.53352 loss)
I0825 17:55:01.883746 27361 sgd_solver.cpp:106] Iteration 920, lr = 8.81021e-06
I0825 17:55:23.274782 27361 solver.cpp:228] Iteration 930, loss = 1.83824
I0825 17:55:23.274829 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893127
I0825 17:55:23.274838 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.48798 (* 1 = 1.48798 loss)
I0825 17:55:23.274847 27361 sgd_solver.cpp:106] Iteration 930, lr = 8.79906e-06
I0825 17:55:44.760412 27361 solver.cpp:228] Iteration 940, loss = 1.53387
I0825 17:55:44.760469 27361 solver.cpp:244]     Train net output #0: accuracy = 0.818829
I0825 17:55:44.760479 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.48922 (* 1 = 1.48922 loss)
I0825 17:55:44.760488 27361 sgd_solver.cpp:106] Iteration 940, lr = 8.78795e-06
I0825 17:56:06.148218 27361 solver.cpp:228] Iteration 950, loss = 2.04041
I0825 17:56:06.148263 27361 solver.cpp:244]     Train net output #0: accuracy = 0.593567
I0825 17:56:06.148273 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.61276 (* 1 = 2.61276 loss)
I0825 17:56:06.148282 27361 sgd_solver.cpp:106] Iteration 950, lr = 8.77687e-06
I0825 17:56:27.532290 27361 solver.cpp:228] Iteration 960, loss = 2.10988
I0825 17:56:27.532363 27361 solver.cpp:244]     Train net output #0: accuracy = 0.699844
I0825 17:56:27.532374 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.48965 (* 1 = 1.48965 loss)
I0825 17:56:27.532382 27361 sgd_solver.cpp:106] Iteration 960, lr = 8.76582e-06
I0825 17:56:49.023156 27361 solver.cpp:228] Iteration 970, loss = 1.776
I0825 17:56:49.023202 27361 solver.cpp:244]     Train net output #0: accuracy = 0.770786
I0825 17:56:49.023212 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.55688 (* 1 = 1.55688 loss)
I0825 17:56:49.023221 27361 sgd_solver.cpp:106] Iteration 970, lr = 8.75481e-06
I0825 17:57:10.408634 27361 solver.cpp:228] Iteration 980, loss = 1.53915
I0825 17:57:10.408745 27361 solver.cpp:244]     Train net output #0: accuracy = 0.762329
I0825 17:57:10.408756 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.49382 (* 1 = 1.49382 loss)
I0825 17:57:10.408763 27361 sgd_solver.cpp:106] Iteration 980, lr = 8.74383e-06
I0825 17:57:31.799402 27361 solver.cpp:228] Iteration 990, loss = 1.80999
I0825 17:57:31.799445 27361 solver.cpp:244]     Train net output #0: accuracy = 0.80788
I0825 17:57:31.799455 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.38003 (* 1 = 1.38003 loss)
I0825 17:57:31.799463 27361 sgd_solver.cpp:106] Iteration 990, lr = 8.73288e-06
I0825 17:57:51.046118 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_1000.caffemodel
I0825 17:57:51.365070 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_1000.solverstate
I0825 17:57:51.402606 27361 solver.cpp:337] Iteration 1000, Testing net (#0)
I0825 17:57:55.457901 27361 solver.cpp:404]     Test net output #0: accuracy = 0.716401
I0825 17:57:55.457947 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.77616 (* 1 = 1.77616 loss)
I0825 17:57:57.478550 27361 solver.cpp:228] Iteration 1000, loss = 2.13453
I0825 17:57:57.478600 27361 solver.cpp:244]     Train net output #0: accuracy = 0.819824
I0825 17:57:57.478611 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.41895 (* 1 = 1.41895 loss)
I0825 17:57:57.478618 27361 sgd_solver.cpp:106] Iteration 1000, lr = 8.72196e-06
I0825 17:58:18.868360 27361 solver.cpp:228] Iteration 1010, loss = 1.61242
I0825 17:58:18.868403 27361 solver.cpp:244]     Train net output #0: accuracy = 0.840199
I0825 17:58:18.868413 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.46021 (* 1 = 1.46021 loss)
I0825 17:58:18.868420 27361 sgd_solver.cpp:106] Iteration 1010, lr = 8.71107e-06
I0825 17:58:40.269032 27361 solver.cpp:228] Iteration 1020, loss = 1.708
I0825 17:58:40.269121 27361 solver.cpp:244]     Train net output #0: accuracy = 0.823982
I0825 17:58:40.269132 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.35643 (* 1 = 1.35643 loss)
I0825 17:58:40.269143 27361 sgd_solver.cpp:106] Iteration 1020, lr = 8.70022e-06
I0825 17:59:01.656388 27361 solver.cpp:228] Iteration 1030, loss = 1.79162
I0825 17:59:01.656436 27361 solver.cpp:244]     Train net output #0: accuracy = 0.733341
I0825 17:59:01.656446 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.15859 (* 1 = 2.15859 loss)
I0825 17:59:01.656455 27361 sgd_solver.cpp:106] Iteration 1030, lr = 8.68939e-06
I0825 17:59:23.042649 27361 solver.cpp:228] Iteration 1040, loss = 1.94315
I0825 17:59:23.042712 27361 solver.cpp:244]     Train net output #0: accuracy = 0.628937
I0825 17:59:23.042723 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.76683 (* 1 = 1.76683 loss)
I0825 17:59:23.042731 27361 sgd_solver.cpp:106] Iteration 1040, lr = 8.6786e-06
I0825 17:59:44.434166 27361 solver.cpp:228] Iteration 1050, loss = 1.75913
I0825 17:59:44.434213 27361 solver.cpp:244]     Train net output #0: accuracy = 0.865936
I0825 17:59:44.434223 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.32454 (* 1 = 1.32454 loss)
I0825 17:59:44.434231 27361 sgd_solver.cpp:106] Iteration 1050, lr = 8.66784e-06
I0825 18:00:05.822691 27361 solver.cpp:228] Iteration 1060, loss = 1.95684
I0825 18:00:05.822795 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921936
I0825 18:00:05.822806 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.34036 (* 1 = 1.34036 loss)
I0825 18:00:05.822813 27361 sgd_solver.cpp:106] Iteration 1060, lr = 8.65711e-06
I0825 18:00:27.209074 27361 solver.cpp:228] Iteration 1070, loss = 1.62844
I0825 18:00:27.209121 27361 solver.cpp:244]     Train net output #0: accuracy = 0.75655
I0825 18:00:27.209131 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.70826 (* 1 = 1.70826 loss)
I0825 18:00:27.209139 27361 sgd_solver.cpp:106] Iteration 1070, lr = 8.64641e-06
I0825 18:00:48.597352 27361 solver.cpp:228] Iteration 1080, loss = 1.54112
I0825 18:00:48.597463 27361 solver.cpp:244]     Train net output #0: accuracy = 0.865925
I0825 18:00:48.597475 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.59634 (* 1 = 1.59634 loss)
I0825 18:00:48.597482 27361 sgd_solver.cpp:106] Iteration 1080, lr = 8.63574e-06
I0825 18:01:09.994690 27361 solver.cpp:228] Iteration 1090, loss = 1.68439
I0825 18:01:09.994737 27361 solver.cpp:244]     Train net output #0: accuracy = 0.835484
I0825 18:01:09.994747 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.33081 (* 1 = 1.33081 loss)
I0825 18:01:09.994755 27361 sgd_solver.cpp:106] Iteration 1090, lr = 8.62511e-06
I0825 18:01:29.242888 27361 solver.cpp:337] Iteration 1100, Testing net (#0)
I0825 18:01:33.413143 27361 solver.cpp:404]     Test net output #0: accuracy = 0.727592
I0825 18:01:33.413189 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.61405 (* 1 = 1.61405 loss)
I0825 18:01:35.432576 27361 solver.cpp:228] Iteration 1100, loss = 1.84101
I0825 18:01:35.432622 27361 solver.cpp:244]     Train net output #0: accuracy = 0.776917
I0825 18:01:35.432632 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.47994 (* 1 = 1.47994 loss)
I0825 18:01:35.432641 27361 sgd_solver.cpp:106] Iteration 1100, lr = 8.6145e-06
I0825 18:01:56.818526 27361 solver.cpp:228] Iteration 1110, loss = 1.5073
I0825 18:01:56.818572 27361 solver.cpp:244]     Train net output #0: accuracy = 0.831764
I0825 18:01:56.818583 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.44251 (* 1 = 1.44251 loss)
I0825 18:01:56.818593 27361 sgd_solver.cpp:106] Iteration 1110, lr = 8.60392e-06
I0825 18:02:18.204411 27361 solver.cpp:228] Iteration 1120, loss = 1.55069
I0825 18:02:18.204545 27361 solver.cpp:244]     Train net output #0: accuracy = 0.656162
I0825 18:02:18.204555 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.31253 (* 1 = 1.31253 loss)
I0825 18:02:18.204563 27361 sgd_solver.cpp:106] Iteration 1120, lr = 8.59338e-06
I0825 18:02:39.620779 27361 solver.cpp:228] Iteration 1130, loss = 1.55188
I0825 18:02:39.620826 27361 solver.cpp:244]     Train net output #0: accuracy = 0.892937
I0825 18:02:39.620844 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.4054 (* 1 = 1.4054 loss)
I0825 18:02:39.620851 27361 sgd_solver.cpp:106] Iteration 1130, lr = 8.58286e-06
I0825 18:03:01.001690 27361 solver.cpp:228] Iteration 1140, loss = 1.9747
I0825 18:03:01.001808 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87981
I0825 18:03:01.001819 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.6527 (* 1 = 1.6527 loss)
I0825 18:03:01.001827 27361 sgd_solver.cpp:106] Iteration 1140, lr = 8.57238e-06
I0825 18:03:22.395709 27361 solver.cpp:228] Iteration 1150, loss = 1.62375
I0825 18:03:22.395759 27361 solver.cpp:244]     Train net output #0: accuracy = 0.604626
I0825 18:03:22.395769 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.30859 (* 1 = 1.30859 loss)
I0825 18:03:22.395777 27361 sgd_solver.cpp:106] Iteration 1150, lr = 8.56192e-06
I0825 18:03:43.776562 27361 solver.cpp:228] Iteration 1160, loss = 1.62949
I0825 18:03:43.776666 27361 solver.cpp:244]     Train net output #0: accuracy = 0.867001
I0825 18:03:43.776677 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.40557 (* 1 = 1.40557 loss)
I0825 18:03:43.776685 27361 sgd_solver.cpp:106] Iteration 1160, lr = 8.55149e-06
I0825 18:04:05.212527 27361 solver.cpp:228] Iteration 1170, loss = 1.54763
I0825 18:04:05.212573 27361 solver.cpp:244]     Train net output #0: accuracy = 0.687748
I0825 18:04:05.212581 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.1908 (* 1 = 2.1908 loss)
I0825 18:04:05.212589 27361 sgd_solver.cpp:106] Iteration 1170, lr = 8.5411e-06
I0825 18:04:26.615375 27361 solver.cpp:228] Iteration 1180, loss = 1.61444
I0825 18:04:26.615488 27361 solver.cpp:244]     Train net output #0: accuracy = 0.772964
I0825 18:04:26.615499 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.38365 (* 1 = 1.38365 loss)
I0825 18:04:26.615506 27361 sgd_solver.cpp:106] Iteration 1180, lr = 8.53073e-06
I0825 18:04:48.000030 27361 solver.cpp:228] Iteration 1190, loss = 1.60086
I0825 18:04:48.000077 27361 solver.cpp:244]     Train net output #0: accuracy = 0.766308
I0825 18:04:48.000087 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.78798 (* 1 = 1.78798 loss)
I0825 18:04:48.000094 27361 sgd_solver.cpp:106] Iteration 1190, lr = 8.52039e-06
I0825 18:05:07.247138 27361 solver.cpp:337] Iteration 1200, Testing net (#0)
I0825 18:05:11.498551 27361 solver.cpp:404]     Test net output #0: accuracy = 0.712608
I0825 18:05:11.498599 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.73351 (* 1 = 1.73351 loss)
I0825 18:05:13.517688 27361 solver.cpp:228] Iteration 1200, loss = 1.72688
I0825 18:05:13.517734 27361 solver.cpp:244]     Train net output #0: accuracy = 0.699951
I0825 18:05:13.517742 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.96455 (* 1 = 1.96455 loss)
I0825 18:05:13.517750 27361 sgd_solver.cpp:106] Iteration 1200, lr = 8.51008e-06
I0825 18:05:34.943716 27361 solver.cpp:228] Iteration 1210, loss = 1.5318
I0825 18:05:34.943765 27361 solver.cpp:244]     Train net output #0: accuracy = 0.810425
I0825 18:05:34.943774 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.47319 (* 1 = 1.47319 loss)
I0825 18:05:34.943783 27361 sgd_solver.cpp:106] Iteration 1210, lr = 8.4998e-06
I0825 18:05:56.349452 27361 solver.cpp:228] Iteration 1220, loss = 1.99019
I0825 18:05:56.349593 27361 solver.cpp:244]     Train net output #0: accuracy = 0.63599
I0825 18:05:56.349604 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.95409 (* 1 = 1.95409 loss)
I0825 18:05:56.349612 27361 sgd_solver.cpp:106] Iteration 1220, lr = 8.48955e-06
I0825 18:06:17.734326 27361 solver.cpp:228] Iteration 1230, loss = 1.69197
I0825 18:06:17.734367 27361 solver.cpp:244]     Train net output #0: accuracy = 0.632359
I0825 18:06:17.734378 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.83523 (* 1 = 1.83523 loss)
I0825 18:06:17.734385 27361 sgd_solver.cpp:106] Iteration 1230, lr = 8.47933e-06
I0825 18:06:39.114305 27361 solver.cpp:228] Iteration 1240, loss = 1.55311
I0825 18:06:39.114428 27361 solver.cpp:244]     Train net output #0: accuracy = 0.924637
I0825 18:06:39.114439 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.29413 (* 1 = 1.29413 loss)
I0825 18:06:39.114446 27361 sgd_solver.cpp:106] Iteration 1240, lr = 8.46913e-06
I0825 18:07:00.486547 27361 solver.cpp:228] Iteration 1250, loss = 1.95694
I0825 18:07:00.486598 27361 solver.cpp:244]     Train net output #0: accuracy = 0.612553
I0825 18:07:00.486609 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.85911 (* 1 = 1.85911 loss)
I0825 18:07:00.486618 27361 sgd_solver.cpp:106] Iteration 1250, lr = 8.45897e-06
I0825 18:07:21.901597 27361 solver.cpp:228] Iteration 1260, loss = 1.59842
I0825 18:07:21.901710 27361 solver.cpp:244]     Train net output #0: accuracy = 0.658913
I0825 18:07:21.901721 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.50663 (* 1 = 1.50663 loss)
I0825 18:07:21.901728 27361 sgd_solver.cpp:106] Iteration 1260, lr = 8.44883e-06
I0825 18:07:43.284889 27361 solver.cpp:228] Iteration 1270, loss = 1.68164
I0825 18:07:43.284940 27361 solver.cpp:244]     Train net output #0: accuracy = 0.633125
I0825 18:07:43.284950 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.24197 (* 1 = 2.24197 loss)
I0825 18:07:43.284957 27361 sgd_solver.cpp:106] Iteration 1270, lr = 8.43873e-06
I0825 18:08:04.671943 27361 solver.cpp:228] Iteration 1280, loss = 1.43336
I0825 18:08:04.672003 27361 solver.cpp:244]     Train net output #0: accuracy = 0.825386
I0825 18:08:04.672013 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.22591 (* 1 = 1.22591 loss)
I0825 18:08:04.672020 27361 sgd_solver.cpp:106] Iteration 1280, lr = 8.42864e-06
I0825 18:08:26.100035 27361 solver.cpp:228] Iteration 1290, loss = 1.68652
I0825 18:08:26.100083 27361 solver.cpp:244]     Train net output #0: accuracy = 0.568382
I0825 18:08:26.100093 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.27712 (* 1 = 1.27712 loss)
I0825 18:08:26.100101 27361 sgd_solver.cpp:106] Iteration 1290, lr = 8.41859e-06
I0825 18:08:45.394963 27361 solver.cpp:337] Iteration 1300, Testing net (#0)
I0825 18:08:49.564218 27361 solver.cpp:404]     Test net output #0: accuracy = 0.75629
I0825 18:08:49.564262 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.57267 (* 1 = 1.57267 loss)
I0825 18:08:51.584101 27361 solver.cpp:228] Iteration 1300, loss = 1.51722
I0825 18:08:51.584146 27361 solver.cpp:244]     Train net output #0: accuracy = 0.670151
I0825 18:08:51.584156 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.85022 (* 1 = 1.85022 loss)
I0825 18:08:51.584163 27361 sgd_solver.cpp:106] Iteration 1300, lr = 8.40857e-06
I0825 18:09:12.964794 27361 solver.cpp:228] Iteration 1310, loss = 1.5042
I0825 18:09:12.964843 27361 solver.cpp:244]     Train net output #0: accuracy = 0.79007
I0825 18:09:12.964854 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.65285 (* 1 = 1.65285 loss)
I0825 18:09:12.964861 27361 sgd_solver.cpp:106] Iteration 1310, lr = 8.39857e-06
I0825 18:09:34.346200 27361 solver.cpp:228] Iteration 1320, loss = 1.64923
I0825 18:09:34.346340 27361 solver.cpp:244]     Train net output #0: accuracy = 0.760849
I0825 18:09:34.346352 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.95054 (* 1 = 1.95054 loss)
I0825 18:09:34.346360 27361 sgd_solver.cpp:106] Iteration 1320, lr = 8.3886e-06
I0825 18:09:55.728205 27361 solver.cpp:228] Iteration 1330, loss = 1.72602
I0825 18:09:55.728250 27361 solver.cpp:244]     Train net output #0: accuracy = 0.760674
I0825 18:09:55.728260 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.67011 (* 1 = 1.67011 loss)
I0825 18:09:55.728267 27361 sgd_solver.cpp:106] Iteration 1330, lr = 8.37866e-06
I0825 18:10:17.109318 27361 solver.cpp:228] Iteration 1340, loss = 1.47918
I0825 18:10:17.109383 27361 solver.cpp:244]     Train net output #0: accuracy = 0.867558
I0825 18:10:17.109392 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.20629 (* 1 = 1.20629 loss)
I0825 18:10:17.109407 27361 sgd_solver.cpp:106] Iteration 1340, lr = 8.36875e-06
I0825 18:10:38.491314 27361 solver.cpp:228] Iteration 1350, loss = 1.61989
I0825 18:10:38.491361 27361 solver.cpp:244]     Train net output #0: accuracy = 0.65834
I0825 18:10:38.491371 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.81318 (* 1 = 2.81318 loss)
I0825 18:10:38.491379 27361 sgd_solver.cpp:106] Iteration 1350, lr = 8.35886e-06
I0825 18:10:59.869168 27361 solver.cpp:228] Iteration 1360, loss = 1.4014
I0825 18:10:59.869274 27361 solver.cpp:244]     Train net output #0: accuracy = 0.870621
I0825 18:10:59.869285 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.26005 (* 1 = 1.26005 loss)
I0825 18:10:59.869293 27361 sgd_solver.cpp:106] Iteration 1360, lr = 8.349e-06
I0825 18:11:21.239485 27361 solver.cpp:228] Iteration 1370, loss = 1.46526
I0825 18:11:21.239528 27361 solver.cpp:244]     Train net output #0: accuracy = 0.860458
I0825 18:11:21.239538 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.24249 (* 1 = 1.24249 loss)
I0825 18:11:21.239545 27361 sgd_solver.cpp:106] Iteration 1370, lr = 8.33917e-06
I0825 18:11:42.606937 27361 solver.cpp:228] Iteration 1380, loss = 2.02825
I0825 18:11:42.607009 27361 solver.cpp:244]     Train net output #0: accuracy = 0.861649
I0825 18:11:42.607020 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.32096 (* 1 = 1.32096 loss)
I0825 18:11:42.607028 27361 sgd_solver.cpp:106] Iteration 1380, lr = 8.32937e-06
I0825 18:12:03.973987 27361 solver.cpp:228] Iteration 1390, loss = 1.50998
I0825 18:12:03.974035 27361 solver.cpp:244]     Train net output #0: accuracy = 0.740231
I0825 18:12:03.974045 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36928 (* 1 = 1.36928 loss)
I0825 18:12:03.974051 27361 sgd_solver.cpp:106] Iteration 1390, lr = 8.31959e-06
I0825 18:12:23.353354 27361 solver.cpp:337] Iteration 1400, Testing net (#0)
I0825 18:12:27.523663 27361 solver.cpp:404]     Test net output #0: accuracy = 0.738804
I0825 18:12:27.523710 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.62916 (* 1 = 1.62916 loss)
I0825 18:12:29.544653 27361 solver.cpp:228] Iteration 1400, loss = 1.68951
I0825 18:12:29.544699 27361 solver.cpp:244]     Train net output #0: accuracy = 0.791431
I0825 18:12:29.544709 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.43567 (* 1 = 1.43567 loss)
I0825 18:12:29.544718 27361 sgd_solver.cpp:106] Iteration 1400, lr = 8.30984e-06
I0825 18:12:50.927336 27361 solver.cpp:228] Iteration 1410, loss = 1.60126
I0825 18:12:50.927382 27361 solver.cpp:244]     Train net output #0: accuracy = 0.785362
I0825 18:12:50.927392 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.25204 (* 1 = 1.25204 loss)
I0825 18:12:50.927399 27361 sgd_solver.cpp:106] Iteration 1410, lr = 8.30011e-06
I0825 18:13:12.310945 27361 solver.cpp:228] Iteration 1420, loss = 1.64003
I0825 18:13:12.311053 27361 solver.cpp:244]     Train net output #0: accuracy = 0.657951
I0825 18:13:12.311064 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.97752 (* 1 = 1.97752 loss)
I0825 18:13:12.311071 27361 sgd_solver.cpp:106] Iteration 1420, lr = 8.29041e-06
I0825 18:13:33.694102 27361 solver.cpp:228] Iteration 1430, loss = 1.62691
I0825 18:13:33.694146 27361 solver.cpp:244]     Train net output #0: accuracy = 0.730724
I0825 18:13:33.694156 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.69752 (* 1 = 1.69752 loss)
I0825 18:13:33.694164 27361 sgd_solver.cpp:106] Iteration 1430, lr = 8.28074e-06
I0825 18:13:55.079957 27361 solver.cpp:228] Iteration 1440, loss = 1.3989
I0825 18:13:55.080102 27361 solver.cpp:244]     Train net output #0: accuracy = 0.763145
I0825 18:13:55.080114 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.41367 (* 1 = 1.41367 loss)
I0825 18:13:55.080122 27361 sgd_solver.cpp:106] Iteration 1440, lr = 8.2711e-06
I0825 18:14:16.465265 27361 solver.cpp:228] Iteration 1450, loss = 1.46116
I0825 18:14:16.465312 27361 solver.cpp:244]     Train net output #0: accuracy = 0.71616
I0825 18:14:16.465320 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.6806 (* 1 = 1.6806 loss)
I0825 18:14:16.465338 27361 sgd_solver.cpp:106] Iteration 1450, lr = 8.26148e-06
I0825 18:14:37.853750 27361 solver.cpp:228] Iteration 1460, loss = 1.47443
I0825 18:14:37.853865 27361 solver.cpp:244]     Train net output #0: accuracy = 0.772266
I0825 18:14:37.853876 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36368 (* 1 = 1.36368 loss)
I0825 18:14:37.853883 27361 sgd_solver.cpp:106] Iteration 1460, lr = 8.25188e-06
I0825 18:14:59.231979 27361 solver.cpp:228] Iteration 1470, loss = 1.71294
I0825 18:14:59.232024 27361 solver.cpp:244]     Train net output #0: accuracy = 0.509243
I0825 18:14:59.232033 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.02368 (* 1 = 2.02368 loss)
I0825 18:14:59.232041 27361 sgd_solver.cpp:106] Iteration 1470, lr = 8.24232e-06
I0825 18:15:20.615785 27361 solver.cpp:228] Iteration 1480, loss = 1.50745
I0825 18:15:20.615885 27361 solver.cpp:244]     Train net output #0: accuracy = 0.736515
I0825 18:15:20.615896 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.51834 (* 1 = 2.51834 loss)
I0825 18:15:20.615905 27361 sgd_solver.cpp:106] Iteration 1480, lr = 8.23278e-06
I0825 18:15:42.000236 27361 solver.cpp:228] Iteration 1490, loss = 1.50867
I0825 18:15:42.000280 27361 solver.cpp:244]     Train net output #0: accuracy = 0.805897
I0825 18:15:42.000290 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.78612 (* 1 = 1.78612 loss)
I0825 18:15:42.000298 27361 sgd_solver.cpp:106] Iteration 1490, lr = 8.22326e-06
I0825 18:16:01.245573 27361 solver.cpp:337] Iteration 1500, Testing net (#0)
I0825 18:16:05.413358 27361 solver.cpp:404]     Test net output #0: accuracy = 0.75043
I0825 18:16:05.413403 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.58557 (* 1 = 1.58557 loss)
I0825 18:16:07.433286 27361 solver.cpp:228] Iteration 1500, loss = 1.39563
I0825 18:16:07.433331 27361 solver.cpp:244]     Train net output #0: accuracy = 0.852547
I0825 18:16:07.433341 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.40835 (* 1 = 1.40835 loss)
I0825 18:16:07.433348 27361 sgd_solver.cpp:106] Iteration 1500, lr = 8.21377e-06
I0825 18:16:28.814235 27361 solver.cpp:228] Iteration 1510, loss = 1.5653
I0825 18:16:28.814281 27361 solver.cpp:244]     Train net output #0: accuracy = 0.808762
I0825 18:16:28.814291 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.41556 (* 1 = 1.41556 loss)
I0825 18:16:28.814298 27361 sgd_solver.cpp:106] Iteration 1510, lr = 8.2043e-06
I0825 18:16:50.192909 27361 solver.cpp:228] Iteration 1520, loss = 1.50179
I0825 18:16:50.192971 27361 solver.cpp:244]     Train net output #0: accuracy = 0.788643
I0825 18:16:50.192981 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.50615 (* 1 = 1.50615 loss)
I0825 18:16:50.192989 27361 sgd_solver.cpp:106] Iteration 1520, lr = 8.19486e-06
I0825 18:17:11.572139 27361 solver.cpp:228] Iteration 1530, loss = 1.61012
I0825 18:17:11.572186 27361 solver.cpp:244]     Train net output #0: accuracy = 0.67009
I0825 18:17:11.572196 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.5626 (* 1 = 1.5626 loss)
I0825 18:17:11.572203 27361 sgd_solver.cpp:106] Iteration 1530, lr = 8.18545e-06
I0825 18:17:32.951386 27361 solver.cpp:228] Iteration 1540, loss = 1.6917
I0825 18:17:32.951534 27361 solver.cpp:244]     Train net output #0: accuracy = 0.896759
I0825 18:17:32.951546 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.24043 (* 1 = 1.24043 loss)
I0825 18:17:32.951555 27361 sgd_solver.cpp:106] Iteration 1540, lr = 8.17606e-06
I0825 18:17:54.330941 27361 solver.cpp:228] Iteration 1550, loss = 1.44015
I0825 18:17:54.330986 27361 solver.cpp:244]     Train net output #0: accuracy = 0.708656
I0825 18:17:54.330996 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.38369 (* 1 = 1.38369 loss)
I0825 18:17:54.331003 27361 sgd_solver.cpp:106] Iteration 1550, lr = 8.1667e-06
I0825 18:18:15.710052 27361 solver.cpp:228] Iteration 1560, loss = 1.43759
I0825 18:18:15.710168 27361 solver.cpp:244]     Train net output #0: accuracy = 0.696953
I0825 18:18:15.710180 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.5108 (* 1 = 1.5108 loss)
I0825 18:18:15.710187 27361 sgd_solver.cpp:106] Iteration 1560, lr = 8.15736e-06
I0825 18:18:37.144686 27361 solver.cpp:228] Iteration 1570, loss = 1.48756
I0825 18:18:37.144734 27361 solver.cpp:244]     Train net output #0: accuracy = 0.789352
I0825 18:18:37.144744 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.24957 (* 1 = 1.24957 loss)
I0825 18:18:37.144752 27361 sgd_solver.cpp:106] Iteration 1570, lr = 8.14805e-06
I0825 18:18:58.510794 27361 solver.cpp:228] Iteration 1580, loss = 1.37747
I0825 18:18:58.510901 27361 solver.cpp:244]     Train net output #0: accuracy = 0.643131
I0825 18:18:58.510913 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.19667 (* 1 = 1.19667 loss)
I0825 18:18:58.510921 27361 sgd_solver.cpp:106] Iteration 1580, lr = 8.13876e-06
I0825 18:19:19.876134 27361 solver.cpp:228] Iteration 1590, loss = 1.33612
I0825 18:19:19.876178 27361 solver.cpp:244]     Train net output #0: accuracy = 0.781723
I0825 18:19:19.876188 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.21856 (* 1 = 1.21856 loss)
I0825 18:19:19.876195 27361 sgd_solver.cpp:106] Iteration 1590, lr = 8.12949e-06
I0825 18:19:39.168325 27361 solver.cpp:337] Iteration 1600, Testing net (#0)
I0825 18:19:43.334091 27361 solver.cpp:404]     Test net output #0: accuracy = 0.776261
I0825 18:19:43.334133 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.37364 (* 1 = 1.37364 loss)
I0825 18:19:45.353304 27361 solver.cpp:228] Iteration 1600, loss = 1.26927
I0825 18:19:45.353348 27361 solver.cpp:244]     Train net output #0: accuracy = 0.746895
I0825 18:19:45.353358 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.03197 (* 1 = 1.03197 loss)
I0825 18:19:45.353365 27361 sgd_solver.cpp:106] Iteration 1600, lr = 8.12025e-06
I0825 18:20:06.727841 27361 solver.cpp:228] Iteration 1610, loss = 1.29235
I0825 18:20:06.727885 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893688
I0825 18:20:06.727895 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.03265 (* 1 = 1.03265 loss)
I0825 18:20:06.727901 27361 sgd_solver.cpp:106] Iteration 1610, lr = 8.11104e-06
I0825 18:20:28.104689 27361 solver.cpp:228] Iteration 1620, loss = 1.26478
I0825 18:20:28.104799 27361 solver.cpp:244]     Train net output #0: accuracy = 0.816761
I0825 18:20:28.104809 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.29648 (* 1 = 1.29648 loss)
I0825 18:20:28.104817 27361 sgd_solver.cpp:106] Iteration 1620, lr = 8.10185e-06
I0825 18:20:49.478312 27361 solver.cpp:228] Iteration 1630, loss = 1.43127
I0825 18:20:49.478361 27361 solver.cpp:244]     Train net output #0: accuracy = 0.787231
I0825 18:20:49.478370 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.32837 (* 1 = 1.32837 loss)
I0825 18:20:49.478379 27361 sgd_solver.cpp:106] Iteration 1630, lr = 8.09268e-06
I0825 18:21:10.957093 27361 solver.cpp:228] Iteration 1640, loss = 1.25316
I0825 18:21:10.957231 27361 solver.cpp:244]     Train net output #0: accuracy = 0.883739
I0825 18:21:10.957243 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.03934 (* 1 = 1.03934 loss)
I0825 18:21:10.957252 27361 sgd_solver.cpp:106] Iteration 1640, lr = 8.08354e-06
I0825 18:21:32.330785 27361 solver.cpp:228] Iteration 1650, loss = 1.18302
I0825 18:21:32.330831 27361 solver.cpp:244]     Train net output #0: accuracy = 0.799446
I0825 18:21:32.330839 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.84192 (* 1 = 1.84192 loss)
I0825 18:21:32.330847 27361 sgd_solver.cpp:106] Iteration 1650, lr = 8.07442e-06
I0825 18:21:53.703423 27361 solver.cpp:228] Iteration 1660, loss = 1.3664
I0825 18:21:53.703541 27361 solver.cpp:244]     Train net output #0: accuracy = 0.774902
I0825 18:21:53.703552 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.25015 (* 1 = 1.25015 loss)
I0825 18:21:53.703560 27361 sgd_solver.cpp:106] Iteration 1660, lr = 8.06532e-06
I0825 18:22:15.078260 27361 solver.cpp:228] Iteration 1670, loss = 1.3554
I0825 18:22:15.078310 27361 solver.cpp:244]     Train net output #0: accuracy = 0.699276
I0825 18:22:15.078320 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.13135 (* 1 = 1.13135 loss)
I0825 18:22:15.078328 27361 sgd_solver.cpp:106] Iteration 1670, lr = 8.05625e-06
I0825 18:22:36.460376 27361 solver.cpp:228] Iteration 1680, loss = 1.28547
I0825 18:22:36.460484 27361 solver.cpp:244]     Train net output #0: accuracy = 0.779102
I0825 18:22:36.460494 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.07894 (* 1 = 1.07894 loss)
I0825 18:22:36.460501 27361 sgd_solver.cpp:106] Iteration 1680, lr = 8.04721e-06
I0825 18:22:57.834892 27361 solver.cpp:228] Iteration 1690, loss = 1.12317
I0825 18:22:57.834939 27361 solver.cpp:244]     Train net output #0: accuracy = 0.999027
I0825 18:22:57.834949 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.797942 (* 1 = 0.797942 loss)
I0825 18:22:57.834956 27361 sgd_solver.cpp:106] Iteration 1690, lr = 8.03818e-06
I0825 18:23:17.077404 27361 solver.cpp:337] Iteration 1700, Testing net (#0)
I0825 18:23:21.243000 27361 solver.cpp:404]     Test net output #0: accuracy = 0.787543
I0825 18:23:21.243046 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.26155 (* 1 = 1.26155 loss)
I0825 18:23:23.261704 27361 solver.cpp:228] Iteration 1700, loss = 1.18963
I0825 18:23:23.261751 27361 solver.cpp:244]     Train net output #0: accuracy = 0.822582
I0825 18:23:23.261761 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.12931 (* 1 = 1.12931 loss)
I0825 18:23:23.261768 27361 sgd_solver.cpp:106] Iteration 1700, lr = 8.02918e-06
I0825 18:23:44.636572 27361 solver.cpp:228] Iteration 1710, loss = 1.07576
I0825 18:23:44.636622 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87994
I0825 18:23:44.636632 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.88037 (* 1 = 0.88037 loss)
I0825 18:23:44.636641 27361 sgd_solver.cpp:106] Iteration 1710, lr = 8.02021e-06
I0825 18:24:06.006060 27361 solver.cpp:228] Iteration 1720, loss = 1.22811
I0825 18:24:06.006165 27361 solver.cpp:244]     Train net output #0: accuracy = 0.917278
I0825 18:24:06.006176 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.894986 (* 1 = 0.894986 loss)
I0825 18:24:06.006184 27361 sgd_solver.cpp:106] Iteration 1720, lr = 8.01125e-06
I0825 18:24:27.380795 27361 solver.cpp:228] Iteration 1730, loss = 1.27544
I0825 18:24:27.380838 27361 solver.cpp:244]     Train net output #0: accuracy = 0.714783
I0825 18:24:27.380848 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.42782 (* 1 = 1.42782 loss)
I0825 18:24:27.380856 27361 sgd_solver.cpp:106] Iteration 1730, lr = 8.00233e-06
I0825 18:24:48.751147 27361 solver.cpp:228] Iteration 1740, loss = 1.1171
I0825 18:24:48.751253 27361 solver.cpp:244]     Train net output #0: accuracy = 0.670273
I0825 18:24:48.751265 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.265 (* 1 = 1.265 loss)
I0825 18:24:48.751271 27361 sgd_solver.cpp:106] Iteration 1740, lr = 7.99342e-06
I0825 18:25:10.124912 27361 solver.cpp:228] Iteration 1750, loss = 1.12824
I0825 18:25:10.124958 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928173
I0825 18:25:10.124968 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.8054 (* 1 = 0.8054 loss)
I0825 18:25:10.124975 27361 sgd_solver.cpp:106] Iteration 1750, lr = 7.98454e-06
I0825 18:25:31.498311 27361 solver.cpp:228] Iteration 1760, loss = 1.48817
I0825 18:25:31.498402 27361 solver.cpp:244]     Train net output #0: accuracy = 0.809547
I0825 18:25:31.498414 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.24038 (* 1 = 1.24038 loss)
I0825 18:25:31.498421 27361 sgd_solver.cpp:106] Iteration 1760, lr = 7.97568e-06
I0825 18:25:52.869529 27361 solver.cpp:228] Iteration 1770, loss = 1.03619
I0825 18:25:52.869576 27361 solver.cpp:244]     Train net output #0: accuracy = 0.780594
I0825 18:25:52.869586 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.18296 (* 1 = 1.18296 loss)
I0825 18:25:52.869601 27361 sgd_solver.cpp:106] Iteration 1770, lr = 7.96684e-06
I0825 18:26:14.243136 27361 solver.cpp:228] Iteration 1780, loss = 1.33465
I0825 18:26:14.243242 27361 solver.cpp:244]     Train net output #0: accuracy = 0.813587
I0825 18:26:14.243252 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.58113 (* 1 = 1.58113 loss)
I0825 18:26:14.243260 27361 sgd_solver.cpp:106] Iteration 1780, lr = 7.95802e-06
I0825 18:26:35.614349 27361 solver.cpp:228] Iteration 1790, loss = 1.03764
I0825 18:26:35.614398 27361 solver.cpp:244]     Train net output #0: accuracy = 0.757744
I0825 18:26:35.614408 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.947795 (* 1 = 0.947795 loss)
I0825 18:26:35.614415 27361 sgd_solver.cpp:106] Iteration 1790, lr = 7.94923e-06
I0825 18:26:54.851460 27361 solver.cpp:337] Iteration 1800, Testing net (#0)
I0825 18:26:59.017163 27361 solver.cpp:404]     Test net output #0: accuracy = 0.776977
I0825 18:26:59.017211 27361 solver.cpp:404]     Test net output #1: softmaxloss = 1.14886 (* 1 = 1.14886 loss)
I0825 18:27:01.035938 27361 solver.cpp:228] Iteration 1800, loss = 1.17048
I0825 18:27:01.035982 27361 solver.cpp:244]     Train net output #0: accuracy = 0.837173
I0825 18:27:01.035992 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.880429 (* 1 = 0.880429 loss)
I0825 18:27:01.036000 27361 sgd_solver.cpp:106] Iteration 1800, lr = 7.94046e-06
I0825 18:27:22.447391 27361 solver.cpp:228] Iteration 1810, loss = 1.04473
I0825 18:27:22.447437 27361 solver.cpp:244]     Train net output #0: accuracy = 0.716484
I0825 18:27:22.447446 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.947288 (* 1 = 0.947288 loss)
I0825 18:27:22.447454 27361 sgd_solver.cpp:106] Iteration 1810, lr = 7.93172e-06
I0825 18:27:43.805879 27361 solver.cpp:228] Iteration 1820, loss = 1.12455
I0825 18:27:43.805992 27361 solver.cpp:244]     Train net output #0: accuracy = 0.772629
I0825 18:27:43.806004 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.756167 (* 1 = 0.756167 loss)
I0825 18:27:43.806011 27361 sgd_solver.cpp:106] Iteration 1820, lr = 7.92299e-06
I0825 18:28:05.266815 27361 solver.cpp:228] Iteration 1830, loss = 0.71168
I0825 18:28:05.266861 27361 solver.cpp:244]     Train net output #0: accuracy = 0.809246
I0825 18:28:05.266870 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.735814 (* 1 = 0.735814 loss)
I0825 18:28:05.266878 27361 sgd_solver.cpp:106] Iteration 1830, lr = 7.91429e-06
I0825 18:28:26.681249 27361 solver.cpp:228] Iteration 1840, loss = 0.88688
I0825 18:28:26.681372 27361 solver.cpp:244]     Train net output #0: accuracy = 0.680801
I0825 18:28:26.681383 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.09985 (* 1 = 1.09985 loss)
I0825 18:28:26.681391 27361 sgd_solver.cpp:106] Iteration 1840, lr = 7.90561e-06
I0825 18:28:48.039233 27361 solver.cpp:228] Iteration 1850, loss = 0.960863
I0825 18:28:48.039280 27361 solver.cpp:244]     Train net output #0: accuracy = 0.695026
I0825 18:28:48.039289 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.648777 (* 1 = 0.648777 loss)
I0825 18:28:48.039297 27361 sgd_solver.cpp:106] Iteration 1850, lr = 7.89695e-06
I0825 18:29:09.395890 27361 solver.cpp:228] Iteration 1860, loss = 0.888338
I0825 18:29:09.396029 27361 solver.cpp:244]     Train net output #0: accuracy = 0.913345
I0825 18:29:09.396040 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.645485 (* 1 = 0.645485 loss)
I0825 18:29:09.396049 27361 sgd_solver.cpp:106] Iteration 1860, lr = 7.88832e-06
I0825 18:29:30.804702 27361 solver.cpp:228] Iteration 1870, loss = 0.881262
I0825 18:29:30.804750 27361 solver.cpp:244]     Train net output #0: accuracy = 0.818657
I0825 18:29:30.804764 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.09434 (* 1 = 1.09434 loss)
I0825 18:29:30.804774 27361 sgd_solver.cpp:106] Iteration 1870, lr = 7.8797e-06
I0825 18:29:52.152298 27361 solver.cpp:228] Iteration 1880, loss = 1.20524
I0825 18:29:52.152420 27361 solver.cpp:244]     Train net output #0: accuracy = 0.75108
I0825 18:29:52.152446 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.673631 (* 1 = 0.673631 loss)
I0825 18:29:52.152456 27361 sgd_solver.cpp:106] Iteration 1880, lr = 7.87111e-06
I0825 18:30:13.494303 27361 solver.cpp:228] Iteration 1890, loss = 0.601976
I0825 18:30:13.494354 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926373
I0825 18:30:13.494366 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.505504 (* 1 = 0.505504 loss)
I0825 18:30:13.494376 27361 sgd_solver.cpp:106] Iteration 1890, lr = 7.86254e-06
I0825 18:30:32.703291 27361 solver.cpp:337] Iteration 1900, Testing net (#0)
I0825 18:30:36.859228 27361 solver.cpp:404]     Test net output #0: accuracy = 0.794889
I0825 18:30:36.859278 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.9685 (* 1 = 0.9685 loss)
I0825 18:30:38.876601 27361 solver.cpp:228] Iteration 1900, loss = 0.908749
I0825 18:30:38.876648 27361 solver.cpp:244]     Train net output #0: accuracy = 0.856712
I0825 18:30:38.876662 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.80163 (* 1 = 0.80163 loss)
I0825 18:30:38.876672 27361 sgd_solver.cpp:106] Iteration 1900, lr = 7.854e-06
I0825 18:31:00.225746 27361 solver.cpp:228] Iteration 1910, loss = 0.771226
I0825 18:31:00.225795 27361 solver.cpp:244]     Train net output #0: accuracy = 0.672062
I0825 18:31:00.225807 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.98042 (* 1 = 0.98042 loss)
I0825 18:31:00.225818 27361 sgd_solver.cpp:106] Iteration 1910, lr = 7.84547e-06
I0825 18:31:21.571641 27361 solver.cpp:228] Iteration 1920, loss = 0.859436
I0825 18:31:21.571753 27361 solver.cpp:244]     Train net output #0: accuracy = 0.883339
I0825 18:31:21.571768 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.347503 (* 1 = 0.347503 loss)
I0825 18:31:21.571779 27361 sgd_solver.cpp:106] Iteration 1920, lr = 7.83696e-06
I0825 18:31:42.975667 27361 solver.cpp:228] Iteration 1930, loss = 0.885478
I0825 18:31:42.975714 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910694
I0825 18:31:42.975723 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.44139 (* 1 = 0.44139 loss)
I0825 18:31:42.975731 27361 sgd_solver.cpp:106] Iteration 1930, lr = 7.82848e-06
I0825 18:32:04.344595 27361 solver.cpp:228] Iteration 1940, loss = 0.679518
I0825 18:32:04.344708 27361 solver.cpp:244]     Train net output #0: accuracy = 0.875076
I0825 18:32:04.344719 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.670932 (* 1 = 0.670932 loss)
I0825 18:32:04.344727 27361 sgd_solver.cpp:106] Iteration 1940, lr = 7.82002e-06
I0825 18:32:25.714117 27361 solver.cpp:228] Iteration 1950, loss = 1.18474
I0825 18:32:25.714164 27361 solver.cpp:244]     Train net output #0: accuracy = 0.790638
I0825 18:32:25.714174 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.0351 (* 1 = 2.0351 loss)
I0825 18:32:25.714182 27361 sgd_solver.cpp:106] Iteration 1950, lr = 7.81158e-06
I0825 18:32:47.084002 27361 solver.cpp:228] Iteration 1960, loss = 0.844202
I0825 18:32:47.084142 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928852
I0825 18:32:47.084154 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.236564 (* 1 = 0.236564 loss)
I0825 18:32:47.084162 27361 sgd_solver.cpp:106] Iteration 1960, lr = 7.80316e-06
I0825 18:33:08.451045 27361 solver.cpp:228] Iteration 1970, loss = 0.497689
I0825 18:33:08.451088 27361 solver.cpp:244]     Train net output #0: accuracy = 0.906429
I0825 18:33:08.451097 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.41864 (* 1 = 0.41864 loss)
I0825 18:33:08.451105 27361 sgd_solver.cpp:106] Iteration 1970, lr = 7.79476e-06
I0825 18:33:29.923537 27361 solver.cpp:228] Iteration 1980, loss = 0.628945
I0825 18:33:29.923619 27361 solver.cpp:244]     Train net output #0: accuracy = 0.698917
I0825 18:33:29.923630 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.699919 (* 1 = 0.699919 loss)
I0825 18:33:29.923637 27361 sgd_solver.cpp:106] Iteration 1980, lr = 7.78639e-06
I0825 18:33:51.288156 27361 solver.cpp:228] Iteration 1990, loss = 0.589329
I0825 18:33:51.288203 27361 solver.cpp:244]     Train net output #0: accuracy = 0.859066
I0825 18:33:51.288213 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.355445 (* 1 = 0.355445 loss)
I0825 18:33:51.288220 27361 sgd_solver.cpp:106] Iteration 1990, lr = 7.77803e-06
I0825 18:34:10.518851 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_2000.caffemodel
I0825 18:34:10.715147 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_2000.solverstate
I0825 18:34:10.752650 27361 solver.cpp:337] Iteration 2000, Testing net (#0)
I0825 18:34:14.794626 27361 solver.cpp:404]     Test net output #0: accuracy = 0.837339
I0825 18:34:14.794672 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.736551 (* 1 = 0.736551 loss)
I0825 18:34:16.812117 27361 solver.cpp:228] Iteration 2000, loss = 0.753207
I0825 18:34:16.812161 27361 solver.cpp:244]     Train net output #0: accuracy = 0.860626
I0825 18:34:16.812170 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.384716 (* 1 = 0.384716 loss)
I0825 18:34:16.812178 27361 sgd_solver.cpp:106] Iteration 2000, lr = 7.7697e-06
I0825 18:34:38.178028 27361 solver.cpp:228] Iteration 2010, loss = 0.712732
I0825 18:34:38.178076 27361 solver.cpp:244]     Train net output #0: accuracy = 0.783619
I0825 18:34:38.178084 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.572674 (* 1 = 0.572674 loss)
I0825 18:34:38.178092 27361 sgd_solver.cpp:106] Iteration 2010, lr = 7.76138e-06
I0825 18:34:59.545819 27361 solver.cpp:228] Iteration 2020, loss = 0.757627
I0825 18:34:59.545927 27361 solver.cpp:244]     Train net output #0: accuracy = 0.759991
I0825 18:34:59.545938 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.57626 (* 1 = 1.57626 loss)
I0825 18:34:59.545945 27361 sgd_solver.cpp:106] Iteration 2020, lr = 7.75309e-06
I0825 18:35:20.910925 27361 solver.cpp:228] Iteration 2030, loss = 0.70411
I0825 18:35:20.910974 27361 solver.cpp:244]     Train net output #0: accuracy = 0.915237
I0825 18:35:20.910982 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.346977 (* 1 = 0.346977 loss)
I0825 18:35:20.910990 27361 sgd_solver.cpp:106] Iteration 2030, lr = 7.74481e-06
I0825 18:35:42.278079 27361 solver.cpp:228] Iteration 2040, loss = 0.738056
I0825 18:35:42.278188 27361 solver.cpp:244]     Train net output #0: accuracy = 0.782761
I0825 18:35:42.278199 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.806763 (* 1 = 0.806763 loss)
I0825 18:35:42.278208 27361 sgd_solver.cpp:106] Iteration 2040, lr = 7.73656e-06
I0825 18:36:03.644872 27361 solver.cpp:228] Iteration 2050, loss = 0.780024
I0825 18:36:03.644919 27361 solver.cpp:244]     Train net output #0: accuracy = 0.938812
I0825 18:36:03.644928 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.220132 (* 1 = 0.220132 loss)
I0825 18:36:03.644937 27361 sgd_solver.cpp:106] Iteration 2050, lr = 7.72833e-06
I0825 18:36:25.007200 27361 solver.cpp:228] Iteration 2060, loss = 0.453001
I0825 18:36:25.007346 27361 solver.cpp:244]     Train net output #0: accuracy = 0.79768
I0825 18:36:25.007357 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.785674 (* 1 = 0.785674 loss)
I0825 18:36:25.007365 27361 sgd_solver.cpp:106] Iteration 2060, lr = 7.72012e-06
I0825 18:36:46.480909 27361 solver.cpp:228] Iteration 2070, loss = 0.727158
I0825 18:36:46.480954 27361 solver.cpp:244]     Train net output #0: accuracy = 0.924683
I0825 18:36:46.480964 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.297409 (* 1 = 0.297409 loss)
I0825 18:36:46.480972 27361 sgd_solver.cpp:106] Iteration 2070, lr = 7.71193e-06
I0825 18:37:07.847020 27361 solver.cpp:228] Iteration 2080, loss = 0.756701
I0825 18:37:07.847137 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9319
I0825 18:37:07.847147 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.314689 (* 1 = 0.314689 loss)
I0825 18:37:07.847156 27361 sgd_solver.cpp:106] Iteration 2080, lr = 7.70376e-06
I0825 18:37:29.215600 27361 solver.cpp:228] Iteration 2090, loss = 0.549989
I0825 18:37:29.215649 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943295
I0825 18:37:29.215659 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.16388 (* 1 = 0.16388 loss)
I0825 18:37:29.215667 27361 sgd_solver.cpp:106] Iteration 2090, lr = 7.69561e-06
I0825 18:37:48.432718 27361 solver.cpp:337] Iteration 2100, Testing net (#0)
I0825 18:37:52.585940 27361 solver.cpp:404]     Test net output #0: accuracy = 0.83888
I0825 18:37:52.585985 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.661551 (* 1 = 0.661551 loss)
I0825 18:37:54.601052 27361 solver.cpp:228] Iteration 2100, loss = 0.704576
I0825 18:37:54.601094 27361 solver.cpp:244]     Train net output #0: accuracy = 0.811516
I0825 18:37:54.601102 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.739796 (* 1 = 0.739796 loss)
I0825 18:37:54.601110 27361 sgd_solver.cpp:106] Iteration 2100, lr = 7.68748e-06
I0825 18:38:15.991051 27361 solver.cpp:228] Iteration 2110, loss = 0.911926
I0825 18:38:15.991098 27361 solver.cpp:244]     Train net output #0: accuracy = 0.918953
I0825 18:38:15.991107 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.367621 (* 1 = 0.367621 loss)
I0825 18:38:15.991116 27361 sgd_solver.cpp:106] Iteration 2110, lr = 7.67936e-06
I0825 18:38:37.347662 27361 solver.cpp:228] Iteration 2120, loss = 1.19319
I0825 18:38:37.347769 27361 solver.cpp:244]     Train net output #0: accuracy = 0.627785
I0825 18:38:37.347780 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.61824 (* 1 = 1.61824 loss)
I0825 18:38:37.347787 27361 sgd_solver.cpp:106] Iteration 2120, lr = 7.67127e-06
I0825 18:38:58.706995 27361 solver.cpp:228] Iteration 2130, loss = 0.889286
I0825 18:38:58.707041 27361 solver.cpp:244]     Train net output #0: accuracy = 0.628448
I0825 18:38:58.707049 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.673354 (* 1 = 0.673354 loss)
I0825 18:38:58.707057 27361 sgd_solver.cpp:106] Iteration 2130, lr = 7.6632e-06
I0825 18:39:20.063148 27361 solver.cpp:228] Iteration 2140, loss = 0.649817
I0825 18:39:20.063261 27361 solver.cpp:244]     Train net output #0: accuracy = 0.771687
I0825 18:39:20.063271 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.369688 (* 1 = 0.369688 loss)
I0825 18:39:20.063278 27361 sgd_solver.cpp:106] Iteration 2140, lr = 7.65515e-06
I0825 18:39:41.425715 27361 solver.cpp:228] Iteration 2150, loss = 0.624634
I0825 18:39:41.425762 27361 solver.cpp:244]     Train net output #0: accuracy = 0.947395
I0825 18:39:41.425771 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.125322 (* 1 = 0.125322 loss)
I0825 18:39:41.425779 27361 sgd_solver.cpp:106] Iteration 2150, lr = 7.64712e-06
I0825 18:40:02.788136 27361 solver.cpp:228] Iteration 2160, loss = 0.732287
I0825 18:40:02.788246 27361 solver.cpp:244]     Train net output #0: accuracy = 0.580208
I0825 18:40:02.788257 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.853051 (* 1 = 0.853051 loss)
I0825 18:40:02.788264 27361 sgd_solver.cpp:106] Iteration 2160, lr = 7.63911e-06
I0825 18:40:24.143501 27361 solver.cpp:228] Iteration 2170, loss = 0.682253
I0825 18:40:24.143545 27361 solver.cpp:244]     Train net output #0: accuracy = 0.883144
I0825 18:40:24.143554 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.486364 (* 1 = 0.486364 loss)
I0825 18:40:24.143563 27361 sgd_solver.cpp:106] Iteration 2170, lr = 7.63112e-06
I0825 18:40:45.555639 27361 solver.cpp:228] Iteration 2180, loss = 0.683166
I0825 18:40:45.555774 27361 solver.cpp:244]     Train net output #0: accuracy = 0.89299
I0825 18:40:45.555786 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.526153 (* 1 = 0.526153 loss)
I0825 18:40:45.555794 27361 sgd_solver.cpp:106] Iteration 2180, lr = 7.62314e-06
I0825 18:41:06.905525 27361 solver.cpp:228] Iteration 2190, loss = 0.594036
I0825 18:41:06.905575 27361 solver.cpp:244]     Train net output #0: accuracy = 0.664906
I0825 18:41:06.905592 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.554387 (* 1 = 0.554387 loss)
I0825 18:41:06.905601 27361 sgd_solver.cpp:106] Iteration 2190, lr = 7.61519e-06
I0825 18:41:26.173317 27361 solver.cpp:337] Iteration 2200, Testing net (#0)
I0825 18:41:30.335386 27361 solver.cpp:404]     Test net output #0: accuracy = 0.806668
I0825 18:41:30.335429 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.982301 (* 1 = 0.982301 loss)
I0825 18:41:32.354012 27361 solver.cpp:228] Iteration 2200, loss = 0.574533
I0825 18:41:32.354058 27361 solver.cpp:244]     Train net output #0: accuracy = 0.785629
I0825 18:41:32.354066 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.38927 (* 1 = 1.38927 loss)
I0825 18:41:32.354074 27361 sgd_solver.cpp:106] Iteration 2200, lr = 7.60726e-06
I0825 18:41:53.716996 27361 solver.cpp:228] Iteration 2210, loss = 0.467291
I0825 18:41:53.717042 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949886
I0825 18:41:53.717052 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.158167 (* 1 = 0.158167 loss)
I0825 18:41:53.717059 27361 sgd_solver.cpp:106] Iteration 2210, lr = 7.59934e-06
I0825 18:42:15.086976 27361 solver.cpp:228] Iteration 2220, loss = 0.732422
I0825 18:42:15.087036 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910336
I0825 18:42:15.087046 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.313972 (* 1 = 0.313972 loss)
I0825 18:42:15.087054 27361 sgd_solver.cpp:106] Iteration 2220, lr = 7.59145e-06
I0825 18:42:36.450260 27361 solver.cpp:228] Iteration 2230, loss = 0.549832
I0825 18:42:36.450309 27361 solver.cpp:244]     Train net output #0: accuracy = 0.888885
I0825 18:42:36.450319 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.65825 (* 1 = 0.65825 loss)
I0825 18:42:36.450325 27361 sgd_solver.cpp:106] Iteration 2230, lr = 7.58357e-06
I0825 18:42:57.810206 27361 solver.cpp:228] Iteration 2240, loss = 0.426499
I0825 18:42:57.810331 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889072
I0825 18:42:57.810341 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.474239 (* 1 = 0.474239 loss)
I0825 18:42:57.810349 27361 sgd_solver.cpp:106] Iteration 2240, lr = 7.57571e-06
I0825 18:43:19.219938 27361 solver.cpp:228] Iteration 2250, loss = 0.541154
I0825 18:43:19.219988 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93103
I0825 18:43:19.219997 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.224787 (* 1 = 0.224787 loss)
I0825 18:43:19.220005 27361 sgd_solver.cpp:106] Iteration 2250, lr = 7.56788e-06
I0825 18:43:40.577039 27361 solver.cpp:228] Iteration 2260, loss = 0.577182
I0825 18:43:40.577139 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954067
I0825 18:43:40.577150 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.109015 (* 1 = 0.109015 loss)
I0825 18:43:40.577157 27361 sgd_solver.cpp:106] Iteration 2260, lr = 7.56006e-06
I0825 18:44:01.935077 27361 solver.cpp:228] Iteration 2270, loss = 0.607636
I0825 18:44:01.935123 27361 solver.cpp:244]     Train net output #0: accuracy = 0.900146
I0825 18:44:01.935133 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.439821 (* 1 = 0.439821 loss)
I0825 18:44:01.935140 27361 sgd_solver.cpp:106] Iteration 2270, lr = 7.55226e-06
I0825 18:44:23.293072 27361 solver.cpp:228] Iteration 2280, loss = 0.825817
I0825 18:44:23.293165 27361 solver.cpp:244]     Train net output #0: accuracy = 0.669498
I0825 18:44:23.293176 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.90656 (* 1 = 1.90656 loss)
I0825 18:44:23.293184 27361 sgd_solver.cpp:106] Iteration 2280, lr = 7.54447e-06
I0825 18:44:44.706929 27361 solver.cpp:228] Iteration 2290, loss = 0.555017
I0825 18:44:44.706979 27361 solver.cpp:244]     Train net output #0: accuracy = 0.836246
I0825 18:44:44.706990 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.462559 (* 1 = 0.462559 loss)
I0825 18:44:44.706996 27361 sgd_solver.cpp:106] Iteration 2290, lr = 7.53671e-06
I0825 18:45:03.932734 27361 solver.cpp:337] Iteration 2300, Testing net (#0)
I0825 18:45:08.091887 27361 solver.cpp:404]     Test net output #0: accuracy = 0.84937
I0825 18:45:08.091935 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.588266 (* 1 = 0.588266 loss)
I0825 18:45:10.109760 27361 solver.cpp:228] Iteration 2300, loss = 0.655645
I0825 18:45:10.109805 27361 solver.cpp:244]     Train net output #0: accuracy = 0.875904
I0825 18:45:10.109814 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.189889 (* 1 = 0.189889 loss)
I0825 18:45:10.109822 27361 sgd_solver.cpp:106] Iteration 2300, lr = 7.52897e-06
I0825 18:45:31.459664 27361 solver.cpp:228] Iteration 2310, loss = 0.857727
I0825 18:45:31.459712 27361 solver.cpp:244]     Train net output #0: accuracy = 0.781834
I0825 18:45:31.459722 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.57702 (* 1 = 0.57702 loss)
I0825 18:45:31.459728 27361 sgd_solver.cpp:106] Iteration 2310, lr = 7.52124e-06
I0825 18:45:52.805781 27361 solver.cpp:228] Iteration 2320, loss = 0.431077
I0825 18:45:52.805882 27361 solver.cpp:244]     Train net output #0: accuracy = 0.837456
I0825 18:45:52.805892 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.508213 (* 1 = 0.508213 loss)
I0825 18:45:52.805901 27361 sgd_solver.cpp:106] Iteration 2320, lr = 7.51353e-06
I0825 18:46:14.178191 27361 solver.cpp:228] Iteration 2330, loss = 0.683185
I0825 18:46:14.178241 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921745
I0825 18:46:14.178249 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.183046 (* 1 = 0.183046 loss)
I0825 18:46:14.178256 27361 sgd_solver.cpp:106] Iteration 2330, lr = 7.50584e-06
I0825 18:46:35.544301 27361 solver.cpp:228] Iteration 2340, loss = 0.659008
I0825 18:46:35.544404 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954948
I0825 18:46:35.544414 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0889697 (* 1 = 0.0889697 loss)
I0825 18:46:35.544421 27361 sgd_solver.cpp:106] Iteration 2340, lr = 7.49817e-06
I0825 18:46:56.906993 27361 solver.cpp:228] Iteration 2350, loss = 0.976683
I0825 18:46:56.907042 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90234
I0825 18:46:56.907052 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.433043 (* 1 = 0.433043 loss)
I0825 18:46:56.907059 27361 sgd_solver.cpp:106] Iteration 2350, lr = 7.49052e-06
I0825 18:47:18.270413 27361 solver.cpp:228] Iteration 2360, loss = 0.625332
I0825 18:47:18.270506 27361 solver.cpp:244]     Train net output #0: accuracy = 0.952259
I0825 18:47:18.270517 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.143939 (* 1 = 0.143939 loss)
I0825 18:47:18.270525 27361 sgd_solver.cpp:106] Iteration 2360, lr = 7.48289e-06
I0825 18:47:39.633657 27361 solver.cpp:228] Iteration 2370, loss = 0.669631
I0825 18:47:39.633704 27361 solver.cpp:244]     Train net output #0: accuracy = 0.744946
I0825 18:47:39.633713 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.800737 (* 1 = 0.800737 loss)
I0825 18:47:39.633721 27361 sgd_solver.cpp:106] Iteration 2370, lr = 7.47527e-06
I0825 18:48:00.996536 27361 solver.cpp:228] Iteration 2380, loss = 0.629134
I0825 18:48:00.996630 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945381
I0825 18:48:00.996640 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.148418 (* 1 = 0.148418 loss)
I0825 18:48:00.996647 27361 sgd_solver.cpp:106] Iteration 2380, lr = 7.46767e-06
I0825 18:48:22.364883 27361 solver.cpp:228] Iteration 2390, loss = 0.807542
I0825 18:48:22.364931 27361 solver.cpp:244]     Train net output #0: accuracy = 0.591125
I0825 18:48:22.364941 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.63809 (* 1 = 2.63809 loss)
I0825 18:48:22.364948 27361 sgd_solver.cpp:106] Iteration 2390, lr = 7.46009e-06
I0825 18:48:41.643231 27361 solver.cpp:337] Iteration 2400, Testing net (#0)
I0825 18:48:45.799767 27361 solver.cpp:404]     Test net output #0: accuracy = 0.830052
I0825 18:48:45.799811 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.790537 (* 1 = 0.790537 loss)
I0825 18:48:47.870993 27361 solver.cpp:228] Iteration 2400, loss = 0.822679
I0825 18:48:47.871037 27361 solver.cpp:244]     Train net output #0: accuracy = 0.862968
I0825 18:48:47.871047 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.247907 (* 1 = 0.247907 loss)
I0825 18:48:47.871054 27361 sgd_solver.cpp:106] Iteration 2400, lr = 7.45253e-06
I0825 18:49:09.223738 27361 solver.cpp:228] Iteration 2410, loss = 0.53357
I0825 18:49:09.223783 27361 solver.cpp:244]     Train net output #0: accuracy = 0.693478
I0825 18:49:09.223793 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.623608 (* 1 = 0.623608 loss)
I0825 18:49:09.223800 27361 sgd_solver.cpp:106] Iteration 2410, lr = 7.44499e-06
I0825 18:49:30.579237 27361 solver.cpp:228] Iteration 2420, loss = 0.427854
I0825 18:49:30.579352 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943916
I0825 18:49:30.579362 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.202349 (* 1 = 0.202349 loss)
I0825 18:49:30.579370 27361 sgd_solver.cpp:106] Iteration 2420, lr = 7.43746e-06
I0825 18:49:51.934422 27361 solver.cpp:228] Iteration 2430, loss = 0.607884
I0825 18:49:51.934471 27361 solver.cpp:244]     Train net output #0: accuracy = 0.876598
I0825 18:49:51.934481 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.268378 (* 1 = 0.268378 loss)
I0825 18:49:51.934489 27361 sgd_solver.cpp:106] Iteration 2430, lr = 7.42995e-06
I0825 18:50:13.286109 27361 solver.cpp:228] Iteration 2440, loss = 0.438942
I0825 18:50:13.286221 27361 solver.cpp:244]     Train net output #0: accuracy = 0.925179
I0825 18:50:13.286232 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.305263 (* 1 = 0.305263 loss)
I0825 18:50:13.286239 27361 sgd_solver.cpp:106] Iteration 2440, lr = 7.42246e-06
I0825 18:50:34.643410 27361 solver.cpp:228] Iteration 2450, loss = 0.506025
I0825 18:50:34.643455 27361 solver.cpp:244]     Train net output #0: accuracy = 0.813271
I0825 18:50:34.643465 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.353046 (* 1 = 0.353046 loss)
I0825 18:50:34.643472 27361 sgd_solver.cpp:106] Iteration 2450, lr = 7.41499e-06
I0825 18:50:55.991607 27361 solver.cpp:228] Iteration 2460, loss = 0.45079
I0825 18:50:55.991668 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923531
I0825 18:50:55.991678 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.352195 (* 1 = 0.352195 loss)
I0825 18:50:55.991686 27361 sgd_solver.cpp:106] Iteration 2460, lr = 7.40753e-06
I0825 18:51:17.345213 27361 solver.cpp:228] Iteration 2470, loss = 0.857588
I0825 18:51:17.345262 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929852
I0825 18:51:17.345271 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.219934 (* 1 = 0.219934 loss)
I0825 18:51:17.345278 27361 sgd_solver.cpp:106] Iteration 2470, lr = 7.40009e-06
I0825 18:51:38.747221 27361 solver.cpp:228] Iteration 2480, loss = 0.491126
I0825 18:51:38.747308 27361 solver.cpp:244]     Train net output #0: accuracy = 0.903275
I0825 18:51:38.747319 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.220422 (* 1 = 0.220422 loss)
I0825 18:51:38.747328 27361 sgd_solver.cpp:106] Iteration 2480, lr = 7.39267e-06
I0825 18:52:00.095613 27361 solver.cpp:228] Iteration 2490, loss = 0.662604
I0825 18:52:00.095660 27361 solver.cpp:244]     Train net output #0: accuracy = 0.83073
I0825 18:52:00.095670 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.02363 (* 1 = 1.02363 loss)
I0825 18:52:00.095679 27361 sgd_solver.cpp:106] Iteration 2490, lr = 7.38527e-06
I0825 18:52:19.310963 27361 solver.cpp:337] Iteration 2500, Testing net (#0)
I0825 18:52:23.464959 27361 solver.cpp:404]     Test net output #0: accuracy = 0.834906
I0825 18:52:23.465004 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.836777 (* 1 = 0.836777 loss)
I0825 18:52:25.482872 27361 solver.cpp:228] Iteration 2500, loss = 0.894515
I0825 18:52:25.482920 27361 solver.cpp:244]     Train net output #0: accuracy = 0.866867
I0825 18:52:25.482930 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.316011 (* 1 = 0.316011 loss)
I0825 18:52:25.482945 27361 sgd_solver.cpp:106] Iteration 2500, lr = 7.37788e-06
I0825 18:52:46.945652 27361 solver.cpp:228] Iteration 2510, loss = 0.592467
I0825 18:52:46.945699 27361 solver.cpp:244]     Train net output #0: accuracy = 0.767223
I0825 18:52:46.945708 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.17169 (* 1 = 1.17169 loss)
I0825 18:52:46.945715 27361 sgd_solver.cpp:106] Iteration 2510, lr = 7.37051e-06
I0825 18:53:08.359689 27361 solver.cpp:228] Iteration 2520, loss = 0.766974
I0825 18:53:08.359797 27361 solver.cpp:244]     Train net output #0: accuracy = 0.914303
I0825 18:53:08.359808 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.204622 (* 1 = 0.204622 loss)
I0825 18:53:08.359817 27361 sgd_solver.cpp:106] Iteration 2520, lr = 7.36316e-06
I0825 18:53:29.725409 27361 solver.cpp:228] Iteration 2530, loss = 0.686367
I0825 18:53:29.725452 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943542
I0825 18:53:29.725461 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.246886 (* 1 = 0.246886 loss)
I0825 18:53:29.725469 27361 sgd_solver.cpp:106] Iteration 2530, lr = 7.35582e-06
I0825 18:53:51.123127 27361 solver.cpp:228] Iteration 2540, loss = 0.538326
I0825 18:53:51.123231 27361 solver.cpp:244]     Train net output #0: accuracy = 0.691395
I0825 18:53:51.123241 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.61194 (* 1 = 0.61194 loss)
I0825 18:53:51.123250 27361 sgd_solver.cpp:106] Iteration 2540, lr = 7.3485e-06
I0825 18:54:12.530079 27361 solver.cpp:228] Iteration 2550, loss = 0.706098
I0825 18:54:12.530125 27361 solver.cpp:244]     Train net output #0: accuracy = 0.917488
I0825 18:54:12.530135 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.862277 (* 1 = 0.862277 loss)
I0825 18:54:12.530143 27361 sgd_solver.cpp:106] Iteration 2550, lr = 7.3412e-06
I0825 18:54:33.892426 27361 solver.cpp:228] Iteration 2560, loss = 0.660161
I0825 18:54:33.892530 27361 solver.cpp:244]     Train net output #0: accuracy = 0.81226
I0825 18:54:33.892540 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.99232 (* 1 = 0.99232 loss)
I0825 18:54:33.892547 27361 sgd_solver.cpp:106] Iteration 2560, lr = 7.33392e-06
I0825 18:54:55.256036 27361 solver.cpp:228] Iteration 2570, loss = 0.805434
I0825 18:54:55.256083 27361 solver.cpp:244]     Train net output #0: accuracy = 0.819283
I0825 18:54:55.256093 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56772 (* 1 = 1.56772 loss)
I0825 18:54:55.256100 27361 sgd_solver.cpp:106] Iteration 2570, lr = 7.32665e-06
I0825 18:55:16.622102 27361 solver.cpp:228] Iteration 2580, loss = 0.732431
I0825 18:55:16.622211 27361 solver.cpp:244]     Train net output #0: accuracy = 0.754593
I0825 18:55:16.622221 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.916786 (* 1 = 0.916786 loss)
I0825 18:55:16.622228 27361 sgd_solver.cpp:106] Iteration 2580, lr = 7.3194e-06
I0825 18:55:37.984915 27361 solver.cpp:228] Iteration 2590, loss = 0.441421
I0825 18:55:37.984964 27361 solver.cpp:244]     Train net output #0: accuracy = 0.844944
I0825 18:55:37.984973 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.462255 (* 1 = 0.462255 loss)
I0825 18:55:37.984982 27361 sgd_solver.cpp:106] Iteration 2590, lr = 7.31217e-06
I0825 18:55:57.208678 27361 solver.cpp:337] Iteration 2600, Testing net (#0)
I0825 18:56:01.362522 27361 solver.cpp:404]     Test net output #0: accuracy = 0.86291
I0825 18:56:01.362567 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.529333 (* 1 = 0.529333 loss)
I0825 18:56:03.378643 27361 solver.cpp:228] Iteration 2600, loss = 0.619548
I0825 18:56:03.378690 27361 solver.cpp:244]     Train net output #0: accuracy = 0.688019
I0825 18:56:03.378700 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.920536 (* 1 = 0.920536 loss)
I0825 18:56:03.378707 27361 sgd_solver.cpp:106] Iteration 2600, lr = 7.30495e-06
I0825 18:56:24.732903 27361 solver.cpp:228] Iteration 2610, loss = 0.565626
I0825 18:56:24.732954 27361 solver.cpp:244]     Train net output #0: accuracy = 0.89172
I0825 18:56:24.732964 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.403594 (* 1 = 0.403594 loss)
I0825 18:56:24.732971 27361 sgd_solver.cpp:106] Iteration 2610, lr = 7.29775e-06
I0825 18:56:46.139950 27361 solver.cpp:228] Iteration 2620, loss = 0.677842
I0825 18:56:46.140015 27361 solver.cpp:244]     Train net output #0: accuracy = 0.844872
I0825 18:56:46.140025 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.814091 (* 1 = 0.814091 loss)
I0825 18:56:46.140033 27361 sgd_solver.cpp:106] Iteration 2620, lr = 7.29057e-06
I0825 18:57:07.491750 27361 solver.cpp:228] Iteration 2630, loss = 0.516498
I0825 18:57:07.491797 27361 solver.cpp:244]     Train net output #0: accuracy = 0.793076
I0825 18:57:07.491806 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.710229 (* 1 = 0.710229 loss)
I0825 18:57:07.491814 27361 sgd_solver.cpp:106] Iteration 2630, lr = 7.2834e-06
I0825 18:57:28.842147 27361 solver.cpp:228] Iteration 2640, loss = 0.497251
I0825 18:57:28.842249 27361 solver.cpp:244]     Train net output #0: accuracy = 0.970352
I0825 18:57:28.842259 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0967613 (* 1 = 0.0967613 loss)
I0825 18:57:28.842267 27361 sgd_solver.cpp:106] Iteration 2640, lr = 7.27625e-06
I0825 18:57:50.282729 27361 solver.cpp:228] Iteration 2650, loss = 0.772101
I0825 18:57:50.282775 27361 solver.cpp:244]     Train net output #0: accuracy = 0.806259
I0825 18:57:50.282784 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.07854 (* 1 = 1.07854 loss)
I0825 18:57:50.282793 27361 sgd_solver.cpp:106] Iteration 2650, lr = 7.26911e-06
I0825 18:58:11.668336 27361 solver.cpp:228] Iteration 2660, loss = 0.407383
I0825 18:58:11.668406 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961262
I0825 18:58:11.668416 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0615451 (* 1 = 0.0615451 loss)
I0825 18:58:11.668426 27361 sgd_solver.cpp:106] Iteration 2660, lr = 7.26199e-06
I0825 18:58:33.029440 27361 solver.cpp:228] Iteration 2670, loss = 0.63394
I0825 18:58:33.029489 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90155
I0825 18:58:33.029497 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.583569 (* 1 = 0.583569 loss)
I0825 18:58:33.029505 27361 sgd_solver.cpp:106] Iteration 2670, lr = 7.25489e-06
I0825 18:58:54.392124 27361 solver.cpp:228] Iteration 2680, loss = 0.572881
I0825 18:58:54.392226 27361 solver.cpp:244]     Train net output #0: accuracy = 0.91695
I0825 18:58:54.392237 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.303435 (* 1 = 0.303435 loss)
I0825 18:58:54.392246 27361 sgd_solver.cpp:106] Iteration 2680, lr = 7.24781e-06
I0825 18:59:15.750372 27361 solver.cpp:228] Iteration 2690, loss = 0.682893
I0825 18:59:15.750414 27361 solver.cpp:244]     Train net output #0: accuracy = 0.867672
I0825 18:59:15.750423 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.64289 (* 1 = 0.64289 loss)
I0825 18:59:15.750430 27361 sgd_solver.cpp:106] Iteration 2690, lr = 7.24074e-06
I0825 18:59:34.974195 27361 solver.cpp:337] Iteration 2700, Testing net (#0)
I0825 18:59:39.129376 27361 solver.cpp:404]     Test net output #0: accuracy = 0.864809
I0825 18:59:39.129422 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.683842 (* 1 = 0.683842 loss)
I0825 18:59:41.146540 27361 solver.cpp:228] Iteration 2700, loss = 0.713254
I0825 18:59:41.146587 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90097
I0825 18:59:41.146602 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.763723 (* 1 = 0.763723 loss)
I0825 18:59:41.146610 27361 sgd_solver.cpp:106] Iteration 2700, lr = 7.23368e-06
I0825 19:00:02.521646 27361 solver.cpp:228] Iteration 2710, loss = 0.708849
I0825 19:00:02.521693 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949409
I0825 19:00:02.521703 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.188992 (* 1 = 0.188992 loss)
I0825 19:00:02.521710 27361 sgd_solver.cpp:106] Iteration 2710, lr = 7.22664e-06
I0825 19:00:23.874249 27361 solver.cpp:228] Iteration 2720, loss = 0.354632
I0825 19:00:23.874356 27361 solver.cpp:244]     Train net output #0: accuracy = 0.665321
I0825 19:00:23.874367 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.862213 (* 1 = 0.862213 loss)
I0825 19:00:23.874375 27361 sgd_solver.cpp:106] Iteration 2720, lr = 7.21962e-06
I0825 19:00:45.224146 27361 solver.cpp:228] Iteration 2730, loss = 0.559543
I0825 19:00:45.224192 27361 solver.cpp:244]     Train net output #0: accuracy = 0.815739
I0825 19:00:45.224201 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.365187 (* 1 = 0.365187 loss)
I0825 19:00:45.224210 27361 sgd_solver.cpp:106] Iteration 2730, lr = 7.21262e-06
I0825 19:01:06.571023 27361 solver.cpp:228] Iteration 2740, loss = 0.717227
I0825 19:01:06.571084 27361 solver.cpp:244]     Train net output #0: accuracy = 0.861412
I0825 19:01:06.571094 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.574123 (* 1 = 0.574123 loss)
I0825 19:01:06.571100 27361 sgd_solver.cpp:106] Iteration 2740, lr = 7.20563e-06
I0825 19:01:27.924080 27361 solver.cpp:228] Iteration 2750, loss = 0.653694
I0825 19:01:27.924129 27361 solver.cpp:244]     Train net output #0: accuracy = 0.775177
I0825 19:01:27.924139 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.731235 (* 1 = 0.731235 loss)
I0825 19:01:27.924146 27361 sgd_solver.cpp:106] Iteration 2750, lr = 7.19865e-06
I0825 19:01:49.278800 27361 solver.cpp:228] Iteration 2760, loss = 0.823833
I0825 19:01:49.278905 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916016
I0825 19:01:49.278916 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.233619 (* 1 = 0.233619 loss)
I0825 19:01:49.278924 27361 sgd_solver.cpp:106] Iteration 2760, lr = 7.19169e-06
I0825 19:02:10.633018 27361 solver.cpp:228] Iteration 2770, loss = 0.503692
I0825 19:02:10.633064 27361 solver.cpp:244]     Train net output #0: accuracy = 0.881737
I0825 19:02:10.633074 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.307591 (* 1 = 0.307591 loss)
I0825 19:02:10.633080 27361 sgd_solver.cpp:106] Iteration 2770, lr = 7.18475e-06
I0825 19:02:31.983240 27361 solver.cpp:228] Iteration 2780, loss = 0.473111
I0825 19:02:31.983302 27361 solver.cpp:244]     Train net output #0: accuracy = 0.841198
I0825 19:02:31.983311 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.270313 (* 1 = 0.270313 loss)
I0825 19:02:31.983319 27361 sgd_solver.cpp:106] Iteration 2780, lr = 7.17782e-06
I0825 19:02:53.330307 27361 solver.cpp:228] Iteration 2790, loss = 0.448654
I0825 19:02:53.330354 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934746
I0825 19:02:53.330364 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.151202 (* 1 = 0.151202 loss)
I0825 19:02:53.330371 27361 sgd_solver.cpp:106] Iteration 2790, lr = 7.17091e-06
I0825 19:03:12.546571 27361 solver.cpp:337] Iteration 2800, Testing net (#0)
I0825 19:03:16.704943 27361 solver.cpp:404]     Test net output #0: accuracy = 0.845017
I0825 19:03:16.704988 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.786874 (* 1 = 0.786874 loss)
I0825 19:03:18.722849 27361 solver.cpp:228] Iteration 2800, loss = 0.412273
I0825 19:03:18.722893 27361 solver.cpp:244]     Train net output #0: accuracy = 0.693802
I0825 19:03:18.722903 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.672046 (* 1 = 0.672046 loss)
I0825 19:03:18.722909 27361 sgd_solver.cpp:106] Iteration 2800, lr = 7.16402e-06
I0825 19:03:40.080241 27361 solver.cpp:228] Iteration 2810, loss = 0.626358
I0825 19:03:40.080288 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963837
I0825 19:03:40.080297 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0645353 (* 1 = 0.0645353 loss)
I0825 19:03:40.080305 27361 sgd_solver.cpp:106] Iteration 2810, lr = 7.15713e-06
I0825 19:04:01.436570 27361 solver.cpp:228] Iteration 2820, loss = 0.583634
I0825 19:04:01.436696 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926765
I0825 19:04:01.436713 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.153849 (* 1 = 0.153849 loss)
I0825 19:04:01.436722 27361 sgd_solver.cpp:106] Iteration 2820, lr = 7.15027e-06
I0825 19:04:22.796499 27361 solver.cpp:228] Iteration 2830, loss = 0.670949
I0825 19:04:22.796546 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93605
I0825 19:04:22.796556 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.359731 (* 1 = 0.359731 loss)
I0825 19:04:22.796563 27361 sgd_solver.cpp:106] Iteration 2830, lr = 7.14342e-06
I0825 19:04:44.159570 27361 solver.cpp:228] Iteration 2840, loss = 0.684623
I0825 19:04:44.159673 27361 solver.cpp:244]     Train net output #0: accuracy = 0.932232
I0825 19:04:44.159683 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.588959 (* 1 = 0.588959 loss)
I0825 19:04:44.159692 27361 sgd_solver.cpp:106] Iteration 2840, lr = 7.13659e-06
I0825 19:05:05.519588 27361 solver.cpp:228] Iteration 2850, loss = 0.771156
I0825 19:05:05.519634 27361 solver.cpp:244]     Train net output #0: accuracy = 0.870159
I0825 19:05:05.519644 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.242153 (* 1 = 0.242153 loss)
I0825 19:05:05.519651 27361 sgd_solver.cpp:106] Iteration 2850, lr = 7.12977e-06
I0825 19:05:26.878787 27361 solver.cpp:228] Iteration 2860, loss = 0.716996
I0825 19:05:26.878846 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933418
I0825 19:05:26.878855 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.24703 (* 1 = 0.24703 loss)
I0825 19:05:26.878864 27361 sgd_solver.cpp:106] Iteration 2860, lr = 7.12296e-06
I0825 19:05:48.228291 27361 solver.cpp:228] Iteration 2870, loss = 0.624496
I0825 19:05:48.228332 27361 solver.cpp:244]     Train net output #0: accuracy = 0.888271
I0825 19:05:48.228343 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.598716 (* 1 = 0.598716 loss)
I0825 19:05:48.228349 27361 sgd_solver.cpp:106] Iteration 2870, lr = 7.11617e-06
I0825 19:06:09.570783 27361 solver.cpp:228] Iteration 2880, loss = 0.729866
I0825 19:06:09.570888 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945084
I0825 19:06:09.570899 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0865342 (* 1 = 0.0865342 loss)
I0825 19:06:09.570906 27361 sgd_solver.cpp:106] Iteration 2880, lr = 7.1094e-06
I0825 19:06:30.911967 27361 solver.cpp:228] Iteration 2890, loss = 0.449569
I0825 19:06:30.912011 27361 solver.cpp:244]     Train net output #0: accuracy = 0.857544
I0825 19:06:30.912020 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.563463 (* 1 = 0.563463 loss)
I0825 19:06:30.912029 27361 sgd_solver.cpp:106] Iteration 2890, lr = 7.10264e-06
I0825 19:06:50.152976 27361 solver.cpp:337] Iteration 2900, Testing net (#0)
I0825 19:06:54.308990 27361 solver.cpp:404]     Test net output #0: accuracy = 0.850782
I0825 19:06:54.309037 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.72884 (* 1 = 0.72884 loss)
I0825 19:06:56.327087 27361 solver.cpp:228] Iteration 2900, loss = 0.631275
I0825 19:06:56.327132 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933559
I0825 19:06:56.327142 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.280249 (* 1 = 0.280249 loss)
I0825 19:06:56.327149 27361 sgd_solver.cpp:106] Iteration 2900, lr = 7.09589e-06
I0825 19:07:17.747719 27361 solver.cpp:228] Iteration 2910, loss = 0.391723
I0825 19:07:17.747761 27361 solver.cpp:244]     Train net output #0: accuracy = 0.794579
I0825 19:07:17.747771 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.501538 (* 1 = 0.501538 loss)
I0825 19:07:17.747778 27361 sgd_solver.cpp:106] Iteration 2910, lr = 7.08917e-06
I0825 19:07:39.150601 27361 solver.cpp:228] Iteration 2920, loss = 0.638567
I0825 19:07:39.150749 27361 solver.cpp:244]     Train net output #0: accuracy = 0.877975
I0825 19:07:39.150760 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.625886 (* 1 = 0.625886 loss)
I0825 19:07:39.150768 27361 sgd_solver.cpp:106] Iteration 2920, lr = 7.08245e-06
I0825 19:08:00.507858 27361 solver.cpp:228] Iteration 2930, loss = 0.427325
I0825 19:08:00.507908 27361 solver.cpp:244]     Train net output #0: accuracy = 0.946346
I0825 19:08:00.507918 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.220624 (* 1 = 0.220624 loss)
I0825 19:08:00.507925 27361 sgd_solver.cpp:106] Iteration 2930, lr = 7.07575e-06
I0825 19:08:21.867620 27361 solver.cpp:228] Iteration 2940, loss = 0.65185
I0825 19:08:21.867722 27361 solver.cpp:244]     Train net output #0: accuracy = 0.913719
I0825 19:08:21.867733 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.337628 (* 1 = 0.337628 loss)
I0825 19:08:21.867739 27361 sgd_solver.cpp:106] Iteration 2940, lr = 7.06907e-06
I0825 19:08:43.228091 27361 solver.cpp:228] Iteration 2950, loss = 0.516001
I0825 19:08:43.228129 27361 solver.cpp:244]     Train net output #0: accuracy = 0.876461
I0825 19:08:43.228138 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.824913 (* 1 = 0.824913 loss)
I0825 19:08:43.228147 27361 sgd_solver.cpp:106] Iteration 2950, lr = 7.0624e-06
I0825 19:09:04.637053 27361 solver.cpp:228] Iteration 2960, loss = 0.563296
I0825 19:09:04.637164 27361 solver.cpp:244]     Train net output #0: accuracy = 0.899029
I0825 19:09:04.637176 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.353135 (* 1 = 0.353135 loss)
I0825 19:09:04.637183 27361 sgd_solver.cpp:106] Iteration 2960, lr = 7.05574e-06
I0825 19:09:26.042935 27361 solver.cpp:228] Iteration 2970, loss = 0.484895
I0825 19:09:26.042979 27361 solver.cpp:244]     Train net output #0: accuracy = 0.901428
I0825 19:09:26.042987 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.583215 (* 1 = 0.583215 loss)
I0825 19:09:26.042994 27361 sgd_solver.cpp:106] Iteration 2970, lr = 7.0491e-06
I0825 19:09:47.400635 27361 solver.cpp:228] Iteration 2980, loss = 0.870971
I0825 19:09:47.400741 27361 solver.cpp:244]     Train net output #0: accuracy = 0.885612
I0825 19:09:47.400753 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.6998 (* 1 = 2.6998 loss)
I0825 19:09:47.400759 27361 sgd_solver.cpp:106] Iteration 2980, lr = 7.04248e-06
I0825 19:10:08.861707 27361 solver.cpp:228] Iteration 2990, loss = 1.04499
I0825 19:10:08.861753 27361 solver.cpp:244]     Train net output #0: accuracy = 0.789753
I0825 19:10:08.861763 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.931368 (* 1 = 0.931368 loss)
I0825 19:10:08.861771 27361 sgd_solver.cpp:106] Iteration 2990, lr = 7.03586e-06
I0825 19:10:28.088229 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_3000.caffemodel
I0825 19:10:28.284523 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_3000.solverstate
I0825 19:10:28.322779 27361 solver.cpp:337] Iteration 3000, Testing net (#0)
I0825 19:10:32.359329 27361 solver.cpp:404]     Test net output #0: accuracy = 0.871743
I0825 19:10:32.359375 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.64929 (* 1 = 0.64929 loss)
I0825 19:10:34.377341 27361 solver.cpp:228] Iteration 3000, loss = 0.840531
I0825 19:10:34.377385 27361 solver.cpp:244]     Train net output #0: accuracy = 0.814339
I0825 19:10:34.377395 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.505348 (* 1 = 0.505348 loss)
I0825 19:10:34.377403 27361 sgd_solver.cpp:106] Iteration 3000, lr = 7.02927e-06
I0825 19:10:55.727196 27361 solver.cpp:228] Iteration 3010, loss = 0.659919
I0825 19:10:55.727239 27361 solver.cpp:244]     Train net output #0: accuracy = 0.808346
I0825 19:10:55.727248 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.609317 (* 1 = 0.609317 loss)
I0825 19:10:55.727257 27361 sgd_solver.cpp:106] Iteration 3010, lr = 7.02268e-06
I0825 19:11:17.070585 27361 solver.cpp:228] Iteration 3020, loss = 0.764312
I0825 19:11:17.070690 27361 solver.cpp:244]     Train net output #0: accuracy = 0.806751
I0825 19:11:17.070701 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.60545 (* 1 = 0.60545 loss)
I0825 19:11:17.070709 27361 sgd_solver.cpp:106] Iteration 3020, lr = 7.01612e-06
I0825 19:11:38.436280 27361 solver.cpp:228] Iteration 3030, loss = 0.632235
I0825 19:11:38.436331 27361 solver.cpp:244]     Train net output #0: accuracy = 0.920479
I0825 19:11:38.436339 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.382718 (* 1 = 0.382718 loss)
I0825 19:11:38.436347 27361 sgd_solver.cpp:106] Iteration 3030, lr = 7.00956e-06
I0825 19:11:59.809782 27361 solver.cpp:228] Iteration 3040, loss = 0.429732
I0825 19:11:59.809895 27361 solver.cpp:244]     Train net output #0: accuracy = 0.820122
I0825 19:11:59.809906 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.395708 (* 1 = 0.395708 loss)
I0825 19:11:59.809912 27361 sgd_solver.cpp:106] Iteration 3040, lr = 7.00302e-06
I0825 19:12:21.163744 27361 solver.cpp:228] Iteration 3050, loss = 0.888105
I0825 19:12:21.163790 27361 solver.cpp:244]     Train net output #0: accuracy = 0.692619
I0825 19:12:21.163800 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.647764 (* 1 = 0.647764 loss)
I0825 19:12:21.163807 27361 sgd_solver.cpp:106] Iteration 3050, lr = 6.9965e-06
I0825 19:12:42.511574 27361 solver.cpp:228] Iteration 3060, loss = 0.487692
I0825 19:12:42.511677 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893349
I0825 19:12:42.511687 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.259147 (* 1 = 0.259147 loss)
I0825 19:12:42.511695 27361 sgd_solver.cpp:106] Iteration 3060, lr = 6.98998e-06
I0825 19:13:03.863319 27361 solver.cpp:228] Iteration 3070, loss = 0.555196
I0825 19:13:03.863366 27361 solver.cpp:244]     Train net output #0: accuracy = 0.823372
I0825 19:13:03.863375 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.586585 (* 1 = 0.586585 loss)
I0825 19:13:03.863384 27361 sgd_solver.cpp:106] Iteration 3070, lr = 6.98349e-06
I0825 19:13:25.263306 27361 solver.cpp:228] Iteration 3080, loss = 0.742965
I0825 19:13:25.263409 27361 solver.cpp:244]     Train net output #0: accuracy = 0.940468
I0825 19:13:25.263419 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0967955 (* 1 = 0.0967955 loss)
I0825 19:13:25.263427 27361 sgd_solver.cpp:106] Iteration 3080, lr = 6.977e-06
I0825 19:13:46.667213 27361 solver.cpp:228] Iteration 3090, loss = 0.54498
I0825 19:13:46.667263 27361 solver.cpp:244]     Train net output #0: accuracy = 0.88549
I0825 19:13:46.667271 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.34648 (* 1 = 0.34648 loss)
I0825 19:13:46.667279 27361 sgd_solver.cpp:106] Iteration 3090, lr = 6.97053e-06
I0825 19:14:05.884421 27361 solver.cpp:337] Iteration 3100, Testing net (#0)
I0825 19:14:10.038784 27361 solver.cpp:404]     Test net output #0: accuracy = 0.867276
I0825 19:14:10.038831 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.505013 (* 1 = 0.505013 loss)
I0825 19:14:12.056691 27361 solver.cpp:228] Iteration 3100, loss = 0.543416
I0825 19:14:12.056736 27361 solver.cpp:244]     Train net output #0: accuracy = 0.780621
I0825 19:14:12.056746 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.597515 (* 1 = 0.597515 loss)
I0825 19:14:12.056753 27361 sgd_solver.cpp:106] Iteration 3100, lr = 6.96408e-06
I0825 19:14:33.410768 27361 solver.cpp:228] Iteration 3110, loss = 0.68008
I0825 19:14:33.410820 27361 solver.cpp:244]     Train net output #0: accuracy = 0.878349
I0825 19:14:33.410828 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.64188 (* 1 = 1.64188 loss)
I0825 19:14:33.410835 27361 sgd_solver.cpp:106] Iteration 3110, lr = 6.95764e-06
I0825 19:14:54.867529 27361 solver.cpp:228] Iteration 3120, loss = 0.463152
I0825 19:14:54.867668 27361 solver.cpp:244]     Train net output #0: accuracy = 0.806961
I0825 19:14:54.867679 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.351714 (* 1 = 0.351714 loss)
I0825 19:14:54.867687 27361 sgd_solver.cpp:106] Iteration 3120, lr = 6.95121e-06
I0825 19:15:16.217572 27361 solver.cpp:228] Iteration 3130, loss = 0.611655
I0825 19:15:16.217619 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951504
I0825 19:15:16.217629 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.135093 (* 1 = 0.135093 loss)
I0825 19:15:16.217644 27361 sgd_solver.cpp:106] Iteration 3130, lr = 6.9448e-06
I0825 19:15:37.568217 27361 solver.cpp:228] Iteration 3140, loss = 0.620509
I0825 19:15:37.568317 27361 solver.cpp:244]     Train net output #0: accuracy = 0.920231
I0825 19:15:37.568327 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.296612 (* 1 = 0.296612 loss)
I0825 19:15:37.568334 27361 sgd_solver.cpp:106] Iteration 3140, lr = 6.9384e-06
I0825 19:15:58.919865 27361 solver.cpp:228] Iteration 3150, loss = 0.405471
I0825 19:15:58.919912 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945404
I0825 19:15:58.919922 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.281012 (* 1 = 0.281012 loss)
I0825 19:15:58.919929 27361 sgd_solver.cpp:106] Iteration 3150, lr = 6.93201e-06
I0825 19:16:20.311015 27361 solver.cpp:228] Iteration 3160, loss = 0.511068
I0825 19:16:20.311128 27361 solver.cpp:244]     Train net output #0: accuracy = 0.902348
I0825 19:16:20.311139 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.299869 (* 1 = 0.299869 loss)
I0825 19:16:20.311146 27361 sgd_solver.cpp:106] Iteration 3160, lr = 6.92564e-06
I0825 19:16:41.701724 27361 solver.cpp:228] Iteration 3170, loss = 0.849125
I0825 19:16:41.701771 27361 solver.cpp:244]     Train net output #0: accuracy = 0.880016
I0825 19:16:41.701779 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.509386 (* 1 = 0.509386 loss)
I0825 19:16:41.701787 27361 sgd_solver.cpp:106] Iteration 3170, lr = 6.91928e-06
I0825 19:17:03.083851 27361 solver.cpp:228] Iteration 3180, loss = 0.879352
I0825 19:17:03.083959 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950726
I0825 19:17:03.083971 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.124502 (* 1 = 0.124502 loss)
I0825 19:17:03.083977 27361 sgd_solver.cpp:106] Iteration 3180, lr = 6.91294e-06
I0825 19:17:24.482381 27361 solver.cpp:228] Iteration 3190, loss = 0.645782
I0825 19:17:24.482429 27361 solver.cpp:244]     Train net output #0: accuracy = 0.932819
I0825 19:17:24.482439 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.203269 (* 1 = 0.203269 loss)
I0825 19:17:24.482445 27361 sgd_solver.cpp:106] Iteration 3190, lr = 6.9066e-06
I0825 19:17:43.696261 27361 solver.cpp:337] Iteration 3200, Testing net (#0)
I0825 19:17:47.851446 27361 solver.cpp:404]     Test net output #0: accuracy = 0.876363
I0825 19:17:47.851488 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.549176 (* 1 = 0.549176 loss)
I0825 19:17:49.867102 27361 solver.cpp:228] Iteration 3200, loss = 0.736534
I0825 19:17:49.867146 27361 solver.cpp:244]     Train net output #0: accuracy = 0.930939
I0825 19:17:49.867156 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.270672 (* 1 = 0.270672 loss)
I0825 19:17:49.867162 27361 sgd_solver.cpp:106] Iteration 3200, lr = 6.90029e-06
I0825 19:18:11.213188 27361 solver.cpp:228] Iteration 3210, loss = 0.705214
I0825 19:18:11.213238 27361 solver.cpp:244]     Train net output #0: accuracy = 0.637539
I0825 19:18:11.213248 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.92456 (* 1 = 1.92456 loss)
I0825 19:18:11.213255 27361 sgd_solver.cpp:106] Iteration 3210, lr = 6.89398e-06
I0825 19:18:32.546069 27361 solver.cpp:228] Iteration 3220, loss = 0.576166
I0825 19:18:32.546200 27361 solver.cpp:244]     Train net output #0: accuracy = 0.828136
I0825 19:18:32.546211 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.434497 (* 1 = 0.434497 loss)
I0825 19:18:32.546218 27361 sgd_solver.cpp:106] Iteration 3220, lr = 6.88769e-06
I0825 19:18:53.881103 27361 solver.cpp:228] Iteration 3230, loss = 0.625398
I0825 19:18:53.881150 27361 solver.cpp:244]     Train net output #0: accuracy = 0.839283
I0825 19:18:53.881158 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.621152 (* 1 = 0.621152 loss)
I0825 19:18:53.881166 27361 sgd_solver.cpp:106] Iteration 3230, lr = 6.88141e-06
I0825 19:19:15.226408 27361 solver.cpp:228] Iteration 3240, loss = 0.698647
I0825 19:19:15.226491 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973579
I0825 19:19:15.226503 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0439198 (* 1 = 0.0439198 loss)
I0825 19:19:15.226511 27361 sgd_solver.cpp:106] Iteration 3240, lr = 6.87515e-06
I0825 19:19:36.571599 27361 solver.cpp:228] Iteration 3250, loss = 0.613072
I0825 19:19:36.571647 27361 solver.cpp:244]     Train net output #0: accuracy = 0.687958
I0825 19:19:36.571656 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.56754 (* 1 = 1.56754 loss)
I0825 19:19:36.571665 27361 sgd_solver.cpp:106] Iteration 3250, lr = 6.8689e-06
I0825 19:19:57.914014 27361 solver.cpp:228] Iteration 3260, loss = 0.482458
I0825 19:19:57.914116 27361 solver.cpp:244]     Train net output #0: accuracy = 0.975933
I0825 19:19:57.914126 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.105784 (* 1 = 0.105784 loss)
I0825 19:19:57.914134 27361 sgd_solver.cpp:106] Iteration 3260, lr = 6.86266e-06
I0825 19:20:19.272092 27361 solver.cpp:228] Iteration 3270, loss = 0.524871
I0825 19:20:19.272137 27361 solver.cpp:244]     Train net output #0: accuracy = 0.817337
I0825 19:20:19.272147 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.328598 (* 1 = 0.328598 loss)
I0825 19:20:19.272155 27361 sgd_solver.cpp:106] Iteration 3270, lr = 6.85643e-06
I0825 19:20:40.613437 27361 solver.cpp:228] Iteration 3280, loss = 0.464468
I0825 19:20:40.613551 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962864
I0825 19:20:40.613561 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.167324 (* 1 = 0.167324 loss)
I0825 19:20:40.613569 27361 sgd_solver.cpp:106] Iteration 3280, lr = 6.85022e-06
I0825 19:21:01.975795 27361 solver.cpp:228] Iteration 3290, loss = 0.614481
I0825 19:21:01.975841 27361 solver.cpp:244]     Train net output #0: accuracy = 0.790367
I0825 19:21:01.975852 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.74127 (* 1 = 1.74127 loss)
I0825 19:21:01.975858 27361 sgd_solver.cpp:106] Iteration 3290, lr = 6.84402e-06
I0825 19:21:21.192167 27361 solver.cpp:337] Iteration 3300, Testing net (#0)
I0825 19:21:25.348361 27361 solver.cpp:404]     Test net output #0: accuracy = 0.859452
I0825 19:21:25.348407 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.794909 (* 1 = 0.794909 loss)
I0825 19:21:27.365836 27361 solver.cpp:228] Iteration 3300, loss = 0.656311
I0825 19:21:27.365882 27361 solver.cpp:244]     Train net output #0: accuracy = 0.858486
I0825 19:21:27.365892 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.750376 (* 1 = 0.750376 loss)
I0825 19:21:27.365900 27361 sgd_solver.cpp:106] Iteration 3300, lr = 6.83784e-06
I0825 19:21:48.722007 27361 solver.cpp:228] Iteration 3310, loss = 0.781428
I0825 19:21:48.722048 27361 solver.cpp:244]     Train net output #0: accuracy = 0.825722
I0825 19:21:48.722056 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.659149 (* 1 = 0.659149 loss)
I0825 19:21:48.722064 27361 sgd_solver.cpp:106] Iteration 3310, lr = 6.83167e-06
I0825 19:22:10.078538 27361 solver.cpp:228] Iteration 3320, loss = 0.583626
I0825 19:22:10.078685 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957783
I0825 19:22:10.078696 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.279789 (* 1 = 0.279789 loss)
I0825 19:22:10.078704 27361 sgd_solver.cpp:106] Iteration 3320, lr = 6.82551e-06
I0825 19:22:31.434967 27361 solver.cpp:228] Iteration 3330, loss = 0.675013
I0825 19:22:31.435014 27361 solver.cpp:244]     Train net output #0: accuracy = 0.826313
I0825 19:22:31.435024 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.378357 (* 1 = 0.378357 loss)
I0825 19:22:31.435031 27361 sgd_solver.cpp:106] Iteration 3330, lr = 6.81936e-06
I0825 19:22:52.789800 27361 solver.cpp:228] Iteration 3340, loss = 0.411151
I0825 19:22:52.789916 27361 solver.cpp:244]     Train net output #0: accuracy = 0.805317
I0825 19:22:52.789927 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.569735 (* 1 = 0.569735 loss)
I0825 19:22:52.789935 27361 sgd_solver.cpp:106] Iteration 3340, lr = 6.81323e-06
I0825 19:23:14.142674 27361 solver.cpp:228] Iteration 3350, loss = 0.432888
I0825 19:23:14.142720 27361 solver.cpp:244]     Train net output #0: accuracy = 0.84967
I0825 19:23:14.142729 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.432621 (* 1 = 0.432621 loss)
I0825 19:23:14.142737 27361 sgd_solver.cpp:106] Iteration 3350, lr = 6.80711e-06
I0825 19:23:35.492544 27361 solver.cpp:228] Iteration 3360, loss = 0.45501
I0825 19:23:35.492648 27361 solver.cpp:244]     Train net output #0: accuracy = 0.869602
I0825 19:23:35.492658 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.781641 (* 1 = 0.781641 loss)
I0825 19:23:35.492666 27361 sgd_solver.cpp:106] Iteration 3360, lr = 6.801e-06
I0825 19:23:56.846052 27361 solver.cpp:228] Iteration 3370, loss = 0.376056
I0825 19:23:56.846099 27361 solver.cpp:244]     Train net output #0: accuracy = 0.953167
I0825 19:23:56.846109 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.19285 (* 1 = 0.19285 loss)
I0825 19:23:56.846117 27361 sgd_solver.cpp:106] Iteration 3370, lr = 6.7949e-06
I0825 19:24:18.304950 27361 solver.cpp:228] Iteration 3380, loss = 0.687997
I0825 19:24:18.305068 27361 solver.cpp:244]     Train net output #0: accuracy = 0.888927
I0825 19:24:18.305079 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.638766 (* 1 = 0.638766 loss)
I0825 19:24:18.305086 27361 sgd_solver.cpp:106] Iteration 3380, lr = 6.78882e-06
I0825 19:24:39.662369 27361 solver.cpp:228] Iteration 3390, loss = 0.817928
I0825 19:24:39.662416 27361 solver.cpp:244]     Train net output #0: accuracy = 0.811104
I0825 19:24:39.662426 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.708851 (* 1 = 0.708851 loss)
I0825 19:24:39.662433 27361 sgd_solver.cpp:106] Iteration 3390, lr = 6.78275e-06
I0825 19:24:58.933763 27361 solver.cpp:337] Iteration 3400, Testing net (#0)
I0825 19:25:03.178033 27361 solver.cpp:404]     Test net output #0: accuracy = 0.871611
I0825 19:25:03.178078 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.527194 (* 1 = 0.527194 loss)
I0825 19:25:05.194468 27361 solver.cpp:228] Iteration 3400, loss = 0.460147
I0825 19:25:05.194511 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949047
I0825 19:25:05.194520 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.155451 (* 1 = 0.155451 loss)
I0825 19:25:05.194527 27361 sgd_solver.cpp:106] Iteration 3400, lr = 6.7767e-06
I0825 19:25:26.539317 27361 solver.cpp:228] Iteration 3410, loss = 0.618213
I0825 19:25:26.539366 27361 solver.cpp:244]     Train net output #0: accuracy = 0.897152
I0825 19:25:26.539374 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.260999 (* 1 = 0.260999 loss)
I0825 19:25:26.539381 27361 sgd_solver.cpp:106] Iteration 3410, lr = 6.77065e-06
I0825 19:25:48.027631 27361 solver.cpp:228] Iteration 3420, loss = 0.386084
I0825 19:25:48.027752 27361 solver.cpp:244]     Train net output #0: accuracy = 0.871185
I0825 19:25:48.027762 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.207721 (* 1 = 0.207721 loss)
I0825 19:25:48.027770 27361 sgd_solver.cpp:106] Iteration 3420, lr = 6.76462e-06
I0825 19:26:09.426426 27361 solver.cpp:228] Iteration 3430, loss = 0.313956
I0825 19:26:09.426475 27361 solver.cpp:244]     Train net output #0: accuracy = 0.80114
I0825 19:26:09.426487 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.456669 (* 1 = 0.456669 loss)
I0825 19:26:09.426498 27361 sgd_solver.cpp:106] Iteration 3430, lr = 6.7586e-06
I0825 19:26:30.827148 27361 solver.cpp:228] Iteration 3440, loss = 0.634996
I0825 19:26:30.827291 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954124
I0825 19:26:30.827302 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.204025 (* 1 = 0.204025 loss)
I0825 19:26:30.827311 27361 sgd_solver.cpp:106] Iteration 3440, lr = 6.75259e-06
I0825 19:26:52.175457 27361 solver.cpp:228] Iteration 3450, loss = 0.640859
I0825 19:26:52.175505 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939461
I0825 19:26:52.175523 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.253744 (* 1 = 0.253744 loss)
I0825 19:26:52.175530 27361 sgd_solver.cpp:106] Iteration 3450, lr = 6.7466e-06
I0825 19:27:13.672787 27361 solver.cpp:228] Iteration 3460, loss = 0.498804
I0825 19:27:13.672897 27361 solver.cpp:244]     Train net output #0: accuracy = 0.959995
I0825 19:27:13.672909 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.1696 (* 1 = 0.1696 loss)
I0825 19:27:13.672915 27361 sgd_solver.cpp:106] Iteration 3460, lr = 6.74062e-06
I0825 19:27:35.028735 27361 solver.cpp:228] Iteration 3470, loss = 0.636773
I0825 19:27:35.028784 27361 solver.cpp:244]     Train net output #0: accuracy = 0.908546
I0825 19:27:35.028792 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.380221 (* 1 = 0.380221 loss)
I0825 19:27:35.028800 27361 sgd_solver.cpp:106] Iteration 3470, lr = 6.73465e-06
I0825 19:27:56.382568 27361 solver.cpp:228] Iteration 3480, loss = 1.51125
I0825 19:27:56.382735 27361 solver.cpp:244]     Train net output #0: accuracy = 0.807785
I0825 19:27:56.382747 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.368952 (* 1 = 0.368952 loss)
I0825 19:27:56.382755 27361 sgd_solver.cpp:106] Iteration 3480, lr = 6.72869e-06
I0825 19:28:17.736729 27361 solver.cpp:228] Iteration 3490, loss = 0.417275
I0825 19:28:17.736771 27361 solver.cpp:244]     Train net output #0: accuracy = 0.914101
I0825 19:28:17.736781 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.288481 (* 1 = 0.288481 loss)
I0825 19:28:17.736789 27361 sgd_solver.cpp:106] Iteration 3490, lr = 6.72275e-06
I0825 19:28:36.952219 27361 solver.cpp:337] Iteration 3500, Testing net (#0)
I0825 19:28:41.103193 27361 solver.cpp:404]     Test net output #0: accuracy = 0.900133
I0825 19:28:41.103240 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.603884 (* 1 = 0.603884 loss)
I0825 19:28:43.119519 27361 solver.cpp:228] Iteration 3500, loss = 0.587244
I0825 19:28:43.119565 27361 solver.cpp:244]     Train net output #0: accuracy = 0.924141
I0825 19:28:43.119573 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.252863 (* 1 = 0.252863 loss)
I0825 19:28:43.119580 27361 sgd_solver.cpp:106] Iteration 3500, lr = 6.71681e-06
I0825 19:29:04.567828 27361 solver.cpp:228] Iteration 3510, loss = 0.436771
I0825 19:29:04.567874 27361 solver.cpp:244]     Train net output #0: accuracy = 0.97057
I0825 19:29:04.567884 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0535289 (* 1 = 0.0535289 loss)
I0825 19:29:04.567891 27361 sgd_solver.cpp:106] Iteration 3510, lr = 6.71089e-06
I0825 19:29:25.915479 27361 solver.cpp:228] Iteration 3520, loss = 0.604012
I0825 19:29:25.915593 27361 solver.cpp:244]     Train net output #0: accuracy = 0.814438
I0825 19:29:25.915604 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.903156 (* 1 = 0.903156 loss)
I0825 19:29:25.915612 27361 sgd_solver.cpp:106] Iteration 3520, lr = 6.70498e-06
I0825 19:29:47.258931 27361 solver.cpp:228] Iteration 3530, loss = 0.836064
I0825 19:29:47.258980 27361 solver.cpp:244]     Train net output #0: accuracy = 0.705986
I0825 19:29:47.258991 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.703446 (* 1 = 0.703446 loss)
I0825 19:29:47.258997 27361 sgd_solver.cpp:106] Iteration 3530, lr = 6.69909e-06
I0825 19:30:08.614418 27361 solver.cpp:228] Iteration 3540, loss = 0.912741
I0825 19:30:08.614558 27361 solver.cpp:244]     Train net output #0: accuracy = 0.750126
I0825 19:30:08.614569 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.855738 (* 1 = 0.855738 loss)
I0825 19:30:08.614576 27361 sgd_solver.cpp:106] Iteration 3540, lr = 6.6932e-06
I0825 19:30:29.959260 27361 solver.cpp:228] Iteration 3550, loss = 0.62023
I0825 19:30:29.959306 27361 solver.cpp:244]     Train net output #0: accuracy = 0.838348
I0825 19:30:29.959314 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.839432 (* 1 = 0.839432 loss)
I0825 19:30:29.959322 27361 sgd_solver.cpp:106] Iteration 3550, lr = 6.68733e-06
I0825 19:30:51.303647 27361 solver.cpp:228] Iteration 3560, loss = 0.839794
I0825 19:30:51.303761 27361 solver.cpp:244]     Train net output #0: accuracy = 0.898109
I0825 19:30:51.303772 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.414437 (* 1 = 0.414437 loss)
I0825 19:30:51.303779 27361 sgd_solver.cpp:106] Iteration 3560, lr = 6.68147e-06
I0825 19:31:12.647362 27361 solver.cpp:228] Iteration 3570, loss = 0.544828
I0825 19:31:12.647409 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923149
I0825 19:31:12.647419 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.336173 (* 1 = 0.336173 loss)
I0825 19:31:12.647426 27361 sgd_solver.cpp:106] Iteration 3570, lr = 6.67562e-06
I0825 19:31:33.986771 27361 solver.cpp:228] Iteration 3580, loss = 0.585172
I0825 19:31:33.986873 27361 solver.cpp:244]     Train net output #0: accuracy = 0.760941
I0825 19:31:33.986883 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.874785 (* 1 = 0.874785 loss)
I0825 19:31:33.986891 27361 sgd_solver.cpp:106] Iteration 3580, lr = 6.66979e-06
I0825 19:31:55.327877 27361 solver.cpp:228] Iteration 3590, loss = 0.754251
I0825 19:31:55.327924 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961197
I0825 19:31:55.327932 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.173736 (* 1 = 0.173736 loss)
I0825 19:31:55.327939 27361 sgd_solver.cpp:106] Iteration 3590, lr = 6.66396e-06
I0825 19:32:14.538949 27361 solver.cpp:337] Iteration 3600, Testing net (#0)
I0825 19:32:18.691049 27361 solver.cpp:404]     Test net output #0: accuracy = 0.881544
I0825 19:32:18.691094 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.582814 (* 1 = 0.582814 loss)
I0825 19:32:20.708029 27361 solver.cpp:228] Iteration 3600, loss = 0.555486
I0825 19:32:20.708075 27361 solver.cpp:244]     Train net output #0: accuracy = 0.865452
I0825 19:32:20.708083 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.75803 (* 1 = 0.75803 loss)
I0825 19:32:20.708091 27361 sgd_solver.cpp:106] Iteration 3600, lr = 6.65815e-06
I0825 19:32:42.056577 27361 solver.cpp:228] Iteration 3610, loss = 0.465076
I0825 19:32:42.056622 27361 solver.cpp:244]     Train net output #0: accuracy = 0.947559
I0825 19:32:42.056632 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.299831 (* 1 = 0.299831 loss)
I0825 19:32:42.056638 27361 sgd_solver.cpp:106] Iteration 3610, lr = 6.65235e-06
I0825 19:33:03.411082 27361 solver.cpp:228] Iteration 3620, loss = 0.725667
I0825 19:33:03.411183 27361 solver.cpp:244]     Train net output #0: accuracy = 0.909004
I0825 19:33:03.411195 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.681328 (* 1 = 0.681328 loss)
I0825 19:33:03.411202 27361 sgd_solver.cpp:106] Iteration 3620, lr = 6.64656e-06
I0825 19:33:24.863824 27361 solver.cpp:228] Iteration 3630, loss = 0.358133
I0825 19:33:24.863865 27361 solver.cpp:244]     Train net output #0: accuracy = 0.89782
I0825 19:33:24.863875 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.247525 (* 1 = 0.247525 loss)
I0825 19:33:24.863883 27361 sgd_solver.cpp:106] Iteration 3630, lr = 6.64078e-06
I0825 19:33:46.220553 27361 solver.cpp:228] Iteration 3640, loss = 0.933312
I0825 19:33:46.220659 27361 solver.cpp:244]     Train net output #0: accuracy = 0.88546
I0825 19:33:46.220670 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.493 (* 1 = 0.493 loss)
I0825 19:33:46.220677 27361 sgd_solver.cpp:106] Iteration 3640, lr = 6.63502e-06
I0825 19:34:07.610122 27361 solver.cpp:228] Iteration 3650, loss = 1.05323
I0825 19:34:07.610168 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868694
I0825 19:34:07.610177 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.9141 (* 1 = 0.9141 loss)
I0825 19:34:07.610185 27361 sgd_solver.cpp:106] Iteration 3650, lr = 6.62927e-06
I0825 19:34:28.963222 27361 solver.cpp:228] Iteration 3660, loss = 0.621292
I0825 19:34:28.963342 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935272
I0825 19:34:28.963353 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.165887 (* 1 = 0.165887 loss)
I0825 19:34:28.963367 27361 sgd_solver.cpp:106] Iteration 3660, lr = 6.62352e-06
I0825 19:34:50.318969 27361 solver.cpp:228] Iteration 3670, loss = 0.362102
I0825 19:34:50.319016 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93425
I0825 19:34:50.319026 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.457679 (* 1 = 0.457679 loss)
I0825 19:34:50.319033 27361 sgd_solver.cpp:106] Iteration 3670, lr = 6.61779e-06
I0825 19:35:11.777113 27361 solver.cpp:228] Iteration 3680, loss = 0.59063
I0825 19:35:11.777221 27361 solver.cpp:244]     Train net output #0: accuracy = 0.861084
I0825 19:35:11.777231 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.899275 (* 1 = 0.899275 loss)
I0825 19:35:11.777240 27361 sgd_solver.cpp:106] Iteration 3680, lr = 6.61207e-06
I0825 19:35:33.130156 27361 solver.cpp:228] Iteration 3690, loss = 0.644638
I0825 19:35:33.130203 27361 solver.cpp:244]     Train net output #0: accuracy = 0.878086
I0825 19:35:33.130213 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.77763 (* 1 = 0.77763 loss)
I0825 19:35:33.130219 27361 sgd_solver.cpp:106] Iteration 3690, lr = 6.60637e-06
I0825 19:35:52.351436 27361 solver.cpp:337] Iteration 3700, Testing net (#0)
I0825 19:35:56.502429 27361 solver.cpp:404]     Test net output #0: accuracy = 0.889631
I0825 19:35:56.502473 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.620985 (* 1 = 0.620985 loss)
I0825 19:35:58.519902 27361 solver.cpp:228] Iteration 3700, loss = 0.718261
I0825 19:35:58.519945 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934994
I0825 19:35:58.519955 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.539413 (* 1 = 0.539413 loss)
I0825 19:35:58.519963 27361 sgd_solver.cpp:106] Iteration 3700, lr = 6.60067e-06
I0825 19:36:19.869603 27361 solver.cpp:228] Iteration 3710, loss = 0.379712
I0825 19:36:19.869652 27361 solver.cpp:244]     Train net output #0: accuracy = 0.851746
I0825 19:36:19.869660 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.299697 (* 1 = 0.299697 loss)
I0825 19:36:19.869668 27361 sgd_solver.cpp:106] Iteration 3710, lr = 6.59499e-06
I0825 19:36:41.301990 27361 solver.cpp:228] Iteration 3720, loss = 0.603918
I0825 19:36:41.302096 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963131
I0825 19:36:41.302108 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.231212 (* 1 = 0.231212 loss)
I0825 19:36:41.302114 27361 sgd_solver.cpp:106] Iteration 3720, lr = 6.58931e-06
I0825 19:37:02.637323 27361 solver.cpp:228] Iteration 3730, loss = 0.762131
I0825 19:37:02.637372 27361 solver.cpp:244]     Train net output #0: accuracy = 0.701332
I0825 19:37:02.637382 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.868149 (* 1 = 0.868149 loss)
I0825 19:37:02.637388 27361 sgd_solver.cpp:106] Iteration 3730, lr = 6.58365e-06
I0825 19:37:24.010540 27361 solver.cpp:228] Iteration 3740, loss = 0.657814
I0825 19:37:24.010684 27361 solver.cpp:244]     Train net output #0: accuracy = 0.936455
I0825 19:37:24.010695 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.382045 (* 1 = 0.382045 loss)
I0825 19:37:24.010704 27361 sgd_solver.cpp:106] Iteration 3740, lr = 6.578e-06
I0825 19:37:45.366991 27361 solver.cpp:228] Iteration 3750, loss = 0.508831
I0825 19:37:45.367038 27361 solver.cpp:244]     Train net output #0: accuracy = 0.826191
I0825 19:37:45.367046 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.494594 (* 1 = 0.494594 loss)
I0825 19:37:45.367054 27361 sgd_solver.cpp:106] Iteration 3750, lr = 6.57236e-06
I0825 19:38:06.719538 27361 solver.cpp:228] Iteration 3760, loss = 0.626909
I0825 19:38:06.719643 27361 solver.cpp:244]     Train net output #0: accuracy = 0.982521
I0825 19:38:06.719655 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0801192 (* 1 = 0.0801192 loss)
I0825 19:38:06.719661 27361 sgd_solver.cpp:106] Iteration 3760, lr = 6.56673e-06
I0825 19:38:28.123602 27361 solver.cpp:228] Iteration 3770, loss = 0.67677
I0825 19:38:28.123651 27361 solver.cpp:244]     Train net output #0: accuracy = 0.853462
I0825 19:38:28.123669 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.23111 (* 1 = 1.23111 loss)
I0825 19:38:28.123682 27361 sgd_solver.cpp:106] Iteration 3770, lr = 6.56112e-06
I0825 19:38:49.510740 27361 solver.cpp:228] Iteration 3780, loss = 0.448608
I0825 19:38:49.510845 27361 solver.cpp:244]     Train net output #0: accuracy = 0.967525
I0825 19:38:49.510856 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0988668 (* 1 = 0.0988668 loss)
I0825 19:38:49.510864 27361 sgd_solver.cpp:106] Iteration 3780, lr = 6.55551e-06
I0825 19:39:10.863205 27361 solver.cpp:228] Iteration 3790, loss = 0.421026
I0825 19:39:10.863250 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942616
I0825 19:39:10.863260 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.330723 (* 1 = 0.330723 loss)
I0825 19:39:10.863267 27361 sgd_solver.cpp:106] Iteration 3790, lr = 6.54992e-06
I0825 19:39:30.079669 27361 solver.cpp:337] Iteration 3800, Testing net (#0)
I0825 19:39:34.233135 27361 solver.cpp:404]     Test net output #0: accuracy = 0.875724
I0825 19:39:34.233180 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.725556 (* 1 = 0.725556 loss)
I0825 19:39:36.248927 27361 solver.cpp:228] Iteration 3800, loss = 0.620728
I0825 19:39:36.248973 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912994
I0825 19:39:36.248983 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.287874 (* 1 = 0.287874 loss)
I0825 19:39:36.248991 27361 sgd_solver.cpp:106] Iteration 3800, lr = 6.54433e-06
I0825 19:39:57.597048 27361 solver.cpp:228] Iteration 3810, loss = 0.428659
I0825 19:39:57.597097 27361 solver.cpp:244]     Train net output #0: accuracy = 1
I0825 19:39:57.597107 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.00192932 (* 1 = 0.00192932 loss)
I0825 19:39:57.597115 27361 sgd_solver.cpp:106] Iteration 3810, lr = 6.53876e-06
I0825 19:40:18.939898 27361 solver.cpp:228] Iteration 3820, loss = 0.716142
I0825 19:40:18.940011 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961239
I0825 19:40:18.940021 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.181928 (* 1 = 0.181928 loss)
I0825 19:40:18.940029 27361 sgd_solver.cpp:106] Iteration 3820, lr = 6.5332e-06
I0825 19:40:40.270154 27361 solver.cpp:228] Iteration 3830, loss = 0.711255
I0825 19:40:40.270200 27361 solver.cpp:244]     Train net output #0: accuracy = 0.860901
I0825 19:40:40.270210 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.909422 (* 1 = 0.909422 loss)
I0825 19:40:40.270216 27361 sgd_solver.cpp:106] Iteration 3830, lr = 6.52765e-06
I0825 19:41:01.599071 27361 solver.cpp:228] Iteration 3840, loss = 0.568408
I0825 19:41:01.599175 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927685
I0825 19:41:01.599186 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.306745 (* 1 = 0.306745 loss)
I0825 19:41:01.599194 27361 sgd_solver.cpp:106] Iteration 3840, lr = 6.52211e-06
I0825 19:41:22.968065 27361 solver.cpp:228] Iteration 3850, loss = 0.713335
I0825 19:41:22.968111 27361 solver.cpp:244]     Train net output #0: accuracy = 0.904957
I0825 19:41:22.968122 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.487167 (* 1 = 0.487167 loss)
I0825 19:41:22.968128 27361 sgd_solver.cpp:106] Iteration 3850, lr = 6.51658e-06
I0825 19:41:44.313861 27361 solver.cpp:228] Iteration 3860, loss = 0.817011
I0825 19:41:44.313968 27361 solver.cpp:244]     Train net output #0: accuracy = 0.773647
I0825 19:41:44.313980 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.45015 (* 1 = 1.45015 loss)
I0825 19:41:44.313987 27361 sgd_solver.cpp:106] Iteration 3860, lr = 6.51107e-06
I0825 19:42:05.704913 27361 solver.cpp:228] Iteration 3870, loss = 0.448608
I0825 19:42:05.704958 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962029
I0825 19:42:05.704968 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.311979 (* 1 = 0.311979 loss)
I0825 19:42:05.704975 27361 sgd_solver.cpp:106] Iteration 3870, lr = 6.50556e-06
I0825 19:42:27.043341 27361 solver.cpp:228] Iteration 3880, loss = 0.282126
I0825 19:42:27.043452 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934307
I0825 19:42:27.043462 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.28338 (* 1 = 0.28338 loss)
I0825 19:42:27.043468 27361 sgd_solver.cpp:106] Iteration 3880, lr = 6.50007e-06
I0825 19:42:48.440399 27361 solver.cpp:228] Iteration 3890, loss = 1.05727
I0825 19:42:48.440448 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916527
I0825 19:42:48.440457 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.491661 (* 1 = 0.491661 loss)
I0825 19:42:48.440464 27361 sgd_solver.cpp:106] Iteration 3890, lr = 6.49458e-06
I0825 19:43:07.653336 27361 solver.cpp:337] Iteration 3900, Testing net (#0)
I0825 19:43:11.807893 27361 solver.cpp:404]     Test net output #0: accuracy = 0.875852
I0825 19:43:11.807939 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.611016 (* 1 = 0.611016 loss)
I0825 19:43:13.824585 27361 solver.cpp:228] Iteration 3900, loss = 0.370798
I0825 19:43:13.824633 27361 solver.cpp:244]     Train net output #0: accuracy = 0.750271
I0825 19:43:13.824643 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.550546 (* 1 = 0.550546 loss)
I0825 19:43:13.824651 27361 sgd_solver.cpp:106] Iteration 3900, lr = 6.48911e-06
I0825 19:43:35.227525 27361 solver.cpp:228] Iteration 3910, loss = 0.728556
I0825 19:43:35.227571 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950794
I0825 19:43:35.227581 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.638197 (* 1 = 0.638197 loss)
I0825 19:43:35.227588 27361 sgd_solver.cpp:106] Iteration 3910, lr = 6.48364e-06
I0825 19:43:56.627761 27361 solver.cpp:228] Iteration 3920, loss = 0.465264
I0825 19:43:56.627871 27361 solver.cpp:244]     Train net output #0: accuracy = 0.885456
I0825 19:43:56.627882 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.547523 (* 1 = 0.547523 loss)
I0825 19:43:56.627889 27361 sgd_solver.cpp:106] Iteration 3920, lr = 6.47819e-06
I0825 19:44:17.981946 27361 solver.cpp:228] Iteration 3930, loss = 0.716965
I0825 19:44:17.981993 27361 solver.cpp:244]     Train net output #0: accuracy = 0.808964
I0825 19:44:17.982002 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.22484 (* 1 = 1.22484 loss)
I0825 19:44:17.982010 27361 sgd_solver.cpp:106] Iteration 3930, lr = 6.47275e-06
I0825 19:44:39.334357 27361 solver.cpp:228] Iteration 3940, loss = 0.447202
I0825 19:44:39.334471 27361 solver.cpp:244]     Train net output #0: accuracy = 0.884296
I0825 19:44:39.334481 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.586291 (* 1 = 0.586291 loss)
I0825 19:44:39.334489 27361 sgd_solver.cpp:106] Iteration 3940, lr = 6.46732e-06
I0825 19:45:00.689393 27361 solver.cpp:228] Iteration 3950, loss = 0.323381
I0825 19:45:00.689441 27361 solver.cpp:244]     Train net output #0: accuracy = 0.975872
I0825 19:45:00.689452 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0369769 (* 1 = 0.0369769 loss)
I0825 19:45:00.689460 27361 sgd_solver.cpp:106] Iteration 3950, lr = 6.4619e-06
I0825 19:45:22.042034 27361 solver.cpp:228] Iteration 3960, loss = 0.510468
I0825 19:45:22.042163 27361 solver.cpp:244]     Train net output #0: accuracy = 0.815845
I0825 19:45:22.042174 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.76935 (* 1 = 1.76935 loss)
I0825 19:45:22.042181 27361 sgd_solver.cpp:106] Iteration 3960, lr = 6.45649e-06
I0825 19:45:43.393497 27361 solver.cpp:228] Iteration 3970, loss = 0.497581
I0825 19:45:43.393545 27361 solver.cpp:244]     Train net output #0: accuracy = 0.860214
I0825 19:45:43.393555 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.536861 (* 1 = 0.536861 loss)
I0825 19:45:43.393563 27361 sgd_solver.cpp:106] Iteration 3970, lr = 6.45109e-06
I0825 19:46:04.746013 27361 solver.cpp:228] Iteration 3980, loss = 0.780606
I0825 19:46:04.746125 27361 solver.cpp:244]     Train net output #0: accuracy = 0.77879
I0825 19:46:04.746136 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.448877 (* 1 = 0.448877 loss)
I0825 19:46:04.746150 27361 sgd_solver.cpp:106] Iteration 3980, lr = 6.4457e-06
I0825 19:46:26.099473 27361 solver.cpp:228] Iteration 3990, loss = 0.464565
I0825 19:46:26.099519 27361 solver.cpp:244]     Train net output #0: accuracy = 0.825993
I0825 19:46:26.099529 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.6393 (* 1 = 1.6393 loss)
I0825 19:46:26.099535 27361 sgd_solver.cpp:106] Iteration 3990, lr = 6.44032e-06
I0825 19:46:45.316375 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_4000.caffemodel
I0825 19:46:45.510301 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_4000.solverstate
I0825 19:46:45.547801 27361 solver.cpp:337] Iteration 4000, Testing net (#0)
I0825 19:46:49.586343 27361 solver.cpp:404]     Test net output #0: accuracy = 0.862741
I0825 19:46:49.586386 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.648196 (* 1 = 0.648196 loss)
I0825 19:46:51.602576 27361 solver.cpp:228] Iteration 4000, loss = 0.368196
I0825 19:46:51.602625 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921291
I0825 19:46:51.602635 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.287097 (* 1 = 0.287097 loss)
I0825 19:46:51.602643 27361 sgd_solver.cpp:106] Iteration 4000, lr = 6.43496e-06
I0825 19:47:12.948884 27361 solver.cpp:228] Iteration 4010, loss = 0.549466
I0825 19:47:12.948931 27361 solver.cpp:244]     Train net output #0: accuracy = 0.898533
I0825 19:47:12.948941 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.335399 (* 1 = 0.335399 loss)
I0825 19:47:12.948950 27361 sgd_solver.cpp:106] Iteration 4010, lr = 6.4296e-06
I0825 19:47:34.299156 27361 solver.cpp:228] Iteration 4020, loss = 0.425787
I0825 19:47:34.299258 27361 solver.cpp:244]     Train net output #0: accuracy = 0.914726
I0825 19:47:34.299268 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.638907 (* 1 = 0.638907 loss)
I0825 19:47:34.299276 27361 sgd_solver.cpp:106] Iteration 4020, lr = 6.42425e-06
I0825 19:47:55.647169 27361 solver.cpp:228] Iteration 4030, loss = 0.528968
I0825 19:47:55.647217 27361 solver.cpp:244]     Train net output #0: accuracy = 0.877331
I0825 19:47:55.647228 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.416446 (* 1 = 0.416446 loss)
I0825 19:47:55.647234 27361 sgd_solver.cpp:106] Iteration 4030, lr = 6.41892e-06
I0825 19:48:16.998425 27361 solver.cpp:228] Iteration 4040, loss = 0.443293
I0825 19:48:16.998538 27361 solver.cpp:244]     Train net output #0: accuracy = 0.832447
I0825 19:48:16.998549 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.341641 (* 1 = 0.341641 loss)
I0825 19:48:16.998558 27361 sgd_solver.cpp:106] Iteration 4040, lr = 6.41359e-06
I0825 19:48:38.350585 27361 solver.cpp:228] Iteration 4050, loss = 0.437409
I0825 19:48:38.350636 27361 solver.cpp:244]     Train net output #0: accuracy = 0.838577
I0825 19:48:38.350646 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.65745 (* 1 = 0.65745 loss)
I0825 19:48:38.350653 27361 sgd_solver.cpp:106] Iteration 4050, lr = 6.40827e-06
I0825 19:48:59.700989 27361 solver.cpp:228] Iteration 4060, loss = 0.922635
I0825 19:48:59.701128 27361 solver.cpp:244]     Train net output #0: accuracy = 0.880249
I0825 19:48:59.701139 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.866206 (* 1 = 0.866206 loss)
I0825 19:48:59.701148 27361 sgd_solver.cpp:106] Iteration 4060, lr = 6.40297e-06
I0825 19:49:21.051640 27361 solver.cpp:228] Iteration 4070, loss = 0.668654
I0825 19:49:21.051688 27361 solver.cpp:244]     Train net output #0: accuracy = 0.964954
I0825 19:49:21.051698 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.124749 (* 1 = 0.124749 loss)
I0825 19:49:21.051707 27361 sgd_solver.cpp:106] Iteration 4070, lr = 6.39767e-06
I0825 19:49:42.401131 27361 solver.cpp:228] Iteration 4080, loss = 0.602727
I0825 19:49:42.401252 27361 solver.cpp:244]     Train net output #0: accuracy = 0.752346
I0825 19:49:42.401263 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.01156 (* 1 = 1.01156 loss)
I0825 19:49:42.401278 27361 sgd_solver.cpp:106] Iteration 4080, lr = 6.39239e-06
I0825 19:50:03.850018 27361 solver.cpp:228] Iteration 4090, loss = 0.696127
I0825 19:50:03.850064 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910889
I0825 19:50:03.850072 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.654291 (* 1 = 0.654291 loss)
I0825 19:50:03.850080 27361 sgd_solver.cpp:106] Iteration 4090, lr = 6.38711e-06
I0825 19:50:23.115548 27361 solver.cpp:337] Iteration 4100, Testing net (#0)
I0825 19:50:27.269294 27361 solver.cpp:404]     Test net output #0: accuracy = 0.873276
I0825 19:50:27.269341 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.732928 (* 1 = 0.732928 loss)
I0825 19:50:29.284494 27361 solver.cpp:228] Iteration 4100, loss = 0.79965
I0825 19:50:29.284538 27361 solver.cpp:244]     Train net output #0: accuracy = 0.878998
I0825 19:50:29.284548 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.482922 (* 1 = 0.482922 loss)
I0825 19:50:29.284555 27361 sgd_solver.cpp:106] Iteration 4100, lr = 6.38185e-06
I0825 19:50:50.626811 27361 solver.cpp:228] Iteration 4110, loss = 0.835853
I0825 19:50:50.626859 27361 solver.cpp:244]     Train net output #0: accuracy = 0.896008
I0825 19:50:50.626868 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.608505 (* 1 = 0.608505 loss)
I0825 19:50:50.626876 27361 sgd_solver.cpp:106] Iteration 4110, lr = 6.37659e-06
I0825 19:51:11.971667 27361 solver.cpp:228] Iteration 4120, loss = 0.652153
I0825 19:51:11.971778 27361 solver.cpp:244]     Train net output #0: accuracy = 0.890831
I0825 19:51:11.971788 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.947735 (* 1 = 0.947735 loss)
I0825 19:51:11.971796 27361 sgd_solver.cpp:106] Iteration 4120, lr = 6.37135e-06
I0825 19:51:33.313298 27361 solver.cpp:228] Iteration 4130, loss = 0.481047
I0825 19:51:33.313346 27361 solver.cpp:244]     Train net output #0: accuracy = 0.89653
I0825 19:51:33.313355 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.338075 (* 1 = 0.338075 loss)
I0825 19:51:33.313362 27361 sgd_solver.cpp:106] Iteration 4130, lr = 6.36611e-06
I0825 19:51:54.659019 27361 solver.cpp:228] Iteration 4140, loss = 0.571749
I0825 19:51:54.659128 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942501
I0825 19:51:54.659139 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.244067 (* 1 = 0.244067 loss)
I0825 19:51:54.659147 27361 sgd_solver.cpp:106] Iteration 4140, lr = 6.36089e-06
I0825 19:52:16.002688 27361 solver.cpp:228] Iteration 4150, loss = 0.590895
I0825 19:52:16.002735 27361 solver.cpp:244]     Train net output #0: accuracy = 0.837971
I0825 19:52:16.002745 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.4415 (* 1 = 1.4415 loss)
I0825 19:52:16.002753 27361 sgd_solver.cpp:106] Iteration 4150, lr = 6.35567e-06
I0825 19:52:37.348155 27361 solver.cpp:228] Iteration 4160, loss = 0.610747
I0825 19:52:37.348299 27361 solver.cpp:244]     Train net output #0: accuracy = 0.801804
I0825 19:52:37.348310 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.46179 (* 1 = 1.46179 loss)
I0825 19:52:37.348317 27361 sgd_solver.cpp:106] Iteration 4160, lr = 6.35047e-06
I0825 19:52:58.691411 27361 solver.cpp:228] Iteration 4170, loss = 0.842106
I0825 19:52:58.691459 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956688
I0825 19:52:58.691468 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.247385 (* 1 = 0.247385 loss)
I0825 19:52:58.691476 27361 sgd_solver.cpp:106] Iteration 4170, lr = 6.34528e-06
I0825 19:53:20.037271 27361 solver.cpp:228] Iteration 4180, loss = 0.48484
I0825 19:53:20.037334 27361 solver.cpp:244]     Train net output #0: accuracy = 0.876392
I0825 19:53:20.037343 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.318247 (* 1 = 0.318247 loss)
I0825 19:53:20.037351 27361 sgd_solver.cpp:106] Iteration 4180, lr = 6.34009e-06
I0825 19:53:41.383266 27361 solver.cpp:228] Iteration 4190, loss = 0.574316
I0825 19:53:41.383322 27361 solver.cpp:244]     Train net output #0: accuracy = 0.900974
I0825 19:53:41.383332 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.513332 (* 1 = 0.513332 loss)
I0825 19:53:41.383339 27361 sgd_solver.cpp:106] Iteration 4190, lr = 6.33492e-06
I0825 19:54:00.596659 27361 solver.cpp:337] Iteration 4200, Testing net (#0)
I0825 19:54:04.750614 27361 solver.cpp:404]     Test net output #0: accuracy = 0.891296
I0825 19:54:04.750658 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.658978 (* 1 = 0.658978 loss)
I0825 19:54:06.767261 27361 solver.cpp:228] Iteration 4200, loss = 0.519753
I0825 19:54:06.767302 27361 solver.cpp:244]     Train net output #0: accuracy = 0.899162
I0825 19:54:06.767310 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.339166 (* 1 = 0.339166 loss)
I0825 19:54:06.767318 27361 sgd_solver.cpp:106] Iteration 4200, lr = 6.32975e-06
I0825 19:54:28.117074 27361 solver.cpp:228] Iteration 4210, loss = 0.835327
I0825 19:54:28.117122 27361 solver.cpp:244]     Train net output #0: accuracy = 0.913559
I0825 19:54:28.117132 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.637754 (* 1 = 0.637754 loss)
I0825 19:54:28.117139 27361 sgd_solver.cpp:106] Iteration 4210, lr = 6.3246e-06
I0825 19:54:49.470036 27361 solver.cpp:228] Iteration 4220, loss = 1.00272
I0825 19:54:49.470144 27361 solver.cpp:244]     Train net output #0: accuracy = 0.777298
I0825 19:54:49.470155 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.683913 (* 1 = 0.683913 loss)
I0825 19:54:49.470162 27361 sgd_solver.cpp:106] Iteration 4220, lr = 6.31945e-06
I0825 19:55:10.821880 27361 solver.cpp:228] Iteration 4230, loss = 0.635927
I0825 19:55:10.821926 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93119
I0825 19:55:10.821936 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.305265 (* 1 = 0.305265 loss)
I0825 19:55:10.821943 27361 sgd_solver.cpp:106] Iteration 4230, lr = 6.31431e-06
I0825 19:55:32.169476 27361 solver.cpp:228] Iteration 4240, loss = 0.652731
I0825 19:55:32.169584 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961956
I0825 19:55:32.169595 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.117666 (* 1 = 0.117666 loss)
I0825 19:55:32.169602 27361 sgd_solver.cpp:106] Iteration 4240, lr = 6.30919e-06
I0825 19:55:53.520831 27361 solver.cpp:228] Iteration 4250, loss = 1.00048
I0825 19:55:53.520879 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95364
I0825 19:55:53.520889 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.16609 (* 1 = 0.16609 loss)
I0825 19:55:53.520897 27361 sgd_solver.cpp:106] Iteration 4250, lr = 6.30407e-06
I0825 19:56:14.927639 27361 solver.cpp:228] Iteration 4260, loss = 0.646277
I0825 19:56:14.927742 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961212
I0825 19:56:14.927752 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.159074 (* 1 = 0.159074 loss)
I0825 19:56:14.927759 27361 sgd_solver.cpp:106] Iteration 4260, lr = 6.29897e-06
I0825 19:56:36.337693 27361 solver.cpp:228] Iteration 4270, loss = 0.443071
I0825 19:56:36.337739 27361 solver.cpp:244]     Train net output #0: accuracy = 0.913979
I0825 19:56:36.337749 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.559041 (* 1 = 0.559041 loss)
I0825 19:56:36.337756 27361 sgd_solver.cpp:106] Iteration 4270, lr = 6.29387e-06
I0825 19:56:57.690199 27361 solver.cpp:228] Iteration 4280, loss = 0.703997
I0825 19:56:57.690309 27361 solver.cpp:244]     Train net output #0: accuracy = 0.863766
I0825 19:56:57.690320 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.604518 (* 1 = 0.604518 loss)
I0825 19:56:57.690328 27361 sgd_solver.cpp:106] Iteration 4280, lr = 6.28878e-06
I0825 19:57:19.091840 27361 solver.cpp:228] Iteration 4290, loss = 0.544175
I0825 19:57:19.091889 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927006
I0825 19:57:19.091898 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.292921 (* 1 = 0.292921 loss)
I0825 19:57:19.091914 27361 sgd_solver.cpp:106] Iteration 4290, lr = 6.2837e-06
I0825 19:57:38.405218 27361 solver.cpp:337] Iteration 4300, Testing net (#0)
I0825 19:57:42.556835 27361 solver.cpp:404]     Test net output #0: accuracy = 0.88849
I0825 19:57:42.556879 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.605251 (* 1 = 0.605251 loss)
I0825 19:57:44.573057 27361 solver.cpp:228] Iteration 4300, loss = 0.609759
I0825 19:57:44.573102 27361 solver.cpp:244]     Train net output #0: accuracy = 0.915791
I0825 19:57:44.573112 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.1726 (* 1 = 0.1726 loss)
I0825 19:57:44.573118 27361 sgd_solver.cpp:106] Iteration 4300, lr = 6.27864e-06
I0825 19:58:06.017738 27361 solver.cpp:228] Iteration 4310, loss = 1.03951
I0825 19:58:06.017793 27361 solver.cpp:244]     Train net output #0: accuracy = 1
I0825 19:58:06.017805 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.00138095 (* 1 = 0.00138095 loss)
I0825 19:58:06.017813 27361 sgd_solver.cpp:106] Iteration 4310, lr = 6.27358e-06
I0825 19:58:27.363700 27361 solver.cpp:228] Iteration 4320, loss = 0.389559
I0825 19:58:27.363803 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949512
I0825 19:58:27.363814 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.219234 (* 1 = 0.219234 loss)
I0825 19:58:27.363821 27361 sgd_solver.cpp:106] Iteration 4320, lr = 6.26853e-06
I0825 19:58:48.709584 27361 solver.cpp:228] Iteration 4330, loss = 0.431937
I0825 19:58:48.709631 27361 solver.cpp:244]     Train net output #0: accuracy = 0.925301
I0825 19:58:48.709641 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.320937 (* 1 = 0.320937 loss)
I0825 19:58:48.709648 27361 sgd_solver.cpp:106] Iteration 4330, lr = 6.26349e-06
I0825 19:59:10.108340 27361 solver.cpp:228] Iteration 4340, loss = 0.930568
I0825 19:59:10.108445 27361 solver.cpp:244]     Train net output #0: accuracy = 0.853077
I0825 19:59:10.108455 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.32979 (* 1 = 1.32979 loss)
I0825 19:59:10.108464 27361 sgd_solver.cpp:106] Iteration 4340, lr = 6.25846e-06
I0825 19:59:31.457739 27361 solver.cpp:228] Iteration 4350, loss = 0.703358
I0825 19:59:31.457788 27361 solver.cpp:244]     Train net output #0: accuracy = 0.924942
I0825 19:59:31.457798 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.5666 (* 1 = 0.5666 loss)
I0825 19:59:31.457805 27361 sgd_solver.cpp:106] Iteration 4350, lr = 6.25344e-06
I0825 19:59:52.809180 27361 solver.cpp:228] Iteration 4360, loss = 0.541821
I0825 19:59:52.809238 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928932
I0825 19:59:52.809248 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.158448 (* 1 = 0.158448 loss)
I0825 19:59:52.809255 27361 sgd_solver.cpp:106] Iteration 4360, lr = 6.24843e-06
I0825 20:00:14.155632 27361 solver.cpp:228] Iteration 4370, loss = 0.443566
I0825 20:00:14.155681 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962662
I0825 20:00:14.155690 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0953329 (* 1 = 0.0953329 loss)
I0825 20:00:14.155699 27361 sgd_solver.cpp:106] Iteration 4370, lr = 6.24342e-06
I0825 20:00:35.503834 27361 solver.cpp:228] Iteration 4380, loss = 0.519092
I0825 20:00:35.503988 27361 solver.cpp:244]     Train net output #0: accuracy = 0.837616
I0825 20:00:35.503999 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.348826 (* 1 = 0.348826 loss)
I0825 20:00:35.504007 27361 sgd_solver.cpp:106] Iteration 4380, lr = 6.23843e-06
I0825 20:00:56.888659 27361 solver.cpp:228] Iteration 4390, loss = 0.935952
I0825 20:00:56.888707 27361 solver.cpp:244]     Train net output #0: accuracy = 0.900749
I0825 20:00:56.888716 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.532134 (* 1 = 0.532134 loss)
I0825 20:00:56.888725 27361 sgd_solver.cpp:106] Iteration 4390, lr = 6.23345e-06
I0825 20:01:16.105183 27361 solver.cpp:337] Iteration 4400, Testing net (#0)
I0825 20:01:20.262100 27361 solver.cpp:404]     Test net output #0: accuracy = 0.866266
I0825 20:01:20.262153 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.61158 (* 1 = 0.61158 loss)
I0825 20:01:22.278559 27361 solver.cpp:228] Iteration 4400, loss = 0.833511
I0825 20:01:22.278609 27361 solver.cpp:244]     Train net output #0: accuracy = 0.816772
I0825 20:01:22.278619 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.674038 (* 1 = 0.674038 loss)
I0825 20:01:22.278625 27361 sgd_solver.cpp:106] Iteration 4400, lr = 6.22847e-06
I0825 20:01:43.622324 27361 solver.cpp:228] Iteration 4410, loss = 0.46606
I0825 20:01:43.622371 27361 solver.cpp:244]     Train net output #0: accuracy = 0.909538
I0825 20:01:43.622380 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.282045 (* 1 = 0.282045 loss)
I0825 20:01:43.622387 27361 sgd_solver.cpp:106] Iteration 4410, lr = 6.22351e-06
I0825 20:02:04.964192 27361 solver.cpp:228] Iteration 4420, loss = 0.594777
I0825 20:02:04.964305 27361 solver.cpp:244]     Train net output #0: accuracy = 0.857719
I0825 20:02:04.964315 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.910343 (* 1 = 0.910343 loss)
I0825 20:02:04.964323 27361 sgd_solver.cpp:106] Iteration 4420, lr = 6.21855e-06
I0825 20:02:26.355083 27361 solver.cpp:228] Iteration 4430, loss = 0.968942
I0825 20:02:26.355134 27361 solver.cpp:244]     Train net output #0: accuracy = 0.888851
I0825 20:02:26.355142 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.382647 (* 1 = 0.382647 loss)
I0825 20:02:26.355150 27361 sgd_solver.cpp:106] Iteration 4430, lr = 6.21361e-06
I0825 20:02:47.747015 27361 solver.cpp:228] Iteration 4440, loss = 0.711694
I0825 20:02:47.747117 27361 solver.cpp:244]     Train net output #0: accuracy = 0.938911
I0825 20:02:47.747128 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.327806 (* 1 = 0.327806 loss)
I0825 20:02:47.747135 27361 sgd_solver.cpp:106] Iteration 4440, lr = 6.20867e-06
I0825 20:03:09.091794 27361 solver.cpp:228] Iteration 4450, loss = 0.678982
I0825 20:03:09.091841 27361 solver.cpp:244]     Train net output #0: accuracy = 0.925213
I0825 20:03:09.091850 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.358427 (* 1 = 0.358427 loss)
I0825 20:03:09.091858 27361 sgd_solver.cpp:106] Iteration 4450, lr = 6.20374e-06
I0825 20:03:30.432695 27361 solver.cpp:228] Iteration 4460, loss = 0.546569
I0825 20:03:30.432796 27361 solver.cpp:244]     Train net output #0: accuracy = 0.885971
I0825 20:03:30.432806 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.337309 (* 1 = 0.337309 loss)
I0825 20:03:30.432814 27361 sgd_solver.cpp:106] Iteration 4460, lr = 6.19882e-06
I0825 20:03:51.772253 27361 solver.cpp:228] Iteration 4470, loss = 0.741724
I0825 20:03:51.772296 27361 solver.cpp:244]     Train net output #0: accuracy = 0.908287
I0825 20:03:51.772306 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.616551 (* 1 = 0.616551 loss)
I0825 20:03:51.772313 27361 sgd_solver.cpp:106] Iteration 4470, lr = 6.19391e-06
I0825 20:04:13.113193 27361 solver.cpp:228] Iteration 4480, loss = 0.44581
I0825 20:04:13.113323 27361 solver.cpp:244]     Train net output #0: accuracy = 0.836216
I0825 20:04:13.113335 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.25345 (* 1 = 1.25345 loss)
I0825 20:04:13.113343 27361 sgd_solver.cpp:106] Iteration 4480, lr = 6.18901e-06
I0825 20:04:34.459118 27361 solver.cpp:228] Iteration 4490, loss = 0.45928
I0825 20:04:34.459164 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910992
I0825 20:04:34.459173 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.174696 (* 1 = 0.174696 loss)
I0825 20:04:34.459182 27361 sgd_solver.cpp:106] Iteration 4490, lr = 6.18412e-06
I0825 20:04:53.669378 27361 solver.cpp:337] Iteration 4500, Testing net (#0)
I0825 20:04:57.821496 27361 solver.cpp:404]     Test net output #0: accuracy = 0.8859
I0825 20:04:57.821540 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.568676 (* 1 = 0.568676 loss)
I0825 20:04:59.837925 27361 solver.cpp:228] Iteration 4500, loss = 0.505886
I0825 20:04:59.837972 27361 solver.cpp:244]     Train net output #0: accuracy = 0.783806
I0825 20:04:59.837991 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.27556 (* 1 = 1.27556 loss)
I0825 20:04:59.837999 27361 sgd_solver.cpp:106] Iteration 4500, lr = 6.17924e-06
I0825 20:05:21.192512 27361 solver.cpp:228] Iteration 4510, loss = 0.628395
I0825 20:05:21.192561 27361 solver.cpp:244]     Train net output #0: accuracy = 0.733112
I0825 20:05:21.192570 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.978638 (* 1 = 0.978638 loss)
I0825 20:05:21.192579 27361 sgd_solver.cpp:106] Iteration 4510, lr = 6.17436e-06
I0825 20:05:42.543375 27361 solver.cpp:228] Iteration 4520, loss = 0.525128
I0825 20:05:42.543483 27361 solver.cpp:244]     Train net output #0: accuracy = 0.83041
I0825 20:05:42.543493 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.78445 (* 1 = 0.78445 loss)
I0825 20:05:42.543500 27361 sgd_solver.cpp:106] Iteration 4520, lr = 6.1695e-06
I0825 20:06:03.890574 27361 solver.cpp:228] Iteration 4530, loss = 0.608038
I0825 20:06:03.890625 27361 solver.cpp:244]     Train net output #0: accuracy = 0.91378
I0825 20:06:03.890635 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.853665 (* 1 = 0.853665 loss)
I0825 20:06:03.890642 27361 sgd_solver.cpp:106] Iteration 4530, lr = 6.16464e-06
I0825 20:06:25.255411 27361 solver.cpp:228] Iteration 4540, loss = 0.420198
I0825 20:06:25.255517 27361 solver.cpp:244]     Train net output #0: accuracy = 0.862377
I0825 20:06:25.255527 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.640573 (* 1 = 0.640573 loss)
I0825 20:06:25.255533 27361 sgd_solver.cpp:106] Iteration 4540, lr = 6.15979e-06
I0825 20:06:46.655213 27361 solver.cpp:228] Iteration 4550, loss = 0.668553
I0825 20:06:46.655261 27361 solver.cpp:244]     Train net output #0: accuracy = 0.882576
I0825 20:06:46.655272 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.703046 (* 1 = 0.703046 loss)
I0825 20:06:46.655278 27361 sgd_solver.cpp:106] Iteration 4550, lr = 6.15496e-06
I0825 20:07:08.002710 27361 solver.cpp:228] Iteration 4560, loss = 0.457837
I0825 20:07:08.002816 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942909
I0825 20:07:08.002827 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.264845 (* 1 = 0.264845 loss)
I0825 20:07:08.002835 27361 sgd_solver.cpp:106] Iteration 4560, lr = 6.15013e-06
I0825 20:07:29.349441 27361 solver.cpp:228] Iteration 4570, loss = 0.398883
I0825 20:07:29.349489 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950829
I0825 20:07:29.349503 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.288178 (* 1 = 0.288178 loss)
I0825 20:07:29.349511 27361 sgd_solver.cpp:106] Iteration 4570, lr = 6.14531e-06
I0825 20:07:50.702682 27361 solver.cpp:228] Iteration 4580, loss = 0.9016
I0825 20:07:50.702783 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912514
I0825 20:07:50.702795 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.616874 (* 1 = 0.616874 loss)
I0825 20:07:50.702801 27361 sgd_solver.cpp:106] Iteration 4580, lr = 6.14049e-06
I0825 20:08:12.048193 27361 solver.cpp:228] Iteration 4590, loss = 0.401599
I0825 20:08:12.048238 27361 solver.cpp:244]     Train net output #0: accuracy = 0.969421
I0825 20:08:12.048247 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.255744 (* 1 = 0.255744 loss)
I0825 20:08:12.048255 27361 sgd_solver.cpp:106] Iteration 4590, lr = 6.13569e-06
I0825 20:08:31.265215 27361 solver.cpp:337] Iteration 4600, Testing net (#0)
I0825 20:08:35.419809 27361 solver.cpp:404]     Test net output #0: accuracy = 0.896705
I0825 20:08:35.419857 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.7065 (* 1 = 0.7065 loss)
I0825 20:08:37.436208 27361 solver.cpp:228] Iteration 4600, loss = 0.381756
I0825 20:08:37.436252 27361 solver.cpp:244]     Train net output #0: accuracy = 0.972095
I0825 20:08:37.436261 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.195443 (* 1 = 0.195443 loss)
I0825 20:08:37.436269 27361 sgd_solver.cpp:106] Iteration 4600, lr = 6.1309e-06
I0825 20:08:58.783773 27361 solver.cpp:228] Iteration 4610, loss = 0.330098
I0825 20:08:58.783815 27361 solver.cpp:244]     Train net output #0: accuracy = 0.946186
I0825 20:08:58.783824 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.249063 (* 1 = 0.249063 loss)
I0825 20:08:58.783831 27361 sgd_solver.cpp:106] Iteration 4610, lr = 6.12611e-06
I0825 20:09:20.131165 27361 solver.cpp:228] Iteration 4620, loss = 0.661239
I0825 20:09:20.131273 27361 solver.cpp:244]     Train net output #0: accuracy = 0.901733
I0825 20:09:20.131283 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.261168 (* 1 = 0.261168 loss)
I0825 20:09:20.131290 27361 sgd_solver.cpp:106] Iteration 4620, lr = 6.12134e-06
I0825 20:09:41.514678 27361 solver.cpp:228] Iteration 4630, loss = 0.428611
I0825 20:09:41.514729 27361 solver.cpp:244]     Train net output #0: accuracy = 0.885395
I0825 20:09:41.514737 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.484408 (* 1 = 0.484408 loss)
I0825 20:09:41.514744 27361 sgd_solver.cpp:106] Iteration 4630, lr = 6.11657e-06
I0825 20:10:02.861264 27361 solver.cpp:228] Iteration 4640, loss = 0.524661
I0825 20:10:02.861376 27361 solver.cpp:244]     Train net output #0: accuracy = 0.856293
I0825 20:10:02.861385 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.743891 (* 1 = 0.743891 loss)
I0825 20:10:02.861393 27361 sgd_solver.cpp:106] Iteration 4640, lr = 6.11181e-06
I0825 20:10:24.209331 27361 solver.cpp:228] Iteration 4650, loss = 0.469813
I0825 20:10:24.209378 27361 solver.cpp:244]     Train net output #0: accuracy = 0.958771
I0825 20:10:24.209388 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.263774 (* 1 = 0.263774 loss)
I0825 20:10:24.209395 27361 sgd_solver.cpp:106] Iteration 4650, lr = 6.10706e-06
I0825 20:10:45.553827 27361 solver.cpp:228] Iteration 4660, loss = 0.526039
I0825 20:10:45.553885 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910683
I0825 20:10:45.553895 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.376013 (* 1 = 0.376013 loss)
I0825 20:10:45.553903 27361 sgd_solver.cpp:106] Iteration 4660, lr = 6.10232e-06
I0825 20:11:06.906654 27361 solver.cpp:228] Iteration 4670, loss = 0.382272
I0825 20:11:06.906703 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939529
I0825 20:11:06.906713 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.262443 (* 1 = 0.262443 loss)
I0825 20:11:06.906720 27361 sgd_solver.cpp:106] Iteration 4670, lr = 6.09758e-06
I0825 20:11:28.256531 27361 solver.cpp:228] Iteration 4680, loss = 1.06641
I0825 20:11:28.256639 27361 solver.cpp:244]     Train net output #0: accuracy = 0.773537
I0825 20:11:28.256649 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.49995 (* 1 = 2.49995 loss)
I0825 20:11:28.256657 27361 sgd_solver.cpp:106] Iteration 4680, lr = 6.09286e-06
I0825 20:11:49.603443 27361 solver.cpp:228] Iteration 4690, loss = 0.527811
I0825 20:11:49.603490 27361 solver.cpp:244]     Train net output #0: accuracy = 0.834869
I0825 20:11:49.603499 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.773556 (* 1 = 0.773556 loss)
I0825 20:11:49.603507 27361 sgd_solver.cpp:106] Iteration 4690, lr = 6.08814e-06
I0825 20:12:08.819411 27361 solver.cpp:337] Iteration 4700, Testing net (#0)
I0825 20:12:12.973116 27361 solver.cpp:404]     Test net output #0: accuracy = 0.881412
I0825 20:12:12.973162 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.716504 (* 1 = 0.716504 loss)
I0825 20:12:14.989015 27361 solver.cpp:228] Iteration 4700, loss = 0.373248
I0825 20:12:14.989060 27361 solver.cpp:244]     Train net output #0: accuracy = 0.837307
I0825 20:12:14.989070 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.671759 (* 1 = 0.671759 loss)
I0825 20:12:14.989078 27361 sgd_solver.cpp:106] Iteration 4700, lr = 6.08343e-06
I0825 20:12:36.325906 27361 solver.cpp:228] Iteration 4710, loss = 0.635387
I0825 20:12:36.325953 27361 solver.cpp:244]     Train net output #0: accuracy = 0.852772
I0825 20:12:36.325963 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.659694 (* 1 = 0.659694 loss)
I0825 20:12:36.325979 27361 sgd_solver.cpp:106] Iteration 4710, lr = 6.07873e-06
I0825 20:12:57.669698 27361 solver.cpp:228] Iteration 4720, loss = 0.662511
I0825 20:12:57.669806 27361 solver.cpp:244]     Train net output #0: accuracy = 0.752445
I0825 20:12:57.669816 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.01786 (* 1 = 1.01786 loss)
I0825 20:12:57.669824 27361 sgd_solver.cpp:106] Iteration 4720, lr = 6.07404e-06
I0825 20:13:19.012712 27361 solver.cpp:228] Iteration 4730, loss = 0.729205
I0825 20:13:19.012758 27361 solver.cpp:244]     Train net output #0: accuracy = 0.765385
I0825 20:13:19.012768 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.52006 (* 1 = 2.52006 loss)
I0825 20:13:19.012774 27361 sgd_solver.cpp:106] Iteration 4730, lr = 6.06936e-06
I0825 20:13:40.371876 27361 solver.cpp:228] Iteration 4740, loss = 0.680229
I0825 20:13:40.371986 27361 solver.cpp:244]     Train net output #0: accuracy = 0.972332
I0825 20:13:40.371999 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.056268 (* 1 = 0.056268 loss)
I0825 20:13:40.372006 27361 sgd_solver.cpp:106] Iteration 4740, lr = 6.06469e-06
I0825 20:14:01.709064 27361 solver.cpp:228] Iteration 4750, loss = 0.402852
I0825 20:14:01.709112 27361 solver.cpp:244]     Train net output #0: accuracy = 0.901539
I0825 20:14:01.709122 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.403648 (* 1 = 0.403648 loss)
I0825 20:14:01.709130 27361 sgd_solver.cpp:106] Iteration 4750, lr = 6.06002e-06
I0825 20:14:23.049818 27361 solver.cpp:228] Iteration 4760, loss = 0.639169
I0825 20:14:23.049921 27361 solver.cpp:244]     Train net output #0: accuracy = 0.874439
I0825 20:14:23.049932 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.190239 (* 1 = 0.190239 loss)
I0825 20:14:23.049939 27361 sgd_solver.cpp:106] Iteration 4760, lr = 6.05536e-06
I0825 20:14:44.390282 27361 solver.cpp:228] Iteration 4770, loss = 0.583047
I0825 20:14:44.390327 27361 solver.cpp:244]     Train net output #0: accuracy = 0.96508
I0825 20:14:44.390336 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.522261 (* 1 = 0.522261 loss)
I0825 20:14:44.390344 27361 sgd_solver.cpp:106] Iteration 4770, lr = 6.05071e-06
I0825 20:15:05.784070 27361 solver.cpp:228] Iteration 4780, loss = 0.33197
I0825 20:15:05.784174 27361 solver.cpp:244]     Train net output #0: accuracy = 0.913597
I0825 20:15:05.784184 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.304557 (* 1 = 0.304557 loss)
I0825 20:15:05.784193 27361 sgd_solver.cpp:106] Iteration 4780, lr = 6.04607e-06
I0825 20:15:27.117136 27361 solver.cpp:228] Iteration 4790, loss = 0.487902
I0825 20:15:27.117185 27361 solver.cpp:244]     Train net output #0: accuracy = 0.974697
I0825 20:15:27.117195 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0785435 (* 1 = 0.0785435 loss)
I0825 20:15:27.117202 27361 sgd_solver.cpp:106] Iteration 4790, lr = 6.04144e-06
I0825 20:15:46.374236 27361 solver.cpp:337] Iteration 4800, Testing net (#0)
I0825 20:15:50.525049 27361 solver.cpp:404]     Test net output #0: accuracy = 0.896379
I0825 20:15:50.525094 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.530167 (* 1 = 0.530167 loss)
I0825 20:15:52.540285 27361 solver.cpp:228] Iteration 4800, loss = 0.383301
I0825 20:15:52.540329 27361 solver.cpp:244]     Train net output #0: accuracy = 0.922798
I0825 20:15:52.540339 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.185676 (* 1 = 0.185676 loss)
I0825 20:15:52.540346 27361 sgd_solver.cpp:106] Iteration 4800, lr = 6.03682e-06
I0825 20:16:13.884033 27361 solver.cpp:228] Iteration 4810, loss = 0.632156
I0825 20:16:13.884081 27361 solver.cpp:244]     Train net output #0: accuracy = 0.964478
I0825 20:16:13.884091 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.189163 (* 1 = 0.189163 loss)
I0825 20:16:13.884099 27361 sgd_solver.cpp:106] Iteration 4810, lr = 6.0322e-06
I0825 20:16:35.229887 27361 solver.cpp:228] Iteration 4820, loss = 0.786643
I0825 20:16:35.229954 27361 solver.cpp:244]     Train net output #0: accuracy = 0.891998
I0825 20:16:35.229964 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.714445 (* 1 = 0.714445 loss)
I0825 20:16:35.229971 27361 sgd_solver.cpp:106] Iteration 4820, lr = 6.02759e-06
I0825 20:16:56.573295 27361 solver.cpp:228] Iteration 4830, loss = 0.353382
I0825 20:16:56.573343 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87888
I0825 20:16:56.573353 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.36358 (* 1 = 0.36358 loss)
I0825 20:16:56.573360 27361 sgd_solver.cpp:106] Iteration 4830, lr = 6.02299e-06
I0825 20:17:17.917232 27361 solver.cpp:228] Iteration 4840, loss = 0.566604
I0825 20:17:17.917338 27361 solver.cpp:244]     Train net output #0: accuracy = 0.877609
I0825 20:17:17.917349 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.713015 (* 1 = 0.713015 loss)
I0825 20:17:17.917356 27361 sgd_solver.cpp:106] Iteration 4840, lr = 6.0184e-06
I0825 20:17:39.268663 27361 solver.cpp:228] Iteration 4850, loss = 0.642153
I0825 20:17:39.268710 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912659
I0825 20:17:39.268719 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.03686 (* 1 = 1.03686 loss)
I0825 20:17:39.268728 27361 sgd_solver.cpp:106] Iteration 4850, lr = 6.01382e-06
I0825 20:18:00.612882 27361 solver.cpp:228] Iteration 4860, loss = 1.0702
I0825 20:18:00.612941 27361 solver.cpp:244]     Train net output #0: accuracy = 0.879276
I0825 20:18:00.612951 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.619342 (* 1 = 0.619342 loss)
I0825 20:18:00.612959 27361 sgd_solver.cpp:106] Iteration 4860, lr = 6.00924e-06
I0825 20:18:21.959642 27361 solver.cpp:228] Iteration 4870, loss = 0.601483
I0825 20:18:21.959692 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923916
I0825 20:18:21.959702 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.80354 (* 1 = 0.80354 loss)
I0825 20:18:21.959708 27361 sgd_solver.cpp:106] Iteration 4870, lr = 6.00468e-06
I0825 20:18:43.304700 27361 solver.cpp:228] Iteration 4880, loss = 0.673941
I0825 20:18:43.304813 27361 solver.cpp:244]     Train net output #0: accuracy = 0.900322
I0825 20:18:43.304824 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.919468 (* 1 = 0.919468 loss)
I0825 20:18:43.304832 27361 sgd_solver.cpp:106] Iteration 4880, lr = 6.00012e-06
I0825 20:19:04.636672 27361 solver.cpp:228] Iteration 4890, loss = 0.34672
I0825 20:19:04.636718 27361 solver.cpp:244]     Train net output #0: accuracy = 0.914474
I0825 20:19:04.636729 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.223431 (* 1 = 0.223431 loss)
I0825 20:19:04.636735 27361 sgd_solver.cpp:106] Iteration 4890, lr = 5.99557e-06
I0825 20:19:23.872139 27361 solver.cpp:337] Iteration 4900, Testing net (#0)
I0825 20:19:28.024438 27361 solver.cpp:404]     Test net output #0: accuracy = 0.903941
I0825 20:19:28.024484 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.512607 (* 1 = 0.512607 loss)
I0825 20:19:30.040899 27361 solver.cpp:228] Iteration 4900, loss = 0.58156
I0825 20:19:30.040943 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87009
I0825 20:19:30.040953 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.67332 (* 1 = 0.67332 loss)
I0825 20:19:30.040959 27361 sgd_solver.cpp:106] Iteration 4900, lr = 5.99102e-06
I0825 20:19:51.425976 27361 solver.cpp:228] Iteration 4910, loss = 0.512722
I0825 20:19:51.426023 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929478
I0825 20:19:51.426033 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.157519 (* 1 = 0.157519 loss)
I0825 20:19:51.426040 27361 sgd_solver.cpp:106] Iteration 4910, lr = 5.98649e-06
I0825 20:20:12.817728 27361 solver.cpp:228] Iteration 4920, loss = 0.775956
I0825 20:20:12.817867 27361 solver.cpp:244]     Train net output #0: accuracy = 0.940876
I0825 20:20:12.817879 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.211702 (* 1 = 0.211702 loss)
I0825 20:20:12.817890 27361 sgd_solver.cpp:106] Iteration 4920, lr = 5.98196e-06
I0825 20:20:34.165819 27361 solver.cpp:228] Iteration 4930, loss = 0.509759
I0825 20:20:34.165868 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893948
I0825 20:20:34.165877 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.215772 (* 1 = 0.215772 loss)
I0825 20:20:34.165884 27361 sgd_solver.cpp:106] Iteration 4930, lr = 5.97744e-06
I0825 20:20:55.508667 27361 solver.cpp:228] Iteration 4940, loss = 0.525784
I0825 20:20:55.508776 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889988
I0825 20:20:55.508786 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.455731 (* 1 = 0.455731 loss)
I0825 20:20:55.508793 27361 sgd_solver.cpp:106] Iteration 4940, lr = 5.97293e-06
I0825 20:21:16.851615 27361 solver.cpp:228] Iteration 4950, loss = 0.524192
I0825 20:21:16.851660 27361 solver.cpp:244]     Train net output #0: accuracy = 0.887978
I0825 20:21:16.851670 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.669863 (* 1 = 0.669863 loss)
I0825 20:21:16.851676 27361 sgd_solver.cpp:106] Iteration 4950, lr = 5.96843e-06
I0825 20:21:38.241245 27361 solver.cpp:228] Iteration 4960, loss = 0.677079
I0825 20:21:38.241350 27361 solver.cpp:244]     Train net output #0: accuracy = 0.807632
I0825 20:21:38.241361 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.2947 (* 1 = 1.2947 loss)
I0825 20:21:38.241369 27361 sgd_solver.cpp:106] Iteration 4960, lr = 5.96394e-06
I0825 20:21:59.576725 27361 solver.cpp:228] Iteration 4970, loss = 0.466078
I0825 20:21:59.576772 27361 solver.cpp:244]     Train net output #0: accuracy = 0.887722
I0825 20:21:59.576781 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.335466 (* 1 = 0.335466 loss)
I0825 20:21:59.576789 27361 sgd_solver.cpp:106] Iteration 4970, lr = 5.95945e-06
I0825 20:22:20.911306 27361 solver.cpp:228] Iteration 4980, loss = 0.474981
I0825 20:22:20.911411 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934776
I0825 20:22:20.911420 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.579558 (* 1 = 0.579558 loss)
I0825 20:22:20.911428 27361 sgd_solver.cpp:106] Iteration 4980, lr = 5.95497e-06
I0825 20:22:42.248801 27361 solver.cpp:228] Iteration 4990, loss = 0.706979
I0825 20:22:42.248847 27361 solver.cpp:244]     Train net output #0: accuracy = 0.922573
I0825 20:22:42.248857 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.204649 (* 1 = 0.204649 loss)
I0825 20:22:42.248863 27361 sgd_solver.cpp:106] Iteration 4990, lr = 5.9505e-06
I0825 20:23:01.509232 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_5000.caffemodel
I0825 20:23:01.704773 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_5000.solverstate
I0825 20:23:01.743154 27361 solver.cpp:337] Iteration 5000, Testing net (#0)
I0825 20:23:05.779877 27361 solver.cpp:404]     Test net output #0: accuracy = 0.887145
I0825 20:23:05.779919 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.626943 (* 1 = 0.626943 loss)
I0825 20:23:07.795730 27361 solver.cpp:228] Iteration 5000, loss = 0.794497
I0825 20:23:07.795773 27361 solver.cpp:244]     Train net output #0: accuracy = 0.879036
I0825 20:23:07.795783 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.388076 (* 1 = 0.388076 loss)
I0825 20:23:07.795790 27361 sgd_solver.cpp:106] Iteration 5000, lr = 5.94604e-06
I0825 20:23:29.131235 27361 solver.cpp:228] Iteration 5010, loss = 0.563768
I0825 20:23:29.131283 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966293
I0825 20:23:29.131292 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.136623 (* 1 = 0.136623 loss)
I0825 20:23:29.131300 27361 sgd_solver.cpp:106] Iteration 5010, lr = 5.94158e-06
I0825 20:23:50.467058 27361 solver.cpp:228] Iteration 5020, loss = 0.297948
I0825 20:23:50.467195 27361 solver.cpp:244]     Train net output #0: accuracy = 0.885704
I0825 20:23:50.467206 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.404794 (* 1 = 0.404794 loss)
I0825 20:23:50.467216 27361 sgd_solver.cpp:106] Iteration 5020, lr = 5.93713e-06
I0825 20:24:11.904062 27361 solver.cpp:228] Iteration 5030, loss = 0.608994
I0825 20:24:11.904108 27361 solver.cpp:244]     Train net output #0: accuracy = 0.876034
I0825 20:24:11.904117 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.570199 (* 1 = 0.570199 loss)
I0825 20:24:11.904124 27361 sgd_solver.cpp:106] Iteration 5030, lr = 5.93269e-06
I0825 20:24:33.239655 27361 solver.cpp:228] Iteration 5040, loss = 0.432161
I0825 20:24:33.239717 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910797
I0825 20:24:33.239727 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.40446 (* 1 = 1.40446 loss)
I0825 20:24:33.239734 27361 sgd_solver.cpp:106] Iteration 5040, lr = 5.92826e-06
I0825 20:24:54.576944 27361 solver.cpp:228] Iteration 5050, loss = 0.567328
I0825 20:24:54.576992 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93663
I0825 20:24:54.577002 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.284451 (* 1 = 0.284451 loss)
I0825 20:24:54.577008 27361 sgd_solver.cpp:106] Iteration 5050, lr = 5.92384e-06
I0825 20:25:15.913254 27361 solver.cpp:228] Iteration 5060, loss = 0.581801
I0825 20:25:15.913352 27361 solver.cpp:244]     Train net output #0: accuracy = 0.82663
I0825 20:25:15.913362 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.90801 (* 1 = 0.90801 loss)
I0825 20:25:15.913370 27361 sgd_solver.cpp:106] Iteration 5060, lr = 5.91942e-06
I0825 20:25:37.249912 27361 solver.cpp:228] Iteration 5070, loss = 0.728723
I0825 20:25:37.249961 27361 solver.cpp:244]     Train net output #0: accuracy = 0.796185
I0825 20:25:37.249970 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.569 (* 1 = 1.569 loss)
I0825 20:25:37.249979 27361 sgd_solver.cpp:106] Iteration 5070, lr = 5.91501e-06
I0825 20:25:58.588774 27361 solver.cpp:228] Iteration 5080, loss = 0.955976
I0825 20:25:58.588832 27361 solver.cpp:244]     Train net output #0: accuracy = 0.79641
I0825 20:25:58.588842 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.97319 (* 1 = 2.97319 loss)
I0825 20:25:58.588850 27361 sgd_solver.cpp:106] Iteration 5080, lr = 5.91061e-06
I0825 20:26:19.924312 27361 solver.cpp:228] Iteration 5090, loss = 0.393474
I0825 20:26:19.924362 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928688
I0825 20:26:19.924372 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.180312 (* 1 = 0.180312 loss)
I0825 20:26:19.924379 27361 sgd_solver.cpp:106] Iteration 5090, lr = 5.90621e-06
I0825 20:26:39.129472 27361 solver.cpp:337] Iteration 5100, Testing net (#0)
I0825 20:26:43.280829 27361 solver.cpp:404]     Test net output #0: accuracy = 0.899038
I0825 20:26:43.280874 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.595764 (* 1 = 0.595764 loss)
I0825 20:26:45.295557 27361 solver.cpp:228] Iteration 5100, loss = 0.610977
I0825 20:26:45.295601 27361 solver.cpp:244]     Train net output #0: accuracy = 0.721363
I0825 20:26:45.295610 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.69946 (* 1 = 1.69946 loss)
I0825 20:26:45.295617 27361 sgd_solver.cpp:106] Iteration 5100, lr = 5.90183e-06
I0825 20:27:06.628983 27361 solver.cpp:228] Iteration 5110, loss = 0.518932
I0825 20:27:06.629027 27361 solver.cpp:244]     Train net output #0: accuracy = 0.919067
I0825 20:27:06.629036 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.738716 (* 1 = 0.738716 loss)
I0825 20:27:06.629045 27361 sgd_solver.cpp:106] Iteration 5110, lr = 5.89745e-06
I0825 20:27:27.967743 27361 solver.cpp:228] Iteration 5120, loss = 0.444537
I0825 20:27:27.967900 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86721
I0825 20:27:27.967911 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.598908 (* 1 = 0.598908 loss)
I0825 20:27:27.967919 27361 sgd_solver.cpp:106] Iteration 5120, lr = 5.89308e-06
I0825 20:27:49.301424 27361 solver.cpp:228] Iteration 5130, loss = 0.411557
I0825 20:27:49.301472 27361 solver.cpp:244]     Train net output #0: accuracy = 0.947819
I0825 20:27:49.301491 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.376511 (* 1 = 0.376511 loss)
I0825 20:27:49.301498 27361 sgd_solver.cpp:106] Iteration 5130, lr = 5.88871e-06
I0825 20:28:10.636713 27361 solver.cpp:228] Iteration 5140, loss = 0.844735
I0825 20:28:10.636818 27361 solver.cpp:244]     Train net output #0: accuracy = 0.80135
I0825 20:28:10.636828 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.24644 (* 1 = 1.24644 loss)
I0825 20:28:10.636837 27361 sgd_solver.cpp:106] Iteration 5140, lr = 5.88436e-06
I0825 20:28:31.977365 27361 solver.cpp:228] Iteration 5150, loss = 0.649971
I0825 20:28:31.977411 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868221
I0825 20:28:31.977419 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.332709 (* 1 = 0.332709 loss)
I0825 20:28:31.977427 27361 sgd_solver.cpp:106] Iteration 5150, lr = 5.88001e-06
I0825 20:28:53.310487 27361 solver.cpp:228] Iteration 5160, loss = 0.444776
I0825 20:28:53.310592 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950771
I0825 20:28:53.310605 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.345442 (* 1 = 0.345442 loss)
I0825 20:28:53.310612 27361 sgd_solver.cpp:106] Iteration 5160, lr = 5.87567e-06
I0825 20:29:14.647286 27361 solver.cpp:228] Iteration 5170, loss = 0.398116
I0825 20:29:14.647332 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941326
I0825 20:29:14.647341 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.450178 (* 1 = 0.450178 loss)
I0825 20:29:14.647349 27361 sgd_solver.cpp:106] Iteration 5170, lr = 5.87133e-06
I0825 20:29:35.986732 27361 solver.cpp:228] Iteration 5180, loss = 0.660796
I0825 20:29:35.986840 27361 solver.cpp:244]     Train net output #0: accuracy = 0.873482
I0825 20:29:35.986850 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.375135 (* 1 = 0.375135 loss)
I0825 20:29:35.986858 27361 sgd_solver.cpp:106] Iteration 5180, lr = 5.86701e-06
I0825 20:29:57.308068 27361 solver.cpp:228] Iteration 5190, loss = 0.359444
I0825 20:29:57.308115 27361 solver.cpp:244]     Train net output #0: accuracy = 0.869217
I0825 20:29:57.308125 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.303247 (* 1 = 0.303247 loss)
I0825 20:29:57.308132 27361 sgd_solver.cpp:106] Iteration 5190, lr = 5.86269e-06
I0825 20:30:16.541396 27361 solver.cpp:337] Iteration 5200, Testing net (#0)
I0825 20:30:20.690325 27361 solver.cpp:404]     Test net output #0: accuracy = 0.905641
I0825 20:30:20.690366 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.629013 (* 1 = 0.629013 loss)
I0825 20:30:22.706138 27361 solver.cpp:228] Iteration 5200, loss = 0.281138
I0825 20:30:22.706178 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950809
I0825 20:30:22.706188 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.247798 (* 1 = 0.247798 loss)
I0825 20:30:22.706195 27361 sgd_solver.cpp:106] Iteration 5200, lr = 5.85838e-06
I0825 20:30:44.045382 27361 solver.cpp:228] Iteration 5210, loss = 0.625185
I0825 20:30:44.045428 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950123
I0825 20:30:44.045439 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.484969 (* 1 = 0.484969 loss)
I0825 20:30:44.045445 27361 sgd_solver.cpp:106] Iteration 5210, lr = 5.85407e-06
I0825 20:31:05.383208 27361 solver.cpp:228] Iteration 5220, loss = 0.636286
I0825 20:31:05.383343 27361 solver.cpp:244]     Train net output #0: accuracy = 0.98098
I0825 20:31:05.383354 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0301051 (* 1 = 0.0301051 loss)
I0825 20:31:05.383363 27361 sgd_solver.cpp:106] Iteration 5220, lr = 5.84978e-06
I0825 20:31:26.706308 27361 solver.cpp:228] Iteration 5230, loss = 0.521064
I0825 20:31:26.706357 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889576
I0825 20:31:26.706367 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.83089 (* 1 = 0.83089 loss)
I0825 20:31:26.706373 27361 sgd_solver.cpp:106] Iteration 5230, lr = 5.84549e-06
I0825 20:31:48.075608 27361 solver.cpp:228] Iteration 5240, loss = 0.687842
I0825 20:31:48.075726 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954346
I0825 20:31:48.075738 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.359731 (* 1 = 0.359731 loss)
I0825 20:31:48.075745 27361 sgd_solver.cpp:106] Iteration 5240, lr = 5.84121e-06
I0825 20:32:09.415267 27361 solver.cpp:228] Iteration 5250, loss = 0.653233
I0825 20:32:09.415313 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868103
I0825 20:32:09.415323 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.05524 (* 1 = 1.05524 loss)
I0825 20:32:09.415329 27361 sgd_solver.cpp:106] Iteration 5250, lr = 5.83693e-06
I0825 20:32:30.757172 27361 solver.cpp:228] Iteration 5260, loss = 0.339306
I0825 20:32:30.757279 27361 solver.cpp:244]     Train net output #0: accuracy = 0.990833
I0825 20:32:30.757290 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0268531 (* 1 = 0.0268531 loss)
I0825 20:32:30.757298 27361 sgd_solver.cpp:106] Iteration 5260, lr = 5.83266e-06
I0825 20:32:52.092555 27361 solver.cpp:228] Iteration 5270, loss = 0.514187
I0825 20:32:52.092602 27361 solver.cpp:244]     Train net output #0: accuracy = 0.8414
I0825 20:32:52.092612 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.437595 (* 1 = 0.437595 loss)
I0825 20:32:52.092619 27361 sgd_solver.cpp:106] Iteration 5270, lr = 5.8284e-06
I0825 20:33:13.431913 27361 solver.cpp:228] Iteration 5280, loss = 0.411012
I0825 20:33:13.431965 27361 solver.cpp:244]     Train net output #0: accuracy = 0.752178
I0825 20:33:13.431974 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.873351 (* 1 = 0.873351 loss)
I0825 20:33:13.431982 27361 sgd_solver.cpp:106] Iteration 5280, lr = 5.82415e-06
I0825 20:33:34.768962 27361 solver.cpp:228] Iteration 5290, loss = 0.67912
I0825 20:33:34.769004 27361 solver.cpp:244]     Train net output #0: accuracy = 0.773968
I0825 20:33:34.769014 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.68396 (* 1 = 1.68396 loss)
I0825 20:33:34.769021 27361 sgd_solver.cpp:106] Iteration 5290, lr = 5.81991e-06
I0825 20:33:53.973119 27361 solver.cpp:337] Iteration 5300, Testing net (#0)
I0825 20:33:58.121333 27361 solver.cpp:404]     Test net output #0: accuracy = 0.880448
I0825 20:33:58.121379 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.642159 (* 1 = 0.642159 loss)
I0825 20:34:00.136895 27361 solver.cpp:228] Iteration 5300, loss = 0.456015
I0825 20:34:00.136939 27361 solver.cpp:244]     Train net output #0: accuracy = 0.874287
I0825 20:34:00.136947 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.19444 (* 1 = 1.19444 loss)
I0825 20:34:00.136955 27361 sgd_solver.cpp:106] Iteration 5300, lr = 5.81567e-06
I0825 20:34:21.463342 27361 solver.cpp:228] Iteration 5310, loss = 0.487422
I0825 20:34:21.463389 27361 solver.cpp:244]     Train net output #0: accuracy = 0.834293
I0825 20:34:21.463398 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.932051 (* 1 = 0.932051 loss)
I0825 20:34:21.463407 27361 sgd_solver.cpp:106] Iteration 5310, lr = 5.81144e-06
I0825 20:34:42.843488 27361 solver.cpp:228] Iteration 5320, loss = 0.511321
I0825 20:34:42.843629 27361 solver.cpp:244]     Train net output #0: accuracy = 0.803822
I0825 20:34:42.843641 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.49563 (* 1 = 0.49563 loss)
I0825 20:34:42.843648 27361 sgd_solver.cpp:106] Iteration 5320, lr = 5.80721e-06
I0825 20:35:04.193511 27361 solver.cpp:228] Iteration 5330, loss = 0.424107
I0825 20:35:04.193557 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966545
I0825 20:35:04.193567 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.168828 (* 1 = 0.168828 loss)
I0825 20:35:04.193574 27361 sgd_solver.cpp:106] Iteration 5330, lr = 5.803e-06
I0825 20:35:25.542055 27361 solver.cpp:228] Iteration 5340, loss = 0.675653
I0825 20:35:25.542156 27361 solver.cpp:244]     Train net output #0: accuracy = 0.858868
I0825 20:35:25.542166 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.590675 (* 1 = 0.590675 loss)
I0825 20:35:25.542181 27361 sgd_solver.cpp:106] Iteration 5340, lr = 5.79879e-06
I0825 20:35:46.891981 27361 solver.cpp:228] Iteration 5350, loss = 0.373772
I0825 20:35:46.892029 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937378
I0825 20:35:46.892038 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.49719 (* 1 = 0.49719 loss)
I0825 20:35:46.892046 27361 sgd_solver.cpp:106] Iteration 5350, lr = 5.79458e-06
I0825 20:36:08.244000 27361 solver.cpp:228] Iteration 5360, loss = 0.795933
I0825 20:36:08.244104 27361 solver.cpp:244]     Train net output #0: accuracy = 0.875179
I0825 20:36:08.244114 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.525802 (* 1 = 0.525802 loss)
I0825 20:36:08.244122 27361 sgd_solver.cpp:106] Iteration 5360, lr = 5.79039e-06
I0825 20:36:29.588711 27361 solver.cpp:228] Iteration 5370, loss = 0.625294
I0825 20:36:29.588757 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934113
I0825 20:36:29.588767 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.564997 (* 1 = 0.564997 loss)
I0825 20:36:29.588774 27361 sgd_solver.cpp:106] Iteration 5370, lr = 5.7862e-06
I0825 20:36:50.938343 27361 solver.cpp:228] Iteration 5380, loss = 0.324819
I0825 20:36:50.938453 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954453
I0825 20:36:50.938463 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.311689 (* 1 = 0.311689 loss)
I0825 20:36:50.938472 27361 sgd_solver.cpp:106] Iteration 5380, lr = 5.78202e-06
I0825 20:37:12.282636 27361 solver.cpp:228] Iteration 5390, loss = 0.361059
I0825 20:37:12.282682 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971302
I0825 20:37:12.282691 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.126045 (* 1 = 0.126045 loss)
I0825 20:37:12.282699 27361 sgd_solver.cpp:106] Iteration 5390, lr = 5.77784e-06
I0825 20:37:31.497573 27361 solver.cpp:337] Iteration 5400, Testing net (#0)
I0825 20:37:35.648870 27361 solver.cpp:404]     Test net output #0: accuracy = 0.900876
I0825 20:37:35.648916 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.530434 (* 1 = 0.530434 loss)
I0825 20:37:37.665086 27361 solver.cpp:228] Iteration 5400, loss = 0.473225
I0825 20:37:37.665132 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916824
I0825 20:37:37.665141 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.520165 (* 1 = 0.520165 loss)
I0825 20:37:37.665149 27361 sgd_solver.cpp:106] Iteration 5400, lr = 5.77368e-06
I0825 20:37:59.014776 27361 solver.cpp:228] Iteration 5410, loss = 0.917192
I0825 20:37:59.014825 27361 solver.cpp:244]     Train net output #0: accuracy = 0.903381
I0825 20:37:59.014834 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.986841 (* 1 = 0.986841 loss)
I0825 20:37:59.014842 27361 sgd_solver.cpp:106] Iteration 5410, lr = 5.76952e-06
I0825 20:38:20.358472 27361 solver.cpp:228] Iteration 5420, loss = 0.984681
I0825 20:38:20.358625 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934116
I0825 20:38:20.358636 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.320726 (* 1 = 0.320726 loss)
I0825 20:38:20.358644 27361 sgd_solver.cpp:106] Iteration 5420, lr = 5.76536e-06
I0825 20:38:41.704236 27361 solver.cpp:228] Iteration 5430, loss = 0.845793
I0825 20:38:41.704282 27361 solver.cpp:244]     Train net output #0: accuracy = 0.998299
I0825 20:38:41.704291 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.7639 (* 1 = 1.7639 loss)
I0825 20:38:41.704299 27361 sgd_solver.cpp:106] Iteration 5430, lr = 5.76122e-06
I0825 20:39:03.050297 27361 solver.cpp:228] Iteration 5440, loss = 0.557748
I0825 20:39:03.050410 27361 solver.cpp:244]     Train net output #0: accuracy = 0.953861
I0825 20:39:03.050421 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.384767 (* 1 = 0.384767 loss)
I0825 20:39:03.050428 27361 sgd_solver.cpp:106] Iteration 5440, lr = 5.75708e-06
I0825 20:39:24.446859 27361 solver.cpp:228] Iteration 5450, loss = 0.440977
I0825 20:39:24.446914 27361 solver.cpp:244]     Train net output #0: accuracy = 0.904766
I0825 20:39:24.446923 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.960032 (* 1 = 0.960032 loss)
I0825 20:39:24.446931 27361 sgd_solver.cpp:106] Iteration 5450, lr = 5.75295e-06
I0825 20:39:45.833143 27361 solver.cpp:228] Iteration 5460, loss = 0.655408
I0825 20:39:45.833246 27361 solver.cpp:244]     Train net output #0: accuracy = 0.914665
I0825 20:39:45.833258 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.418725 (* 1 = 0.418725 loss)
I0825 20:39:45.833266 27361 sgd_solver.cpp:106] Iteration 5460, lr = 5.74882e-06
I0825 20:40:07.191226 27361 solver.cpp:228] Iteration 5470, loss = 0.510363
I0825 20:40:07.191273 27361 solver.cpp:244]     Train net output #0: accuracy = 0.767479
I0825 20:40:07.191283 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.987755 (* 1 = 0.987755 loss)
I0825 20:40:07.191290 27361 sgd_solver.cpp:106] Iteration 5470, lr = 5.7447e-06
I0825 20:40:28.571099 27361 solver.cpp:228] Iteration 5480, loss = 0.59992
I0825 20:40:28.571203 27361 solver.cpp:244]     Train net output #0: accuracy = 0.985966
I0825 20:40:28.571214 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0291095 (* 1 = 0.0291095 loss)
I0825 20:40:28.571223 27361 sgd_solver.cpp:106] Iteration 5480, lr = 5.74059e-06
I0825 20:40:49.962015 27361 solver.cpp:228] Iteration 5490, loss = 0.850479
I0825 20:40:49.962062 27361 solver.cpp:244]     Train net output #0: accuracy = 0.88932
I0825 20:40:49.962072 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.736135 (* 1 = 0.736135 loss)
I0825 20:40:49.962080 27361 sgd_solver.cpp:106] Iteration 5490, lr = 5.73649e-06
I0825 20:41:09.175292 27361 solver.cpp:337] Iteration 5500, Testing net (#0)
I0825 20:41:13.327281 27361 solver.cpp:404]     Test net output #0: accuracy = 0.901903
I0825 20:41:13.327328 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.681987 (* 1 = 0.681987 loss)
I0825 20:41:15.342247 27361 solver.cpp:228] Iteration 5500, loss = 0.465539
I0825 20:41:15.342293 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945908
I0825 20:41:15.342301 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.396565 (* 1 = 0.396565 loss)
I0825 20:41:15.342309 27361 sgd_solver.cpp:106] Iteration 5500, lr = 5.73239e-06
I0825 20:41:36.665998 27361 solver.cpp:228] Iteration 5510, loss = 0.523844
I0825 20:41:36.666043 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937675
I0825 20:41:36.666052 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.462164 (* 1 = 0.462164 loss)
I0825 20:41:36.666059 27361 sgd_solver.cpp:106] Iteration 5510, lr = 5.7283e-06
I0825 20:41:57.988215 27361 solver.cpp:228] Iteration 5520, loss = 0.535253
I0825 20:41:57.988328 27361 solver.cpp:244]     Train net output #0: accuracy = 0.848339
I0825 20:41:57.988338 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.562043 (* 1 = 0.562043 loss)
I0825 20:41:57.988346 27361 sgd_solver.cpp:106] Iteration 5520, lr = 5.72421e-06
I0825 20:42:19.312479 27361 solver.cpp:228] Iteration 5530, loss = 0.882335
I0825 20:42:19.312528 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951889
I0825 20:42:19.312538 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.384763 (* 1 = 0.384763 loss)
I0825 20:42:19.312546 27361 sgd_solver.cpp:106] Iteration 5530, lr = 5.72013e-06
I0825 20:42:40.665977 27361 solver.cpp:228] Iteration 5540, loss = 0.431177
I0825 20:42:40.666116 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941284
I0825 20:42:40.666128 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.2225 (* 1 = 0.2225 loss)
I0825 20:42:40.666136 27361 sgd_solver.cpp:106] Iteration 5540, lr = 5.71606e-06
I0825 20:43:02.007347 27361 solver.cpp:228] Iteration 5550, loss = 0.382805
I0825 20:43:02.007390 27361 solver.cpp:244]     Train net output #0: accuracy = 0.854641
I0825 20:43:02.007400 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.581296 (* 1 = 0.581296 loss)
I0825 20:43:02.007406 27361 sgd_solver.cpp:106] Iteration 5550, lr = 5.712e-06
I0825 20:43:23.399978 27361 solver.cpp:228] Iteration 5560, loss = 0.60722
I0825 20:43:23.400094 27361 solver.cpp:244]     Train net output #0: accuracy = 0.863441
I0825 20:43:23.400104 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.689614 (* 1 = 0.689614 loss)
I0825 20:43:23.400112 27361 sgd_solver.cpp:106] Iteration 5560, lr = 5.70794e-06
I0825 20:43:44.728198 27361 solver.cpp:228] Iteration 5570, loss = 0.472818
I0825 20:43:44.728240 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868893
I0825 20:43:44.728250 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.456292 (* 1 = 0.456292 loss)
I0825 20:43:44.728257 27361 sgd_solver.cpp:106] Iteration 5570, lr = 5.70389e-06
I0825 20:44:06.059046 27361 solver.cpp:228] Iteration 5580, loss = 0.616972
I0825 20:44:06.059149 27361 solver.cpp:244]     Train net output #0: accuracy = 0.809673
I0825 20:44:06.059159 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.94251 (* 1 = 1.94251 loss)
I0825 20:44:06.059166 27361 sgd_solver.cpp:106] Iteration 5580, lr = 5.69985e-06
I0825 20:44:27.388700 27361 solver.cpp:228] Iteration 5590, loss = 0.605594
I0825 20:44:27.388747 27361 solver.cpp:244]     Train net output #0: accuracy = 0.934402
I0825 20:44:27.388757 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.554773 (* 1 = 0.554773 loss)
I0825 20:44:27.388764 27361 sgd_solver.cpp:106] Iteration 5590, lr = 5.69581e-06
I0825 20:44:46.587615 27361 solver.cpp:337] Iteration 5600, Testing net (#0)
I0825 20:44:50.735158 27361 solver.cpp:404]     Test net output #0: accuracy = 0.92233
I0825 20:44:50.735200 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.488163 (* 1 = 0.488163 loss)
I0825 20:44:52.750622 27361 solver.cpp:228] Iteration 5600, loss = 0.795181
I0825 20:44:52.750665 27361 solver.cpp:244]     Train net output #0: accuracy = 0.831512
I0825 20:44:52.750674 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.27774 (* 1 = 1.27774 loss)
I0825 20:44:52.750682 27361 sgd_solver.cpp:106] Iteration 5600, lr = 5.69178e-06
I0825 20:45:14.089689 27361 solver.cpp:228] Iteration 5610, loss = 0.465981
I0825 20:45:14.089736 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889141
I0825 20:45:14.089746 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.166563 (* 1 = 0.166563 loss)
I0825 20:45:14.089753 27361 sgd_solver.cpp:106] Iteration 5610, lr = 5.68776e-06
I0825 20:45:35.431318 27361 solver.cpp:228] Iteration 5620, loss = 0.195054
I0825 20:45:35.431378 27361 solver.cpp:244]     Train net output #0: accuracy = 0.974373
I0825 20:45:35.431388 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.163644 (* 1 = 0.163644 loss)
I0825 20:45:35.431396 27361 sgd_solver.cpp:106] Iteration 5620, lr = 5.68374e-06
I0825 20:45:56.827572 27361 solver.cpp:228] Iteration 5630, loss = 0.774197
I0825 20:45:56.827620 27361 solver.cpp:244]     Train net output #0: accuracy = 0.855526
I0825 20:45:56.827630 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.910259 (* 1 = 0.910259 loss)
I0825 20:45:56.827638 27361 sgd_solver.cpp:106] Iteration 5630, lr = 5.67973e-06
I0825 20:46:18.175099 27361 solver.cpp:228] Iteration 5640, loss = 0.410412
I0825 20:46:18.175235 27361 solver.cpp:244]     Train net output #0: accuracy = 0.983311
I0825 20:46:18.175246 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0888768 (* 1 = 0.0888768 loss)
I0825 20:46:18.175254 27361 sgd_solver.cpp:106] Iteration 5640, lr = 5.67572e-06
I0825 20:46:39.519414 27361 solver.cpp:228] Iteration 5650, loss = 0.434295
I0825 20:46:39.519459 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90321
I0825 20:46:39.519469 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.390326 (* 1 = 0.390326 loss)
I0825 20:46:39.519477 27361 sgd_solver.cpp:106] Iteration 5650, lr = 5.67173e-06
I0825 20:47:00.867216 27361 solver.cpp:228] Iteration 5660, loss = 0.556739
I0825 20:47:00.867334 27361 solver.cpp:244]     Train net output #0: accuracy = 0.909058
I0825 20:47:00.867353 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.241686 (* 1 = 0.241686 loss)
I0825 20:47:00.867362 27361 sgd_solver.cpp:106] Iteration 5660, lr = 5.66774e-06
I0825 20:47:22.218575 27361 solver.cpp:228] Iteration 5670, loss = 0.463588
I0825 20:47:22.218626 27361 solver.cpp:244]     Train net output #0: accuracy = 0.890503
I0825 20:47:22.218636 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.52839 (* 1 = 1.52839 loss)
I0825 20:47:22.218642 27361 sgd_solver.cpp:106] Iteration 5670, lr = 5.66375e-06
I0825 20:47:43.565297 27361 solver.cpp:228] Iteration 5680, loss = 0.553865
I0825 20:47:43.565359 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941296
I0825 20:47:43.565368 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.223827 (* 1 = 0.223827 loss)
I0825 20:47:43.565376 27361 sgd_solver.cpp:106] Iteration 5680, lr = 5.65977e-06
I0825 20:48:04.913805 27361 solver.cpp:228] Iteration 5690, loss = 0.622644
I0825 20:48:04.913856 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956181
I0825 20:48:04.913866 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.463854 (* 1 = 0.463854 loss)
I0825 20:48:04.913872 27361 sgd_solver.cpp:106] Iteration 5690, lr = 5.6558e-06
I0825 20:48:24.128315 27361 solver.cpp:337] Iteration 5700, Testing net (#0)
I0825 20:48:28.280731 27361 solver.cpp:404]     Test net output #0: accuracy = 0.91437
I0825 20:48:28.280776 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.626855 (* 1 = 0.626855 loss)
I0825 20:48:30.296566 27361 solver.cpp:228] Iteration 5700, loss = 0.600182
I0825 20:48:30.296610 27361 solver.cpp:244]     Train net output #0: accuracy = 0.925278
I0825 20:48:30.296619 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.903422 (* 1 = 0.903422 loss)
I0825 20:48:30.296627 27361 sgd_solver.cpp:106] Iteration 5700, lr = 5.65184e-06
I0825 20:48:51.642138 27361 solver.cpp:228] Iteration 5710, loss = 0.509548
I0825 20:48:51.642182 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962875
I0825 20:48:51.642192 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.181536 (* 1 = 0.181536 loss)
I0825 20:48:51.642200 27361 sgd_solver.cpp:106] Iteration 5710, lr = 5.64788e-06
I0825 20:49:12.987579 27361 solver.cpp:228] Iteration 5720, loss = 0.417852
I0825 20:49:12.987691 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943886
I0825 20:49:12.987702 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.389017 (* 1 = 0.389017 loss)
I0825 20:49:12.987709 27361 sgd_solver.cpp:106] Iteration 5720, lr = 5.64393e-06
I0825 20:49:34.328464 27361 solver.cpp:228] Iteration 5730, loss = 0.531648
I0825 20:49:34.328511 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929447
I0825 20:49:34.328521 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.603399 (* 1 = 0.603399 loss)
I0825 20:49:34.328528 27361 sgd_solver.cpp:106] Iteration 5730, lr = 5.63998e-06
I0825 20:49:55.676633 27361 solver.cpp:228] Iteration 5740, loss = 0.703707
I0825 20:49:55.676766 27361 solver.cpp:244]     Train net output #0: accuracy = 0.920261
I0825 20:49:55.676777 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.592155 (* 1 = 0.592155 loss)
I0825 20:49:55.676784 27361 sgd_solver.cpp:106] Iteration 5740, lr = 5.63604e-06
I0825 20:50:17.025866 27361 solver.cpp:228] Iteration 5750, loss = 0.961592
I0825 20:50:17.025913 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937912
I0825 20:50:17.025923 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.3892 (* 1 = 0.3892 loss)
I0825 20:50:17.025930 27361 sgd_solver.cpp:106] Iteration 5750, lr = 5.63211e-06
I0825 20:50:38.387233 27361 solver.cpp:228] Iteration 5760, loss = 0.822628
I0825 20:50:38.387346 27361 solver.cpp:244]     Train net output #0: accuracy = 0.823006
I0825 20:50:38.387357 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.10691 (* 1 = 1.10691 loss)
I0825 20:50:38.387365 27361 sgd_solver.cpp:106] Iteration 5760, lr = 5.62818e-06
I0825 20:50:59.731081 27361 solver.cpp:228] Iteration 5770, loss = 0.666134
I0825 20:50:59.731130 27361 solver.cpp:244]     Train net output #0: accuracy = 0.925766
I0825 20:50:59.731140 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.737338 (* 1 = 0.737338 loss)
I0825 20:50:59.731148 27361 sgd_solver.cpp:106] Iteration 5770, lr = 5.62426e-06
I0825 20:51:21.076880 27361 solver.cpp:228] Iteration 5780, loss = 0.507646
I0825 20:51:21.076988 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942371
I0825 20:51:21.076997 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.258206 (* 1 = 0.258206 loss)
I0825 20:51:21.077005 27361 sgd_solver.cpp:106] Iteration 5780, lr = 5.62035e-06
I0825 20:51:42.454952 27361 solver.cpp:228] Iteration 5790, loss = 0.35595
I0825 20:51:42.455000 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949265
I0825 20:51:42.455009 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.311692 (* 1 = 0.311692 loss)
I0825 20:51:42.455018 27361 sgd_solver.cpp:106] Iteration 5790, lr = 5.61644e-06
I0825 20:52:01.670047 27361 solver.cpp:337] Iteration 5800, Testing net (#0)
I0825 20:52:05.821739 27361 solver.cpp:404]     Test net output #0: accuracy = 0.89882
I0825 20:52:05.821787 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.621197 (* 1 = 0.621197 loss)
I0825 20:52:07.836983 27361 solver.cpp:228] Iteration 5800, loss = 0.362766
I0825 20:52:07.837029 27361 solver.cpp:244]     Train net output #0: accuracy = 0.902981
I0825 20:52:07.837039 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.695096 (* 1 = 0.695096 loss)
I0825 20:52:07.837047 27361 sgd_solver.cpp:106] Iteration 5800, lr = 5.61254e-06
I0825 20:52:29.173740 27361 solver.cpp:228] Iteration 5810, loss = 0.508354
I0825 20:52:29.173786 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955093
I0825 20:52:29.173795 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.191457 (* 1 = 0.191457 loss)
I0825 20:52:29.173804 27361 sgd_solver.cpp:106] Iteration 5810, lr = 5.60865e-06
I0825 20:52:50.512601 27361 solver.cpp:228] Iteration 5820, loss = 0.501478
I0825 20:52:50.512708 27361 solver.cpp:244]     Train net output #0: accuracy = 0.793205
I0825 20:52:50.512718 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.02398 (* 1 = 1.02398 loss)
I0825 20:52:50.512727 27361 sgd_solver.cpp:106] Iteration 5820, lr = 5.60476e-06
I0825 20:53:11.851882 27361 solver.cpp:228] Iteration 5830, loss = 0.4768
I0825 20:53:11.851929 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9221
I0825 20:53:11.851939 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.590501 (* 1 = 0.590501 loss)
I0825 20:53:11.851946 27361 sgd_solver.cpp:106] Iteration 5830, lr = 5.60088e-06
I0825 20:53:33.188662 27361 solver.cpp:228] Iteration 5840, loss = 0.524938
I0825 20:53:33.188768 27361 solver.cpp:244]     Train net output #0: accuracy = 0.892761
I0825 20:53:33.188778 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.02518 (* 1 = 1.02518 loss)
I0825 20:53:33.188786 27361 sgd_solver.cpp:106] Iteration 5840, lr = 5.597e-06
I0825 20:53:54.526372 27361 solver.cpp:228] Iteration 5850, loss = 0.396844
I0825 20:53:54.526420 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933498
I0825 20:53:54.526430 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.12321 (* 1 = 1.12321 loss)
I0825 20:53:54.526438 27361 sgd_solver.cpp:106] Iteration 5850, lr = 5.59313e-06
I0825 20:54:15.860674 27361 solver.cpp:228] Iteration 5860, loss = 0.587645
I0825 20:54:15.860808 27361 solver.cpp:244]     Train net output #0: accuracy = 0.948715
I0825 20:54:15.860821 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.390588 (* 1 = 0.390588 loss)
I0825 20:54:15.860827 27361 sgd_solver.cpp:106] Iteration 5860, lr = 5.58927e-06
I0825 20:54:37.198580 27361 solver.cpp:228] Iteration 5870, loss = 0.544229
I0825 20:54:37.198631 27361 solver.cpp:244]     Train net output #0: accuracy = 0.815796
I0825 20:54:37.198639 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.846967 (* 1 = 0.846967 loss)
I0825 20:54:37.198655 27361 sgd_solver.cpp:106] Iteration 5870, lr = 5.58541e-06
I0825 20:54:58.534525 27361 solver.cpp:228] Iteration 5880, loss = 0.508148
I0825 20:54:58.534682 27361 solver.cpp:244]     Train net output #0: accuracy = 0.888313
I0825 20:54:58.534708 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.94572 (* 1 = 0.94572 loss)
I0825 20:54:58.534721 27361 sgd_solver.cpp:106] Iteration 5880, lr = 5.58156e-06
I0825 20:55:19.982929 27361 solver.cpp:228] Iteration 5890, loss = 0.626038
I0825 20:55:19.982976 27361 solver.cpp:244]     Train net output #0: accuracy = 0.830925
I0825 20:55:19.982986 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.707775 (* 1 = 0.707775 loss)
I0825 20:55:19.982995 27361 sgd_solver.cpp:106] Iteration 5890, lr = 5.57772e-06
I0825 20:55:39.187012 27361 solver.cpp:337] Iteration 5900, Testing net (#0)
I0825 20:55:43.338944 27361 solver.cpp:404]     Test net output #0: accuracy = 0.910171
I0825 20:55:43.338992 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.53411 (* 1 = 0.53411 loss)
I0825 20:55:45.355007 27361 solver.cpp:228] Iteration 5900, loss = 0.57094
I0825 20:55:45.355054 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961479
I0825 20:55:45.355063 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.286037 (* 1 = 0.286037 loss)
I0825 20:55:45.355072 27361 sgd_solver.cpp:106] Iteration 5900, lr = 5.57388e-06
I0825 20:56:06.701414 27361 solver.cpp:228] Iteration 5910, loss = 0.615115
I0825 20:56:06.701460 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951069
I0825 20:56:06.701469 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.114496 (* 1 = 0.114496 loss)
I0825 20:56:06.701478 27361 sgd_solver.cpp:106] Iteration 5910, lr = 5.57005e-06
I0825 20:56:28.050899 27361 solver.cpp:228] Iteration 5920, loss = 0.594919
I0825 20:56:28.051002 27361 solver.cpp:244]     Train net output #0: accuracy = 0.869999
I0825 20:56:28.051012 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.06516 (* 1 = 1.06516 loss)
I0825 20:56:28.051019 27361 sgd_solver.cpp:106] Iteration 5920, lr = 5.56622e-06
I0825 20:56:49.398157 27361 solver.cpp:228] Iteration 5930, loss = 0.4524
I0825 20:56:49.398205 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973175
I0825 20:56:49.398214 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0939811 (* 1 = 0.0939811 loss)
I0825 20:56:49.398222 27361 sgd_solver.cpp:106] Iteration 5930, lr = 5.5624e-06
I0825 20:57:10.740553 27361 solver.cpp:228] Iteration 5940, loss = 0.488638
I0825 20:57:10.740664 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916649
I0825 20:57:10.740674 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.814356 (* 1 = 0.814356 loss)
I0825 20:57:10.740681 27361 sgd_solver.cpp:106] Iteration 5940, lr = 5.55859e-06
I0825 20:57:32.085008 27361 solver.cpp:228] Iteration 5950, loss = 0.505853
I0825 20:57:32.085057 27361 solver.cpp:244]     Train net output #0: accuracy = 0.981106
I0825 20:57:32.085067 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0749927 (* 1 = 0.0749927 loss)
I0825 20:57:32.085073 27361 sgd_solver.cpp:106] Iteration 5950, lr = 5.55478e-06
I0825 20:57:53.430315 27361 solver.cpp:228] Iteration 5960, loss = 0.506017
I0825 20:57:53.430444 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921814
I0825 20:57:53.430454 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.379965 (* 1 = 0.379965 loss)
I0825 20:57:53.430461 27361 sgd_solver.cpp:106] Iteration 5960, lr = 5.55098e-06
I0825 20:58:14.882719 27361 solver.cpp:228] Iteration 5970, loss = 0.580915
I0825 20:58:14.882764 27361 solver.cpp:244]     Train net output #0: accuracy = 0.907845
I0825 20:58:14.882774 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.772049 (* 1 = 0.772049 loss)
I0825 20:58:14.882781 27361 sgd_solver.cpp:106] Iteration 5970, lr = 5.54718e-06
I0825 20:58:36.223644 27361 solver.cpp:228] Iteration 5980, loss = 0.511128
I0825 20:58:36.223752 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868477
I0825 20:58:36.223769 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.680463 (* 1 = 0.680463 loss)
I0825 20:58:36.223778 27361 sgd_solver.cpp:106] Iteration 5980, lr = 5.54339e-06
I0825 20:58:57.571533 27361 solver.cpp:228] Iteration 5990, loss = 0.637093
I0825 20:58:57.571579 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916042
I0825 20:58:57.571589 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.879128 (* 1 = 0.879128 loss)
I0825 20:58:57.571596 27361 sgd_solver.cpp:106] Iteration 5990, lr = 5.53961e-06
I0825 20:59:16.782127 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_6000.caffemodel
I0825 20:59:16.975515 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_6000.solverstate
I0825 20:59:17.012923 27361 solver.cpp:337] Iteration 6000, Testing net (#0)
I0825 20:59:21.048580 27361 solver.cpp:404]     Test net output #0: accuracy = 0.915957
I0825 20:59:21.048625 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.545073 (* 1 = 0.545073 loss)
I0825 20:59:23.063908 27361 solver.cpp:228] Iteration 6000, loss = 0.267667
I0825 20:59:23.063951 27361 solver.cpp:244]     Train net output #0: accuracy = 0.874889
I0825 20:59:23.063959 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.347542 (* 1 = 0.347542 loss)
I0825 20:59:23.063967 27361 sgd_solver.cpp:106] Iteration 6000, lr = 5.53583e-06
I0825 20:59:44.406379 27361 solver.cpp:228] Iteration 6010, loss = 0.477694
I0825 20:59:44.406427 27361 solver.cpp:244]     Train net output #0: accuracy = 0.867428
I0825 20:59:44.406437 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.600442 (* 1 = 0.600442 loss)
I0825 20:59:44.406445 27361 sgd_solver.cpp:106] Iteration 6010, lr = 5.53206e-06
I0825 21:00:05.752487 27361 solver.cpp:228] Iteration 6020, loss = 0.65411
I0825 21:00:05.752599 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9048
I0825 21:00:05.752609 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.173823 (* 1 = 0.173823 loss)
I0825 21:00:05.752616 27361 sgd_solver.cpp:106] Iteration 6020, lr = 5.5283e-06
I0825 21:00:27.098559 27361 solver.cpp:228] Iteration 6030, loss = 0.572102
I0825 21:00:27.098719 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963192
I0825 21:00:27.098731 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.309394 (* 1 = 0.309394 loss)
I0825 21:00:27.098739 27361 sgd_solver.cpp:106] Iteration 6030, lr = 5.52454e-06
I0825 21:00:48.443812 27361 solver.cpp:228] Iteration 6040, loss = 0.518059
I0825 21:00:48.443979 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935059
I0825 21:00:48.443989 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.450126 (* 1 = 0.450126 loss)
I0825 21:00:48.443996 27361 sgd_solver.cpp:106] Iteration 6040, lr = 5.52078e-06
I0825 21:01:09.805709 27361 solver.cpp:228] Iteration 6050, loss = 0.439464
I0825 21:01:09.805768 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956596
I0825 21:01:09.805779 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.207023 (* 1 = 0.207023 loss)
I0825 21:01:09.805788 27361 sgd_solver.cpp:106] Iteration 6050, lr = 5.51704e-06
I0825 21:01:31.152621 27361 solver.cpp:228] Iteration 6060, loss = 0.55361
I0825 21:01:31.152757 27361 solver.cpp:244]     Train net output #0: accuracy = 0.965137
I0825 21:01:31.152770 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.217698 (* 1 = 0.217698 loss)
I0825 21:01:31.152776 27361 sgd_solver.cpp:106] Iteration 6060, lr = 5.51329e-06
I0825 21:01:52.491170 27361 solver.cpp:228] Iteration 6070, loss = 0.451916
I0825 21:01:52.491219 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943905
I0825 21:01:52.491227 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.572143 (* 1 = 0.572143 loss)
I0825 21:01:52.491235 27361 sgd_solver.cpp:106] Iteration 6070, lr = 5.50956e-06
I0825 21:02:13.828040 27361 solver.cpp:228] Iteration 6080, loss = 0.386631
I0825 21:02:13.828157 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929836
I0825 21:02:13.828176 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.532816 (* 1 = 0.532816 loss)
I0825 21:02:13.828184 27361 sgd_solver.cpp:106] Iteration 6080, lr = 5.50583e-06
I0825 21:02:35.219835 27361 solver.cpp:228] Iteration 6090, loss = 0.438337
I0825 21:02:35.219878 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955151
I0825 21:02:35.219887 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.182544 (* 1 = 0.182544 loss)
I0825 21:02:35.219895 27361 sgd_solver.cpp:106] Iteration 6090, lr = 5.5021e-06
I0825 21:02:54.433895 27361 solver.cpp:337] Iteration 6100, Testing net (#0)
I0825 21:02:58.584776 27361 solver.cpp:404]     Test net output #0: accuracy = 0.909847
I0825 21:02:58.584821 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.692588 (* 1 = 0.692588 loss)
I0825 21:03:00.600893 27361 solver.cpp:228] Iteration 6100, loss = 0.414495
I0825 21:03:00.600939 27361 solver.cpp:244]     Train net output #0: accuracy = 0.92231
I0825 21:03:00.600950 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.255542 (* 1 = 0.255542 loss)
I0825 21:03:00.600956 27361 sgd_solver.cpp:106] Iteration 6100, lr = 5.49839e-06
I0825 21:03:21.933259 27361 solver.cpp:228] Iteration 6110, loss = 0.466875
I0825 21:03:21.933306 27361 solver.cpp:244]     Train net output #0: accuracy = 0.940044
I0825 21:03:21.933315 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.612091 (* 1 = 0.612091 loss)
I0825 21:03:21.933323 27361 sgd_solver.cpp:106] Iteration 6110, lr = 5.49467e-06
I0825 21:03:43.253959 27361 solver.cpp:228] Iteration 6120, loss = 0.545274
I0825 21:03:43.254073 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963322
I0825 21:03:43.254084 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.254674 (* 1 = 0.254674 loss)
I0825 21:03:43.254092 27361 sgd_solver.cpp:106] Iteration 6120, lr = 5.49097e-06
I0825 21:04:04.615514 27361 solver.cpp:228] Iteration 6130, loss = 0.467213
I0825 21:04:04.615562 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95689
I0825 21:04:04.615572 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.322965 (* 1 = 0.322965 loss)
I0825 21:04:04.615581 27361 sgd_solver.cpp:106] Iteration 6130, lr = 5.48727e-06
I0825 21:04:25.952548 27361 solver.cpp:228] Iteration 6140, loss = 0.582363
I0825 21:04:25.952744 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960438
I0825 21:04:25.952754 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.318162 (* 1 = 0.318162 loss)
I0825 21:04:25.952762 27361 sgd_solver.cpp:106] Iteration 6140, lr = 5.48357e-06
I0825 21:04:47.290073 27361 solver.cpp:228] Iteration 6150, loss = 0.842974
I0825 21:04:47.290120 27361 solver.cpp:244]     Train net output #0: accuracy = 0.859093
I0825 21:04:47.290129 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.03953 (* 1 = 1.03953 loss)
I0825 21:04:47.290138 27361 sgd_solver.cpp:106] Iteration 6150, lr = 5.47988e-06
I0825 21:05:08.632150 27361 solver.cpp:228] Iteration 6160, loss = 0.630116
I0825 21:05:08.632293 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973335
I0825 21:05:08.632305 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0946223 (* 1 = 0.0946223 loss)
I0825 21:05:08.632313 27361 sgd_solver.cpp:106] Iteration 6160, lr = 5.4762e-06
I0825 21:05:30.021958 27361 solver.cpp:228] Iteration 6170, loss = 0.393927
I0825 21:05:30.022006 27361 solver.cpp:244]     Train net output #0: accuracy = 0.876923
I0825 21:05:30.022016 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.894099 (* 1 = 0.894099 loss)
I0825 21:05:30.022022 27361 sgd_solver.cpp:106] Iteration 6170, lr = 5.47252e-06
I0825 21:05:51.355206 27361 solver.cpp:228] Iteration 6180, loss = 0.707669
I0825 21:05:51.355317 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889481
I0825 21:05:51.355329 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.505789 (* 1 = 0.505789 loss)
I0825 21:05:51.355335 27361 sgd_solver.cpp:106] Iteration 6180, lr = 5.46885e-06
I0825 21:06:12.689101 27361 solver.cpp:228] Iteration 6190, loss = 0.669987
I0825 21:06:12.689144 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962391
I0825 21:06:12.689153 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.214221 (* 1 = 0.214221 loss)
I0825 21:06:12.689160 27361 sgd_solver.cpp:106] Iteration 6190, lr = 5.46519e-06
I0825 21:06:31.887493 27361 solver.cpp:337] Iteration 6200, Testing net (#0)
I0825 21:06:36.037910 27361 solver.cpp:404]     Test net output #0: accuracy = 0.909363
I0825 21:06:36.037956 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.594319 (* 1 = 0.594319 loss)
I0825 21:06:38.053627 27361 solver.cpp:228] Iteration 6200, loss = 0.538896
I0825 21:06:38.053673 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927216
I0825 21:06:38.053683 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.13174 (* 1 = 0.13174 loss)
I0825 21:06:38.053689 27361 sgd_solver.cpp:106] Iteration 6200, lr = 5.46153e-06
I0825 21:06:59.450633 27361 solver.cpp:228] Iteration 6210, loss = 0.824583
I0825 21:06:59.450682 27361 solver.cpp:244]     Train net output #0: accuracy = 0.905903
I0825 21:06:59.450692 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.723792 (* 1 = 0.723792 loss)
I0825 21:06:59.450700 27361 sgd_solver.cpp:106] Iteration 6210, lr = 5.45787e-06
I0825 21:07:20.846326 27361 solver.cpp:228] Iteration 6220, loss = 0.545628
I0825 21:07:20.846437 27361 solver.cpp:244]     Train net output #0: accuracy = 0.990795
I0825 21:07:20.846448 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0571961 (* 1 = 0.0571961 loss)
I0825 21:07:20.846457 27361 sgd_solver.cpp:106] Iteration 6220, lr = 5.45422e-06
I0825 21:07:42.187283 27361 solver.cpp:228] Iteration 6230, loss = 0.344928
I0825 21:07:42.187330 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868912
I0825 21:07:42.187340 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.697528 (* 1 = 0.697528 loss)
I0825 21:07:42.187346 27361 sgd_solver.cpp:106] Iteration 6230, lr = 5.45058e-06
I0825 21:08:03.578789 27361 solver.cpp:228] Iteration 6240, loss = 0.461858
I0825 21:08:03.578902 27361 solver.cpp:244]     Train net output #0: accuracy = 0.826981
I0825 21:08:03.578912 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.898101 (* 1 = 0.898101 loss)
I0825 21:08:03.578920 27361 sgd_solver.cpp:106] Iteration 6240, lr = 5.44694e-06
I0825 21:08:24.947372 27361 solver.cpp:228] Iteration 6250, loss = 0.496377
I0825 21:08:24.947420 27361 solver.cpp:244]     Train net output #0: accuracy = 0.953316
I0825 21:08:24.947430 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.139593 (* 1 = 0.139593 loss)
I0825 21:08:24.947438 27361 sgd_solver.cpp:106] Iteration 6250, lr = 5.44331e-06
I0825 21:08:46.350385 27361 solver.cpp:228] Iteration 6260, loss = 0.422857
I0825 21:08:46.350489 27361 solver.cpp:244]     Train net output #0: accuracy = 0.959564
I0825 21:08:46.350499 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.269571 (* 1 = 0.269571 loss)
I0825 21:08:46.350507 27361 sgd_solver.cpp:106] Iteration 6260, lr = 5.43968e-06
I0825 21:09:07.730512 27361 solver.cpp:228] Iteration 6270, loss = 0.435515
I0825 21:09:07.730557 27361 solver.cpp:244]     Train net output #0: accuracy = 0.991966
I0825 21:09:07.730567 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0463809 (* 1 = 0.0463809 loss)
I0825 21:09:07.730576 27361 sgd_solver.cpp:106] Iteration 6270, lr = 5.43606e-06
I0825 21:09:29.095564 27361 solver.cpp:228] Iteration 6280, loss = 0.393083
I0825 21:09:29.095659 27361 solver.cpp:244]     Train net output #0: accuracy = 0.882858
I0825 21:09:29.095669 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.291188 (* 1 = 0.291188 loss)
I0825 21:09:29.095676 27361 sgd_solver.cpp:106] Iteration 6280, lr = 5.43245e-06
I0825 21:09:50.485396 27361 solver.cpp:228] Iteration 6290, loss = 0.361323
I0825 21:09:50.485445 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87011
I0825 21:09:50.485462 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.445639 (* 1 = 0.445639 loss)
I0825 21:09:50.485471 27361 sgd_solver.cpp:106] Iteration 6290, lr = 5.42884e-06
I0825 21:10:09.693634 27361 solver.cpp:337] Iteration 6300, Testing net (#0)
I0825 21:10:13.845654 27361 solver.cpp:404]     Test net output #0: accuracy = 0.912368
I0825 21:10:13.845697 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.618213 (* 1 = 0.618213 loss)
I0825 21:10:15.861984 27361 solver.cpp:228] Iteration 6300, loss = 0.57031
I0825 21:10:15.862027 27361 solver.cpp:244]     Train net output #0: accuracy = 0.979862
I0825 21:10:15.862036 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0794543 (* 1 = 0.0794543 loss)
I0825 21:10:15.862045 27361 sgd_solver.cpp:106] Iteration 6300, lr = 5.42524e-06
I0825 21:10:37.195509 27361 solver.cpp:228] Iteration 6310, loss = 0.509453
I0825 21:10:37.195559 27361 solver.cpp:244]     Train net output #0: accuracy = 0.906559
I0825 21:10:37.195567 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.475742 (* 1 = 0.475742 loss)
I0825 21:10:37.195582 27361 sgd_solver.cpp:106] Iteration 6310, lr = 5.42164e-06
I0825 21:10:58.580632 27361 solver.cpp:228] Iteration 6320, loss = 0.74309
I0825 21:10:58.580739 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926826
I0825 21:10:58.580750 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.691897 (* 1 = 0.691897 loss)
I0825 21:10:58.580759 27361 sgd_solver.cpp:106] Iteration 6320, lr = 5.41805e-06
I0825 21:11:19.921757 27361 solver.cpp:228] Iteration 6330, loss = 0.427302
I0825 21:11:19.921804 27361 solver.cpp:244]     Train net output #0: accuracy = 0.986393
I0825 21:11:19.921813 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0537064 (* 1 = 0.0537064 loss)
I0825 21:11:19.921821 27361 sgd_solver.cpp:106] Iteration 6330, lr = 5.41446e-06
I0825 21:11:41.265550 27361 solver.cpp:228] Iteration 6340, loss = 0.79927
I0825 21:11:41.265610 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933388
I0825 21:11:41.265620 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.313394 (* 1 = 0.313394 loss)
I0825 21:11:41.265628 27361 sgd_solver.cpp:106] Iteration 6340, lr = 5.41088e-06
I0825 21:12:02.608846 27361 solver.cpp:228] Iteration 6350, loss = 0.483526
I0825 21:12:02.608896 27361 solver.cpp:244]     Train net output #0: accuracy = 0.886589
I0825 21:12:02.608906 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.73905 (* 1 = 1.73905 loss)
I0825 21:12:02.608912 27361 sgd_solver.cpp:106] Iteration 6350, lr = 5.4073e-06
I0825 21:12:23.968267 27361 solver.cpp:228] Iteration 6360, loss = 0.664355
I0825 21:12:23.968328 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955212
I0825 21:12:23.968338 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.316647 (* 1 = 0.316647 loss)
I0825 21:12:23.968346 27361 sgd_solver.cpp:106] Iteration 6360, lr = 5.40373e-06
I0825 21:12:45.414122 27361 solver.cpp:228] Iteration 6370, loss = 0.492569
I0825 21:12:45.414170 27361 solver.cpp:244]     Train net output #0: accuracy = 0.940697
I0825 21:12:45.414180 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.818115 (* 1 = 0.818115 loss)
I0825 21:12:45.414187 27361 sgd_solver.cpp:106] Iteration 6370, lr = 5.40017e-06
I0825 21:13:06.759822 27361 solver.cpp:228] Iteration 6380, loss = 0.558845
I0825 21:13:06.759951 27361 solver.cpp:244]     Train net output #0: accuracy = 0.931866
I0825 21:13:06.759963 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.378417 (* 1 = 0.378417 loss)
I0825 21:13:06.759970 27361 sgd_solver.cpp:106] Iteration 6380, lr = 5.39661e-06
I0825 21:13:28.105993 27361 solver.cpp:228] Iteration 6390, loss = 0.547038
I0825 21:13:28.106042 27361 solver.cpp:244]     Train net output #0: accuracy = 0.959538
I0825 21:13:28.106051 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0795085 (* 1 = 0.0795085 loss)
I0825 21:13:28.106058 27361 sgd_solver.cpp:106] Iteration 6390, lr = 5.39305e-06
I0825 21:13:47.349192 27361 solver.cpp:337] Iteration 6400, Testing net (#0)
I0825 21:13:51.495393 27361 solver.cpp:404]     Test net output #0: accuracy = 0.917712
I0825 21:13:51.495440 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.545714 (* 1 = 0.545714 loss)
I0825 21:13:53.510376 27361 solver.cpp:228] Iteration 6400, loss = 0.496986
I0825 21:13:53.510423 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889732
I0825 21:13:53.510432 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.616048 (* 1 = 0.616048 loss)
I0825 21:13:53.510439 27361 sgd_solver.cpp:106] Iteration 6400, lr = 5.3895e-06
I0825 21:14:14.840721 27361 solver.cpp:228] Iteration 6410, loss = 0.42251
I0825 21:14:14.840767 27361 solver.cpp:244]     Train net output #0: accuracy = 0.980225
I0825 21:14:14.840777 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0970648 (* 1 = 0.0970648 loss)
I0825 21:14:14.840785 27361 sgd_solver.cpp:106] Iteration 6410, lr = 5.38596e-06
I0825 21:14:36.166836 27361 solver.cpp:228] Iteration 6420, loss = 0.527783
I0825 21:14:36.166942 27361 solver.cpp:244]     Train net output #0: accuracy = 0.909367
I0825 21:14:36.166952 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.845524 (* 1 = 0.845524 loss)
I0825 21:14:36.166960 27361 sgd_solver.cpp:106] Iteration 6420, lr = 5.38242e-06
I0825 21:14:57.494730 27361 solver.cpp:228] Iteration 6430, loss = 0.249048
I0825 21:14:57.494778 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966537
I0825 21:14:57.494787 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0536767 (* 1 = 0.0536767 loss)
I0825 21:14:57.494796 27361 sgd_solver.cpp:106] Iteration 6430, lr = 5.37889e-06
I0825 21:15:18.827003 27361 solver.cpp:228] Iteration 6440, loss = 0.437982
I0825 21:15:18.827121 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923828
I0825 21:15:18.827131 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.377035 (* 1 = 0.377035 loss)
I0825 21:15:18.827138 27361 sgd_solver.cpp:106] Iteration 6440, lr = 5.37537e-06
I0825 21:15:40.209671 27361 solver.cpp:228] Iteration 6450, loss = 0.49385
I0825 21:15:40.209718 27361 solver.cpp:244]     Train net output #0: accuracy = 0.905605
I0825 21:15:40.209728 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.274478 (* 1 = 0.274478 loss)
I0825 21:15:40.209735 27361 sgd_solver.cpp:106] Iteration 6450, lr = 5.37184e-06
I0825 21:16:01.543830 27361 solver.cpp:228] Iteration 6460, loss = 0.340483
I0825 21:16:01.543933 27361 solver.cpp:244]     Train net output #0: accuracy = 0.999989
I0825 21:16:01.543943 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0113348 (* 1 = 0.0113348 loss)
I0825 21:16:01.543951 27361 sgd_solver.cpp:106] Iteration 6460, lr = 5.36833e-06
I0825 21:16:22.882145 27361 solver.cpp:228] Iteration 6470, loss = 0.461169
I0825 21:16:22.882190 27361 solver.cpp:244]     Train net output #0: accuracy = 0.932194
I0825 21:16:22.882200 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.527242 (* 1 = 0.527242 loss)
I0825 21:16:22.882206 27361 sgd_solver.cpp:106] Iteration 6470, lr = 5.36482e-06
I0825 21:16:44.217296 27361 solver.cpp:228] Iteration 6480, loss = 0.687011
I0825 21:16:44.217445 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933083
I0825 21:16:44.217458 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.455416 (* 1 = 0.455416 loss)
I0825 21:16:44.217464 27361 sgd_solver.cpp:106] Iteration 6480, lr = 5.36131e-06
I0825 21:17:05.540839 27361 solver.cpp:228] Iteration 6490, loss = 0.467311
I0825 21:17:05.540882 27361 solver.cpp:244]     Train net output #0: accuracy = 0.884315
I0825 21:17:05.540892 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.898051 (* 1 = 0.898051 loss)
I0825 21:17:05.540899 27361 sgd_solver.cpp:106] Iteration 6490, lr = 5.35781e-06
I0825 21:17:24.729691 27361 solver.cpp:337] Iteration 6500, Testing net (#0)
I0825 21:17:28.874055 27361 solver.cpp:404]     Test net output #0: accuracy = 0.917033
I0825 21:17:28.874097 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.622006 (* 1 = 0.622006 loss)
I0825 21:17:30.888864 27361 solver.cpp:228] Iteration 6500, loss = 0.574474
I0825 21:17:30.888901 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966908
I0825 21:17:30.888913 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.10813 (* 1 = 0.10813 loss)
I0825 21:17:30.888924 27361 sgd_solver.cpp:106] Iteration 6500, lr = 5.35432e-06
I0825 21:17:52.264981 27361 solver.cpp:228] Iteration 6510, loss = 0.721347
I0825 21:17:52.265029 27361 solver.cpp:244]     Train net output #0: accuracy = 0.908207
I0825 21:17:52.265038 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.797226 (* 1 = 0.797226 loss)
I0825 21:17:52.265046 27361 sgd_solver.cpp:106] Iteration 6510, lr = 5.35083e-06
I0825 21:18:13.707626 27361 solver.cpp:228] Iteration 6520, loss = 0.616572
I0825 21:18:13.707728 27361 solver.cpp:244]     Train net output #0: accuracy = 0.878166
I0825 21:18:13.707739 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.562561 (* 1 = 0.562561 loss)
I0825 21:18:13.707746 27361 sgd_solver.cpp:106] Iteration 6520, lr = 5.34734e-06
I0825 21:18:35.054239 27361 solver.cpp:228] Iteration 6530, loss = 0.687285
I0825 21:18:35.054285 27361 solver.cpp:244]     Train net output #0: accuracy = 0.895889
I0825 21:18:35.054293 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.538597 (* 1 = 0.538597 loss)
I0825 21:18:35.054301 27361 sgd_solver.cpp:106] Iteration 6530, lr = 5.34387e-06
I0825 21:18:56.397837 27361 solver.cpp:228] Iteration 6540, loss = 0.648401
I0825 21:18:56.397945 27361 solver.cpp:244]     Train net output #0: accuracy = 0.988495
I0825 21:18:56.397956 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0344999 (* 1 = 0.0344999 loss)
I0825 21:18:56.397964 27361 sgd_solver.cpp:106] Iteration 6540, lr = 5.34039e-06
I0825 21:19:17.741017 27361 solver.cpp:228] Iteration 6550, loss = 0.589005
I0825 21:19:17.741060 27361 solver.cpp:244]     Train net output #0: accuracy = 0.881973
I0825 21:19:17.741070 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.808454 (* 1 = 0.808454 loss)
I0825 21:19:17.741076 27361 sgd_solver.cpp:106] Iteration 6550, lr = 5.33692e-06
I0825 21:19:39.085216 27361 solver.cpp:228] Iteration 6560, loss = 0.525208
I0825 21:19:39.085345 27361 solver.cpp:244]     Train net output #0: accuracy = 0.96209
I0825 21:19:39.085356 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.33892 (* 1 = 0.33892 loss)
I0825 21:19:39.085363 27361 sgd_solver.cpp:106] Iteration 6560, lr = 5.33346e-06
I0825 21:20:00.430264 27361 solver.cpp:228] Iteration 6570, loss = 0.633447
I0825 21:20:00.430310 27361 solver.cpp:244]     Train net output #0: accuracy = 0.850475
I0825 21:20:00.430320 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.946761 (* 1 = 0.946761 loss)
I0825 21:20:00.430328 27361 sgd_solver.cpp:106] Iteration 6570, lr = 5.33e-06
I0825 21:20:21.772871 27361 solver.cpp:228] Iteration 6580, loss = 0.563183
I0825 21:20:21.773003 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937035
I0825 21:20:21.773013 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.39133 (* 1 = 1.39133 loss)
I0825 21:20:21.773021 27361 sgd_solver.cpp:106] Iteration 6580, lr = 5.32655e-06
I0825 21:20:43.118240 27361 solver.cpp:228] Iteration 6590, loss = 0.594496
I0825 21:20:43.118288 27361 solver.cpp:244]     Train net output #0: accuracy = 0.983578
I0825 21:20:43.118297 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0450669 (* 1 = 0.0450669 loss)
I0825 21:20:43.118305 27361 sgd_solver.cpp:106] Iteration 6590, lr = 5.3231e-06
I0825 21:21:02.326745 27361 solver.cpp:337] Iteration 6600, Testing net (#0)
I0825 21:21:06.478451 27361 solver.cpp:404]     Test net output #0: accuracy = 0.92532
I0825 21:21:06.478498 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.640015 (* 1 = 0.640015 loss)
I0825 21:21:08.494285 27361 solver.cpp:228] Iteration 6600, loss = 0.552346
I0825 21:21:08.494333 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893742
I0825 21:21:08.494341 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36747 (* 1 = 1.36747 loss)
I0825 21:21:08.494359 27361 sgd_solver.cpp:106] Iteration 6600, lr = 5.31966e-06
I0825 21:21:29.835441 27361 solver.cpp:228] Iteration 6610, loss = 0.692287
I0825 21:21:29.835487 27361 solver.cpp:244]     Train net output #0: accuracy = 0.899677
I0825 21:21:29.835497 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.866783 (* 1 = 0.866783 loss)
I0825 21:21:29.835505 27361 sgd_solver.cpp:106] Iteration 6610, lr = 5.31622e-06
I0825 21:21:51.173641 27361 solver.cpp:228] Iteration 6620, loss = 0.565037
I0825 21:21:51.173754 27361 solver.cpp:244]     Train net output #0: accuracy = 0.94558
I0825 21:21:51.173765 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.130139 (* 1 = 0.130139 loss)
I0825 21:21:51.173774 27361 sgd_solver.cpp:106] Iteration 6620, lr = 5.31279e-06
I0825 21:22:12.518517 27361 solver.cpp:228] Iteration 6630, loss = 0.38633
I0825 21:22:12.518566 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951199
I0825 21:22:12.518576 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.264213 (* 1 = 0.264213 loss)
I0825 21:22:12.518584 27361 sgd_solver.cpp:106] Iteration 6630, lr = 5.30937e-06
I0825 21:22:33.883815 27361 solver.cpp:228] Iteration 6640, loss = 0.628682
I0825 21:22:33.883904 27361 solver.cpp:244]     Train net output #0: accuracy = 0.857548
I0825 21:22:33.883915 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36602 (* 1 = 1.36602 loss)
I0825 21:22:33.883924 27361 sgd_solver.cpp:106] Iteration 6640, lr = 5.30595e-06
I0825 21:22:55.226438 27361 solver.cpp:228] Iteration 6650, loss = 0.936555
I0825 21:22:55.226481 27361 solver.cpp:244]     Train net output #0: accuracy = 0.936073
I0825 21:22:55.226492 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.543724 (* 1 = 0.543724 loss)
I0825 21:22:55.226500 27361 sgd_solver.cpp:106] Iteration 6650, lr = 5.30253e-06
I0825 21:23:16.572116 27361 solver.cpp:228] Iteration 6660, loss = 0.319378
I0825 21:23:16.572224 27361 solver.cpp:244]     Train net output #0: accuracy = 0.92701
I0825 21:23:16.572235 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.28284 (* 1 = 0.28284 loss)
I0825 21:23:16.572242 27361 sgd_solver.cpp:106] Iteration 6660, lr = 5.29912e-06
I0825 21:23:37.915681 27361 solver.cpp:228] Iteration 6670, loss = 0.249485
I0825 21:23:37.915726 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963276
I0825 21:23:37.915735 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.222895 (* 1 = 0.222895 loss)
I0825 21:23:37.915743 27361 sgd_solver.cpp:106] Iteration 6670, lr = 5.29571e-06
I0825 21:23:59.262121 27361 solver.cpp:228] Iteration 6680, loss = 0.644485
I0825 21:23:59.262225 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928879
I0825 21:23:59.262235 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.167219 (* 1 = 0.167219 loss)
I0825 21:23:59.262244 27361 sgd_solver.cpp:106] Iteration 6680, lr = 5.29231e-06
I0825 21:24:20.605619 27361 solver.cpp:228] Iteration 6690, loss = 0.522198
I0825 21:24:20.605666 27361 solver.cpp:244]     Train net output #0: accuracy = 0.843437
I0825 21:24:20.605676 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.859301 (* 1 = 0.859301 loss)
I0825 21:24:20.605684 27361 sgd_solver.cpp:106] Iteration 6690, lr = 5.28892e-06
I0825 21:24:39.814738 27361 solver.cpp:337] Iteration 6700, Testing net (#0)
I0825 21:24:43.966063 27361 solver.cpp:404]     Test net output #0: accuracy = 0.917233
I0825 21:24:43.966105 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.653916 (* 1 = 0.653916 loss)
I0825 21:24:45.979954 27361 solver.cpp:228] Iteration 6700, loss = 0.291369
I0825 21:24:45.979996 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943245
I0825 21:24:45.980005 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.481881 (* 1 = 0.481881 loss)
I0825 21:24:45.980013 27361 sgd_solver.cpp:106] Iteration 6700, lr = 5.28552e-06
I0825 21:25:07.316676 27361 solver.cpp:228] Iteration 6710, loss = 0.583825
I0825 21:25:07.316730 27361 solver.cpp:244]     Train net output #0: accuracy = 0.930408
I0825 21:25:07.316740 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.782743 (* 1 = 0.782743 loss)
I0825 21:25:07.316747 27361 sgd_solver.cpp:106] Iteration 6710, lr = 5.28214e-06
I0825 21:25:28.648331 27361 solver.cpp:228] Iteration 6720, loss = 0.337954
I0825 21:25:28.648444 27361 solver.cpp:244]     Train net output #0: accuracy = 0.918549
I0825 21:25:28.648455 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.212961 (* 1 = 0.212961 loss)
I0825 21:25:28.648463 27361 sgd_solver.cpp:106] Iteration 6720, lr = 5.27876e-06
I0825 21:25:50.031325 27361 solver.cpp:228] Iteration 6730, loss = 0.453272
I0825 21:25:50.031373 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928276
I0825 21:25:50.031383 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.172839 (* 1 = 0.172839 loss)
I0825 21:25:50.031391 27361 sgd_solver.cpp:106] Iteration 6730, lr = 5.27538e-06
I0825 21:26:11.407783 27361 solver.cpp:228] Iteration 6740, loss = 0.820584
I0825 21:26:11.407886 27361 solver.cpp:244]     Train net output #0: accuracy = 0.895149
I0825 21:26:11.407897 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.05016 (* 1 = 1.05016 loss)
I0825 21:26:11.407904 27361 sgd_solver.cpp:106] Iteration 6740, lr = 5.27201e-06
I0825 21:26:32.745764 27361 solver.cpp:228] Iteration 6750, loss = 0.517278
I0825 21:26:32.745802 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951241
I0825 21:26:32.745812 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.34942 (* 1 = 0.34942 loss)
I0825 21:26:32.745820 27361 sgd_solver.cpp:106] Iteration 6750, lr = 5.26865e-06
I0825 21:26:54.078646 27361 solver.cpp:228] Iteration 6760, loss = 0.912733
I0825 21:26:54.078750 27361 solver.cpp:244]     Train net output #0: accuracy = 0.875935
I0825 21:26:54.078761 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.595949 (* 1 = 0.595949 loss)
I0825 21:26:54.078768 27361 sgd_solver.cpp:106] Iteration 6760, lr = 5.26529e-06
I0825 21:27:15.413893 27361 solver.cpp:228] Iteration 6770, loss = 0.526975
I0825 21:27:15.413940 27361 solver.cpp:244]     Train net output #0: accuracy = 0.953842
I0825 21:27:15.413949 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.133989 (* 1 = 0.133989 loss)
I0825 21:27:15.413956 27361 sgd_solver.cpp:106] Iteration 6770, lr = 5.26193e-06
I0825 21:27:36.886678 27361 solver.cpp:228] Iteration 6780, loss = 0.738416
I0825 21:27:36.886792 27361 solver.cpp:244]     Train net output #0: accuracy = 0.938381
I0825 21:27:36.886802 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.588409 (* 1 = 0.588409 loss)
I0825 21:27:36.886811 27361 sgd_solver.cpp:106] Iteration 6780, lr = 5.25858e-06
I0825 21:27:58.218788 27361 solver.cpp:228] Iteration 6790, loss = 0.288761
I0825 21:27:58.218832 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926022
I0825 21:27:58.218842 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.217869 (* 1 = 0.217869 loss)
I0825 21:27:58.218849 27361 sgd_solver.cpp:106] Iteration 6790, lr = 5.25524e-06
I0825 21:28:17.422011 27361 solver.cpp:337] Iteration 6800, Testing net (#0)
I0825 21:28:21.573747 27361 solver.cpp:404]     Test net output #0: accuracy = 0.91923
I0825 21:28:21.573787 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.606841 (* 1 = 0.606841 loss)
I0825 21:28:23.590301 27361 solver.cpp:228] Iteration 6800, loss = 0.859586
I0825 21:28:23.590348 27361 solver.cpp:244]     Train net output #0: accuracy = 0.885567
I0825 21:28:23.590356 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.04586 (* 1 = 1.04586 loss)
I0825 21:28:23.590364 27361 sgd_solver.cpp:106] Iteration 6800, lr = 5.25189e-06
I0825 21:28:44.929276 27361 solver.cpp:228] Iteration 6810, loss = 0.57883
I0825 21:28:44.929322 27361 solver.cpp:244]     Train net output #0: accuracy = 0.894413
I0825 21:28:44.929332 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.10723 (* 1 = 1.10723 loss)
I0825 21:28:44.929347 27361 sgd_solver.cpp:106] Iteration 6810, lr = 5.24856e-06
I0825 21:29:06.260608 27361 solver.cpp:228] Iteration 6820, loss = 0.562365
I0825 21:29:06.260716 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935192
I0825 21:29:06.260726 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.485918 (* 1 = 0.485918 loss)
I0825 21:29:06.260733 27361 sgd_solver.cpp:106] Iteration 6820, lr = 5.24523e-06
I0825 21:29:27.595126 27361 solver.cpp:228] Iteration 6830, loss = 0.523181
I0825 21:29:27.595175 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941528
I0825 21:29:27.595185 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.488187 (* 1 = 0.488187 loss)
I0825 21:29:27.595192 27361 sgd_solver.cpp:106] Iteration 6830, lr = 5.2419e-06
I0825 21:29:48.923439 27361 solver.cpp:228] Iteration 6840, loss = 0.479516
I0825 21:29:48.923542 27361 solver.cpp:244]     Train net output #0: accuracy = 0.895653
I0825 21:29:48.923552 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.179378 (* 1 = 0.179378 loss)
I0825 21:29:48.923558 27361 sgd_solver.cpp:106] Iteration 6840, lr = 5.23858e-06
I0825 21:30:10.288691 27361 solver.cpp:228] Iteration 6850, loss = 0.48627
I0825 21:30:10.288727 27361 solver.cpp:244]     Train net output #0: accuracy = 0.981876
I0825 21:30:10.288738 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0768038 (* 1 = 0.0768038 loss)
I0825 21:30:10.288745 27361 sgd_solver.cpp:106] Iteration 6850, lr = 5.23527e-06
I0825 21:30:31.631772 27361 solver.cpp:228] Iteration 6860, loss = 0.480865
I0825 21:30:31.631896 27361 solver.cpp:244]     Train net output #0: accuracy = 0.911766
I0825 21:30:31.631907 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.975432 (* 1 = 0.975432 loss)
I0825 21:30:31.631916 27361 sgd_solver.cpp:106] Iteration 6860, lr = 5.23195e-06
I0825 21:30:52.976439 27361 solver.cpp:228] Iteration 6870, loss = 0.330279
I0825 21:30:52.976485 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86536
I0825 21:30:52.976493 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.452019 (* 1 = 0.452019 loss)
I0825 21:30:52.976501 27361 sgd_solver.cpp:106] Iteration 6870, lr = 5.22865e-06
I0825 21:31:14.318754 27361 solver.cpp:228] Iteration 6880, loss = 0.51596
I0825 21:31:14.318855 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961407
I0825 21:31:14.318864 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.216951 (* 1 = 0.216951 loss)
I0825 21:31:14.318872 27361 sgd_solver.cpp:106] Iteration 6880, lr = 5.22535e-06
I0825 21:31:35.660410 27361 solver.cpp:228] Iteration 6890, loss = 0.361952
I0825 21:31:35.660454 27361 solver.cpp:244]     Train net output #0: accuracy = 0.858356
I0825 21:31:35.660462 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.362216 (* 1 = 0.362216 loss)
I0825 21:31:35.660470 27361 sgd_solver.cpp:106] Iteration 6890, lr = 5.22205e-06
I0825 21:31:54.854296 27361 solver.cpp:337] Iteration 6900, Testing net (#0)
I0825 21:31:58.995667 27361 solver.cpp:404]     Test net output #0: accuracy = 0.943668
I0825 21:31:58.995712 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.45129 (* 1 = 0.45129 loss)
I0825 21:32:01.009814 27361 solver.cpp:228] Iteration 6900, loss = 0.335136
I0825 21:32:01.009856 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955769
I0825 21:32:01.009866 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.423528 (* 1 = 0.423528 loss)
I0825 21:32:01.009874 27361 sgd_solver.cpp:106] Iteration 6900, lr = 5.21876e-06
I0825 21:32:22.335060 27361 solver.cpp:228] Iteration 6910, loss = 0.304522
I0825 21:32:22.335109 27361 solver.cpp:244]     Train net output #0: accuracy = 0.965492
I0825 21:32:22.335119 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0633353 (* 1 = 0.0633353 loss)
I0825 21:32:22.335126 27361 sgd_solver.cpp:106] Iteration 6910, lr = 5.21547e-06
I0825 21:32:43.775701 27361 solver.cpp:228] Iteration 6920, loss = 0.990527
I0825 21:32:43.775812 27361 solver.cpp:244]     Train net output #0: accuracy = 0.952469
I0825 21:32:43.775830 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.334806 (* 1 = 0.334806 loss)
I0825 21:32:43.775838 27361 sgd_solver.cpp:106] Iteration 6920, lr = 5.21219e-06
I0825 21:33:05.115082 27361 solver.cpp:228] Iteration 6930, loss = 0.572936
I0825 21:33:05.115130 27361 solver.cpp:244]     Train net output #0: accuracy = 1
I0825 21:33:05.115140 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.00123993 (* 1 = 0.00123993 loss)
I0825 21:33:05.115149 27361 sgd_solver.cpp:106] Iteration 6930, lr = 5.20891e-06
I0825 21:33:26.475093 27361 solver.cpp:228] Iteration 6940, loss = 0.318958
I0825 21:33:26.475206 27361 solver.cpp:244]     Train net output #0: accuracy = 0.858879
I0825 21:33:26.475217 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.288181 (* 1 = 0.288181 loss)
I0825 21:33:26.475225 27361 sgd_solver.cpp:106] Iteration 6940, lr = 5.20564e-06
I0825 21:33:47.838747 27361 solver.cpp:228] Iteration 6950, loss = 0.389329
I0825 21:33:47.838796 27361 solver.cpp:244]     Train net output #0: accuracy = 0.882637
I0825 21:33:47.838806 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.950692 (* 1 = 0.950692 loss)
I0825 21:33:47.838824 27361 sgd_solver.cpp:106] Iteration 6950, lr = 5.20237e-06
I0825 21:34:09.183703 27361 solver.cpp:228] Iteration 6960, loss = 0.258448
I0825 21:34:09.183815 27361 solver.cpp:244]     Train net output #0: accuracy = 0.931847
I0825 21:34:09.183826 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.2114 (* 1 = 0.2114 loss)
I0825 21:34:09.183833 27361 sgd_solver.cpp:106] Iteration 6960, lr = 5.19911e-06
I0825 21:34:30.510931 27361 solver.cpp:228] Iteration 6970, loss = 0.488361
I0825 21:34:30.510979 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95628
I0825 21:34:30.510989 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.541032 (* 1 = 0.541032 loss)
I0825 21:34:30.510996 27361 sgd_solver.cpp:106] Iteration 6970, lr = 5.19585e-06
I0825 21:34:51.919375 27361 solver.cpp:228] Iteration 6980, loss = 0.566909
I0825 21:34:51.919493 27361 solver.cpp:244]     Train net output #0: accuracy = 0.865742
I0825 21:34:51.919504 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.565368 (* 1 = 0.565368 loss)
I0825 21:34:51.919512 27361 sgd_solver.cpp:106] Iteration 6980, lr = 5.1926e-06
I0825 21:35:13.357435 27361 solver.cpp:228] Iteration 6990, loss = 0.561566
I0825 21:35:13.357482 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912109
I0825 21:35:13.357491 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.211709 (* 1 = 0.211709 loss)
I0825 21:35:13.357499 27361 sgd_solver.cpp:106] Iteration 6990, lr = 5.18935e-06
I0825 21:35:32.571504 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_7000.caffemodel
I0825 21:35:32.765162 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_7000.solverstate
I0825 21:35:32.802705 27361 solver.cpp:337] Iteration 7000, Testing net (#0)
I0825 21:35:36.835943 27361 solver.cpp:404]     Test net output #0: accuracy = 0.924817
I0825 21:35:36.835989 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.571281 (* 1 = 0.571281 loss)
I0825 21:35:38.851451 27361 solver.cpp:228] Iteration 7000, loss = 0.509742
I0825 21:35:38.851496 27361 solver.cpp:244]     Train net output #0: accuracy = 0.882706
I0825 21:35:38.851506 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.949643 (* 1 = 0.949643 loss)
I0825 21:35:38.851513 27361 sgd_solver.cpp:106] Iteration 7000, lr = 5.18611e-06
I0825 21:36:00.187489 27361 solver.cpp:228] Iteration 7010, loss = 0.509859
I0825 21:36:00.187538 27361 solver.cpp:244]     Train net output #0: accuracy = 0.908852
I0825 21:36:00.187548 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.276429 (* 1 = 0.276429 loss)
I0825 21:36:00.187556 27361 sgd_solver.cpp:106] Iteration 7010, lr = 5.18287e-06
I0825 21:36:21.571547 27361 solver.cpp:228] Iteration 7020, loss = 0.258044
I0825 21:36:21.571689 27361 solver.cpp:244]     Train net output #0: accuracy = 0.967228
I0825 21:36:21.571704 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.199241 (* 1 = 0.199241 loss)
I0825 21:36:21.571712 27361 sgd_solver.cpp:106] Iteration 7020, lr = 5.17964e-06
I0825 21:36:42.904899 27361 solver.cpp:228] Iteration 7030, loss = 0.516546
I0825 21:36:42.904947 27361 solver.cpp:244]     Train net output #0: accuracy = 0.820801
I0825 21:36:42.904955 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.626949 (* 1 = 0.626949 loss)
I0825 21:36:42.904963 27361 sgd_solver.cpp:106] Iteration 7030, lr = 5.17641e-06
I0825 21:37:04.235966 27361 solver.cpp:228] Iteration 7040, loss = 0.804234
I0825 21:37:04.236075 27361 solver.cpp:244]     Train net output #0: accuracy = 0.991619
I0825 21:37:04.236086 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0251225 (* 1 = 0.0251225 loss)
I0825 21:37:04.236094 27361 sgd_solver.cpp:106] Iteration 7040, lr = 5.17318e-06
I0825 21:37:25.566483 27361 solver.cpp:228] Iteration 7050, loss = 0.557873
I0825 21:37:25.566530 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956104
I0825 21:37:25.566540 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.217191 (* 1 = 0.217191 loss)
I0825 21:37:25.566547 27361 sgd_solver.cpp:106] Iteration 7050, lr = 5.16996e-06
I0825 21:37:46.953390 27361 solver.cpp:228] Iteration 7060, loss = 0.449635
I0825 21:37:46.953500 27361 solver.cpp:244]     Train net output #0: accuracy = 0.994484
I0825 21:37:46.953510 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0418469 (* 1 = 0.0418469 loss)
I0825 21:37:46.953518 27361 sgd_solver.cpp:106] Iteration 7060, lr = 5.16674e-06
I0825 21:38:08.284925 27361 solver.cpp:228] Iteration 7070, loss = 0.362797
I0825 21:38:08.284975 27361 solver.cpp:244]     Train net output #0: accuracy = 0.938007
I0825 21:38:08.284983 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.474256 (* 1 = 0.474256 loss)
I0825 21:38:08.284991 27361 sgd_solver.cpp:106] Iteration 7070, lr = 5.16353e-06
I0825 21:38:29.609254 27361 solver.cpp:228] Iteration 7080, loss = 1.24138
I0825 21:38:29.609361 27361 solver.cpp:244]     Train net output #0: accuracy = 0.73259
I0825 21:38:29.609371 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.59192 (* 1 = 2.59192 loss)
I0825 21:38:29.609380 27361 sgd_solver.cpp:106] Iteration 7080, lr = 5.16033e-06
I0825 21:38:50.983880 27361 solver.cpp:228] Iteration 7090, loss = 0.304084
I0825 21:38:50.983930 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93848
I0825 21:38:50.983939 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.564185 (* 1 = 0.564185 loss)
I0825 21:38:50.983950 27361 sgd_solver.cpp:106] Iteration 7090, lr = 5.15713e-06
I0825 21:39:10.190564 27361 solver.cpp:337] Iteration 7100, Testing net (#0)
I0825 21:39:14.339481 27361 solver.cpp:404]     Test net output #0: accuracy = 0.940709
I0825 21:39:14.339521 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.566378 (* 1 = 0.566378 loss)
I0825 21:39:16.354526 27361 solver.cpp:228] Iteration 7100, loss = 0.522218
I0825 21:39:16.354569 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941475
I0825 21:39:16.354578 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.609955 (* 1 = 0.609955 loss)
I0825 21:39:16.354586 27361 sgd_solver.cpp:106] Iteration 7100, lr = 5.15393e-06
I0825 21:39:37.689622 27361 solver.cpp:228] Iteration 7110, loss = 0.254496
I0825 21:39:37.689668 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971481
I0825 21:39:37.689677 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.169411 (* 1 = 0.169411 loss)
I0825 21:39:37.689684 27361 sgd_solver.cpp:106] Iteration 7110, lr = 5.15074e-06
I0825 21:39:59.009027 27361 solver.cpp:228] Iteration 7120, loss = 0.435968
I0825 21:39:59.009163 27361 solver.cpp:244]     Train net output #0: accuracy = 0.906033
I0825 21:39:59.009176 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.339934 (* 1 = 0.339934 loss)
I0825 21:39:59.009183 27361 sgd_solver.cpp:106] Iteration 7120, lr = 5.14755e-06
I0825 21:40:20.334616 27361 solver.cpp:228] Iteration 7130, loss = 0.569851
I0825 21:40:20.334662 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942726
I0825 21:40:20.334671 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0892453 (* 1 = 0.0892453 loss)
I0825 21:40:20.334679 27361 sgd_solver.cpp:106] Iteration 7130, lr = 5.14437e-06
I0825 21:40:41.705368 27361 solver.cpp:228] Iteration 7140, loss = 0.585101
I0825 21:40:41.705505 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923843
I0825 21:40:41.705523 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.534747 (* 1 = 0.534747 loss)
I0825 21:40:41.705543 27361 sgd_solver.cpp:106] Iteration 7140, lr = 5.14119e-06
I0825 21:41:03.037781 27361 solver.cpp:228] Iteration 7150, loss = 0.545934
I0825 21:41:03.037830 27361 solver.cpp:244]     Train net output #0: accuracy = 0.958656
I0825 21:41:03.037842 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.233076 (* 1 = 0.233076 loss)
I0825 21:41:03.037848 27361 sgd_solver.cpp:106] Iteration 7150, lr = 5.13801e-06
I0825 21:41:24.375072 27361 solver.cpp:228] Iteration 7160, loss = 0.81024
I0825 21:41:24.375177 27361 solver.cpp:244]     Train net output #0: accuracy = 0.726414
I0825 21:41:24.375187 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.00241 (* 1 = 2.00241 loss)
I0825 21:41:24.375195 27361 sgd_solver.cpp:106] Iteration 7160, lr = 5.13484e-06
I0825 21:41:45.707793 27361 solver.cpp:228] Iteration 7170, loss = 0.636269
I0825 21:41:45.707840 27361 solver.cpp:244]     Train net output #0: accuracy = 0.975704
I0825 21:41:45.707849 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.144334 (* 1 = 0.144334 loss)
I0825 21:41:45.707857 27361 sgd_solver.cpp:106] Iteration 7170, lr = 5.13168e-06
I0825 21:42:07.029644 27361 solver.cpp:228] Iteration 7180, loss = 0.329272
I0825 21:42:07.029734 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927269
I0825 21:42:07.029744 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.421166 (* 1 = 0.421166 loss)
I0825 21:42:07.029752 27361 sgd_solver.cpp:106] Iteration 7180, lr = 5.12852e-06
I0825 21:42:28.354406 27361 solver.cpp:228] Iteration 7190, loss = 0.408352
I0825 21:42:28.354455 27361 solver.cpp:244]     Train net output #0: accuracy = 0.947159
I0825 21:42:28.354465 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.573332 (* 1 = 0.573332 loss)
I0825 21:42:28.354472 27361 sgd_solver.cpp:106] Iteration 7190, lr = 5.12536e-06
I0825 21:42:47.543858 27361 solver.cpp:337] Iteration 7200, Testing net (#0)
I0825 21:42:51.694278 27361 solver.cpp:404]     Test net output #0: accuracy = 0.910488
I0825 21:42:51.694324 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.740074 (* 1 = 0.740074 loss)
I0825 21:42:53.708137 27361 solver.cpp:228] Iteration 7200, loss = 0.380248
I0825 21:42:53.708184 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929443
I0825 21:42:53.708194 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.610722 (* 1 = 0.610722 loss)
I0825 21:42:53.708200 27361 sgd_solver.cpp:106] Iteration 7200, lr = 5.12221e-06
I0825 21:43:15.080878 27361 solver.cpp:228] Iteration 7210, loss = 0.732913
I0825 21:43:15.080919 27361 solver.cpp:244]     Train net output #0: accuracy = 0.873215
I0825 21:43:15.080929 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.36593 (* 1 = 1.36593 loss)
I0825 21:43:15.080936 27361 sgd_solver.cpp:106] Iteration 7210, lr = 5.11907e-06
I0825 21:43:36.457309 27361 solver.cpp:228] Iteration 7220, loss = 0.795747
I0825 21:43:36.457440 27361 solver.cpp:244]     Train net output #0: accuracy = 0.823849
I0825 21:43:36.457453 27361 solver.cpp:244]     Train net output #1: softmaxloss = 3.20715 (* 1 = 3.20715 loss)
I0825 21:43:36.457460 27361 sgd_solver.cpp:106] Iteration 7220, lr = 5.11592e-06
I0825 21:43:57.832249 27361 solver.cpp:228] Iteration 7230, loss = 0.779168
I0825 21:43:57.832295 27361 solver.cpp:244]     Train net output #0: accuracy = 0.876793
I0825 21:43:57.832304 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.940195 (* 1 = 0.940195 loss)
I0825 21:43:57.832320 27361 sgd_solver.cpp:106] Iteration 7230, lr = 5.11279e-06
I0825 21:44:19.163816 27361 solver.cpp:228] Iteration 7240, loss = 0.495379
I0825 21:44:19.163939 27361 solver.cpp:244]     Train net output #0: accuracy = 0.932133
I0825 21:44:19.163949 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.50783 (* 1 = 0.50783 loss)
I0825 21:44:19.163957 27361 sgd_solver.cpp:106] Iteration 7240, lr = 5.10965e-06
I0825 21:44:40.536782 27361 solver.cpp:228] Iteration 7250, loss = 0.421967
I0825 21:44:40.536829 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954899
I0825 21:44:40.536839 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.257069 (* 1 = 0.257069 loss)
I0825 21:44:40.536846 27361 sgd_solver.cpp:106] Iteration 7250, lr = 5.10652e-06
I0825 21:45:01.876075 27361 solver.cpp:228] Iteration 7260, loss = 0.401801
I0825 21:45:01.876173 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926914
I0825 21:45:01.876183 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.663094 (* 1 = 0.663094 loss)
I0825 21:45:01.876190 27361 sgd_solver.cpp:106] Iteration 7260, lr = 5.1034e-06
I0825 21:45:23.212676 27361 solver.cpp:228] Iteration 7270, loss = 0.577356
I0825 21:45:23.212723 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929855
I0825 21:45:23.212733 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.467308 (* 1 = 0.467308 loss)
I0825 21:45:23.212740 27361 sgd_solver.cpp:106] Iteration 7270, lr = 5.10028e-06
I0825 21:45:44.544637 27361 solver.cpp:228] Iteration 7280, loss = 0.46234
I0825 21:45:44.544749 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90448
I0825 21:45:44.544759 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.561945 (* 1 = 0.561945 loss)
I0825 21:45:44.544767 27361 sgd_solver.cpp:106] Iteration 7280, lr = 5.09717e-06
I0825 21:46:05.886221 27361 solver.cpp:228] Iteration 7290, loss = 0.692012
I0825 21:46:05.886270 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935768
I0825 21:46:05.886279 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.642017 (* 1 = 0.642017 loss)
I0825 21:46:05.886287 27361 sgd_solver.cpp:106] Iteration 7290, lr = 5.09405e-06
I0825 21:46:25.092030 27361 solver.cpp:337] Iteration 7300, Testing net (#0)
I0825 21:46:29.243294 27361 solver.cpp:404]     Test net output #0: accuracy = 0.926629
I0825 21:46:29.243340 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.56034 (* 1 = 0.56034 loss)
I0825 21:46:31.260005 27361 solver.cpp:228] Iteration 7300, loss = 0.771893
I0825 21:46:31.260046 27361 solver.cpp:244]     Train net output #0: accuracy = 0.881336
I0825 21:46:31.260056 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.460807 (* 1 = 0.460807 loss)
I0825 21:46:31.260062 27361 sgd_solver.cpp:106] Iteration 7300, lr = 5.09095e-06
I0825 21:46:52.614704 27361 solver.cpp:228] Iteration 7310, loss = 0.450492
I0825 21:46:52.614750 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912899
I0825 21:46:52.614759 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.756475 (* 1 = 0.756475 loss)
I0825 21:46:52.614768 27361 sgd_solver.cpp:106] Iteration 7310, lr = 5.08785e-06
I0825 21:47:13.961452 27361 solver.cpp:228] Iteration 7320, loss = 0.638865
I0825 21:47:13.961585 27361 solver.cpp:244]     Train net output #0: accuracy = 0.891663
I0825 21:47:13.961596 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.584947 (* 1 = 0.584947 loss)
I0825 21:47:13.961603 27361 sgd_solver.cpp:106] Iteration 7320, lr = 5.08475e-06
I0825 21:47:35.305771 27361 solver.cpp:228] Iteration 7330, loss = 0.372463
I0825 21:47:35.305817 27361 solver.cpp:244]     Train net output #0: accuracy = 0.898907
I0825 21:47:35.305826 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.825287 (* 1 = 0.825287 loss)
I0825 21:47:35.305835 27361 sgd_solver.cpp:106] Iteration 7330, lr = 5.08165e-06
I0825 21:47:56.653053 27361 solver.cpp:228] Iteration 7340, loss = 0.408383
I0825 21:47:56.653141 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95879
I0825 21:47:56.653151 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.193597 (* 1 = 0.193597 loss)
I0825 21:47:56.653159 27361 sgd_solver.cpp:106] Iteration 7340, lr = 5.07857e-06
I0825 21:48:18.000411 27361 solver.cpp:228] Iteration 7350, loss = 0.207139
I0825 21:48:18.000459 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951881
I0825 21:48:18.000469 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.160986 (* 1 = 0.160986 loss)
I0825 21:48:18.000476 27361 sgd_solver.cpp:106] Iteration 7350, lr = 5.07548e-06
I0825 21:48:39.342288 27361 solver.cpp:228] Iteration 7360, loss = 0.327837
I0825 21:48:39.342389 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960468
I0825 21:48:39.342401 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.200132 (* 1 = 0.200132 loss)
I0825 21:48:39.342408 27361 sgd_solver.cpp:106] Iteration 7360, lr = 5.0724e-06
I0825 21:49:00.688052 27361 solver.cpp:228] Iteration 7370, loss = 0.423665
I0825 21:49:00.688098 27361 solver.cpp:244]     Train net output #0: accuracy = 0.970001
I0825 21:49:00.688108 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0684002 (* 1 = 0.0684002 loss)
I0825 21:49:00.688115 27361 sgd_solver.cpp:106] Iteration 7370, lr = 5.06933e-06
I0825 21:49:22.037091 27361 solver.cpp:228] Iteration 7380, loss = 0.634424
I0825 21:49:22.037199 27361 solver.cpp:244]     Train net output #0: accuracy = 0.952393
I0825 21:49:22.037209 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.21498 (* 1 = 0.21498 loss)
I0825 21:49:22.037216 27361 sgd_solver.cpp:106] Iteration 7380, lr = 5.06625e-06
I0825 21:49:43.573550 27361 solver.cpp:228] Iteration 7390, loss = 0.538932
I0825 21:49:43.573606 27361 solver.cpp:244]     Train net output #0: accuracy = 0.983246
I0825 21:49:43.573616 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0412278 (* 1 = 0.0412278 loss)
I0825 21:49:43.573626 27361 sgd_solver.cpp:106] Iteration 7390, lr = 5.06319e-06
I0825 21:50:02.791750 27361 solver.cpp:337] Iteration 7400, Testing net (#0)
I0825 21:50:06.943395 27361 solver.cpp:404]     Test net output #0: accuracy = 0.899201
I0825 21:50:06.943441 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.61409 (* 1 = 0.61409 loss)
I0825 21:50:08.959560 27361 solver.cpp:228] Iteration 7400, loss = 0.413138
I0825 21:50:08.959609 27361 solver.cpp:244]     Train net output #0: accuracy = 0.867878
I0825 21:50:08.959619 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.833152 (* 1 = 0.833152 loss)
I0825 21:50:08.959625 27361 sgd_solver.cpp:106] Iteration 7400, lr = 5.06012e-06
I0825 21:50:30.297312 27361 solver.cpp:228] Iteration 7410, loss = 0.553696
I0825 21:50:30.297359 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935097
I0825 21:50:30.297369 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.592152 (* 1 = 0.592152 loss)
I0825 21:50:30.297375 27361 sgd_solver.cpp:106] Iteration 7410, lr = 5.05707e-06
I0825 21:50:51.640159 27361 solver.cpp:228] Iteration 7420, loss = 0.54956
I0825 21:50:51.640250 27361 solver.cpp:244]     Train net output #0: accuracy = 0.91127
I0825 21:50:51.640260 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.392191 (* 1 = 0.392191 loss)
I0825 21:50:51.640267 27361 sgd_solver.cpp:106] Iteration 7420, lr = 5.05401e-06
I0825 21:51:13.036939 27361 solver.cpp:228] Iteration 7430, loss = 0.583692
I0825 21:51:13.036988 27361 solver.cpp:244]     Train net output #0: accuracy = 0.907032
I0825 21:51:13.036996 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.640656 (* 1 = 0.640656 loss)
I0825 21:51:13.037005 27361 sgd_solver.cpp:106] Iteration 7430, lr = 5.05096e-06
I0825 21:51:34.372097 27361 solver.cpp:228] Iteration 7440, loss = 0.764968
I0825 21:51:34.372159 27361 solver.cpp:244]     Train net output #0: accuracy = 0.870605
I0825 21:51:34.372169 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.16523 (* 1 = 2.16523 loss)
I0825 21:51:34.372184 27361 sgd_solver.cpp:106] Iteration 7440, lr = 5.04792e-06
I0825 21:51:55.715412 27361 solver.cpp:228] Iteration 7450, loss = 0.548379
I0825 21:51:55.715456 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889462
I0825 21:51:55.715466 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.300409 (* 1 = 0.300409 loss)
I0825 21:51:55.715473 27361 sgd_solver.cpp:106] Iteration 7450, lr = 5.04488e-06
I0825 21:52:17.054533 27361 solver.cpp:228] Iteration 7460, loss = 0.560976
I0825 21:52:17.054651 27361 solver.cpp:244]     Train net output #0: accuracy = 0.987827
I0825 21:52:17.054661 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.039152 (* 1 = 0.039152 loss)
I0825 21:52:17.054669 27361 sgd_solver.cpp:106] Iteration 7460, lr = 5.04184e-06
I0825 21:52:38.420346 27361 solver.cpp:228] Iteration 7470, loss = 0.579151
I0825 21:52:38.420394 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950417
I0825 21:52:38.420403 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.377413 (* 1 = 0.377413 loss)
I0825 21:52:38.420411 27361 sgd_solver.cpp:106] Iteration 7470, lr = 5.03881e-06
I0825 21:52:59.763206 27361 solver.cpp:228] Iteration 7480, loss = 0.626358
I0825 21:52:59.763301 27361 solver.cpp:244]     Train net output #0: accuracy = 0.887119
I0825 21:52:59.763312 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.471379 (* 1 = 0.471379 loss)
I0825 21:52:59.763319 27361 sgd_solver.cpp:106] Iteration 7480, lr = 5.03578e-06
I0825 21:53:21.163079 27361 solver.cpp:228] Iteration 7490, loss = 0.735395
I0825 21:53:21.163135 27361 solver.cpp:244]     Train net output #0: accuracy = 0.84885
I0825 21:53:21.163146 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.20282 (* 1 = 2.20282 loss)
I0825 21:53:21.163154 27361 sgd_solver.cpp:106] Iteration 7490, lr = 5.03275e-06
I0825 21:53:40.421751 27361 solver.cpp:337] Iteration 7500, Testing net (#0)
I0825 21:53:44.569751 27361 solver.cpp:404]     Test net output #0: accuracy = 0.920862
I0825 21:53:44.569797 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.589474 (* 1 = 0.589474 loss)
I0825 21:53:46.585047 27361 solver.cpp:228] Iteration 7500, loss = 0.415475
I0825 21:53:46.585093 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927338
I0825 21:53:46.585103 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.872797 (* 1 = 0.872797 loss)
I0825 21:53:46.585110 27361 sgd_solver.cpp:106] Iteration 7500, lr = 5.02973e-06
I0825 21:54:08.015424 27361 solver.cpp:228] Iteration 7510, loss = 0.491697
I0825 21:54:08.015472 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973465
I0825 21:54:08.015482 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.254128 (* 1 = 0.254128 loss)
I0825 21:54:08.015496 27361 sgd_solver.cpp:106] Iteration 7510, lr = 5.02672e-06
I0825 21:54:29.349980 27361 solver.cpp:228] Iteration 7520, loss = 0.543623
I0825 21:54:29.350057 27361 solver.cpp:244]     Train net output #0: accuracy = 0.831902
I0825 21:54:29.350069 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.403602 (* 1 = 0.403602 loss)
I0825 21:54:29.350076 27361 sgd_solver.cpp:106] Iteration 7520, lr = 5.02371e-06
I0825 21:54:50.686882 27361 solver.cpp:228] Iteration 7530, loss = 0.52514
I0825 21:54:50.686925 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960735
I0825 21:54:50.686935 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.515747 (* 1 = 0.515747 loss)
I0825 21:54:50.686942 27361 sgd_solver.cpp:106] Iteration 7530, lr = 5.0207e-06
I0825 21:55:12.021246 27361 solver.cpp:228] Iteration 7540, loss = 0.503022
I0825 21:55:12.021384 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971901
I0825 21:55:12.021395 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0719047 (* 1 = 0.0719047 loss)
I0825 21:55:12.021404 27361 sgd_solver.cpp:106] Iteration 7540, lr = 5.0177e-06
I0825 21:55:33.363417 27361 solver.cpp:228] Iteration 7550, loss = 0.575357
I0825 21:55:33.363463 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963852
I0825 21:55:33.363482 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.637112 (* 1 = 0.637112 loss)
I0825 21:55:33.363490 27361 sgd_solver.cpp:106] Iteration 7550, lr = 5.0147e-06
I0825 21:55:54.802224 27361 solver.cpp:228] Iteration 7560, loss = 0.761238
I0825 21:55:54.802340 27361 solver.cpp:244]     Train net output #0: accuracy = 0.981178
I0825 21:55:54.802350 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0929545 (* 1 = 0.0929545 loss)
I0825 21:55:54.802357 27361 sgd_solver.cpp:106] Iteration 7560, lr = 5.0117e-06
I0825 21:56:16.142362 27361 solver.cpp:228] Iteration 7570, loss = 0.47109
I0825 21:56:16.142406 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921738
I0825 21:56:16.142416 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.315727 (* 1 = 0.315727 loss)
I0825 21:56:16.142423 27361 sgd_solver.cpp:106] Iteration 7570, lr = 5.00871e-06
I0825 21:56:37.476238 27361 solver.cpp:228] Iteration 7580, loss = 0.518137
I0825 21:56:37.476337 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912209
I0825 21:56:37.476348 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.543774 (* 1 = 0.543774 loss)
I0825 21:56:37.476356 27361 sgd_solver.cpp:106] Iteration 7580, lr = 5.00573e-06
I0825 21:56:58.816027 27361 solver.cpp:228] Iteration 7590, loss = 0.461246
I0825 21:56:58.816074 27361 solver.cpp:244]     Train net output #0: accuracy = 0.987156
I0825 21:56:58.816084 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.106288 (* 1 = 0.106288 loss)
I0825 21:56:58.816092 27361 sgd_solver.cpp:106] Iteration 7590, lr = 5.00274e-06
I0825 21:57:18.025748 27361 solver.cpp:337] Iteration 7600, Testing net (#0)
I0825 21:57:22.176852 27361 solver.cpp:404]     Test net output #0: accuracy = 0.918734
I0825 21:57:22.176895 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.742665 (* 1 = 0.742665 loss)
I0825 21:57:24.193305 27361 solver.cpp:228] Iteration 7600, loss = 0.42793
I0825 21:57:24.193352 27361 solver.cpp:244]     Train net output #0: accuracy = 0.967323
I0825 21:57:24.193361 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.428419 (* 1 = 0.428419 loss)
I0825 21:57:24.193369 27361 sgd_solver.cpp:106] Iteration 7600, lr = 4.99976e-06
I0825 21:57:45.544070 27361 solver.cpp:228] Iteration 7610, loss = 0.520629
I0825 21:57:45.544118 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935368
I0825 21:57:45.544127 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.563376 (* 1 = 0.563376 loss)
I0825 21:57:45.544134 27361 sgd_solver.cpp:106] Iteration 7610, lr = 4.99679e-06
I0825 21:58:06.890648 27361 solver.cpp:228] Iteration 7620, loss = 0.454073
I0825 21:58:06.890754 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973938
I0825 21:58:06.890765 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.202402 (* 1 = 0.202402 loss)
I0825 21:58:06.890774 27361 sgd_solver.cpp:106] Iteration 7620, lr = 4.99382e-06
I0825 21:58:28.341255 27361 solver.cpp:228] Iteration 7630, loss = 0.339805
I0825 21:58:28.341305 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927692
I0825 21:58:28.341315 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.202971 (* 1 = 0.202971 loss)
I0825 21:58:28.341322 27361 sgd_solver.cpp:106] Iteration 7630, lr = 4.99086e-06
I0825 21:58:49.674401 27361 solver.cpp:228] Iteration 7640, loss = 0.464232
I0825 21:58:49.674538 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962276
I0825 21:58:49.674549 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.653164 (* 1 = 0.653164 loss)
I0825 21:58:49.674557 27361 sgd_solver.cpp:106] Iteration 7640, lr = 4.98789e-06
I0825 21:59:11.011453 27361 solver.cpp:228] Iteration 7650, loss = 0.424389
I0825 21:59:11.011499 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942688
I0825 21:59:11.011509 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.332735 (* 1 = 0.332735 loss)
I0825 21:59:11.011517 27361 sgd_solver.cpp:106] Iteration 7650, lr = 4.98494e-06
I0825 21:59:32.345875 27361 solver.cpp:228] Iteration 7660, loss = 0.843778
I0825 21:59:32.345985 27361 solver.cpp:244]     Train net output #0: accuracy = 0.836235
I0825 21:59:32.345995 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.81305 (* 1 = 1.81305 loss)
I0825 21:59:32.346002 27361 sgd_solver.cpp:106] Iteration 7660, lr = 4.98198e-06
I0825 21:59:53.742621 27361 solver.cpp:228] Iteration 7670, loss = 0.497475
I0825 21:59:53.742666 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960922
I0825 21:59:53.742674 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.265316 (* 1 = 0.265316 loss)
I0825 21:59:53.742681 27361 sgd_solver.cpp:106] Iteration 7670, lr = 4.97903e-06
I0825 22:00:15.117967 27361 solver.cpp:228] Iteration 7680, loss = 0.528424
I0825 22:00:15.118078 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945564
I0825 22:00:15.118088 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.664074 (* 1 = 0.664074 loss)
I0825 22:00:15.118096 27361 sgd_solver.cpp:106] Iteration 7680, lr = 4.97609e-06
I0825 22:00:36.466706 27361 solver.cpp:228] Iteration 7690, loss = 0.409542
I0825 22:00:36.466753 27361 solver.cpp:244]     Train net output #0: accuracy = 0.944401
I0825 22:00:36.466763 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.417217 (* 1 = 0.417217 loss)
I0825 22:00:36.466771 27361 sgd_solver.cpp:106] Iteration 7690, lr = 4.97315e-06
I0825 22:00:55.678704 27361 solver.cpp:337] Iteration 7700, Testing net (#0)
I0825 22:00:59.829056 27361 solver.cpp:404]     Test net output #0: accuracy = 0.927401
I0825 22:00:59.829102 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.644022 (* 1 = 0.644022 loss)
I0825 22:01:01.845221 27361 solver.cpp:228] Iteration 7700, loss = 0.513204
I0825 22:01:01.845265 27361 solver.cpp:244]     Train net output #0: accuracy = 0.988434
I0825 22:01:01.845275 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0792658 (* 1 = 0.0792658 loss)
I0825 22:01:01.845283 27361 sgd_solver.cpp:106] Iteration 7700, lr = 4.97021e-06
I0825 22:01:23.185279 27361 solver.cpp:228] Iteration 7710, loss = 0.727564
I0825 22:01:23.185324 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9561
I0825 22:01:23.185334 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.447634 (* 1 = 0.447634 loss)
I0825 22:01:23.185341 27361 sgd_solver.cpp:106] Iteration 7710, lr = 4.96728e-06
I0825 22:01:44.624732 27361 solver.cpp:228] Iteration 7720, loss = 0.496077
I0825 22:01:44.624841 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935455
I0825 22:01:44.624851 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.449674 (* 1 = 0.449674 loss)
I0825 22:01:44.624860 27361 sgd_solver.cpp:106] Iteration 7720, lr = 4.96435e-06
I0825 22:02:05.986881 27361 solver.cpp:228] Iteration 7730, loss = 0.431598
I0825 22:02:05.986927 27361 solver.cpp:244]     Train net output #0: accuracy = 0.946537
I0825 22:02:05.986937 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.407365 (* 1 = 0.407365 loss)
I0825 22:02:05.986944 27361 sgd_solver.cpp:106] Iteration 7730, lr = 4.96142e-06
I0825 22:02:27.335273 27361 solver.cpp:228] Iteration 7740, loss = 0.524468
I0825 22:02:27.335381 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923126
I0825 22:02:27.335392 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.282183 (* 1 = 0.282183 loss)
I0825 22:02:27.335400 27361 sgd_solver.cpp:106] Iteration 7740, lr = 4.9585e-06
I0825 22:02:48.680481 27361 solver.cpp:228] Iteration 7750, loss = 0.697819
I0825 22:02:48.680528 27361 solver.cpp:244]     Train net output #0: accuracy = 0.888355
I0825 22:02:48.680538 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.467328 (* 1 = 0.467328 loss)
I0825 22:02:48.680546 27361 sgd_solver.cpp:106] Iteration 7750, lr = 4.95558e-06
I0825 22:03:10.065403 27361 solver.cpp:228] Iteration 7760, loss = 0.455033
I0825 22:03:10.065513 27361 solver.cpp:244]     Train net output #0: accuracy = 0.932087
I0825 22:03:10.065524 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.445498 (* 1 = 0.445498 loss)
I0825 22:03:10.065539 27361 sgd_solver.cpp:106] Iteration 7760, lr = 4.95267e-06
I0825 22:03:31.399873 27361 solver.cpp:228] Iteration 7770, loss = 0.402207
I0825 22:03:31.399920 27361 solver.cpp:244]     Train net output #0: accuracy = 0.898533
I0825 22:03:31.399930 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.757414 (* 1 = 0.757414 loss)
I0825 22:03:31.399937 27361 sgd_solver.cpp:106] Iteration 7770, lr = 4.94976e-06
I0825 22:03:52.733773 27361 solver.cpp:228] Iteration 7780, loss = 0.541202
I0825 22:03:52.733882 27361 solver.cpp:244]     Train net output #0: accuracy = 0.96484
I0825 22:03:52.733892 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.195751 (* 1 = 0.195751 loss)
I0825 22:03:52.733901 27361 sgd_solver.cpp:106] Iteration 7780, lr = 4.94686e-06
I0825 22:04:14.066498 27361 solver.cpp:228] Iteration 7790, loss = 0.59876
I0825 22:04:14.066545 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973049
I0825 22:04:14.066555 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.183427 (* 1 = 0.183427 loss)
I0825 22:04:14.066562 27361 sgd_solver.cpp:106] Iteration 7790, lr = 4.94396e-06
I0825 22:04:33.325919 27361 solver.cpp:337] Iteration 7800, Testing net (#0)
I0825 22:04:37.477043 27361 solver.cpp:404]     Test net output #0: accuracy = 0.925729
I0825 22:04:37.477089 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.75333 (* 1 = 0.75333 loss)
I0825 22:04:39.492411 27361 solver.cpp:228] Iteration 7800, loss = 0.393073
I0825 22:04:39.492455 27361 solver.cpp:244]     Train net output #0: accuracy = 0.984001
I0825 22:04:39.492465 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.07848 (* 1 = 0.07848 loss)
I0825 22:04:39.492472 27361 sgd_solver.cpp:106] Iteration 7800, lr = 4.94106e-06
I0825 22:05:00.830305 27361 solver.cpp:228] Iteration 7810, loss = 0.565631
I0825 22:05:00.830351 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9519
I0825 22:05:00.830360 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.25571 (* 1 = 0.25571 loss)
I0825 22:05:00.830368 27361 sgd_solver.cpp:106] Iteration 7810, lr = 4.93817e-06
I0825 22:05:22.165338 27361 solver.cpp:228] Iteration 7820, loss = 0.435523
I0825 22:05:22.165400 27361 solver.cpp:244]     Train net output #0: accuracy = 0.974487
I0825 22:05:22.165410 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.118281 (* 1 = 0.118281 loss)
I0825 22:05:22.165417 27361 sgd_solver.cpp:106] Iteration 7820, lr = 4.93528e-06
I0825 22:05:43.498220 27361 solver.cpp:228] Iteration 7830, loss = 0.706113
I0825 22:05:43.498267 27361 solver.cpp:244]     Train net output #0: accuracy = 0.983475
I0825 22:05:43.498277 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0573168 (* 1 = 0.0573168 loss)
I0825 22:05:43.498286 27361 sgd_solver.cpp:106] Iteration 7830, lr = 4.93239e-06
I0825 22:06:04.830139 27361 solver.cpp:228] Iteration 7840, loss = 0.744776
I0825 22:06:04.830274 27361 solver.cpp:244]     Train net output #0: accuracy = 0.91563
I0825 22:06:04.830286 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.861263 (* 1 = 0.861263 loss)
I0825 22:06:04.830293 27361 sgd_solver.cpp:106] Iteration 7840, lr = 4.92951e-06
I0825 22:06:26.258044 27361 solver.cpp:228] Iteration 7850, loss = 1.11337
I0825 22:06:26.258091 27361 solver.cpp:244]     Train net output #0: accuracy = 0.911858
I0825 22:06:26.258101 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.705351 (* 1 = 0.705351 loss)
I0825 22:06:26.258108 27361 sgd_solver.cpp:106] Iteration 7850, lr = 4.92663e-06
I0825 22:06:47.576176 27361 solver.cpp:228] Iteration 7860, loss = 0.382477
I0825 22:06:47.576284 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929005
I0825 22:06:47.576295 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.692093 (* 1 = 0.692093 loss)
I0825 22:06:47.576303 27361 sgd_solver.cpp:106] Iteration 7860, lr = 4.92376e-06
I0825 22:07:08.894878 27361 solver.cpp:228] Iteration 7870, loss = 0.459114
I0825 22:07:08.894927 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86969
I0825 22:07:08.894944 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.929545 (* 1 = 0.929545 loss)
I0825 22:07:08.894953 27361 sgd_solver.cpp:106] Iteration 7870, lr = 4.92089e-06
I0825 22:07:30.260911 27361 solver.cpp:228] Iteration 7880, loss = 0.339426
I0825 22:07:30.261013 27361 solver.cpp:244]     Train net output #0: accuracy = 0.894722
I0825 22:07:30.261023 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.310559 (* 1 = 0.310559 loss)
I0825 22:07:30.261031 27361 sgd_solver.cpp:106] Iteration 7880, lr = 4.91802e-06
I0825 22:07:51.594812 27361 solver.cpp:228] Iteration 7890, loss = 0.392415
I0825 22:07:51.594857 27361 solver.cpp:244]     Train net output #0: accuracy = 0.930199
I0825 22:07:51.594867 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.242125 (* 1 = 0.242125 loss)
I0825 22:07:51.594874 27361 sgd_solver.cpp:106] Iteration 7890, lr = 4.91516e-06
I0825 22:08:10.797811 27361 solver.cpp:337] Iteration 7900, Testing net (#0)
I0825 22:08:14.943503 27361 solver.cpp:404]     Test net output #0: accuracy = 0.942915
I0825 22:08:14.943549 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.629639 (* 1 = 0.629639 loss)
I0825 22:08:16.959353 27361 solver.cpp:228] Iteration 7900, loss = 0.397095
I0825 22:08:16.959399 27361 solver.cpp:244]     Train net output #0: accuracy = 0.989792
I0825 22:08:16.959408 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.130863 (* 1 = 0.130863 loss)
I0825 22:08:16.959416 27361 sgd_solver.cpp:106] Iteration 7900, lr = 4.9123e-06
I0825 22:08:38.301440 27361 solver.cpp:228] Iteration 7910, loss = 0.477389
I0825 22:08:38.301482 27361 solver.cpp:244]     Train net output #0: accuracy = 0.922699
I0825 22:08:38.301492 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.68641 (* 1 = 0.68641 loss)
I0825 22:08:38.301499 27361 sgd_solver.cpp:106] Iteration 7910, lr = 4.90945e-06
I0825 22:08:59.651365 27361 solver.cpp:228] Iteration 7920, loss = 0.339108
I0825 22:08:59.651468 27361 solver.cpp:244]     Train net output #0: accuracy = 0.987465
I0825 22:08:59.651479 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.052564 (* 1 = 0.052564 loss)
I0825 22:08:59.651487 27361 sgd_solver.cpp:106] Iteration 7920, lr = 4.9066e-06
I0825 22:09:20.990646 27361 solver.cpp:228] Iteration 7930, loss = 0.464472
I0825 22:09:20.990689 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939793
I0825 22:09:20.990698 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.203407 (* 1 = 0.203407 loss)
I0825 22:09:20.990706 27361 sgd_solver.cpp:106] Iteration 7930, lr = 4.90375e-06
I0825 22:09:42.334086 27361 solver.cpp:228] Iteration 7940, loss = 0.620459
I0825 22:09:42.334144 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927086
I0825 22:09:42.334154 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.469711 (* 1 = 0.469711 loss)
I0825 22:09:42.334161 27361 sgd_solver.cpp:106] Iteration 7940, lr = 4.90091e-06
I0825 22:10:03.679070 27361 solver.cpp:228] Iteration 7950, loss = 0.565924
I0825 22:10:03.679117 27361 solver.cpp:244]     Train net output #0: accuracy = 0.94733
I0825 22:10:03.679126 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.144341 (* 1 = 0.144341 loss)
I0825 22:10:03.679133 27361 sgd_solver.cpp:106] Iteration 7950, lr = 4.89807e-06
I0825 22:10:25.021653 27361 solver.cpp:228] Iteration 7960, loss = 0.735655
I0825 22:10:25.021806 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933979
I0825 22:10:25.021816 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.492215 (* 1 = 0.492215 loss)
I0825 22:10:25.021824 27361 sgd_solver.cpp:106] Iteration 7960, lr = 4.89524e-06
I0825 22:10:46.361532 27361 solver.cpp:228] Iteration 7970, loss = 0.404519
I0825 22:10:46.361577 27361 solver.cpp:244]     Train net output #0: accuracy = 0.897354
I0825 22:10:46.361587 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.456386 (* 1 = 0.456386 loss)
I0825 22:10:46.361594 27361 sgd_solver.cpp:106] Iteration 7970, lr = 4.89241e-06
I0825 22:11:07.757064 27361 solver.cpp:228] Iteration 7980, loss = 0.620569
I0825 22:11:07.757182 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957954
I0825 22:11:07.757192 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.212005 (* 1 = 0.212005 loss)
I0825 22:11:07.757200 27361 sgd_solver.cpp:106] Iteration 7980, lr = 4.88958e-06
I0825 22:11:29.090435 27361 solver.cpp:228] Iteration 7990, loss = 0.513809
I0825 22:11:29.090483 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941231
I0825 22:11:29.090492 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.5164 (* 1 = 0.5164 loss)
I0825 22:11:29.090500 27361 sgd_solver.cpp:106] Iteration 7990, lr = 4.88676e-06
I0825 22:11:48.352200 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_8000.caffemodel
I0825 22:11:48.548090 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_8000.solverstate
I0825 22:11:48.586439 27361 solver.cpp:337] Iteration 8000, Testing net (#0)
I0825 22:11:52.619454 27361 solver.cpp:404]     Test net output #0: accuracy = 0.934053
I0825 22:11:52.619500 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.582861 (* 1 = 0.582861 loss)
I0825 22:11:54.634902 27361 solver.cpp:228] Iteration 8000, loss = 0.377265
I0825 22:11:54.634949 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941643
I0825 22:11:54.634958 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.332012 (* 1 = 0.332012 loss)
I0825 22:11:54.634965 27361 sgd_solver.cpp:106] Iteration 8000, lr = 4.88394e-06
I0825 22:12:15.974943 27361 solver.cpp:228] Iteration 8010, loss = 0.583745
I0825 22:12:15.974992 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955223
I0825 22:12:15.975002 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.133881 (* 1 = 0.133881 loss)
I0825 22:12:15.975009 27361 sgd_solver.cpp:106] Iteration 8010, lr = 4.88112e-06
I0825 22:12:37.406785 27361 solver.cpp:228] Iteration 8020, loss = 0.560656
I0825 22:12:37.406846 27361 solver.cpp:244]     Train net output #0: accuracy = 0.875237
I0825 22:12:37.406854 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.855132 (* 1 = 0.855132 loss)
I0825 22:12:37.406862 27361 sgd_solver.cpp:106] Iteration 8020, lr = 4.87831e-06
I0825 22:12:58.749969 27361 solver.cpp:228] Iteration 8030, loss = 0.405064
I0825 22:12:58.750013 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961365
I0825 22:12:58.750022 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.142422 (* 1 = 0.142422 loss)
I0825 22:12:58.750030 27361 sgd_solver.cpp:106] Iteration 8030, lr = 4.8755e-06
I0825 22:13:20.093026 27361 solver.cpp:228] Iteration 8040, loss = 0.524695
I0825 22:13:20.093128 27361 solver.cpp:244]     Train net output #0: accuracy = 0.920429
I0825 22:13:20.093139 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.691634 (* 1 = 0.691634 loss)
I0825 22:13:20.093147 27361 sgd_solver.cpp:106] Iteration 8040, lr = 4.8727e-06
I0825 22:13:41.435286 27361 solver.cpp:228] Iteration 8050, loss = 0.950772
I0825 22:13:41.435333 27361 solver.cpp:244]     Train net output #0: accuracy = 0.880093
I0825 22:13:41.435343 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.23519 (* 1 = 2.23519 loss)
I0825 22:13:41.435350 27361 sgd_solver.cpp:106] Iteration 8050, lr = 4.86989e-06
I0825 22:14:02.781369 27361 solver.cpp:228] Iteration 8060, loss = 0.558742
I0825 22:14:02.781505 27361 solver.cpp:244]     Train net output #0: accuracy = 0.938648
I0825 22:14:02.781517 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.664414 (* 1 = 0.664414 loss)
I0825 22:14:02.781525 27361 sgd_solver.cpp:106] Iteration 8060, lr = 4.8671e-06
I0825 22:14:24.127981 27361 solver.cpp:228] Iteration 8070, loss = 0.428164
I0825 22:14:24.128028 27361 solver.cpp:244]     Train net output #0: accuracy = 0.92448
I0825 22:14:24.128038 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.556808 (* 1 = 0.556808 loss)
I0825 22:14:24.128056 27361 sgd_solver.cpp:106] Iteration 8070, lr = 4.86431e-06
I0825 22:14:45.471091 27361 solver.cpp:228] Iteration 8080, loss = 0.383664
I0825 22:14:45.471199 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960815
I0825 22:14:45.471209 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.1744 (* 1 = 0.1744 loss)
I0825 22:14:45.471215 27361 sgd_solver.cpp:106] Iteration 8080, lr = 4.86152e-06
I0825 22:15:06.811149 27361 solver.cpp:228] Iteration 8090, loss = 0.516667
I0825 22:15:06.811197 27361 solver.cpp:244]     Train net output #0: accuracy = 0.790592
I0825 22:15:06.811206 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.765675 (* 1 = 0.765675 loss)
I0825 22:15:06.811213 27361 sgd_solver.cpp:106] Iteration 8090, lr = 4.85873e-06
I0825 22:15:26.058864 27361 solver.cpp:337] Iteration 8100, Testing net (#0)
I0825 22:15:30.265964 27361 solver.cpp:404]     Test net output #0: accuracy = 0.939484
I0825 22:15:30.266018 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.518679 (* 1 = 0.518679 loss)
I0825 22:15:32.292794 27361 solver.cpp:228] Iteration 8100, loss = 0.842878
I0825 22:15:32.292842 27361 solver.cpp:244]     Train net output #0: accuracy = 0.845058
I0825 22:15:32.292851 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.593835 (* 1 = 0.593835 loss)
I0825 22:15:32.292858 27361 sgd_solver.cpp:106] Iteration 8100, lr = 4.85595e-06
I0825 22:15:53.680869 27361 solver.cpp:228] Iteration 8110, loss = 0.58903
I0825 22:15:53.680917 27361 solver.cpp:244]     Train net output #0: accuracy = 0.906803
I0825 22:15:53.680927 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.277192 (* 1 = 0.277192 loss)
I0825 22:15:53.680934 27361 sgd_solver.cpp:106] Iteration 8110, lr = 4.85317e-06
I0825 22:16:15.015964 27361 solver.cpp:228] Iteration 8120, loss = 0.826509
I0825 22:16:15.016075 27361 solver.cpp:244]     Train net output #0: accuracy = 0.906036
I0825 22:16:15.016086 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.881952 (* 1 = 0.881952 loss)
I0825 22:16:15.016093 27361 sgd_solver.cpp:106] Iteration 8120, lr = 4.85039e-06
I0825 22:16:36.352124 27361 solver.cpp:228] Iteration 8130, loss = 0.617237
I0825 22:16:36.352172 27361 solver.cpp:244]     Train net output #0: accuracy = 0.967827
I0825 22:16:36.352181 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.170602 (* 1 = 0.170602 loss)
I0825 22:16:36.352190 27361 sgd_solver.cpp:106] Iteration 8130, lr = 4.84762e-06
I0825 22:16:57.684449 27361 solver.cpp:228] Iteration 8140, loss = 0.600849
I0825 22:16:57.684554 27361 solver.cpp:244]     Train net output #0: accuracy = 0.958099
I0825 22:16:57.684566 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.074881 (* 1 = 0.074881 loss)
I0825 22:16:57.684572 27361 sgd_solver.cpp:106] Iteration 8140, lr = 4.84486e-06
I0825 22:17:19.107867 27361 solver.cpp:228] Iteration 8150, loss = 0.590455
I0825 22:17:19.107923 27361 solver.cpp:244]     Train net output #0: accuracy = 0.919853
I0825 22:17:19.107933 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.805421 (* 1 = 0.805421 loss)
I0825 22:17:19.107942 27361 sgd_solver.cpp:106] Iteration 8150, lr = 4.84209e-06
I0825 22:17:40.505498 27361 solver.cpp:228] Iteration 8160, loss = 0.660312
I0825 22:17:40.505656 27361 solver.cpp:244]     Train net output #0: accuracy = 0.895077
I0825 22:17:40.505671 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.22726 (* 1 = 1.22726 loss)
I0825 22:17:40.505679 27361 sgd_solver.cpp:106] Iteration 8160, lr = 4.83933e-06
I0825 22:18:01.837898 27361 solver.cpp:228] Iteration 8170, loss = 0.377699
I0825 22:18:01.837945 27361 solver.cpp:244]     Train net output #0: accuracy = 0.981575
I0825 22:18:01.837955 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0994567 (* 1 = 0.0994567 loss)
I0825 22:18:01.837966 27361 sgd_solver.cpp:106] Iteration 8170, lr = 4.83658e-06
I0825 22:18:23.270733 27361 solver.cpp:228] Iteration 8180, loss = 0.308118
I0825 22:18:23.270838 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95031
I0825 22:18:23.270856 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.520645 (* 1 = 0.520645 loss)
I0825 22:18:23.270864 27361 sgd_solver.cpp:106] Iteration 8180, lr = 4.83383e-06
I0825 22:18:44.612705 27361 solver.cpp:228] Iteration 8190, loss = 0.668272
I0825 22:18:44.612751 27361 solver.cpp:244]     Train net output #0: accuracy = 0.901112
I0825 22:18:44.612761 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.9449 (* 1 = 1.9449 loss)
I0825 22:18:44.612768 27361 sgd_solver.cpp:106] Iteration 8190, lr = 4.83108e-06
I0825 22:19:03.815939 27361 solver.cpp:337] Iteration 8200, Testing net (#0)
I0825 22:19:07.965242 27361 solver.cpp:404]     Test net output #0: accuracy = 0.918889
I0825 22:19:07.965288 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.663413 (* 1 = 0.663413 loss)
I0825 22:19:09.981292 27361 solver.cpp:228] Iteration 8200, loss = 0.737241
I0825 22:19:09.981338 27361 solver.cpp:244]     Train net output #0: accuracy = 0.809265
I0825 22:19:09.981346 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.52114 (* 1 = 1.52114 loss)
I0825 22:19:09.981354 27361 sgd_solver.cpp:106] Iteration 8200, lr = 4.82833e-06
I0825 22:19:31.360606 27361 solver.cpp:228] Iteration 8210, loss = 0.962819
I0825 22:19:31.360676 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86552
I0825 22:19:31.360689 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.795754 (* 1 = 0.795754 loss)
I0825 22:19:31.360702 27361 sgd_solver.cpp:106] Iteration 8210, lr = 4.82559e-06
I0825 22:19:52.764750 27361 solver.cpp:228] Iteration 8220, loss = 0.798553
I0825 22:19:52.764859 27361 solver.cpp:244]     Train net output #0: accuracy = 0.970478
I0825 22:19:52.764870 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.340987 (* 1 = 0.340987 loss)
I0825 22:19:52.764878 27361 sgd_solver.cpp:106] Iteration 8220, lr = 4.82285e-06
I0825 22:20:14.109390 27361 solver.cpp:228] Iteration 8230, loss = 0.242196
I0825 22:20:14.109436 27361 solver.cpp:244]     Train net output #0: accuracy = 0.97131
I0825 22:20:14.109446 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.111327 (* 1 = 0.111327 loss)
I0825 22:20:14.109452 27361 sgd_solver.cpp:106] Iteration 8230, lr = 4.82012e-06
I0825 22:20:35.450781 27361 solver.cpp:228] Iteration 8240, loss = 0.602718
I0825 22:20:35.450841 27361 solver.cpp:244]     Train net output #0: accuracy = 0.879639
I0825 22:20:35.450850 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.01317 (* 1 = 1.01317 loss)
I0825 22:20:35.450858 27361 sgd_solver.cpp:106] Iteration 8240, lr = 4.81739e-06
I0825 22:20:56.793929 27361 solver.cpp:228] Iteration 8250, loss = 0.368576
I0825 22:20:56.793977 27361 solver.cpp:244]     Train net output #0: accuracy = 0.859653
I0825 22:20:56.793987 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.451857 (* 1 = 0.451857 loss)
I0825 22:20:56.794000 27361 sgd_solver.cpp:106] Iteration 8250, lr = 4.81466e-06
I0825 22:21:18.138365 27361 solver.cpp:228] Iteration 8260, loss = 0.393326
I0825 22:21:18.138460 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93745
I0825 22:21:18.138470 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.367761 (* 1 = 0.367761 loss)
I0825 22:21:18.138478 27361 sgd_solver.cpp:106] Iteration 8260, lr = 4.81194e-06
I0825 22:21:39.482957 27361 solver.cpp:228] Iteration 8270, loss = 0.537853
I0825 22:21:39.483003 27361 solver.cpp:244]     Train net output #0: accuracy = 0.953087
I0825 22:21:39.483014 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.282939 (* 1 = 0.282939 loss)
I0825 22:21:39.483021 27361 sgd_solver.cpp:106] Iteration 8270, lr = 4.80922e-06
I0825 22:22:00.825191 27361 solver.cpp:228] Iteration 8280, loss = 0.472632
I0825 22:22:00.825301 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956795
I0825 22:22:00.825314 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.947015 (* 1 = 0.947015 loss)
I0825 22:22:00.825321 27361 sgd_solver.cpp:106] Iteration 8280, lr = 4.8065e-06
I0825 22:22:22.170039 27361 solver.cpp:228] Iteration 8290, loss = 0.663763
I0825 22:22:22.170097 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966194
I0825 22:22:22.170107 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.223611 (* 1 = 0.223611 loss)
I0825 22:22:22.170115 27361 sgd_solver.cpp:106] Iteration 8290, lr = 4.80379e-06
I0825 22:22:41.380049 27361 solver.cpp:337] Iteration 8300, Testing net (#0)
I0825 22:22:45.528347 27361 solver.cpp:404]     Test net output #0: accuracy = 0.931095
I0825 22:22:45.528391 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.527428 (* 1 = 0.527428 loss)
I0825 22:22:47.545321 27361 solver.cpp:228] Iteration 8300, loss = 0.83227
I0825 22:22:47.545367 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929333
I0825 22:22:47.545375 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.789768 (* 1 = 0.789768 loss)
I0825 22:22:47.545382 27361 sgd_solver.cpp:106] Iteration 8300, lr = 4.80108e-06
I0825 22:23:08.890120 27361 solver.cpp:228] Iteration 8310, loss = 0.364868
I0825 22:23:08.890166 27361 solver.cpp:244]     Train net output #0: accuracy = 0.828568
I0825 22:23:08.890174 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.1293 (* 1 = 1.1293 loss)
I0825 22:23:08.890182 27361 sgd_solver.cpp:106] Iteration 8310, lr = 4.79837e-06
I0825 22:23:30.284611 27361 solver.cpp:228] Iteration 8320, loss = 0.549715
I0825 22:23:30.284718 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926708
I0825 22:23:30.284729 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.935656 (* 1 = 0.935656 loss)
I0825 22:23:30.284736 27361 sgd_solver.cpp:106] Iteration 8320, lr = 4.79567e-06
I0825 22:23:51.677947 27361 solver.cpp:228] Iteration 8330, loss = 0.442879
I0825 22:23:51.677994 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929726
I0825 22:23:51.678002 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.428479 (* 1 = 0.428479 loss)
I0825 22:23:51.678010 27361 sgd_solver.cpp:106] Iteration 8330, lr = 4.79297e-06
I0825 22:24:13.023758 27361 solver.cpp:228] Iteration 8340, loss = 0.656368
I0825 22:24:13.023869 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935368
I0825 22:24:13.023880 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.11992 (* 1 = 1.11992 loss)
I0825 22:24:13.023888 27361 sgd_solver.cpp:106] Iteration 8340, lr = 4.79028e-06
I0825 22:24:34.363919 27361 solver.cpp:228] Iteration 8350, loss = 0.531892
I0825 22:24:34.363966 27361 solver.cpp:244]     Train net output #0: accuracy = 0.98793
I0825 22:24:34.363976 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0786961 (* 1 = 0.0786961 loss)
I0825 22:24:34.363983 27361 sgd_solver.cpp:106] Iteration 8350, lr = 4.78759e-06
I0825 22:24:55.703503 27361 solver.cpp:228] Iteration 8360, loss = 0.582037
I0825 22:24:55.703605 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941792
I0825 22:24:55.703616 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.702476 (* 1 = 0.702476 loss)
I0825 22:24:55.703624 27361 sgd_solver.cpp:106] Iteration 8360, lr = 4.7849e-06
I0825 22:25:17.065485 27361 solver.cpp:228] Iteration 8370, loss = 0.520369
I0825 22:25:17.065539 27361 solver.cpp:244]     Train net output #0: accuracy = 0.848537
I0825 22:25:17.065548 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.952408 (* 1 = 0.952408 loss)
I0825 22:25:17.065557 27361 sgd_solver.cpp:106] Iteration 8370, lr = 4.78221e-06
I0825 22:25:38.448818 27361 solver.cpp:228] Iteration 8380, loss = 0.426292
I0825 22:25:38.448961 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945053
I0825 22:25:38.448972 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.387211 (* 1 = 0.387211 loss)
I0825 22:25:38.448979 27361 sgd_solver.cpp:106] Iteration 8380, lr = 4.77953e-06
I0825 22:25:59.783895 27361 solver.cpp:228] Iteration 8390, loss = 0.444466
I0825 22:25:59.783939 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957699
I0825 22:25:59.783948 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.40173 (* 1 = 0.40173 loss)
I0825 22:25:59.783967 27361 sgd_solver.cpp:106] Iteration 8390, lr = 4.77685e-06
I0825 22:26:19.037112 27361 solver.cpp:337] Iteration 8400, Testing net (#0)
I0825 22:26:23.180855 27361 solver.cpp:404]     Test net output #0: accuracy = 0.935137
I0825 22:26:23.180903 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.607162 (* 1 = 0.607162 loss)
I0825 22:26:25.195008 27361 solver.cpp:228] Iteration 8400, loss = 0.385183
I0825 22:26:25.195053 27361 solver.cpp:244]     Train net output #0: accuracy = 0.96524
I0825 22:26:25.195062 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.105293 (* 1 = 0.105293 loss)
I0825 22:26:25.195070 27361 sgd_solver.cpp:106] Iteration 8400, lr = 4.77418e-06
I0825 22:26:46.513619 27361 solver.cpp:228] Iteration 8410, loss = 0.275728
I0825 22:26:46.513664 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966969
I0825 22:26:46.513672 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.264075 (* 1 = 0.264075 loss)
I0825 22:26:46.513680 27361 sgd_solver.cpp:106] Iteration 8410, lr = 4.77151e-06
I0825 22:27:07.873081 27361 solver.cpp:228] Iteration 8420, loss = 0.390241
I0825 22:27:07.873188 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954597
I0825 22:27:07.873199 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.106203 (* 1 = 0.106203 loss)
I0825 22:27:07.873208 27361 sgd_solver.cpp:106] Iteration 8420, lr = 4.76884e-06
I0825 22:27:29.209055 27361 solver.cpp:228] Iteration 8430, loss = 0.559474
I0825 22:27:29.209098 27361 solver.cpp:244]     Train net output #0: accuracy = 0.958668
I0825 22:27:29.209108 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.183436 (* 1 = 0.183436 loss)
I0825 22:27:29.209115 27361 sgd_solver.cpp:106] Iteration 8430, lr = 4.76618e-06
I0825 22:27:50.544792 27361 solver.cpp:228] Iteration 8440, loss = 0.4056
I0825 22:27:50.544901 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951694
I0825 22:27:50.544912 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.443968 (* 1 = 0.443968 loss)
I0825 22:27:50.544919 27361 sgd_solver.cpp:106] Iteration 8440, lr = 4.76352e-06
I0825 22:28:11.878998 27361 solver.cpp:228] Iteration 8450, loss = 0.394685
I0825 22:28:11.879045 27361 solver.cpp:244]     Train net output #0: accuracy = 0.983734
I0825 22:28:11.879053 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0653671 (* 1 = 0.0653671 loss)
I0825 22:28:11.879061 27361 sgd_solver.cpp:106] Iteration 8450, lr = 4.76086e-06
I0825 22:28:33.214289 27361 solver.cpp:228] Iteration 8460, loss = 0.785067
I0825 22:28:33.214395 27361 solver.cpp:244]     Train net output #0: accuracy = 0.905865
I0825 22:28:33.214406 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.920119 (* 1 = 0.920119 loss)
I0825 22:28:33.214413 27361 sgd_solver.cpp:106] Iteration 8460, lr = 4.75821e-06
I0825 22:28:54.549041 27361 solver.cpp:228] Iteration 8470, loss = 0.635314
I0825 22:28:54.549085 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893154
I0825 22:28:54.549094 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.264885 (* 1 = 0.264885 loss)
I0825 22:28:54.549103 27361 sgd_solver.cpp:106] Iteration 8470, lr = 4.75556e-06
I0825 22:29:15.883690 27361 solver.cpp:228] Iteration 8480, loss = 0.689713
I0825 22:29:15.883783 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960636
I0825 22:29:15.883793 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.300751 (* 1 = 0.300751 loss)
I0825 22:29:15.883800 27361 sgd_solver.cpp:106] Iteration 8480, lr = 4.75292e-06
I0825 22:29:37.220502 27361 solver.cpp:228] Iteration 8490, loss = 0.683918
I0825 22:29:37.220549 27361 solver.cpp:244]     Train net output #0: accuracy = 0.811634
I0825 22:29:37.220558 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.53666 (* 1 = 2.53666 loss)
I0825 22:29:37.220566 27361 sgd_solver.cpp:106] Iteration 8490, lr = 4.75027e-06
I0825 22:29:56.432406 27361 solver.cpp:337] Iteration 8500, Testing net (#0)
I0825 22:30:00.579108 27361 solver.cpp:404]     Test net output #0: accuracy = 0.947874
I0825 22:30:00.579159 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.489998 (* 1 = 0.489998 loss)
I0825 22:30:02.594892 27361 solver.cpp:228] Iteration 8500, loss = 0.436567
I0825 22:30:02.594938 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916958
I0825 22:30:02.594946 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.677804 (* 1 = 0.677804 loss)
I0825 22:30:02.594954 27361 sgd_solver.cpp:106] Iteration 8500, lr = 4.74763e-06
I0825 22:30:23.935345 27361 solver.cpp:228] Iteration 8510, loss = 0.481945
I0825 22:30:23.935392 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971252
I0825 22:30:23.935401 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.420755 (* 1 = 0.420755 loss)
I0825 22:30:23.935410 27361 sgd_solver.cpp:106] Iteration 8510, lr = 4.745e-06
I0825 22:30:45.279677 27361 solver.cpp:228] Iteration 8520, loss = 0.345092
I0825 22:30:45.279791 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957554
I0825 22:30:45.279803 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.266348 (* 1 = 0.266348 loss)
I0825 22:30:45.279810 27361 sgd_solver.cpp:106] Iteration 8520, lr = 4.74237e-06
I0825 22:31:06.626317 27361 solver.cpp:228] Iteration 8530, loss = 0.286605
I0825 22:31:06.626365 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929691
I0825 22:31:06.626375 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.467513 (* 1 = 0.467513 loss)
I0825 22:31:06.626382 27361 sgd_solver.cpp:106] Iteration 8530, lr = 4.73974e-06
I0825 22:31:27.971835 27361 solver.cpp:228] Iteration 8540, loss = 0.489145
I0825 22:31:27.971951 27361 solver.cpp:244]     Train net output #0: accuracy = 0.954636
I0825 22:31:27.971961 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.265836 (* 1 = 0.265836 loss)
I0825 22:31:27.971969 27361 sgd_solver.cpp:106] Iteration 8540, lr = 4.73711e-06
I0825 22:31:49.361541 27361 solver.cpp:228] Iteration 8550, loss = 0.690928
I0825 22:31:49.361587 27361 solver.cpp:244]     Train net output #0: accuracy = 0.948383
I0825 22:31:49.361595 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.340886 (* 1 = 0.340886 loss)
I0825 22:31:49.361603 27361 sgd_solver.cpp:106] Iteration 8550, lr = 4.73449e-06
I0825 22:32:10.706177 27361 solver.cpp:228] Iteration 8560, loss = 0.712998
I0825 22:32:10.706296 27361 solver.cpp:244]     Train net output #0: accuracy = 0.846558
I0825 22:32:10.706307 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.57554 (* 1 = 1.57554 loss)
I0825 22:32:10.706315 27361 sgd_solver.cpp:106] Iteration 8560, lr = 4.73187e-06
I0825 22:32:32.095849 27361 solver.cpp:228] Iteration 8570, loss = 0.441599
I0825 22:32:32.095899 27361 solver.cpp:244]     Train net output #0: accuracy = 0.914524
I0825 22:32:32.095909 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.957065 (* 1 = 0.957065 loss)
I0825 22:32:32.095916 27361 sgd_solver.cpp:106] Iteration 8570, lr = 4.72925e-06
I0825 22:32:53.438604 27361 solver.cpp:228] Iteration 8580, loss = 0.494547
I0825 22:32:53.438699 27361 solver.cpp:244]     Train net output #0: accuracy = 0.82946
I0825 22:32:53.438709 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.80889 (* 1 = 1.80889 loss)
I0825 22:32:53.438716 27361 sgd_solver.cpp:106] Iteration 8580, lr = 4.72664e-06
I0825 22:33:14.779331 27361 solver.cpp:228] Iteration 8590, loss = 0.477652
I0825 22:33:14.779373 27361 solver.cpp:244]     Train net output #0: accuracy = 0.905323
I0825 22:33:14.779383 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.835884 (* 1 = 0.835884 loss)
I0825 22:33:14.779392 27361 sgd_solver.cpp:106] Iteration 8590, lr = 4.72403e-06
I0825 22:33:33.988279 27361 solver.cpp:337] Iteration 8600, Testing net (#0)
I0825 22:33:38.136291 27361 solver.cpp:404]     Test net output #0: accuracy = 0.931708
I0825 22:33:38.136335 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.570916 (* 1 = 0.570916 loss)
I0825 22:33:40.151511 27361 solver.cpp:228] Iteration 8600, loss = 0.384819
I0825 22:33:40.151566 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933784
I0825 22:33:40.151576 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.612076 (* 1 = 0.612076 loss)
I0825 22:33:40.151583 27361 sgd_solver.cpp:106] Iteration 8600, lr = 4.72143e-06
I0825 22:34:01.534313 27361 solver.cpp:228] Iteration 8610, loss = 0.606275
I0825 22:34:01.534358 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893105
I0825 22:34:01.534368 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.688344 (* 1 = 0.688344 loss)
I0825 22:34:01.534374 27361 sgd_solver.cpp:106] Iteration 8610, lr = 4.71883e-06
I0825 22:34:22.876721 27361 solver.cpp:228] Iteration 8620, loss = 0.367064
I0825 22:34:22.876827 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937389
I0825 22:34:22.876838 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.406913 (* 1 = 0.406913 loss)
I0825 22:34:22.876847 27361 sgd_solver.cpp:106] Iteration 8620, lr = 4.71623e-06
I0825 22:34:44.219065 27361 solver.cpp:228] Iteration 8630, loss = 0.697166
I0825 22:34:44.219113 27361 solver.cpp:244]     Train net output #0: accuracy = 0.930866
I0825 22:34:44.219122 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.463936 (* 1 = 0.463936 loss)
I0825 22:34:44.219130 27361 sgd_solver.cpp:106] Iteration 8630, lr = 4.71363e-06
I0825 22:35:05.559833 27361 solver.cpp:228] Iteration 8640, loss = 0.552507
I0825 22:35:05.559891 27361 solver.cpp:244]     Train net output #0: accuracy = 0.850239
I0825 22:35:05.559901 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.33609 (* 1 = 2.33609 loss)
I0825 22:35:05.559909 27361 sgd_solver.cpp:106] Iteration 8640, lr = 4.71104e-06
I0825 22:35:26.950834 27361 solver.cpp:228] Iteration 8650, loss = 1.09783
I0825 22:35:26.950881 27361 solver.cpp:244]     Train net output #0: accuracy = 0.978527
I0825 22:35:26.950891 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0408836 (* 1 = 0.0408836 loss)
I0825 22:35:26.950898 27361 sgd_solver.cpp:106] Iteration 8650, lr = 4.70845e-06
I0825 22:35:48.342422 27361 solver.cpp:228] Iteration 8660, loss = 0.344949
I0825 22:35:48.342483 27361 solver.cpp:244]     Train net output #0: accuracy = 0.980785
I0825 22:35:48.342492 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.195467 (* 1 = 0.195467 loss)
I0825 22:35:48.342499 27361 sgd_solver.cpp:106] Iteration 8660, lr = 4.70587e-06
I0825 22:36:09.678320 27361 solver.cpp:228] Iteration 8670, loss = 0.594092
I0825 22:36:09.678364 27361 solver.cpp:244]     Train net output #0: accuracy = 0.940575
I0825 22:36:09.678374 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.530956 (* 1 = 0.530956 loss)
I0825 22:36:09.678381 27361 sgd_solver.cpp:106] Iteration 8670, lr = 4.70328e-06
I0825 22:36:31.018515 27361 solver.cpp:228] Iteration 8680, loss = 0.797232
I0825 22:36:31.018635 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95602
I0825 22:36:31.018646 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.555838 (* 1 = 0.555838 loss)
I0825 22:36:31.018653 27361 sgd_solver.cpp:106] Iteration 8680, lr = 4.7007e-06
I0825 22:36:52.360765 27361 solver.cpp:228] Iteration 8690, loss = 0.589607
I0825 22:36:52.360813 27361 solver.cpp:244]     Train net output #0: accuracy = 0.932064
I0825 22:36:52.360823 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.597247 (* 1 = 0.597247 loss)
I0825 22:36:52.360831 27361 sgd_solver.cpp:106] Iteration 8690, lr = 4.69813e-06
I0825 22:37:11.571203 27361 solver.cpp:337] Iteration 8700, Testing net (#0)
I0825 22:37:15.722578 27361 solver.cpp:404]     Test net output #0: accuracy = 0.941242
I0825 22:37:15.722622 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.509806 (* 1 = 0.509806 loss)
I0825 22:37:17.738054 27361 solver.cpp:228] Iteration 8700, loss = 0.65547
I0825 22:37:17.738095 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87252
I0825 22:37:17.738103 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.32924 (* 1 = 1.32924 loss)
I0825 22:37:17.738119 27361 sgd_solver.cpp:106] Iteration 8700, lr = 4.69556e-06
I0825 22:37:39.073315 27361 solver.cpp:228] Iteration 8710, loss = 0.515969
I0825 22:37:39.073362 27361 solver.cpp:244]     Train net output #0: accuracy = 0.972427
I0825 22:37:39.073372 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.078567 (* 1 = 0.078567 loss)
I0825 22:37:39.073380 27361 sgd_solver.cpp:106] Iteration 8710, lr = 4.69299e-06
I0825 22:38:00.408386 27361 solver.cpp:228] Iteration 8720, loss = 0.752089
I0825 22:38:00.408495 27361 solver.cpp:244]     Train net output #0: accuracy = 0.909752
I0825 22:38:00.408506 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.267684 (* 1 = 0.267684 loss)
I0825 22:38:00.408514 27361 sgd_solver.cpp:106] Iteration 8720, lr = 4.69042e-06
I0825 22:38:21.741825 27361 solver.cpp:228] Iteration 8730, loss = 0.532374
I0825 22:38:21.741868 27361 solver.cpp:244]     Train net output #0: accuracy = 0.83963
I0825 22:38:21.741878 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.8227 (* 1 = 1.8227 loss)
I0825 22:38:21.741885 27361 sgd_solver.cpp:106] Iteration 8730, lr = 4.68786e-06
I0825 22:38:43.082289 27361 solver.cpp:228] Iteration 8740, loss = 0.557379
I0825 22:38:43.082402 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939507
I0825 22:38:43.082412 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.720494 (* 1 = 0.720494 loss)
I0825 22:38:43.082420 27361 sgd_solver.cpp:106] Iteration 8740, lr = 4.6853e-06
I0825 22:39:04.417922 27361 solver.cpp:228] Iteration 8750, loss = 0.860798
I0825 22:39:04.417970 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942234
I0825 22:39:04.417979 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.127559 (* 1 = 0.127559 loss)
I0825 22:39:04.417987 27361 sgd_solver.cpp:106] Iteration 8750, lr = 4.68274e-06
I0825 22:39:25.752615 27361 solver.cpp:228] Iteration 8760, loss = 0.454495
I0825 22:39:25.752719 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95306
I0825 22:39:25.752730 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.768203 (* 1 = 0.768203 loss)
I0825 22:39:25.752737 27361 sgd_solver.cpp:106] Iteration 8760, lr = 4.68019e-06
I0825 22:39:47.084512 27361 solver.cpp:228] Iteration 8770, loss = 0.478303
I0825 22:39:47.084563 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939457
I0825 22:39:47.084573 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.552276 (* 1 = 0.552276 loss)
I0825 22:39:47.084579 27361 sgd_solver.cpp:106] Iteration 8770, lr = 4.67764e-06
I0825 22:40:08.423213 27361 solver.cpp:228] Iteration 8780, loss = 0.905668
I0825 22:40:08.423326 27361 solver.cpp:244]     Train net output #0: accuracy = 0.903122
I0825 22:40:08.423336 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.82973 (* 1 = 1.82973 loss)
I0825 22:40:08.423344 27361 sgd_solver.cpp:106] Iteration 8780, lr = 4.6751e-06
I0825 22:40:29.765121 27361 solver.cpp:228] Iteration 8790, loss = 0.69865
I0825 22:40:29.765162 27361 solver.cpp:244]     Train net output #0: accuracy = 0.880547
I0825 22:40:29.765172 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.932761 (* 1 = 0.932761 loss)
I0825 22:40:29.765180 27361 sgd_solver.cpp:106] Iteration 8790, lr = 4.67255e-06
I0825 22:40:49.017323 27361 solver.cpp:337] Iteration 8800, Testing net (#0)
I0825 22:40:53.162338 27361 solver.cpp:404]     Test net output #0: accuracy = 0.953499
I0825 22:40:53.162381 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.374554 (* 1 = 0.374554 loss)
I0825 22:40:55.176288 27361 solver.cpp:228] Iteration 8800, loss = 0.501626
I0825 22:40:55.176331 27361 solver.cpp:244]     Train net output #0: accuracy = 0.908852
I0825 22:40:55.176342 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.805485 (* 1 = 0.805485 loss)
I0825 22:40:55.176348 27361 sgd_solver.cpp:106] Iteration 8800, lr = 4.67001e-06
I0825 22:41:16.510454 27361 solver.cpp:228] Iteration 8810, loss = 0.885339
I0825 22:41:16.510504 27361 solver.cpp:244]     Train net output #0: accuracy = 0.842831
I0825 22:41:16.510520 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.44438 (* 1 = 1.44438 loss)
I0825 22:41:16.510529 27361 sgd_solver.cpp:106] Iteration 8810, lr = 4.66748e-06
I0825 22:41:37.887202 27361 solver.cpp:228] Iteration 8820, loss = 0.547347
I0825 22:41:37.887342 27361 solver.cpp:244]     Train net output #0: accuracy = 0.926865
I0825 22:41:37.887358 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.253611 (* 1 = 0.253611 loss)
I0825 22:41:37.887369 27361 sgd_solver.cpp:106] Iteration 8820, lr = 4.66494e-06
I0825 22:41:59.299362 27361 solver.cpp:228] Iteration 8830, loss = 0.383322
I0825 22:41:59.299408 27361 solver.cpp:244]     Train net output #0: accuracy = 0.931389
I0825 22:41:59.299417 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.60266 (* 1 = 0.60266 loss)
I0825 22:41:59.299425 27361 sgd_solver.cpp:106] Iteration 8830, lr = 4.66241e-06
I0825 22:42:20.642161 27361 solver.cpp:228] Iteration 8840, loss = 0.213745
I0825 22:42:20.642263 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971092
I0825 22:42:20.642273 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.200522 (* 1 = 0.200522 loss)
I0825 22:42:20.642282 27361 sgd_solver.cpp:106] Iteration 8840, lr = 4.65989e-06
I0825 22:42:41.981619 27361 solver.cpp:228] Iteration 8850, loss = 0.391815
I0825 22:42:41.981667 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9543
I0825 22:42:41.981675 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.563024 (* 1 = 0.563024 loss)
I0825 22:42:41.981683 27361 sgd_solver.cpp:106] Iteration 8850, lr = 4.65736e-06
I0825 22:43:03.325774 27361 solver.cpp:228] Iteration 8860, loss = 0.36955
I0825 22:43:03.325834 27361 solver.cpp:244]     Train net output #0: accuracy = 0.995846
I0825 22:43:03.325845 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0224059 (* 1 = 0.0224059 loss)
I0825 22:43:03.325851 27361 sgd_solver.cpp:106] Iteration 8860, lr = 4.65484e-06
I0825 22:43:24.712887 27361 solver.cpp:228] Iteration 8870, loss = 0.671219
I0825 22:43:24.712937 27361 solver.cpp:244]     Train net output #0: accuracy = 0.809982
I0825 22:43:24.712946 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.04018 (* 1 = 1.04018 loss)
I0825 22:43:24.712954 27361 sgd_solver.cpp:106] Iteration 8870, lr = 4.65233e-06
I0825 22:43:46.105902 27361 solver.cpp:228] Iteration 8880, loss = 0.47104
I0825 22:43:46.106004 27361 solver.cpp:244]     Train net output #0: accuracy = 0.982441
I0825 22:43:46.106015 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0661179 (* 1 = 0.0661179 loss)
I0825 22:43:46.106022 27361 sgd_solver.cpp:106] Iteration 8880, lr = 4.64981e-06
I0825 22:44:07.447635 27361 solver.cpp:228] Iteration 8890, loss = 0.581726
I0825 22:44:07.447684 27361 solver.cpp:244]     Train net output #0: accuracy = 0.836681
I0825 22:44:07.447692 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.51648 (* 1 = 2.51648 loss)
I0825 22:44:07.447700 27361 sgd_solver.cpp:106] Iteration 8890, lr = 4.6473e-06
I0825 22:44:26.657611 27361 solver.cpp:337] Iteration 8900, Testing net (#0)
I0825 22:44:30.894048 27361 solver.cpp:404]     Test net output #0: accuracy = 0.929425
I0825 22:44:30.894103 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.632864 (* 1 = 0.632864 loss)
I0825 22:44:32.911753 27361 solver.cpp:228] Iteration 8900, loss = 0.476541
I0825 22:44:32.911799 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86742
I0825 22:44:32.911809 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.731514 (* 1 = 0.731514 loss)
I0825 22:44:32.911818 27361 sgd_solver.cpp:106] Iteration 8900, lr = 4.64479e-06
I0825 22:44:54.245535 27361 solver.cpp:228] Iteration 8910, loss = 0.397456
I0825 22:44:54.245581 27361 solver.cpp:244]     Train net output #0: accuracy = 0.967426
I0825 22:44:54.245590 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.137829 (* 1 = 0.137829 loss)
I0825 22:44:54.245597 27361 sgd_solver.cpp:106] Iteration 8910, lr = 4.64229e-06
I0825 22:45:15.636402 27361 solver.cpp:228] Iteration 8920, loss = 0.550581
I0825 22:45:15.636515 27361 solver.cpp:244]     Train net output #0: accuracy = 0.89867
I0825 22:45:15.636526 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.442566 (* 1 = 0.442566 loss)
I0825 22:45:15.636534 27361 sgd_solver.cpp:106] Iteration 8920, lr = 4.63979e-06
I0825 22:45:36.976605 27361 solver.cpp:228] Iteration 8930, loss = 0.464134
I0825 22:45:36.976650 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912838
I0825 22:45:36.976661 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.287919 (* 1 = 0.287919 loss)
I0825 22:45:36.976668 27361 sgd_solver.cpp:106] Iteration 8930, lr = 4.63729e-06
I0825 22:45:58.318297 27361 solver.cpp:228] Iteration 8940, loss = 0.505275
I0825 22:45:58.318444 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916382
I0825 22:45:58.318454 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.01329 (* 1 = 1.01329 loss)
I0825 22:45:58.318462 27361 sgd_solver.cpp:106] Iteration 8940, lr = 4.63479e-06
I0825 22:46:19.647217 27361 solver.cpp:228] Iteration 8950, loss = 0.561406
I0825 22:46:19.647264 27361 solver.cpp:244]     Train net output #0: accuracy = 0.987892
I0825 22:46:19.647275 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0719285 (* 1 = 0.0719285 loss)
I0825 22:46:19.647282 27361 sgd_solver.cpp:106] Iteration 8950, lr = 4.6323e-06
I0825 22:46:40.969949 27361 solver.cpp:228] Iteration 8960, loss = 0.6379
I0825 22:46:40.970052 27361 solver.cpp:244]     Train net output #0: accuracy = 0.952274
I0825 22:46:40.970062 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.578848 (* 1 = 0.578848 loss)
I0825 22:46:40.970070 27361 sgd_solver.cpp:106] Iteration 8960, lr = 4.62981e-06
I0825 22:47:02.291306 27361 solver.cpp:228] Iteration 8970, loss = 0.446421
I0825 22:47:02.291354 27361 solver.cpp:244]     Train net output #0: accuracy = 0.988789
I0825 22:47:02.291364 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0449864 (* 1 = 0.0449864 loss)
I0825 22:47:02.291373 27361 sgd_solver.cpp:106] Iteration 8970, lr = 4.62733e-06
I0825 22:47:23.616268 27361 solver.cpp:228] Iteration 8980, loss = 0.369088
I0825 22:47:23.616374 27361 solver.cpp:244]     Train net output #0: accuracy = 0.96767
I0825 22:47:23.616385 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.149478 (* 1 = 0.149478 loss)
I0825 22:47:23.616392 27361 sgd_solver.cpp:106] Iteration 8980, lr = 4.62484e-06
I0825 22:47:44.939632 27361 solver.cpp:228] Iteration 8990, loss = 0.545315
I0825 22:47:44.939679 27361 solver.cpp:244]     Train net output #0: accuracy = 0.819443
I0825 22:47:44.939688 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.7325 (* 1 = 1.7325 loss)
I0825 22:47:44.939697 27361 sgd_solver.cpp:106] Iteration 8990, lr = 4.62236e-06
I0825 22:48:04.180663 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_9000.caffemodel
I0825 22:48:04.374171 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_9000.solverstate
I0825 22:48:04.411455 27361 solver.cpp:337] Iteration 9000, Testing net (#0)
I0825 22:48:08.445211 27361 solver.cpp:404]     Test net output #0: accuracy = 0.928384
I0825 22:48:08.445260 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.586996 (* 1 = 0.586996 loss)
I0825 22:48:10.460708 27361 solver.cpp:228] Iteration 9000, loss = 0.498137
I0825 22:48:10.460755 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889851
I0825 22:48:10.460764 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.741411 (* 1 = 0.741411 loss)
I0825 22:48:10.460772 27361 sgd_solver.cpp:106] Iteration 9000, lr = 4.61989e-06
I0825 22:48:31.796180 27361 solver.cpp:228] Iteration 9010, loss = 0.466341
I0825 22:48:31.796226 27361 solver.cpp:244]     Train net output #0: accuracy = 0.88229
I0825 22:48:31.796234 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.02148 (* 1 = 1.02148 loss)
I0825 22:48:31.796241 27361 sgd_solver.cpp:106] Iteration 9010, lr = 4.61741e-06
I0825 22:48:53.133234 27361 solver.cpp:228] Iteration 9020, loss = 0.830047
I0825 22:48:53.133296 27361 solver.cpp:244]     Train net output #0: accuracy = 0.913216
I0825 22:48:53.133306 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.689956 (* 1 = 0.689956 loss)
I0825 22:48:53.133312 27361 sgd_solver.cpp:106] Iteration 9020, lr = 4.61494e-06
I0825 22:49:14.465579 27361 solver.cpp:228] Iteration 9030, loss = 0.516668
I0825 22:49:14.465626 27361 solver.cpp:244]     Train net output #0: accuracy = 0.961418
I0825 22:49:14.465636 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.202408 (* 1 = 0.202408 loss)
I0825 22:49:14.465642 27361 sgd_solver.cpp:106] Iteration 9030, lr = 4.61248e-06
I0825 22:49:35.801067 27361 solver.cpp:228] Iteration 9040, loss = 0.672361
I0825 22:49:35.801172 27361 solver.cpp:244]     Train net output #0: accuracy = 0.919392
I0825 22:49:35.801182 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.12897 (* 1 = 1.12897 loss)
I0825 22:49:35.801190 27361 sgd_solver.cpp:106] Iteration 9040, lr = 4.61001e-06
I0825 22:49:57.136677 27361 solver.cpp:228] Iteration 9050, loss = 0.648889
I0825 22:49:57.136725 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942699
I0825 22:49:57.136735 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.460979 (* 1 = 0.460979 loss)
I0825 22:49:57.136742 27361 sgd_solver.cpp:106] Iteration 9050, lr = 4.60755e-06
I0825 22:50:18.517065 27361 solver.cpp:228] Iteration 9060, loss = 0.543005
I0825 22:50:18.517128 27361 solver.cpp:244]     Train net output #0: accuracy = 0.930672
I0825 22:50:18.517138 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.31915 (* 1 = 1.31915 loss)
I0825 22:50:18.517145 27361 sgd_solver.cpp:106] Iteration 9060, lr = 4.60509e-06
I0825 22:50:39.842393 27361 solver.cpp:228] Iteration 9070, loss = 0.710264
I0825 22:50:39.842439 27361 solver.cpp:244]     Train net output #0: accuracy = 0.984531
I0825 22:50:39.842449 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.151102 (* 1 = 0.151102 loss)
I0825 22:50:39.842456 27361 sgd_solver.cpp:106] Iteration 9070, lr = 4.60264e-06
I0825 22:51:01.223963 27361 solver.cpp:228] Iteration 9080, loss = 0.500642
I0825 22:51:01.224066 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971581
I0825 22:51:01.224077 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.11277 (* 1 = 0.11277 loss)
I0825 22:51:01.224086 27361 sgd_solver.cpp:106] Iteration 9080, lr = 4.60019e-06
I0825 22:51:22.652830 27361 solver.cpp:228] Iteration 9090, loss = 0.381796
I0825 22:51:22.652876 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973625
I0825 22:51:22.652885 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.139148 (* 1 = 0.139148 loss)
I0825 22:51:22.652892 27361 sgd_solver.cpp:106] Iteration 9090, lr = 4.59774e-06
I0825 22:51:41.847801 27361 solver.cpp:337] Iteration 9100, Testing net (#0)
I0825 22:51:45.996649 27361 solver.cpp:404]     Test net output #0: accuracy = 0.92452
I0825 22:51:45.996693 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.831841 (* 1 = 0.831841 loss)
I0825 22:51:48.062728 27361 solver.cpp:228] Iteration 9100, loss = 0.456792
I0825 22:51:48.062775 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929417
I0825 22:51:48.062784 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.620651 (* 1 = 0.620651 loss)
I0825 22:51:48.062793 27361 sgd_solver.cpp:106] Iteration 9100, lr = 4.59529e-06
I0825 22:52:09.431800 27361 solver.cpp:228] Iteration 9110, loss = 0.159842
I0825 22:52:09.431848 27361 solver.cpp:244]     Train net output #0: accuracy = 0.969177
I0825 22:52:09.431857 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.36498 (* 1 = 0.36498 loss)
I0825 22:52:09.431865 27361 sgd_solver.cpp:106] Iteration 9110, lr = 4.59285e-06
I0825 22:52:30.767585 27361 solver.cpp:228] Iteration 9120, loss = 0.596752
I0825 22:52:30.767699 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937801
I0825 22:52:30.767710 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.470443 (* 1 = 0.470443 loss)
I0825 22:52:30.767725 27361 sgd_solver.cpp:106] Iteration 9120, lr = 4.59041e-06
I0825 22:52:52.103127 27361 solver.cpp:228] Iteration 9130, loss = 0.610211
I0825 22:52:52.103174 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956841
I0825 22:52:52.103183 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.350082 (* 1 = 0.350082 loss)
I0825 22:52:52.103191 27361 sgd_solver.cpp:106] Iteration 9130, lr = 4.58797e-06
I0825 22:53:13.439784 27361 solver.cpp:228] Iteration 9140, loss = 0.486837
I0825 22:53:13.439843 27361 solver.cpp:244]     Train net output #0: accuracy = 0.976009
I0825 22:53:13.439852 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.064808 (* 1 = 0.064808 loss)
I0825 22:53:13.439860 27361 sgd_solver.cpp:106] Iteration 9140, lr = 4.58554e-06
I0825 22:53:34.772815 27361 solver.cpp:228] Iteration 9150, loss = 0.590606
I0825 22:53:34.772852 27361 solver.cpp:244]     Train net output #0: accuracy = 0.896252
I0825 22:53:34.772862 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.625546 (* 1 = 0.625546 loss)
I0825 22:53:34.772869 27361 sgd_solver.cpp:106] Iteration 9150, lr = 4.58311e-06
I0825 22:53:56.108562 27361 solver.cpp:228] Iteration 9160, loss = 0.422747
I0825 22:53:56.108670 27361 solver.cpp:244]     Train net output #0: accuracy = 0.984165
I0825 22:53:56.108680 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.15011 (* 1 = 0.15011 loss)
I0825 22:53:56.108688 27361 sgd_solver.cpp:106] Iteration 9160, lr = 4.58068e-06
I0825 22:54:17.445714 27361 solver.cpp:228] Iteration 9170, loss = 0.516095
I0825 22:54:17.445763 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939426
I0825 22:54:17.445773 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.72664 (* 1 = 0.72664 loss)
I0825 22:54:17.445780 27361 sgd_solver.cpp:106] Iteration 9170, lr = 4.57826e-06
I0825 22:54:38.782431 27361 solver.cpp:228] Iteration 9180, loss = 0.467578
I0825 22:54:38.782539 27361 solver.cpp:244]     Train net output #0: accuracy = 0.86385
I0825 22:54:38.782551 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.560612 (* 1 = 0.560612 loss)
I0825 22:54:38.782557 27361 sgd_solver.cpp:106] Iteration 9180, lr = 4.57583e-06
I0825 22:55:00.117930 27361 solver.cpp:228] Iteration 9190, loss = 0.437134
I0825 22:55:00.117975 27361 solver.cpp:244]     Train net output #0: accuracy = 0.969074
I0825 22:55:00.117985 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.129854 (* 1 = 0.129854 loss)
I0825 22:55:00.117992 27361 sgd_solver.cpp:106] Iteration 9190, lr = 4.57342e-06
I0825 22:55:19.321046 27361 solver.cpp:337] Iteration 9200, Testing net (#0)
I0825 22:55:23.468152 27361 solver.cpp:404]     Test net output #0: accuracy = 0.951712
I0825 22:55:23.468200 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.386147 (* 1 = 0.386147 loss)
I0825 22:55:25.484640 27361 solver.cpp:228] Iteration 9200, loss = 0.617255
I0825 22:55:25.484688 27361 solver.cpp:244]     Train net output #0: accuracy = 0.925976
I0825 22:55:25.484697 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.879247 (* 1 = 0.879247 loss)
I0825 22:55:25.484705 27361 sgd_solver.cpp:106] Iteration 9200, lr = 4.571e-06
I0825 22:55:46.819305 27361 solver.cpp:228] Iteration 9210, loss = 0.705012
I0825 22:55:46.819349 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916645
I0825 22:55:46.819357 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.85387 (* 1 = 1.85387 loss)
I0825 22:55:46.819365 27361 sgd_solver.cpp:106] Iteration 9210, lr = 4.56859e-06
I0825 22:56:08.157415 27361 solver.cpp:228] Iteration 9220, loss = 0.402542
I0825 22:56:08.157552 27361 solver.cpp:244]     Train net output #0: accuracy = 0.747513
I0825 22:56:08.157564 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.16297 (* 1 = 1.16297 loss)
I0825 22:56:08.157572 27361 sgd_solver.cpp:106] Iteration 9220, lr = 4.56618e-06
I0825 22:56:29.491166 27361 solver.cpp:228] Iteration 9230, loss = 0.532706
I0825 22:56:29.491211 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942844
I0825 22:56:29.491221 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.481372 (* 1 = 0.481372 loss)
I0825 22:56:29.491228 27361 sgd_solver.cpp:106] Iteration 9230, lr = 4.56377e-06
I0825 22:56:50.828583 27361 solver.cpp:228] Iteration 9240, loss = 0.378509
I0825 22:56:50.828686 27361 solver.cpp:244]     Train net output #0: accuracy = 0.946693
I0825 22:56:50.828696 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.342763 (* 1 = 0.342763 loss)
I0825 22:56:50.828703 27361 sgd_solver.cpp:106] Iteration 9240, lr = 4.56137e-06
I0825 22:57:12.165356 27361 solver.cpp:228] Iteration 9250, loss = 0.537917
I0825 22:57:12.165403 27361 solver.cpp:244]     Train net output #0: accuracy = 0.971455
I0825 22:57:12.165413 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.32567 (* 1 = 0.32567 loss)
I0825 22:57:12.165421 27361 sgd_solver.cpp:106] Iteration 9250, lr = 4.55897e-06
I0825 22:57:33.505352 27361 solver.cpp:228] Iteration 9260, loss = 0.701974
I0825 22:57:33.505457 27361 solver.cpp:244]     Train net output #0: accuracy = 0.933609
I0825 22:57:33.505468 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.755687 (* 1 = 0.755687 loss)
I0825 22:57:33.505476 27361 sgd_solver.cpp:106] Iteration 9260, lr = 4.55657e-06
I0825 22:57:54.837985 27361 solver.cpp:228] Iteration 9270, loss = 0.233034
I0825 22:57:54.838032 27361 solver.cpp:244]     Train net output #0: accuracy = 0.974941
I0825 22:57:54.838042 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.102385 (* 1 = 0.102385 loss)
I0825 22:57:54.838048 27361 sgd_solver.cpp:106] Iteration 9270, lr = 4.55417e-06
I0825 22:58:16.171463 27361 solver.cpp:228] Iteration 9280, loss = 0.378162
I0825 22:58:16.171568 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939751
I0825 22:58:16.171579 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.221356 (* 1 = 0.221356 loss)
I0825 22:58:16.171586 27361 sgd_solver.cpp:106] Iteration 9280, lr = 4.55178e-06
I0825 22:58:37.508533 27361 solver.cpp:228] Iteration 9290, loss = 0.611734
I0825 22:58:37.508579 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949581
I0825 22:58:37.508589 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.6854 (* 1 = 0.6854 loss)
I0825 22:58:37.508596 27361 sgd_solver.cpp:106] Iteration 9290, lr = 4.54939e-06
I0825 22:58:56.713053 27361 solver.cpp:337] Iteration 9300, Testing net (#0)
I0825 22:59:00.862987 27361 solver.cpp:404]     Test net output #0: accuracy = 0.946351
I0825 22:59:00.863031 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.49208 (* 1 = 0.49208 loss)
I0825 22:59:02.878208 27361 solver.cpp:228] Iteration 9300, loss = 0.615616
I0825 22:59:02.878252 27361 solver.cpp:244]     Train net output #0: accuracy = 0.989307
I0825 22:59:02.878262 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0723672 (* 1 = 0.0723672 loss)
I0825 22:59:02.878269 27361 sgd_solver.cpp:106] Iteration 9300, lr = 4.54701e-06
I0825 22:59:24.223297 27361 solver.cpp:228] Iteration 9310, loss = 0.488307
I0825 22:59:24.223346 27361 solver.cpp:244]     Train net output #0: accuracy = 0.856491
I0825 22:59:24.223356 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.04794 (* 1 = 1.04794 loss)
I0825 22:59:24.223362 27361 sgd_solver.cpp:106] Iteration 9310, lr = 4.54462e-06
I0825 22:59:45.562177 27361 solver.cpp:228] Iteration 9320, loss = 0.460527
I0825 22:59:45.562314 27361 solver.cpp:244]     Train net output #0: accuracy = 0.987003
I0825 22:59:45.562325 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0406805 (* 1 = 0.0406805 loss)
I0825 22:59:45.562333 27361 sgd_solver.cpp:106] Iteration 9320, lr = 4.54224e-06
I0825 23:00:06.905959 27361 solver.cpp:228] Iteration 9330, loss = 0.716187
I0825 23:00:06.906007 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951973
I0825 23:00:06.906015 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.406541 (* 1 = 0.406541 loss)
I0825 23:00:06.906023 27361 sgd_solver.cpp:106] Iteration 9330, lr = 4.53986e-06
I0825 23:00:28.252578 27361 solver.cpp:228] Iteration 9340, loss = 0.42827
I0825 23:00:28.252640 27361 solver.cpp:244]     Train net output #0: accuracy = 0.902279
I0825 23:00:28.252650 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.12036 (* 1 = 1.12036 loss)
I0825 23:00:28.252656 27361 sgd_solver.cpp:106] Iteration 9340, lr = 4.53749e-06
I0825 23:00:49.598435 27361 solver.cpp:228] Iteration 9350, loss = 0.42209
I0825 23:00:49.598484 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942249
I0825 23:00:49.598495 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.463301 (* 1 = 0.463301 loss)
I0825 23:00:49.598501 27361 sgd_solver.cpp:106] Iteration 9350, lr = 4.53512e-06
I0825 23:01:10.941615 27361 solver.cpp:228] Iteration 9360, loss = 0.380219
I0825 23:01:10.941728 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966984
I0825 23:01:10.941740 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.178629 (* 1 = 0.178629 loss)
I0825 23:01:10.941747 27361 sgd_solver.cpp:106] Iteration 9360, lr = 4.53275e-06
I0825 23:01:32.288825 27361 solver.cpp:228] Iteration 9370, loss = 1.21216
I0825 23:01:32.288869 27361 solver.cpp:244]     Train net output #0: accuracy = 0.891678
I0825 23:01:32.288879 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.3874 (* 1 = 1.3874 loss)
I0825 23:01:32.288887 27361 sgd_solver.cpp:106] Iteration 9370, lr = 4.53038e-06
I0825 23:01:53.634274 27361 solver.cpp:228] Iteration 9380, loss = 0.508606
I0825 23:01:53.634390 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935459
I0825 23:01:53.634402 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.247811 (* 1 = 0.247811 loss)
I0825 23:01:53.634408 27361 sgd_solver.cpp:106] Iteration 9380, lr = 4.52802e-06
I0825 23:02:14.981019 27361 solver.cpp:228] Iteration 9390, loss = 0.494343
I0825 23:02:14.981066 27361 solver.cpp:244]     Train net output #0: accuracy = 0.929234
I0825 23:02:14.981076 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.730276 (* 1 = 0.730276 loss)
I0825 23:02:14.981084 27361 sgd_solver.cpp:106] Iteration 9390, lr = 4.52566e-06
I0825 23:02:34.193974 27361 solver.cpp:337] Iteration 9400, Testing net (#0)
I0825 23:02:38.341708 27361 solver.cpp:404]     Test net output #0: accuracy = 0.940296
I0825 23:02:38.341753 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.537246 (* 1 = 0.537246 loss)
I0825 23:02:40.356293 27361 solver.cpp:228] Iteration 9400, loss = 0.362186
I0825 23:02:40.356341 27361 solver.cpp:244]     Train net output #0: accuracy = 0.95504
I0825 23:02:40.356350 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.978453 (* 1 = 0.978453 loss)
I0825 23:02:40.356359 27361 sgd_solver.cpp:106] Iteration 9400, lr = 4.5233e-06
I0825 23:03:01.705065 27361 solver.cpp:228] Iteration 9410, loss = 0.297154
I0825 23:03:01.705112 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942169
I0825 23:03:01.705122 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.122283 (* 1 = 0.122283 loss)
I0825 23:03:01.705129 27361 sgd_solver.cpp:106] Iteration 9410, lr = 4.52095e-06
I0825 23:03:23.047178 27361 solver.cpp:228] Iteration 9420, loss = 0.499818
I0825 23:03:23.047312 27361 solver.cpp:244]     Train net output #0: accuracy = 0.992565
I0825 23:03:23.047323 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0254081 (* 1 = 0.0254081 loss)
I0825 23:03:23.047332 27361 sgd_solver.cpp:106] Iteration 9420, lr = 4.5186e-06
I0825 23:03:44.387423 27361 solver.cpp:228] Iteration 9430, loss = 0.457523
I0825 23:03:44.387470 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956497
I0825 23:03:44.387478 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.664431 (* 1 = 0.664431 loss)
I0825 23:03:44.387486 27361 sgd_solver.cpp:106] Iteration 9430, lr = 4.51625e-06
I0825 23:04:05.730669 27361 solver.cpp:228] Iteration 9440, loss = 0.452009
I0825 23:04:05.730769 27361 solver.cpp:244]     Train net output #0: accuracy = 0.964001
I0825 23:04:05.730787 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.140071 (* 1 = 0.140071 loss)
I0825 23:04:05.730794 27361 sgd_solver.cpp:106] Iteration 9440, lr = 4.5139e-06
I0825 23:04:27.074468 27361 solver.cpp:228] Iteration 9450, loss = 0.297167
I0825 23:04:27.074517 27361 solver.cpp:244]     Train net output #0: accuracy = 0.988216
I0825 23:04:27.074525 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0921067 (* 1 = 0.0921067 loss)
I0825 23:04:27.074533 27361 sgd_solver.cpp:106] Iteration 9450, lr = 4.51156e-06
I0825 23:04:48.416167 27361 solver.cpp:228] Iteration 9460, loss = 0.337125
I0825 23:04:48.416270 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93903
I0825 23:04:48.416280 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.544132 (* 1 = 0.544132 loss)
I0825 23:04:48.416288 27361 sgd_solver.cpp:106] Iteration 9460, lr = 4.50922e-06
I0825 23:05:09.759989 27361 solver.cpp:228] Iteration 9470, loss = 0.649113
I0825 23:05:09.760032 27361 solver.cpp:244]     Train net output #0: accuracy = 0.893406
I0825 23:05:09.760041 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.778759 (* 1 = 0.778759 loss)
I0825 23:05:09.760049 27361 sgd_solver.cpp:106] Iteration 9470, lr = 4.50688e-06
I0825 23:05:31.094612 27361 solver.cpp:228] Iteration 9480, loss = 0.507948
I0825 23:05:31.094719 27361 solver.cpp:244]     Train net output #0: accuracy = 0.940834
I0825 23:05:31.094729 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.379284 (* 1 = 0.379284 loss)
I0825 23:05:31.094738 27361 sgd_solver.cpp:106] Iteration 9480, lr = 4.50455e-06
I0825 23:05:52.515733 27361 solver.cpp:228] Iteration 9490, loss = 0.829026
I0825 23:05:52.515779 27361 solver.cpp:244]     Train net output #0: accuracy = 0.815083
I0825 23:05:52.515789 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.25977 (* 1 = 1.25977 loss)
I0825 23:05:52.515797 27361 sgd_solver.cpp:106] Iteration 9490, lr = 4.50221e-06
I0825 23:06:11.777051 27361 solver.cpp:337] Iteration 9500, Testing net (#0)
I0825 23:06:15.925815 27361 solver.cpp:404]     Test net output #0: accuracy = 0.93576
I0825 23:06:15.925859 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.594703 (* 1 = 0.594703 loss)
I0825 23:06:17.940874 27361 solver.cpp:228] Iteration 9500, loss = 0.577352
I0825 23:06:17.940918 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941761
I0825 23:06:17.940927 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.538055 (* 1 = 0.538055 loss)
I0825 23:06:17.940934 27361 sgd_solver.cpp:106] Iteration 9500, lr = 4.49989e-06
I0825 23:06:39.274857 27361 solver.cpp:228] Iteration 9510, loss = 0.576629
I0825 23:06:39.274904 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910294
I0825 23:06:39.274914 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.995125 (* 1 = 0.995125 loss)
I0825 23:06:39.274921 27361 sgd_solver.cpp:106] Iteration 9510, lr = 4.49756e-06
I0825 23:07:00.611536 27361 solver.cpp:228] Iteration 9520, loss = 0.630288
I0825 23:07:00.611670 27361 solver.cpp:244]     Train net output #0: accuracy = 0.9841
I0825 23:07:00.611681 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0459987 (* 1 = 0.0459987 loss)
I0825 23:07:00.611690 27361 sgd_solver.cpp:106] Iteration 9520, lr = 4.49524e-06
I0825 23:07:21.948346 27361 solver.cpp:228] Iteration 9530, loss = 0.399523
I0825 23:07:21.948393 27361 solver.cpp:244]     Train net output #0: accuracy = 0.972599
I0825 23:07:21.948403 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.20305 (* 1 = 0.20305 loss)
I0825 23:07:21.948411 27361 sgd_solver.cpp:106] Iteration 9530, lr = 4.49292e-06
I0825 23:07:43.284474 27361 solver.cpp:228] Iteration 9540, loss = 0.502271
I0825 23:07:43.284541 27361 solver.cpp:244]     Train net output #0: accuracy = 0.973194
I0825 23:07:43.284551 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.103902 (* 1 = 0.103902 loss)
I0825 23:07:43.284559 27361 sgd_solver.cpp:106] Iteration 9540, lr = 4.4906e-06
I0825 23:08:04.626356 27361 solver.cpp:228] Iteration 9550, loss = 0.631165
I0825 23:08:04.626415 27361 solver.cpp:244]     Train net output #0: accuracy = 0.927696
I0825 23:08:04.626431 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.547387 (* 1 = 0.547387 loss)
I0825 23:08:04.626440 27361 sgd_solver.cpp:106] Iteration 9550, lr = 4.48828e-06
I0825 23:08:25.964376 27361 solver.cpp:228] Iteration 9560, loss = 0.720973
I0825 23:08:25.964478 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921959
I0825 23:08:25.964488 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.20971 (* 1 = 1.20971 loss)
I0825 23:08:25.964494 27361 sgd_solver.cpp:106] Iteration 9560, lr = 4.48597e-06
I0825 23:08:47.301326 27361 solver.cpp:228] Iteration 9570, loss = 0.519978
I0825 23:08:47.301373 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93494
I0825 23:08:47.301383 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.661849 (* 1 = 0.661849 loss)
I0825 23:08:47.301390 27361 sgd_solver.cpp:106] Iteration 9570, lr = 4.48366e-06
I0825 23:09:08.670279 27361 solver.cpp:228] Iteration 9580, loss = 0.397228
I0825 23:09:08.670356 27361 solver.cpp:244]     Train net output #0: accuracy = 0.872475
I0825 23:09:08.670367 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.841662 (* 1 = 0.841662 loss)
I0825 23:09:08.670374 27361 sgd_solver.cpp:106] Iteration 9580, lr = 4.48136e-06
I0825 23:09:29.999635 27361 solver.cpp:228] Iteration 9590, loss = 0.658162
I0825 23:09:29.999680 27361 solver.cpp:244]     Train net output #0: accuracy = 0.988579
I0825 23:09:29.999691 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0345806 (* 1 = 0.0345806 loss)
I0825 23:09:29.999697 27361 sgd_solver.cpp:106] Iteration 9590, lr = 4.47905e-06
I0825 23:09:49.304070 27361 solver.cpp:337] Iteration 9600, Testing net (#0)
I0825 23:09:53.452373 27361 solver.cpp:404]     Test net output #0: accuracy = 0.926065
I0825 23:09:53.452414 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.612913 (* 1 = 0.612913 loss)
I0825 23:09:55.467803 27361 solver.cpp:228] Iteration 9600, loss = 0.321964
I0825 23:09:55.467849 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966465
I0825 23:09:55.467857 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.153292 (* 1 = 0.153292 loss)
I0825 23:09:55.467864 27361 sgd_solver.cpp:106] Iteration 9600, lr = 4.47675e-06
I0825 23:10:16.811833 27361 solver.cpp:228] Iteration 9610, loss = 0.604955
I0825 23:10:16.811880 27361 solver.cpp:244]     Train net output #0: accuracy = 0.956192
I0825 23:10:16.811889 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.267259 (* 1 = 0.267259 loss)
I0825 23:10:16.811897 27361 sgd_solver.cpp:106] Iteration 9610, lr = 4.47445e-06
I0825 23:10:38.160114 27361 solver.cpp:228] Iteration 9620, loss = 0.518655
I0825 23:10:38.160225 27361 solver.cpp:244]     Train net output #0: accuracy = 0.99147
I0825 23:10:38.160236 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0360848 (* 1 = 0.0360848 loss)
I0825 23:10:38.160244 27361 sgd_solver.cpp:106] Iteration 9620, lr = 4.47216e-06
I0825 23:10:59.652181 27361 solver.cpp:228] Iteration 9630, loss = 0.432777
I0825 23:10:59.652230 27361 solver.cpp:244]     Train net output #0: accuracy = 0.947845
I0825 23:10:59.652240 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.347731 (* 1 = 0.347731 loss)
I0825 23:10:59.652246 27361 sgd_solver.cpp:106] Iteration 9630, lr = 4.46986e-06
I0825 23:11:21.171843 27361 solver.cpp:228] Iteration 9640, loss = 0.498383
I0825 23:11:21.171936 27361 solver.cpp:244]     Train net output #0: accuracy = 0.959679
I0825 23:11:21.171947 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.317422 (* 1 = 0.317422 loss)
I0825 23:11:21.171954 27361 sgd_solver.cpp:106] Iteration 9640, lr = 4.46757e-06
I0825 23:11:42.537957 27361 solver.cpp:228] Iteration 9650, loss = 0.4138
I0825 23:11:42.538005 27361 solver.cpp:244]     Train net output #0: accuracy = 0.981304
I0825 23:11:42.538014 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.164901 (* 1 = 0.164901 loss)
I0825 23:11:42.538033 27361 sgd_solver.cpp:106] Iteration 9650, lr = 4.46529e-06
I0825 23:12:03.929343 27361 solver.cpp:228] Iteration 9660, loss = 0.453641
I0825 23:12:03.929425 27361 solver.cpp:244]     Train net output #0: accuracy = 0.938538
I0825 23:12:03.929435 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.04964 (* 1 = 1.04964 loss)
I0825 23:12:03.929442 27361 sgd_solver.cpp:106] Iteration 9660, lr = 4.463e-06
I0825 23:12:25.288118 27361 solver.cpp:228] Iteration 9670, loss = 0.321992
I0825 23:12:25.288166 27361 solver.cpp:244]     Train net output #0: accuracy = 0.959221
I0825 23:12:25.288174 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.245841 (* 1 = 0.245841 loss)
I0825 23:12:25.288182 27361 sgd_solver.cpp:106] Iteration 9670, lr = 4.46072e-06
I0825 23:12:46.730242 27361 solver.cpp:228] Iteration 9680, loss = 0.265789
I0825 23:12:46.730348 27361 solver.cpp:244]     Train net output #0: accuracy = 0.962917
I0825 23:12:46.730358 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.268802 (* 1 = 0.268802 loss)
I0825 23:12:46.730366 27361 sgd_solver.cpp:106] Iteration 9680, lr = 4.45844e-06
I0825 23:13:08.075292 27361 solver.cpp:228] Iteration 9690, loss = 0.416363
I0825 23:13:08.075335 27361 solver.cpp:244]     Train net output #0: accuracy = 0.930202
I0825 23:13:08.075345 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.655544 (* 1 = 0.655544 loss)
I0825 23:13:08.075352 27361 sgd_solver.cpp:106] Iteration 9690, lr = 4.45616e-06
I0825 23:13:27.331949 27361 solver.cpp:337] Iteration 9700, Testing net (#0)
I0825 23:13:31.478457 27361 solver.cpp:404]     Test net output #0: accuracy = 0.939245
I0825 23:13:31.478502 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.601488 (* 1 = 0.601488 loss)
I0825 23:13:33.493206 27361 solver.cpp:228] Iteration 9700, loss = 0.458284
I0825 23:13:33.493247 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923103
I0825 23:13:33.493257 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.390629 (* 1 = 0.390629 loss)
I0825 23:13:33.493264 27361 sgd_solver.cpp:106] Iteration 9700, lr = 4.45389e-06
I0825 23:13:54.852681 27361 solver.cpp:228] Iteration 9710, loss = 0.395638
I0825 23:13:54.852726 27361 solver.cpp:244]     Train net output #0: accuracy = 0.90131
I0825 23:13:54.852736 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.620168 (* 1 = 0.620168 loss)
I0825 23:13:54.852743 27361 sgd_solver.cpp:106] Iteration 9710, lr = 4.45162e-06
I0825 23:14:16.228478 27361 solver.cpp:228] Iteration 9720, loss = 0.762612
I0825 23:14:16.228580 27361 solver.cpp:244]     Train net output #0: accuracy = 0.892021
I0825 23:14:16.228590 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.891683 (* 1 = 0.891683 loss)
I0825 23:14:16.228597 27361 sgd_solver.cpp:106] Iteration 9720, lr = 4.44935e-06
I0825 23:14:37.564332 27361 solver.cpp:228] Iteration 9730, loss = 0.424807
I0825 23:14:37.564379 27361 solver.cpp:244]     Train net output #0: accuracy = 0.941692
I0825 23:14:37.564389 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.539862 (* 1 = 0.539862 loss)
I0825 23:14:37.564398 27361 sgd_solver.cpp:106] Iteration 9730, lr = 4.44708e-06
I0825 23:14:58.903195 27361 solver.cpp:228] Iteration 9740, loss = 0.650514
I0825 23:14:58.903332 27361 solver.cpp:244]     Train net output #0: accuracy = 0.948875
I0825 23:14:58.903344 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.5142 (* 1 = 0.5142 loss)
I0825 23:14:58.903352 27361 sgd_solver.cpp:106] Iteration 9740, lr = 4.44482e-06
I0825 23:15:20.380074 27361 solver.cpp:228] Iteration 9750, loss = 0.38113
I0825 23:15:20.380117 27361 solver.cpp:244]     Train net output #0: accuracy = 0.965191
I0825 23:15:20.380126 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.203855 (* 1 = 0.203855 loss)
I0825 23:15:20.380134 27361 sgd_solver.cpp:106] Iteration 9750, lr = 4.44256e-06
I0825 23:15:41.735697 27361 solver.cpp:228] Iteration 9760, loss = 0.578982
I0825 23:15:41.735805 27361 solver.cpp:244]     Train net output #0: accuracy = 0.946423
I0825 23:15:41.735823 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.523331 (* 1 = 0.523331 loss)
I0825 23:15:41.735831 27361 sgd_solver.cpp:106] Iteration 9760, lr = 4.4403e-06
I0825 23:16:03.119069 27361 solver.cpp:228] Iteration 9770, loss = 0.781421
I0825 23:16:03.119120 27361 solver.cpp:244]     Train net output #0: accuracy = 0.986336
I0825 23:16:03.119129 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.182029 (* 1 = 0.182029 loss)
I0825 23:16:03.119138 27361 sgd_solver.cpp:106] Iteration 9770, lr = 4.43805e-06
I0825 23:16:24.442926 27361 solver.cpp:228] Iteration 9780, loss = 0.473117
I0825 23:16:24.443004 27361 solver.cpp:244]     Train net output #0: accuracy = 0.918034
I0825 23:16:24.443016 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.520641 (* 1 = 0.520641 loss)
I0825 23:16:24.443023 27361 sgd_solver.cpp:106] Iteration 9780, lr = 4.4358e-06
I0825 23:16:45.830782 27361 solver.cpp:228] Iteration 9790, loss = 0.450686
I0825 23:16:45.830832 27361 solver.cpp:244]     Train net output #0: accuracy = 0.970238
I0825 23:16:45.830842 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.179157 (* 1 = 0.179157 loss)
I0825 23:16:45.830850 27361 sgd_solver.cpp:106] Iteration 9790, lr = 4.43355e-06
I0825 23:17:05.109714 27361 solver.cpp:337] Iteration 9800, Testing net (#0)
I0825 23:17:09.255121 27361 solver.cpp:404]     Test net output #0: accuracy = 0.956741
I0825 23:17:09.255167 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.436106 (* 1 = 0.436106 loss)
I0825 23:17:11.270642 27361 solver.cpp:228] Iteration 9800, loss = 0.657771
I0825 23:17:11.270689 27361 solver.cpp:244]     Train net output #0: accuracy = 0.88134
I0825 23:17:11.270699 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.689138 (* 1 = 0.689138 loss)
I0825 23:17:11.270705 27361 sgd_solver.cpp:106] Iteration 9800, lr = 4.4313e-06
I0825 23:17:32.597456 27361 solver.cpp:228] Iteration 9810, loss = 0.782527
I0825 23:17:32.597506 27361 solver.cpp:244]     Train net output #0: accuracy = 0.869881
I0825 23:17:32.597514 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.97231 (* 1 = 2.97231 loss)
I0825 23:17:32.597522 27361 sgd_solver.cpp:106] Iteration 9810, lr = 4.42906e-06
I0825 23:17:53.925948 27361 solver.cpp:228] Iteration 9820, loss = 0.472141
I0825 23:17:53.926059 27361 solver.cpp:244]     Train net output #0: accuracy = 0.952007
I0825 23:17:53.926069 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.412109 (* 1 = 0.412109 loss)
I0825 23:17:53.926076 27361 sgd_solver.cpp:106] Iteration 9820, lr = 4.42681e-06
I0825 23:18:15.250684 27361 solver.cpp:228] Iteration 9830, loss = 0.764486
I0825 23:18:15.250730 27361 solver.cpp:244]     Train net output #0: accuracy = 0.832722
I0825 23:18:15.250740 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.10499 (* 1 = 1.10499 loss)
I0825 23:18:15.250746 27361 sgd_solver.cpp:106] Iteration 9830, lr = 4.42458e-06
I0825 23:18:36.579854 27361 solver.cpp:228] Iteration 9840, loss = 0.530825
I0825 23:18:36.579994 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955612
I0825 23:18:36.580005 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.483972 (* 1 = 0.483972 loss)
I0825 23:18:36.580013 27361 sgd_solver.cpp:106] Iteration 9840, lr = 4.42234e-06
I0825 23:18:57.904517 27361 solver.cpp:228] Iteration 9850, loss = 0.668372
I0825 23:18:57.904564 27361 solver.cpp:244]     Train net output #0: accuracy = 0.868809
I0825 23:18:57.904573 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.03708 (* 1 = 1.03708 loss)
I0825 23:18:57.904582 27361 sgd_solver.cpp:106] Iteration 9850, lr = 4.42011e-06
I0825 23:19:19.391857 27361 solver.cpp:228] Iteration 9860, loss = 0.535651
I0825 23:19:19.391927 27361 solver.cpp:244]     Train net output #0: accuracy = 0.886734
I0825 23:19:19.391940 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.905167 (* 1 = 0.905167 loss)
I0825 23:19:19.391949 27361 sgd_solver.cpp:106] Iteration 9860, lr = 4.41787e-06
I0825 23:19:40.727257 27361 solver.cpp:228] Iteration 9870, loss = 0.667437
I0825 23:19:40.727300 27361 solver.cpp:244]     Train net output #0: accuracy = 0.782139
I0825 23:19:40.727309 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.22267 (* 1 = 2.22267 loss)
I0825 23:19:40.727316 27361 sgd_solver.cpp:106] Iteration 9870, lr = 4.41565e-06
I0825 23:20:02.160666 27361 solver.cpp:228] Iteration 9880, loss = 0.434349
I0825 23:20:02.160769 27361 solver.cpp:244]     Train net output #0: accuracy = 0.884171
I0825 23:20:02.160779 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.848783 (* 1 = 0.848783 loss)
I0825 23:20:02.160786 27361 sgd_solver.cpp:106] Iteration 9880, lr = 4.41342e-06
I0825 23:20:23.493161 27361 solver.cpp:228] Iteration 9890, loss = 0.421603
I0825 23:20:23.493211 27361 solver.cpp:244]     Train net output #0: accuracy = 0.916897
I0825 23:20:23.493219 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.879756 (* 1 = 0.879756 loss)
I0825 23:20:23.493227 27361 sgd_solver.cpp:106] Iteration 9890, lr = 4.4112e-06
I0825 23:20:42.696560 27361 solver.cpp:337] Iteration 9900, Testing net (#0)
I0825 23:20:46.846251 27361 solver.cpp:404]     Test net output #0: accuracy = 0.940516
I0825 23:20:46.846292 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.675547 (* 1 = 0.675547 loss)
I0825 23:20:48.863229 27361 solver.cpp:228] Iteration 9900, loss = 0.687744
I0825 23:20:48.863275 27361 solver.cpp:244]     Train net output #0: accuracy = 0.981346
I0825 23:20:48.863283 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.200736 (* 1 = 0.200736 loss)
I0825 23:20:48.863291 27361 sgd_solver.cpp:106] Iteration 9900, lr = 4.40898e-06
I0825 23:21:10.207772 27361 solver.cpp:228] Iteration 9910, loss = 0.750076
I0825 23:21:10.207818 27361 solver.cpp:244]     Train net output #0: accuracy = 0.960583
I0825 23:21:10.207828 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.537603 (* 1 = 0.537603 loss)
I0825 23:21:10.207834 27361 sgd_solver.cpp:106] Iteration 9910, lr = 4.40676e-06
I0825 23:21:31.554890 27361 solver.cpp:228] Iteration 9920, loss = 0.35174
I0825 23:21:31.554998 27361 solver.cpp:244]     Train net output #0: accuracy = 0.985184
I0825 23:21:31.555009 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.183401 (* 1 = 0.183401 loss)
I0825 23:21:31.555016 27361 sgd_solver.cpp:106] Iteration 9920, lr = 4.40454e-06
I0825 23:21:52.899750 27361 solver.cpp:228] Iteration 9930, loss = 0.42006
I0825 23:21:52.899797 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935406
I0825 23:21:52.899807 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.751459 (* 1 = 0.751459 loss)
I0825 23:21:52.899816 27361 sgd_solver.cpp:106] Iteration 9930, lr = 4.40233e-06
I0825 23:22:14.241319 27361 solver.cpp:228] Iteration 9940, loss = 0.350805
I0825 23:22:14.241416 27361 solver.cpp:244]     Train net output #0: accuracy = 0.975559
I0825 23:22:14.241426 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.167561 (* 1 = 0.167561 loss)
I0825 23:22:14.241435 27361 sgd_solver.cpp:106] Iteration 9940, lr = 4.40012e-06
I0825 23:22:35.580664 27361 solver.cpp:228] Iteration 9950, loss = 0.838197
I0825 23:22:35.580713 27361 solver.cpp:244]     Train net output #0: accuracy = 0.939121
I0825 23:22:35.580723 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.350416 (* 1 = 0.350416 loss)
I0825 23:22:35.580730 27361 sgd_solver.cpp:106] Iteration 9950, lr = 4.39791e-06
I0825 23:22:56.927767 27361 solver.cpp:228] Iteration 9960, loss = 0.673676
I0825 23:22:56.927912 27361 solver.cpp:244]     Train net output #0: accuracy = 0.91811
I0825 23:22:56.927923 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.211464 (* 1 = 0.211464 loss)
I0825 23:22:56.927938 27361 sgd_solver.cpp:106] Iteration 9960, lr = 4.39571e-06
I0825 23:23:18.272748 27361 solver.cpp:228] Iteration 9970, loss = 0.587715
I0825 23:23:18.272795 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935814
I0825 23:23:18.272804 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.636918 (* 1 = 0.636918 loss)
I0825 23:23:18.272821 27361 sgd_solver.cpp:106] Iteration 9970, lr = 4.39351e-06
I0825 23:23:39.612920 27361 solver.cpp:228] Iteration 9980, loss = 0.960012
I0825 23:23:39.613039 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950844
I0825 23:23:39.613050 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.523404 (* 1 = 0.523404 loss)
I0825 23:23:39.613057 27361 sgd_solver.cpp:106] Iteration 9980, lr = 4.39131e-06
I0825 23:24:00.939999 27361 solver.cpp:228] Iteration 9990, loss = 0.458347
I0825 23:24:00.940045 27361 solver.cpp:244]     Train net output #0: accuracy = 0.999985
I0825 23:24:00.940054 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0142434 (* 1 = 0.0142434 loss)
I0825 23:24:00.940062 27361 sgd_solver.cpp:106] Iteration 9990, lr = 4.38911e-06
I0825 23:24:20.135735 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_10000.caffemodel
I0825 23:24:20.329496 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_10000.solverstate
I0825 23:24:20.366993 27361 solver.cpp:337] Iteration 10000, Testing net (#0)
I0825 23:24:24.602068 27361 solver.cpp:404]     Test net output #0: accuracy = 0.927734
I0825 23:24:24.602103 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.595783 (* 1 = 0.595783 loss)
I0825 23:24:26.617790 27361 solver.cpp:228] Iteration 10000, loss = 0.715933
I0825 23:24:26.617837 27361 solver.cpp:244]     Train net output #0: accuracy = 0.854797
I0825 23:24:26.617847 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.859326 (* 1 = 0.859326 loss)
I0825 23:24:26.617854 27361 sgd_solver.cpp:106] Iteration 10000, lr = 4.38691e-06
I0825 23:24:47.961829 27361 solver.cpp:228] Iteration 10010, loss = 0.468079
I0825 23:24:47.961872 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951736
I0825 23:24:47.961882 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.55414 (* 1 = 0.55414 loss)
I0825 23:24:47.961889 27361 sgd_solver.cpp:106] Iteration 10010, lr = 4.38472e-06
I0825 23:25:09.382421 27361 solver.cpp:228] Iteration 10020, loss = 0.5345
I0825 23:25:09.382524 27361 solver.cpp:244]     Train net output #0: accuracy = 0.861004
I0825 23:25:09.382534 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.48975 (* 1 = 1.48975 loss)
I0825 23:25:09.382541 27361 sgd_solver.cpp:106] Iteration 10020, lr = 4.38253e-06
I0825 23:25:30.749157 27361 solver.cpp:228] Iteration 10030, loss = 0.427237
I0825 23:25:30.749200 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955631
I0825 23:25:30.749210 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.351621 (* 1 = 0.351621 loss)
I0825 23:25:30.749217 27361 sgd_solver.cpp:106] Iteration 10030, lr = 4.38034e-06
I0825 23:25:52.142221 27361 solver.cpp:228] Iteration 10040, loss = 0.612776
I0825 23:25:52.142323 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963203
I0825 23:25:52.142333 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.745786 (* 1 = 0.745786 loss)
I0825 23:25:52.142340 27361 sgd_solver.cpp:106] Iteration 10040, lr = 4.37816e-06
I0825 23:26:13.539975 27361 solver.cpp:228] Iteration 10050, loss = 0.553969
I0825 23:26:13.540024 27361 solver.cpp:244]     Train net output #0: accuracy = 0.923473
I0825 23:26:13.540033 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.565786 (* 1 = 0.565786 loss)
I0825 23:26:13.540041 27361 sgd_solver.cpp:106] Iteration 10050, lr = 4.37598e-06
I0825 23:26:34.885282 27361 solver.cpp:228] Iteration 10060, loss = 0.364539
I0825 23:26:34.885372 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950325
I0825 23:26:34.885382 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.23767 (* 1 = 0.23767 loss)
I0825 23:26:34.885390 27361 sgd_solver.cpp:106] Iteration 10060, lr = 4.3738e-06
I0825 23:26:56.225277 27361 solver.cpp:228] Iteration 10070, loss = 0.310596
I0825 23:26:56.225322 27361 solver.cpp:244]     Train net output #0: accuracy = 0.943161
I0825 23:26:56.225339 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.601199 (* 1 = 0.601199 loss)
I0825 23:26:56.225347 27361 sgd_solver.cpp:106] Iteration 10070, lr = 4.37162e-06
I0825 23:27:17.676642 27361 solver.cpp:228] Iteration 10080, loss = 0.500331
I0825 23:27:17.676755 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949932
I0825 23:27:17.676765 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.423004 (* 1 = 0.423004 loss)
I0825 23:27:17.676772 27361 sgd_solver.cpp:106] Iteration 10080, lr = 4.36945e-06
I0825 23:27:39.070381 27361 solver.cpp:228] Iteration 10090, loss = 0.572043
I0825 23:27:39.070430 27361 solver.cpp:244]     Train net output #0: accuracy = 0.920094
I0825 23:27:39.070439 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.69401 (* 1 = 0.69401 loss)
I0825 23:27:39.070446 27361 sgd_solver.cpp:106] Iteration 10090, lr = 4.36728e-06
I0825 23:27:58.278317 27361 solver.cpp:337] Iteration 10100, Testing net (#0)
I0825 23:28:02.426252 27361 solver.cpp:404]     Test net output #0: accuracy = 0.939198
I0825 23:28:02.426295 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.574876 (* 1 = 0.574876 loss)
I0825 23:28:04.441350 27361 solver.cpp:228] Iteration 10100, loss = 0.511087
I0825 23:28:04.441395 27361 solver.cpp:244]     Train net output #0: accuracy = 0.928211
I0825 23:28:04.441404 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.991203 (* 1 = 0.991203 loss)
I0825 23:28:04.441411 27361 sgd_solver.cpp:106] Iteration 10100, lr = 4.36511e-06
I0825 23:28:25.868824 27361 solver.cpp:228] Iteration 10110, loss = 0.48567
I0825 23:28:25.868873 27361 solver.cpp:244]     Train net output #0: accuracy = 0.977253
I0825 23:28:25.868883 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.250998 (* 1 = 0.250998 loss)
I0825 23:28:25.868891 27361 sgd_solver.cpp:106] Iteration 10110, lr = 4.36294e-06
I0825 23:28:47.257166 27361 solver.cpp:228] Iteration 10120, loss = 0.564268
I0825 23:28:47.257277 27361 solver.cpp:244]     Train net output #0: accuracy = 0.937626
I0825 23:28:47.257288 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.721014 (* 1 = 0.721014 loss)
I0825 23:28:47.257297 27361 sgd_solver.cpp:106] Iteration 10120, lr = 4.36077e-06
I0825 23:29:08.585716 27361 solver.cpp:228] Iteration 10130, loss = 0.437737
I0825 23:29:08.585759 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957882
I0825 23:29:08.585769 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.398102 (* 1 = 0.398102 loss)
I0825 23:29:08.585777 27361 sgd_solver.cpp:106] Iteration 10130, lr = 4.35861e-06
I0825 23:29:29.919486 27361 solver.cpp:228] Iteration 10140, loss = 0.708086
I0825 23:29:29.919585 27361 solver.cpp:244]     Train net output #0: accuracy = 0.955208
I0825 23:29:29.919596 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.576243 (* 1 = 0.576243 loss)
I0825 23:29:29.919605 27361 sgd_solver.cpp:106] Iteration 10140, lr = 4.35645e-06
I0825 23:29:51.348356 27361 solver.cpp:228] Iteration 10150, loss = 0.746375
I0825 23:29:51.348403 27361 solver.cpp:244]     Train net output #0: accuracy = 0.880566
I0825 23:29:51.348412 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.964631 (* 1 = 0.964631 loss)
I0825 23:29:51.348420 27361 sgd_solver.cpp:106] Iteration 10150, lr = 4.3543e-06
I0825 23:30:12.763083 27361 solver.cpp:228] Iteration 10160, loss = 0.585966
I0825 23:30:12.763258 27361 solver.cpp:244]     Train net output #0: accuracy = 0.965176
I0825 23:30:12.763275 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.348431 (* 1 = 0.348431 loss)
I0825 23:30:12.763288 27361 sgd_solver.cpp:106] Iteration 10160, lr = 4.35214e-06
I0825 23:30:34.110097 27361 solver.cpp:228] Iteration 10170, loss = 0.465735
I0825 23:30:34.110146 27361 solver.cpp:244]     Train net output #0: accuracy = 0.948605
I0825 23:30:34.110155 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.612173 (* 1 = 0.612173 loss)
I0825 23:30:34.110162 27361 sgd_solver.cpp:106] Iteration 10170, lr = 4.34999e-06
I0825 23:30:55.441931 27361 solver.cpp:228] Iteration 10180, loss = 0.361347
I0825 23:30:55.441992 27361 solver.cpp:244]     Train net output #0: accuracy = 0.985718
I0825 23:30:55.442003 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.123765 (* 1 = 0.123765 loss)
I0825 23:30:55.442009 27361 sgd_solver.cpp:106] Iteration 10180, lr = 4.34784e-06
I0825 23:31:16.826166 27361 solver.cpp:228] Iteration 10190, loss = 0.26955
I0825 23:31:16.826215 27361 solver.cpp:244]     Train net output #0: accuracy = 0.969212
I0825 23:31:16.826225 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.303328 (* 1 = 0.303328 loss)
I0825 23:31:16.826232 27361 sgd_solver.cpp:106] Iteration 10190, lr = 4.34569e-06
I0825 23:31:36.012300 27361 solver.cpp:337] Iteration 10200, Testing net (#0)
I0825 23:31:40.153416 27361 solver.cpp:404]     Test net output #0: accuracy = 0.952156
I0825 23:31:40.153460 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.63491 (* 1 = 0.63491 loss)
I0825 23:31:42.168375 27361 solver.cpp:228] Iteration 10200, loss = 0.744328
I0825 23:31:42.168421 27361 solver.cpp:244]     Train net output #0: accuracy = 0.969479
I0825 23:31:42.168431 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.492155 (* 1 = 0.492155 loss)
I0825 23:31:42.168437 27361 sgd_solver.cpp:106] Iteration 10200, lr = 4.34355e-06
I0825 23:32:03.491943 27361 solver.cpp:228] Iteration 10210, loss = 0.336628
I0825 23:32:03.491992 27361 solver.cpp:244]     Train net output #0: accuracy = 0.889969
I0825 23:32:03.492002 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.537866 (* 1 = 0.537866 loss)
I0825 23:32:03.492009 27361 sgd_solver.cpp:106] Iteration 10210, lr = 4.34141e-06
I0825 23:32:24.826225 27361 solver.cpp:228] Iteration 10220, loss = 0.655835
I0825 23:32:24.826325 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957657
I0825 23:32:24.826336 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.756728 (* 1 = 0.756728 loss)
I0825 23:32:24.826344 27361 sgd_solver.cpp:106] Iteration 10220, lr = 4.33927e-06
I0825 23:32:46.150717 27361 solver.cpp:228] Iteration 10230, loss = 0.627783
I0825 23:32:46.150763 27361 solver.cpp:244]     Train net output #0: accuracy = 0.945934
I0825 23:32:46.150773 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.512584 (* 1 = 0.512584 loss)
I0825 23:32:46.150779 27361 sgd_solver.cpp:106] Iteration 10230, lr = 4.33713e-06
I0825 23:33:07.475011 27361 solver.cpp:228] Iteration 10240, loss = 0.752786
I0825 23:33:07.475126 27361 solver.cpp:244]     Train net output #0: accuracy = 0.87727
I0825 23:33:07.475137 27361 solver.cpp:244]     Train net output #1: softmaxloss = 2.25124 (* 1 = 2.25124 loss)
I0825 23:33:07.475144 27361 sgd_solver.cpp:106] Iteration 10240, lr = 4.335e-06
I0825 23:33:28.798817 27361 solver.cpp:228] Iteration 10250, loss = 0.415689
I0825 23:33:28.798864 27361 solver.cpp:244]     Train net output #0: accuracy = 0.921474
I0825 23:33:28.798873 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.787823 (* 1 = 0.787823 loss)
I0825 23:33:28.798882 27361 sgd_solver.cpp:106] Iteration 10250, lr = 4.33286e-06
I0825 23:33:50.161578 27361 solver.cpp:228] Iteration 10260, loss = 0.444397
I0825 23:33:50.161726 27361 solver.cpp:244]     Train net output #0: accuracy = 0.872524
I0825 23:33:50.161738 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.24214 (* 1 = 1.24214 loss)
I0825 23:33:50.161746 27361 sgd_solver.cpp:106] Iteration 10260, lr = 4.33073e-06
I0825 23:34:11.509939 27361 solver.cpp:228] Iteration 10270, loss = 0.683347
I0825 23:34:11.509984 27361 solver.cpp:244]     Train net output #0: accuracy = 0.993805
I0825 23:34:11.509992 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.106018 (* 1 = 0.106018 loss)
I0825 23:34:11.510000 27361 sgd_solver.cpp:106] Iteration 10270, lr = 4.32861e-06
I0825 23:34:32.856629 27361 solver.cpp:228] Iteration 10280, loss = 0.600322
I0825 23:34:32.856693 27361 solver.cpp:244]     Train net output #0: accuracy = 0.951992
I0825 23:34:32.856701 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.320575 (* 1 = 0.320575 loss)
I0825 23:34:32.856717 27361 sgd_solver.cpp:106] Iteration 10280, lr = 4.32648e-06
I0825 23:34:54.242561 27361 solver.cpp:228] Iteration 10290, loss = 0.693392
I0825 23:34:54.242615 27361 solver.cpp:244]     Train net output #0: accuracy = 0.946636
I0825 23:34:54.242627 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.472 (* 1 = 0.472 loss)
I0825 23:34:54.242635 27361 sgd_solver.cpp:106] Iteration 10290, lr = 4.32436e-06
I0825 23:35:13.510562 27361 solver.cpp:337] Iteration 10300, Testing net (#0)
I0825 23:35:17.660908 27361 solver.cpp:404]     Test net output #0: accuracy = 0.92821
I0825 23:35:17.660950 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.656992 (* 1 = 0.656992 loss)
I0825 23:35:19.706594 27361 solver.cpp:228] Iteration 10300, loss = 0.553254
I0825 23:35:19.706639 27361 solver.cpp:244]     Train net output #0: accuracy = 0.890488
I0825 23:35:19.706648 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.776991 (* 1 = 0.776991 loss)
I0825 23:35:19.706655 27361 sgd_solver.cpp:106] Iteration 10300, lr = 4.32224e-06
I0825 23:35:41.086805 27361 solver.cpp:228] Iteration 10310, loss = 0.453383
I0825 23:35:41.086851 27361 solver.cpp:244]     Train net output #0: accuracy = 0.950676
I0825 23:35:41.086861 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.573939 (* 1 = 0.573939 loss)
I0825 23:35:41.086869 27361 sgd_solver.cpp:106] Iteration 10310, lr = 4.32012e-06
I0825 23:36:02.541213 27361 solver.cpp:228] Iteration 10320, loss = 0.533477
I0825 23:36:02.541322 27361 solver.cpp:244]     Train net output #0: accuracy = 0.983139
I0825 23:36:02.541333 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.168483 (* 1 = 0.168483 loss)
I0825 23:36:02.541342 27361 sgd_solver.cpp:106] Iteration 10320, lr = 4.31801e-06
I0825 23:36:23.928284 27361 solver.cpp:228] Iteration 10330, loss = 0.436387
I0825 23:36:23.928331 27361 solver.cpp:244]     Train net output #0: accuracy = 0.968769
I0825 23:36:23.928340 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.291311 (* 1 = 0.291311 loss)
I0825 23:36:23.928349 27361 sgd_solver.cpp:106] Iteration 10330, lr = 4.3159e-06
I0825 23:36:45.575050 27361 solver.cpp:228] Iteration 10340, loss = 0.32355
I0825 23:36:45.575198 27361 solver.cpp:244]     Train net output #0: accuracy = 0.909966
I0825 23:36:45.575220 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.961111 (* 1 = 0.961111 loss)
I0825 23:36:45.575237 27361 sgd_solver.cpp:106] Iteration 10340, lr = 4.31378e-06
I0825 23:37:06.990756 27361 solver.cpp:228] Iteration 10350, loss = 0.646145
I0825 23:37:06.990803 27361 solver.cpp:244]     Train net output #0: accuracy = 0.882618
I0825 23:37:06.990811 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.00661 (* 1 = 1.00661 loss)
I0825 23:37:06.990819 27361 sgd_solver.cpp:106] Iteration 10350, lr = 4.31168e-06
I0825 23:37:28.472857 27361 solver.cpp:228] Iteration 10360, loss = 0.623549
I0825 23:37:28.472995 27361 solver.cpp:244]     Train net output #0: accuracy = 0.903839
I0825 23:37:28.473006 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.641863 (* 1 = 0.641863 loss)
I0825 23:37:28.473014 27361 sgd_solver.cpp:106] Iteration 10360, lr = 4.30957e-06
I0825 23:37:49.978116 27361 solver.cpp:228] Iteration 10370, loss = 0.63411
I0825 23:37:49.978164 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963665
I0825 23:37:49.978174 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.423566 (* 1 = 0.423566 loss)
I0825 23:37:49.978183 27361 sgd_solver.cpp:106] Iteration 10370, lr = 4.30747e-06
I0825 23:38:11.439662 27361 solver.cpp:228] Iteration 10380, loss = 0.393148
I0825 23:38:11.439745 27361 solver.cpp:244]     Train net output #0: accuracy = 0.977474
I0825 23:38:11.439755 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.243111 (* 1 = 0.243111 loss)
I0825 23:38:11.439762 27361 sgd_solver.cpp:106] Iteration 10380, lr = 4.30537e-06
I0825 23:38:33.053228 27361 solver.cpp:228] Iteration 10390, loss = 0.695312
I0825 23:38:33.053287 27361 solver.cpp:244]     Train net output #0: accuracy = 0.94339
I0825 23:38:33.053297 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.572606 (* 1 = 0.572606 loss)
I0825 23:38:33.053304 27361 sgd_solver.cpp:106] Iteration 10390, lr = 4.30327e-06
I0825 23:38:52.418069 27361 solver.cpp:337] Iteration 10400, Testing net (#0)
I0825 23:38:56.565202 27361 solver.cpp:404]     Test net output #0: accuracy = 0.944626
I0825 23:38:56.565246 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.641361 (* 1 = 0.641361 loss)
I0825 23:38:58.580900 27361 solver.cpp:228] Iteration 10400, loss = 0.500201
I0825 23:38:58.580947 27361 solver.cpp:244]     Train net output #0: accuracy = 0.911308
I0825 23:38:58.580956 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.749025 (* 1 = 0.749025 loss)
I0825 23:38:58.580963 27361 sgd_solver.cpp:106] Iteration 10400, lr = 4.30117e-06
I0825 23:39:19.906231 27361 solver.cpp:228] Iteration 10410, loss = 0.304132
I0825 23:39:19.906281 27361 solver.cpp:244]     Train net output #0: accuracy = 0.995899
I0825 23:39:19.906292 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0172372 (* 1 = 0.0172372 loss)
I0825 23:39:19.906301 27361 sgd_solver.cpp:106] Iteration 10410, lr = 4.29908e-06
I0825 23:39:41.250787 27361 solver.cpp:228] Iteration 10420, loss = 1.08233
I0825 23:39:41.250885 27361 solver.cpp:244]     Train net output #0: accuracy = 0.985313
I0825 23:39:41.250896 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.0467749 (* 1 = 0.0467749 loss)
I0825 23:39:41.250905 27361 sgd_solver.cpp:106] Iteration 10420, lr = 4.29699e-06
I0825 23:40:02.592439 27361 solver.cpp:228] Iteration 10430, loss = 0.637227
I0825 23:40:02.592486 27361 solver.cpp:244]     Train net output #0: accuracy = 0.966324
I0825 23:40:02.592496 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.626355 (* 1 = 0.626355 loss)
I0825 23:40:02.592504 27361 sgd_solver.cpp:106] Iteration 10430, lr = 4.2949e-06
I0825 23:40:23.921892 27361 solver.cpp:228] Iteration 10440, loss = 0.437343
I0825 23:40:23.921970 27361 solver.cpp:244]     Train net output #0: accuracy = 0.912895
I0825 23:40:23.921982 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.90236 (* 1 = 1.90236 loss)
I0825 23:40:23.921988 27361 sgd_solver.cpp:106] Iteration 10440, lr = 4.29281e-06
I0825 23:40:45.288125 27361 solver.cpp:228] Iteration 10450, loss = 0.332409
I0825 23:40:45.288172 27361 solver.cpp:244]     Train net output #0: accuracy = 0.967415
I0825 23:40:45.288182 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.255527 (* 1 = 0.255527 loss)
I0825 23:40:45.288189 27361 sgd_solver.cpp:106] Iteration 10450, lr = 4.29073e-06
I0825 23:41:06.624056 27361 solver.cpp:228] Iteration 10460, loss = 0.423763
I0825 23:41:06.624169 27361 solver.cpp:244]     Train net output #0: accuracy = 0.866074
I0825 23:41:06.624181 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.26984 (* 1 = 1.26984 loss)
I0825 23:41:06.624188 27361 sgd_solver.cpp:106] Iteration 10460, lr = 4.28865e-06
I0825 23:41:28.085522 27361 solver.cpp:228] Iteration 10470, loss = 0.402734
I0825 23:41:28.085567 27361 solver.cpp:244]     Train net output #0: accuracy = 0.963116
I0825 23:41:28.085577 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.366554 (* 1 = 0.366554 loss)
I0825 23:41:28.085584 27361 sgd_solver.cpp:106] Iteration 10470, lr = 4.28657e-06
I0825 23:41:49.551151 27361 solver.cpp:228] Iteration 10480, loss = 0.347162
I0825 23:41:49.551291 27361 solver.cpp:244]     Train net output #0: accuracy = 0.93745
I0825 23:41:49.551302 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.148193 (* 1 = 0.148193 loss)
I0825 23:41:49.551311 27361 sgd_solver.cpp:106] Iteration 10480, lr = 4.28449e-06
I0825 23:42:10.931118 27361 solver.cpp:228] Iteration 10490, loss = 0.296163
I0825 23:42:10.931164 27361 solver.cpp:244]     Train net output #0: accuracy = 0.957302
I0825 23:42:10.931174 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.268464 (* 1 = 0.268464 loss)
I0825 23:42:10.931190 27361 sgd_solver.cpp:106] Iteration 10490, lr = 4.28242e-06
I0825 23:42:30.135828 27361 solver.cpp:337] Iteration 10500, Testing net (#0)
I0825 23:42:34.315131 27361 solver.cpp:404]     Test net output #0: accuracy = 0.944698
I0825 23:42:34.315179 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.652578 (* 1 = 0.652578 loss)
I0825 23:42:36.333343 27361 solver.cpp:228] Iteration 10500, loss = 0.393062
I0825 23:42:36.333385 27361 solver.cpp:244]     Train net output #0: accuracy = 0.975803
I0825 23:42:36.333395 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.148742 (* 1 = 0.148742 loss)
I0825 23:42:36.333402 27361 sgd_solver.cpp:106] Iteration 10500, lr = 4.28034e-06
I0825 23:42:57.694921 27361 solver.cpp:228] Iteration 10510, loss = 0.439066
I0825 23:42:57.694968 27361 solver.cpp:244]     Train net output #0: accuracy = 0.949028
I0825 23:42:57.694977 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.54452 (* 1 = 0.54452 loss)
I0825 23:42:57.694985 27361 sgd_solver.cpp:106] Iteration 10510, lr = 4.27827e-06
I0825 23:43:19.152891 27361 solver.cpp:228] Iteration 10520, loss = 0.516364
I0825 23:43:19.153000 27361 solver.cpp:244]     Train net output #0: accuracy = 0.832157
I0825 23:43:19.153012 27361 solver.cpp:244]     Train net output #1: softmaxloss = 1.01086 (* 1 = 1.01086 loss)
I0825 23:43:19.153019 27361 sgd_solver.cpp:106] Iteration 10520, lr = 4.27621e-06
I0825 23:43:40.498824 27361 solver.cpp:228] Iteration 10530, loss = 0.391912
I0825 23:43:40.498872 27361 solver.cpp:244]     Train net output #0: accuracy = 0.910233
I0825 23:43:40.498881 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.554511 (* 1 = 0.554511 loss)
I0825 23:43:40.498888 27361 sgd_solver.cpp:106] Iteration 10530, lr = 4.27414e-06
I0825 23:44:01.866413 27361 solver.cpp:228] Iteration 10540, loss = 0.634218
I0825 23:44:01.866515 27361 solver.cpp:244]     Train net output #0: accuracy = 0.959213
I0825 23:44:01.866526 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.19606 (* 1 = 0.19606 loss)
I0825 23:44:01.866534 27361 sgd_solver.cpp:106] Iteration 10540, lr = 4.27208e-06
I0825 23:44:23.260624 27361 solver.cpp:228] Iteration 10550, loss = 0.463577
I0825 23:44:23.260685 27361 solver.cpp:244]     Train net output #0: accuracy = 0.952969
I0825 23:44:23.260699 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.503234 (* 1 = 0.503234 loss)
I0825 23:44:23.260710 27361 sgd_solver.cpp:106] Iteration 10550, lr = 4.27002e-06
I0825 23:44:44.705307 27361 solver.cpp:228] Iteration 10560, loss = 0.32298
I0825 23:44:44.705412 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935444
I0825 23:44:44.705423 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.624474 (* 1 = 0.624474 loss)
I0825 23:44:44.705432 27361 sgd_solver.cpp:106] Iteration 10560, lr = 4.26796e-06
I0825 23:45:06.065789 27361 solver.cpp:228] Iteration 10570, loss = 0.34182
I0825 23:45:06.065835 27361 solver.cpp:244]     Train net output #0: accuracy = 0.944294
I0825 23:45:06.065845 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.193516 (* 1 = 0.193516 loss)
I0825 23:45:06.065852 27361 sgd_solver.cpp:106] Iteration 10570, lr = 4.2659e-06
I0825 23:45:27.413404 27361 solver.cpp:228] Iteration 10580, loss = 0.766813
I0825 23:45:27.413548 27361 solver.cpp:244]     Train net output #0: accuracy = 0.91872
I0825 23:45:27.413560 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.65456 (* 1 = 0.65456 loss)
I0825 23:45:27.413568 27361 sgd_solver.cpp:106] Iteration 10580, lr = 4.26385e-06
I0825 23:45:48.760380 27361 solver.cpp:228] Iteration 10590, loss = 0.682875
I0825 23:45:48.760423 27361 solver.cpp:244]     Train net output #0: accuracy = 0.872242
I0825 23:45:48.760433 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.548065 (* 1 = 0.548065 loss)
I0825 23:45:48.760440 27361 sgd_solver.cpp:106] Iteration 10590, lr = 4.2618e-06
I0825 23:46:08.004639 27361 solver.cpp:337] Iteration 10600, Testing net (#0)
I0825 23:46:12.158936 27361 solver.cpp:404]     Test net output #0: accuracy = 0.938741
I0825 23:46:12.158988 27361 solver.cpp:404]     Test net output #1: softmaxloss = 0.630268 (* 1 = 0.630268 loss)
I0825 23:46:14.176688 27361 solver.cpp:228] Iteration 10600, loss = 0.424518
I0825 23:46:14.176844 27361 solver.cpp:244]     Train net output #0: accuracy = 0.958065
I0825 23:46:14.176854 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.452784 (* 1 = 0.452784 loss)
I0825 23:46:14.176862 27361 sgd_solver.cpp:106] Iteration 10600, lr = 4.25975e-06
I0825 23:46:35.580374 27361 solver.cpp:228] Iteration 10610, loss = 0.513173
I0825 23:46:35.580420 27361 solver.cpp:244]     Train net output #0: accuracy = 0.942421
I0825 23:46:35.580430 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.549542 (* 1 = 0.549542 loss)
I0825 23:46:35.580437 27361 sgd_solver.cpp:106] Iteration 10610, lr = 4.2577e-06
I0825 23:46:56.899435 27361 solver.cpp:228] Iteration 10620, loss = 0.409351
I0825 23:46:56.899497 27361 solver.cpp:244]     Train net output #0: accuracy = 0.935558
I0825 23:46:56.899507 27361 solver.cpp:244]     Train net output #1: softmaxloss = 0.691347 (* 1 = 0.691347 loss)
I0825 23:46:56.899514 27361 sgd_solver.cpp:106] Iteration 10620, lr = 4.25566e-06
I0825 23:47:01.220890 27361 solver.cpp:454] Snapshotting to binary proto file snapshot_rmsprop_uburn_iter_10623.caffemodel
I0825 23:47:01.422973 27361 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_rmsprop_uburn_iter_10623.solverstate
I0825 23:47:01.464442 27361 solver.cpp:301] Optimization stopped early.
I0825 23:47:01.464458 27361 caffe.cpp:254] Optimization Done.
